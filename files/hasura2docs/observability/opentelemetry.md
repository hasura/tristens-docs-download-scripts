# Export Traces, Metrics and Logs to OpenTelemetry Compliant Receiver from Hasura

## Introduction​

[ Distributed traces ](https://hasura.io/docs/latest/observability/cloud-monitoring/tracing/)track and map journeys of user requests across various
services or components which can then be analyzed via observability tools.

Traces are typically used to diagnose or debug which part of your application could potentially be responsible for a
failure or error state and to monitor the performance of end-user interactions with your application.

Traces are generated by instrumenting application code. Hasura has instrumented all API queries, mutations and
subscriptions with the[ OpenTelemetry ](https://opentelemetry.io/docs/concepts/signals/traces/)format. These traces can
be exported directly from your Hasura instances to your observability tool that supports OpenTelemetry traces. This can
be configured in the `Settings` section of the Hasura Console.

## Configure the OpenTelemetry receiver​

Supported from

OpenTelemetry traces are supported for Hasura GraphQL Engine versions `v2.18.0` and above on Self-Hosted Enterprise,
with support for metrics export added in `v2.31.0` and for logs export added in `v2.35.0` . Also, available to all cloud
tiers.

We have deprecated the previous Open Telemetry exporter integration on Hasura Cloud in favor of this native feature, and
you can now configure this directly via the Hasura Console's `Settings` page under the `Monitoring & Observability` section.

All users are encouraged to migrate to this new integration.

Traces on Hasura Cloud

Hasura Cloud implements sampling on traces. That means only one in every `n` traces will be sampled and exported
( `n` will be automatically configured based on various parameters during runtime. This can't be manually adjusted).

- Console
- CLI
- API


Go to the `Settings` tab (⚙) in the console and click on `OpenTelemetry Exporter` . After adding appropriate values to
the parameters, click *Update* and then toggle the *Status* button to enable the integration.

Image: [ OpenTelemetry Configuration ](https://hasura.io/docs/assets/images/open-telemetry-exporter_config-ui_2-18-78feb813ee077e3354710d8267b3cd00.png)

Create and update parameters in the file `opentelemetry.yaml` inside the `metadata` directory as follows:

```
status :  enabled
data_types :
   -  traces
   -  metrics
   -  logs
exporter_otlp :
   headers :
     -   name :  x - test - header
       value :  testing
     -   name :  x - header - from - env
       value_from_env :  TEST_ENV_VAR
   resource_attributes :
     -   name :  stage
       value :  production
     -   name :  region
       value :  us - east
   otlp_traces_endpoint :  http : //host.docker.internal : 4318/v1/traces
   otlp_metrics_endpoint :  http : //host.docker.internal : 4318/v1/metrics
   otlp_logs_endpoint :  http : //host.docker.internal : 4318/v1/logs
   protocol :  http/protobuf
   traces_propagators :  
     -  tracecontext
batch_span_processor :
   max_export_batch_size :   512
```

Apply the Metadata by running:

`hasura metadata apply`

See[ API reference documentation ](https://hasura.io/docs/latest/api-reference/metadata-api/observability/#metadata-set-opentelemetry-config).

## Parameters​

The following parameters are needed to set up the integration with your observability tool:

### Endpoint​

The OpenTelemetry compliant receiver endpoint. The URL scheme ( `http` or `https` ) determines if SSL(TLS) should be used
for the communication. Please check the documentation for your observability tool to determine how to set up an
OpenTelemetry endpoint. There may be different endpoints provided for the `HTTP` and `gRPC` protocols ( `gRPC` is not
supported yet), so ensure that you use the appropriate endpoint for your chosen connection type.

#### Endpoint Notes​

- Environment variable templating is available for the endpoint URL, e.g. `https://{{ENV_VAR}}/v1/traces`
- You may need to append `/v1/traces` or `/v1/metrics` to the end of the receiver endpoint URL if the provided URL does
not contain this already. This depends on the observability vendor.
- If you are running Hasura as a Docker container without host networking enabled, and want to connect to a local[ OpenTelemetry Collector ](https://hasura.io/docs/latest/observability/opentelemetry/#opentelemetry-collector), you may want to use this as the endpoint: `http://host.docker.internal:4318/v1/traces` .
- If the `https` endpoint uses a custom or self-signed CA, add the endpoint to the[ Insecure TLS Allow List ](https://hasura.io/docs/latest/deployment/tls-allow-list/).


OpenTelemetry Port Convention

It is a generally accepted convention that the OpenTelemetry receiver endpoint is exposed on port `4318` for HTTP but
can usually be customized. Please check the documentation for your observability tool to determine the port number.

### Connection Type​

The protocol and transport to be used for the communication with the receiver. Hasura currently only supports the
OpenTelemetry Protocol over HTTP (OTLP/HTTP with binary-encoded Protobuf payloads).

### Data Type​

Selects the type of observability data points to be exported. `Traces` , `Logs` and `Metrics` are the only data types
that are currently supported.

### Batch Size​

Batch size is the maximum number of data points (spans in the context of traces) allowed per export request made to the
observability tool. Default size is 512.

### Trace Propagations​

Trace Propagation implements the mechanism that exchanges context between services and processes. It serializes or
deserializes the context object and provides the relevant trace information to be propagated from one service to
another. GraphQL Engine supports the following propagation mechanisms:

- [ B3 Propagation ](https://github.com/openzipkin/b3-propagation)
- [ W3C Trace Context ](https://www.w3.org/TR/trace-context)


Trace Propagation support

W3C Trace Context is supported for Hasura GraphQL Engine versions `v2.35.0` and above.

B3 propagation is enabled by default. You can enable other protocols in the `OpenTelemetry Exporter` configuration.

Image: [ OpenTelemetry Trace Propagation Configuration ](https://hasura.io/docs/assets/images/open-telemetry-trace-propagation-9ef5592c037650a2f618d80d79754418.png)

### Headers​

Headers are *(optionally)* added to every request made by Hasura to the observability tool. They are generally **Authorization/API keys** with the required role/permissions to accept OpenTelemetry data. Please refer to the
documentation in your observability tool to understand how required request headers need to be formatted. You can use an
environment variable as a header value too. This is important for values which are sensitive.

Apply environment variables first

If you use an environment variable as a header value, please make sure that it's applied to the Hasura Docker container
before starting the container.

Example using Console:

Image: [ OpenTelemetry Header Console Configuration ](https://hasura.io/docs/assets/images/open-telemetry-headers_config-ui-headers_2-18-363c60c3ccdf888c41da6b83ebbac207.png)

### Attributes​

[ Resource ](https://opentelemetry.io/docs/reference/specification/overview/#resources)attributes are *(optional)* custom
tags that are sent alongside observability data in order to identify the entity for which the observability data was
recorded. This is usually used to identify sources in a distributed tracing environment and aids in granular filtering
and analytics.

Example using Console:

Image: [ OpenTelemetry Attributes Console Configuration ](https://hasura.io/docs/assets/images/open-telemetry-headers_config-ui-attributes_2-18-f432d5d7b9109ad493c4d8d788f0fe22.png)

Your observability tool may expect to receive certain resource attributes in order to provide full functionality; such
resource attributes must be set with this parameter. Many, but not all, of these resource attributes will be[ OpenTelemetry Semantic Conventions ](https://opentelemetry.io/docs/concepts/semantic-conventions/).

Hasura automatically sets some resource attributes. The values of such attributes can be overridden by specifying your
own value for the attribute using this parameter.

#### Default resource attributes​

| Attribute | Type | Default |
|---|---|---|
| [ service.name ](https://opentelemetry.io/docs/reference/specification/resource/semantic_conventions/#service) | string |  `hasura`  |


Attribute type support

Hasura currently only supports string-valued attributes.

## Consuming and visualizing traces​

You can utilize your observability tool's UI to visualize and perform further analytics on trace data to monitor,
diagnose and troubleshoot your application. Typically, traces and their spans are listed out and selecting a trace shows
a flame graph containing a visual representation of where the operation spent its execution time. Below, we provide some
examples of how to consume and visualize traces using popular observability tools.

### Jaeger​

To use[ Jaeger ](https://www.jaegertracing.io/), simply add this to your `docker-compose.yaml` :

```
jaeger :
   image :  jaegertracing/all - in - one : 1.37
   restart :  always
   ports :
     -  5775 : 5775/udp
     -  6831 : 6831/udp
     -  6832 : 6832/udp
     -  5778 : 5778
     -  4002 : 16686
     -  14250 : 14250
     -  14268 : 14268
     -  14269 : 14269
     -  4317 : 4317   # OTLP gRPC
     -  4318 : 4318   # OTLP HTTP
     -  9411 : 9411
   environment :
     COLLECTOR_OTLP_ENABLED :   'true'
     COLLECTOR_ZIPKIN_HOST_PORT :   '9411'
```

The image below shows a flame graph in Jaeger where a query took 5.64 milliseconds in total, of which 2.78 milliseconds
was the actual Postgres database processing the query.

Image: [ Flame graph for a trace entry in Jaeger ](https://hasura.io/docs/assets/images/jaeger-trace-flame-graph-37fc5da26524c7da809433e9a348a87e.png)

### OpenTelemetry Collector​

OpenTelemetry provides the[ OpenTelemetry Collector ](https://opentelemetry.io/docs/collector/)that can export
OpenTelemetry data to observability tools that do not support native OpenTelemetry ingestion.

To work with such observability tools, Hasura's OpenTelemetry integration can be configured to send OpenTelemetry data
to the collector.

Note

This collector should be run in your infrastructure and should be reachable by the Hasura backend that is configured to
send the data to it. The list of[ supported exporter targets ](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter)can
be found in the[ OpenTelemetry Collector repository ](https://github.com/open-telemetry/opentelemetry-collector-contrib).

## Connect Logs and Traces​

Trace and Span ID are included in the root of the log body. GraphQL Engine follows[ OpenTelemetry's data model ](https://opentelemetry.io/docs/specs/otel/logs/data-model/#log-and-event-record-definition)so that OpenTelemetry-compliant services can automatically correlate logs with Traces. However, some services need
extra configurations.

### Jaeger​

Grafana can link Jaeger with log data sources such as Loki, Elasticsearch, Splunk, etc... To do that, you need to
configure `Trace to logs` in Jaeger's data source settings.

Image: [ Jaeger traces and Loki logs correlation config ](https://hasura.io/docs/assets/images/open-telemetry-jaeger-loki-correlation-config-cca526e6e774d415be2ff2f13351813d.png)

In this example, Traces are linked to Loki logs by the `traceid` . You also can copy the below configuration to the data
source file.

```
datasources :
   -   name :  Jaeger
     type :  jaeger
     url :  http : //jaeger : 16686/
     jsonData :
       tracesToLogsV2 :
         datasourceUid :   'Loki'
         spanStartTimeShift :   '1h'
         spanEndTimeShift :   '-1h'
         filterByTraceID :   false
         filterBySpanID :   false
         customQuery :   true
         query :   "{exporter=\"OTLP\"} | json | traceid=`$${__span.traceId}`"
       traceQuery :
         timeShiftEnabled :   true
         spanStartTimeShift :   '1h'
         spanEndTimeShift :   '-1h'
```

You will see the `Logs for this span` button enabled when exploring the trace detail.

Image: [ Jaeger traces and Loki logs correlation ](https://hasura.io/docs/assets/images/open-telemetry-jaeger-loki-correlation-649f242c239084dc454135597d83b5b0.png)

### Datadog​

If Datadog can't correlate between traces and logs, you should verify the Trace ID attributes mapping.
Read more at[ the troubleshooting section ](https://docs.datadoghq.com/tracing/troubleshooting/correlated-logs-not-showing-up-in-the-trace-id-panel/?tab=jsonlogs#trace-id-option)on Datadog.

Image: [ Datadog traces and logs correlation ](https://hasura.io/docs/assets/images/open-telemetry-datadog-trace-log-01ffdb4eaaf2bdf7e89c1645d890a644.png)

### Honeycomb​

Traces and logs can't correlate together if they are exported to different datasets.
Note that Honeycomb will use the `service.name` attribute as the dataset where logs are exported.
Therefore the `x-honeycomb-dataset` header must be matched with that attribute.

Image: [ Honeycomb traces and logs correlation ](https://hasura.io/docs/assets/images/open-telemetry-honeycomb-trace-log-cfef4a90bc43ca90a6765d8346d739da.png)

### What did you think of this doc?

- [ Introduction ](https://hasura.io/docs/latest/observability/opentelemetry/#introduction)
- [ Configure the OpenTelemetry receiver ](https://hasura.io/docs/latest/observability/opentelemetry/#configure-the-opentelemetry-receiver)
- [ Parameters ](https://hasura.io/docs/latest/observability/opentelemetry/#parameters)
    - [ Endpoint ](https://hasura.io/docs/latest/observability/opentelemetry/#endpoint)

- [ Connection Type ](https://hasura.io/docs/latest/observability/opentelemetry/#connection-type)

- [ Data Type ](https://hasura.io/docs/latest/observability/opentelemetry/#data-type)

- [ Batch Size ](https://hasura.io/docs/latest/observability/opentelemetry/#batch-size)

- [ Trace Propagations ](https://hasura.io/docs/latest/observability/opentelemetry/#trace-propagations)

- [ Headers ](https://hasura.io/docs/latest/observability/opentelemetry/#headers)

- [ Attributes ](https://hasura.io/docs/latest/observability/opentelemetry/#attributes)
- [ Consuming and visualizing traces ](https://hasura.io/docs/latest/observability/opentelemetry/#consuming-and-visualizing-traces)
    - [ Jaeger ](https://hasura.io/docs/latest/observability/opentelemetry/#jaeger)

- [ OpenTelemetry Collector ](https://hasura.io/docs/latest/observability/opentelemetry/#opentelemetry-collector)
- [ Connect Logs and Traces ](https://hasura.io/docs/latest/observability/opentelemetry/#connect-logs-and-traces)
    - [ Jaeger ](https://hasura.io/docs/latest/observability/opentelemetry/#jaeger-1)

- [ Datadog ](https://hasura.io/docs/latest/observability/opentelemetry/#datadog)

- [ Honeycomb ](https://hasura.io/docs/latest/observability/opentelemetry/#honeycomb)


Image: [ Hasura Con ](https://res.cloudinary.com/dh8fp23nd/image/upload/v1677759444/main-web/Group_11455_2_rdpykm.png)

### Best Practices for API Observability with Hasura

### Start with GraphQL on Hasura for Free

- Build apps and APIs 10x faster
- Built-in authorization and caching
- 8x more performant than hand-rolled APIs


Image: [ Promo ](https://hasura.io/docs/assets/images/hasura-free-ff60e409244e0ea12b5a3045d1a9096b.png)