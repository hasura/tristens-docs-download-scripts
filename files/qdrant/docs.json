{"https://qdrant.tech/documentation/": "# Documentation\n\n **Qdrant (read: quadrant)** is a vector similarity search engine. Use our documentation to develop a production-ready service with a convenient API to store, search, and manage vectors with an additional payload. Qdrant\u2019s expanding features allow for all sorts of neural network or semantic-based matching, faceted search, and other applications.\n\n## First-Time Users:\n\nThere are three ways to use Qdrant:\n\n1. [ Run a Docker image ](quick-start/)if you don\u2019t have a Python development environment. Setup a local Qdrant server and storage in a few moments.\n2. [ Get the Python client ](https://github.com/qdrant/qdrant-client)if you\u2019re familiar with Python. Just `pip install qdrant-client` . The client uses an in-memory database.\n3. [ Spin up a Qdrant Cloud cluster: ](cloud/)the recommended method to run Qdrant in production. Read[ Quickstart ](cloud/quickstart-cloud/)to setup your first instance.\n\n\n### Recommended Workflow:\n\nImage: [ Local mode workflow ](https://raw.githubusercontent.com/qdrant/qdrant-client/master/docs/images/try-develop-deploy.png)\n\nImage: [ Local mode workflow ](https://raw.githubusercontent.com/qdrant/qdrant-client/master/docs/images/try-develop-deploy.png)\n\nFirst, try Qdrant locally using the[ Qdrant Client ](https://github.com/qdrant/qdrant-client)and with the help of our[ Tutorials ](tutorials/)and Guides. Develop a sample app from our[ Examples ](examples/)list and try it using a[ Qdrant Docker ](guides/installation/)container. Then, when you are ready for production, deploy to a Free Tier[ Qdrant Cloud ](cloud/)cluster.\n\n## Popular Topics:\n\n| Tutorial | Description | Tutorial | Description |\n|---|---|---|---|\n| [ Installation ](guides/installation/) | Different ways to install Qdrant. | [ Collections ](concepts/collections/) | Learn about the central concept behind Qdrant. |\n| [ Configuration ](guides/configuration/) | Update the default configuration. | [ Bulk Upload ](tutorials/bulk-upload/) | Efficiently upload a large number of vectors. |\n| [ Optimization ](tutorials/optimize/) | Optimize Qdrant\u2019s resource usage. | [ Multitenancy ](tutorials/multiple-partitions/) | Setup Qdrant for multiple independent users. |\n\n\n## Common Use Cases:\n\nQdrant is ideal for deploying applications based on the matching of embeddings produced by neural network encoders. Check out the[ Examples ](examples/)section to learn more about common use cases. Also, you can visit the[ Tutorials ](tutorials/)page to learn how to work with Qdrant in different ways.\n\n| Use Case | Description | Stack |\n|---|---|---|\n| [ Semantic Search for Beginners ](tutorials/search-beginners/) | Build a search engine locally with our most basic instruction set. | Qdrant |\n| [ Build a Simple Neural Search ](tutorials/neural-search/) | Build and deploy a neural search.[ Check out the live demo app. ](https://demo.qdrant.tech/#/) | Qdrant, BERT, FastAPI |\n| [ Build a Search with Aleph Alpha ](tutorials/aleph-alpha-search/) | Build a simple semantic search that combines text and image data. | Qdrant, Aleph Alpha |\n| [ Developing Recommendations Systems ](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_getting_started/getting_started.ipynb) | Learn how to get started building semantic search and recommendation systems. | Qdrant |\n| [ Search and Recommend Newspaper Articles ](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_text_data/qdrant_and_text_data.ipynb) | Work with text data to develop a semantic search and a recommendation engine for news articles. | Qdrant |\n| [ Recommendation System for Songs ](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_audio_data/03_qdrant_101_audio.ipynb) | Use Qdrant to develop a music recommendation engine based on audio embeddings. | Qdrant |\n| [ Image Comparison System for Skin Conditions ](https://colab.research.google.com/github/qdrant/examples/blob/master/qdrant_101_image_data/04_qdrant_101_cv.ipynb) | Use Qdrant to compare challenging images with labels representing different skin diseases. | Qdrant |\n| [ Question and Answer System with LlamaIndex ](https://githubtocolab.com/qdrant/examples/blob/master/llama_index_recency/Qdrant%20and%20LlamaIndex%20%E2%80%94%20A%20new%20way%20to%20keep%20your%20Q%26A%20systems%20up-to-date.ipynb) | Combine Qdrant and LlamaIndex to create a self-updating Q&A system. | Qdrant, LlamaIndex, Cohere |\n| [ Extractive QA System ](https://githubtocolab.com/qdrant/examples/blob/master/extractive_qa/extractive-question-answering.ipynb) | Extract answers directly from context to generate highly relevant answers. | Qdrant |\n| [ Ecommerce Reverse Image Search ](https://githubtocolab.com/qdrant/examples/blob/master/ecommerce_reverse_image_search/ecommerce-reverse-image-search.ipynb) | Accept images as search queries to receive semantically appropriate answers. | Qdrant |\n\n\n##### Table of contents\n\n- [ First-Time Users: ](https://qdrant.tech/documentation/#first-time-users)\n    - [ Recommended Workflow: ](https://qdrant.tech/documentation/#recommended-workflow)\n- [ Popular Topics: ](https://qdrant.tech/documentation/#popular-topics)\n- [ Common Use Cases: ](https://qdrant.tech/documentation/#common-use-cases)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/_index.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/overview/": "# Introduction\n\nImage: [ qdrant ](https://qdrant.tech/images/logo_with_text.png)\n\nImage: [ qdrant ](https://qdrant.tech/images/logo_with_text.png)\n\nVector databases are a relatively new way for interacting with abstract data representations\nderived from opaque machine learning models such as deep learning architectures. These\nrepresentations are often called vectors or embeddings and they are a compressed version of\nthe data used to train a machine learning model to accomplish a task like sentiment analysis,\nspeech recognition, object detection, and many others.\n\nThese new databases shine in many applications like[ semantic search ](https://en.wikipedia.org/wiki/Semantic_search)and[ recommendation systems ](https://en.wikipedia.org/wiki/Recommender_system), and here, we\u2019ll\nlearn about one of the most popular and fastest growing vector databases in the market,[ Qdrant ](https://qdrant.tech).\n\n## What is Qdrant?\n\n[ Qdrant ](http://qdrant.tech)\u201cis a vector similarity search engine that provides a production-ready\nservice with a convenient API to store, search, and manage points (i.e. vectors) with an additional\npayload.\u201d You can think of the payloads as additional pieces of information that can help you\nhone in on your search and also receive useful information that you can give to your users.\n\nYou can get started using Qdrant with the Python `qdrant-client` , by pulling the latest docker\nimage of `qdrant` and connecting to it locally, or by trying out[ Qdrant\u2019s Cloud ](https://cloud.qdrant.io/)free tier option until you are ready to make the full switch.\n\nWith that out of the way, let\u2019s talk about what are vector databases.\n\n## What Are Vector Databases?\n\nImage: [ dbs ](https://raw.githubusercontent.com/ramonpzg/mlops-sydney-2023/main/images/databases.png)\n\nImage: [ dbs ](https://raw.githubusercontent.com/ramonpzg/mlops-sydney-2023/main/images/databases.png)\n\nVector databases are a type of database designed to store and query high-dimensional vectors\nefficiently. In traditional[ OLTP ](https://www.ibm.com/topics/oltp)and[ OLAP ](https://www.ibm.com/topics/olap)databases (as seen in the image above), data is organized in rows and columns (and these are\ncalled **Tables** ), and queries are performed based on the values in those columns. However,\nin certain applications including image recognition, natural language processing, and recommendation\nsystems, data is often represented as vectors in a high-dimensional space, and these vectors, plus\nan id and a payload, are the elements we store in something called a **Collection** a vector\ndatabase like Qdrant.\n\nA vector in this context is a mathematical representation of an object or data point, where each\nelement of the vector corresponds to a specific feature or attribute of the object. For example,\nin an image recognition system, a vector could represent an image, with each element of the vector\nrepresenting a pixel value or a descriptor/characteristic of that pixel. In a music recommendation\nsystem, each vector would represent a song, and each element of the vector would represent a\ncharacteristic song such as tempo, genre, lyrics, and so on.\n\nVector databases are optimized for **storing** and **querying** these high-dimensional vectors\nefficiently, and they often using specialized data structures and indexing techniques such as\nHierarchical Navigable Small World (HNSW) \u2013 which is used to implement Approximate Nearest\nNeighbors \u2013 and Product Quantization, among others. These databases enable fast similarity\nand semantic search while allowing users to find vectors that are the closest to a given query\nvector based on some distance metric. The most commonly used distance metrics are Euclidean\nDistance, Cosine Similarity, and Dot Product, and these three are fully supported Qdrant.\n\nHere\u2019s a quick overview of the three:\n\n- [ Cosine Similarity ](https://en.wikipedia.org/wiki/Cosine_similarity)- Cosine similarity\nis a way to measure how similar two things are. Think of it like a ruler that tells you how far\napart two points are, but instead of measuring distance, it measures how similar two things\nare. It\u2019s often used with text to compare how similar two documents or sentences are to each\nother. The output of the cosine similarity ranges from -1 to 1, where -1 means the two things\nare completely dissimilar, and 1 means the two things are exactly the same. It\u2019s a straightforward\nand effective way to compare two things!\n- [ Dot Product ](https://en.wikipedia.org/wiki/Dot_product)- The dot product similarity\nmetric is another way of measuring how similar two things are, like cosine similarity. It\u2019s\noften used in machine learning and data science when working with numbers. The dot product\nsimilarity is calculated by multiplying the values in two sets of numbers, and then adding\nup those products. The higher the sum, the more similar the two sets of numbers are. So, it\u2019s\nlike a scale that tells you how closely two sets of numbers match each other.\n- [ Euclidean Distance ](https://en.wikipedia.org/wiki/Euclidean_distance)- Euclidean\ndistance is a way to measure the distance between two points in space, similar to how we\nmeasure the distance between two places on a map. It\u2019s calculated by finding the square root\nof the sum of the squared differences between the two points\u2019 coordinates. This distance metric\nis commonly used in machine learning to measure how similar or dissimilar two data points are\nor, in other words, to understand how far apart they are.\n\n\nNow that we know what vector databases are and how they are structurally different than other\ndatabases, let\u2019s go over why they are important.\n\n## Why do we need Vector Databases?\n\nVector databases play a crucial role in various applications that require similarity search, such\nas recommendation systems, content-based image retrieval, and personalized search. By taking\nadvantage of their efficient indexing and searching techniques, vector databases enable faster\nand more accurate retrieval of unstructured data already represented as vectors, which can\nhelp put in front of users the most relevant results to their queries.\n\nIn addition, other benefits of using vector databases include:\n\n1. Efficient storage and indexing of high-dimensional data.\n2. Ability to handle large-scale datasets with billions of data points.\n3. Support for real-time analytics and queries.\n4. Ability to handle vectors derived from complex data types such as images, videos, and natural language text.\n5. Improved performance and reduced latency in machine learning and AI applications.\n6. Reduced development and deployment time and cost compared to building a custom solution.\n\n\nKeep in mind that the specific benefits of using a vector database may vary depending on the\nuse case of your organization and the features of the database you ultimately choose.\n\nLet\u2019s now evaluate, at a high-level, the way Qdrant is architected.\n\n## High-Level Overview of Qdrant\u2019s Architecture\n\nImage: [ qdrant ](https://raw.githubusercontent.com/ramonpzg/mlops-sydney-2023/main/images/qdrant_overview_high_level.png)\n\nImage: [ qdrant ](https://raw.githubusercontent.com/ramonpzg/mlops-sydney-2023/main/images/qdrant_overview_high_level.png)\n\nThe diagram above represents a high-level overview of some of the main components of Qdrant. Here\nare the terminologies you should get familiar with.\n\n- [ Collections ](../concepts/collections/): A collection is a named set of points (vectors with a payload) among which you can search. The vector of each point within the same collection must have the same dimensionality and be compared by a single metric.[ Named vectors ](../concepts/collections/#collection-with-multiple-vectors)can be used to have multiple vectors in a single point, each of which can have their own dimensionality and metric requirements.\n- [ Distance Metrics ](https://en.wikipedia.org/wiki/Metric_space): These are used to measure\nsimilarities among vectors and they must be selected at the same time you are creating a\ncollection. The choice of metric depends on the way the vectors were obtained and, in particular,\non the neural network that will be used to encode new queries.\n- [ Points ](../concepts/points/): The points are the central entity that\nQdrant operates with and they consist of a vector and an optional id and payload.\n    - id: a unique identifier for your vectors.\n\n- Vector: a high-dimensional representation of data, for example, an image, a sound, a document, a video, etc.\n\n- [ Payload ](../concepts/payload/): A payload is a JSON object with additional data you can add to a vector.\n- [ Storage ](../concepts/storage/): Qdrant can use one of two options for\nstorage, **In-memory** storage (Stores all vectors in RAM, has the highest speed since disk\naccess is required only for persistence), or **Memmap** storage, (creates a virtual address\nspace associated with the file on disk).\n- Clients: the programming languages you can use to connect to Qdrant.\n\n\n## Next Steps\n\nNow that you know more about vector databases and Qdrant, you are ready to get started with one\nof our tutorials. If you\u2019ve never used a vector database, go ahead and jump straight into\nthe **Getting Started** section. Conversely, if you are a seasoned developer in these\ntechnology, jump to the section most relevant to your use case.\n\nAs you go through the tutorials, please let us know if any questions come up in our[ Discord channel here ](https://qdrant.to/discord). \ud83d\ude0e\n\n##### Table of contents\n\n- [ What is Qdrant? ](https://qdrant.tech/documentation/overview/#what-is-qdrant)\n- [ What Are Vector Databases? ](https://qdrant.tech/documentation/overview/#what-are-vector-databases)\n- [ Why do we need Vector Databases? ](https://qdrant.tech/documentation/overview/#why-do-we-need-vector-databases)\n- [ High-Level Overview of Qdrant\u2019s Architecture ](https://qdrant.tech/documentation/overview/#high-level-overview-of-qdrants-architecture)\n- [ Next Steps ](https://qdrant.tech/documentation/overview/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/overview/_index.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/overview/vector-search/": "# Vector Search Basics\n\nIf you are still trying to figure out how vector search works, please read ahead. This document describes how vector search is used, covers Qdrant\u2019s place in the larger ecosystem, and outlines how you can use Qdrant to augment your existing projects.\n\nFor those who want to start writing code right away, visit our[ Complete Beginners tutorial ](https://qdrant.tech/documentation/tutorials/search-beginners)to build a search engine in 5-15 minutes.\n\n## A Brief History of Search\n\nHuman memory is unreliable. Thus, as long as we have been trying to collect \u2018knowledge\u2019 in written form, we had to figure out how to search for relevant content without rereading the same books repeatedly. That\u2019s why some brilliant minds introduced the inverted index. In the simplest form, it\u2019s an appendix to a book, typically put at its end, with a list of the essential terms-and links to pages they occur at. Terms are put in alphabetical order. Back in the day, that was a manually crafted list requiring lots of effort to prepare. Once digitalization started, it became a lot easier, but still, we kept the same general principles. That worked, and still, it does.\n\nIf you are looking for a specific topic in a particular book, you can try to find a related phrase and quickly get to the correct page. Of course, assuming you know the proper term. If you don\u2019t, you must try and fail several times or find somebody else to help you form the correct query.\n\nImage: [ A simplified version of the inverted index. ](https://qdrant.tech/docs/gettingstarted/inverted-index.png)\n\nA simplified version of the inverted index.\n\nTime passed, and we haven\u2019t had much change in that area for quite a long time. But our textual data collection started to grow at a greater pace. So we also started building up many processes around those inverted indexes. For example, we allowed our users to provide many words and started splitting them into pieces. That allowed finding some documents which do not necessarily contain all the query words, but possibly part of them. We also started converting words into their root forms to cover more cases, removing stopwords, etc. Effectively we were becoming more and more user-friendly. Still, the idea behind the whole process is derived from the most straightforward keyword-based search known since the Middle Ages, with some tweaks.\n\nImage: [ The process of tokenization with an additional stopwords removal and converstion to root form of a word. ](https://qdrant.tech/docs/gettingstarted/tokenization.png)\n\nThe process of tokenization with an additional stopwords removal and converstion to root form of a word.\n\nTechnically speaking, we encode the documents and queries into so-called sparse vectors where each position has a corresponding word from the whole dictionary. If the input text contains a specific word, it gets a non-zero value at that position. But in reality, none of the texts will contain more than hundreds of different words. So the majority of vectors will have thousands of zeros and a few non-zero values. That\u2019s why we call them sparse. And they might be already used to calculate some word-based similarity by finding the documents which have the biggest overlap.\n\nImage: [ An example of a query vectorized to sparse format. ](https://qdrant.tech/docs/gettingstarted/query.png)\n\nAn example of a query vectorized to sparse format.\n\nSparse vectors have relatively **high dimensionality** ; equal to the size of the dictionary. And the dictionary is obtained automatically from the input data. So if we have a vector, we are able to partially reconstruct the words used in the text that created that vector.\n\n## The Tower of Babel\n\nEvery once in a while, when we discover new problems with inverted indexes, we come up with a new heuristic to tackle it, at least to some extent. Once we realized that people might describe the same concept with different words, we started building lists of synonyms to convert the query to a normalized form. But that won\u2019t work for the cases we didn\u2019t foresee. Still, we need to craft and maintain our dictionaries manually, so they can support the language that changes over time. Another difficult issue comes to light with multilingual scenarios. Old methods require setting up separate pipelines and keeping humans in the loop to maintain the quality.\n\nImage: [ The Tower of Babel, Pieter Bruegel. ](https://qdrant.tech/docs/gettingstarted/babel.jpg)\n\nThe Tower of Babel, Pieter Bruegel.\n\n## The Representation Revolution\n\nThe latest research in Machine Learning for NLP is heavily focused on training Deep Language Models. In this process, the neural network takes a large corpus of text as input and creates a mathematical representation of the words in the form of vectors. These vectors are created in such a way that words with similar meanings and occurring in similar contexts are grouped together and represented by similar vectors. And we can also take, for example, an average of all the word vectors to create the vector for a whole text (e.g query, sentence, or paragraph).\n\nImage: [ deep neural ](https://qdrant.tech/docs/gettingstarted/deep-neural.png)\n\nImage: [ deep neural ](https://qdrant.tech/docs/gettingstarted/deep-neural.png)\n\nWe can take those **dense vectors** produced by the network and use them as a **different data representation** . They are dense because neural networks will rarely produce zeros at any position. In contrary to sparse ones, they have a relatively low dimensionality \u2014 hundreds or a few thousand only. Unfortunately, if we want to have a look and understand the content of the document by looking at the vector it\u2019s no longer possible. Dimensions are no longer representing the presence of specific words.\n\nDense vectors can capture the meaning, not the words used in a text. That being said, **Large Language Models can automatically handle synonyms** . Moreso, since those neural networks might have been trained with multilingual corpora, they translate the same sentence, written in different languages, to similar vector representations, also called **embeddings** . And we can compare them to find similar pieces of text by calculating the distance to other vectors in our database.\n\nImage: [ Input queries contain different words, but they are still converted into similar vector representations, because the neural encoder can capture the meaning of the sentences. That feature can capture synonyms but also different languages.. ](https://qdrant.tech/docs/gettingstarted/input.png)\n\nInput queries contain different words, but they are still converted into similar vector representations, because the neural encoder can capture the meaning of the sentences. That feature can capture synonyms but also different languages..\n\n **Vector search** is a process of finding similar objects based on their embeddings similarity. The good thing is, you don\u2019t have to design and train your neural network on your own. Many pre-trained models are available, either on **HuggingFace** or by using libraries like[ SentenceTransformers ](https://www.sbert.net/?ref=hackernoon.com). If you, however, prefer not to get your hands dirty with neural models, you can also create the embeddings with SaaS tools, like[ co.embed API ](https://docs.cohere.com/reference/embed?ref=hackernoon.com).\n\n## Why Qdrant?\n\nThe challenge with vector search arises when we need to find similar documents in a big set of objects. If we want to find the closest examples, the naive approach would require calculating the distance to every document. That might work with dozens or even hundreds of examples but may become a bottleneck if we have more than that. When we work with relational data, we set up database indexes to speed things up and avoid full table scans. And the same is true for vector search. Qdrant is a fully-fledged vector database that speeds up the search process by using a graph-like structure to find the closest objects in sublinear time. So you don\u2019t calculate the distance to every object from the database, but some candidates only.\n\nImage: [ Vector search with Qdrant. Thanks to HNSW graph we are able to compare the distance to some of the objects from the database, not to all of them. ](https://qdrant.tech/docs/gettingstarted/vector-search.png)\n\nVector search with Qdrant. Thanks to HNSW graph we are able to compare the distance to some of the objects from the database, not to all of them.\n\nWhile doing a semantic search at scale, because this is what we sometimes call the vector search done on texts, we need a specialized tool to do it effectively \u2014 a tool like Qdrant.\n\n## Next Steps\n\nVector search is an exciting alternative to sparse methods. It solves the issues we had with the keyword-based search without needing to maintain lots of heuristics manually. It requires an additional component, a neural encoder, to convert text into vectors.\n\n[ Tutorial 1 - Qdrant for Complete Beginners ](../../tutorials/search-beginners)Despite its complicated background, vectors search is extraordinarily simple to set up. With Qdrant, you can have a search engine up-and-running in five minutes. Our[ Complete Beginners tutorial ](../../tutorials/search-beginners)will show you how.\n\n[ Tutorial 2 - Question and Answer System ](../../../articles/qa-with-cohere-and-qdrant)However, you can also choose SaaS tools to generate them and avoid building your model. Setting up a vector search project with Qdrant Cloud and Cohere co.embed API is fairly easy if you follow the[ Question and Answer system tutorial ](../../../articles/qa-with-cohere-and-qdrant).\n\nThere is another exciting thing about vector search. You can search for any kind of data as long as there is a neural network that would vectorize your data type. Do you think about a reverse image search? That\u2019s also possible with vector embeddings.\n\n##### Table of contents\n\n- [ A Brief History of Search ](https://qdrant.tech/documentation/overview/vector-search/#a-brief-history-of-search)\n- [ The Tower of Babel ](https://qdrant.tech/documentation/overview/vector-search/#the-tower-of-babel)\n- [ The Representation Revolution ](https://qdrant.tech/documentation/overview/vector-search/#the-representation-revolution)\n- [ Why Qdrant? ](https://qdrant.tech/documentation/overview/vector-search/#why-qdrant)\n- [ Next Steps ](https://qdrant.tech/documentation/overview/vector-search/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/overview/vector-search.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/overview/qdrant-alternatives/": "# Comparing Qdrant with alternatives\n\nIf you are currently using other vector databases, we recommend you read this short guide. It breaks down the key differences between Qdrant and other similar products. This document should help you decide which product has the features and support you need.\nUnfortunately, since Pinecone is not an open source product, we can\u2019t include it in our[ benchmarks ](https://qdrant.tech/benchmarks/). However, we still recommend you use the[ benchmark tool ](https://qdrant.tech/benchmarks/)while exploring Qdrant.\n\n## Feature comparison\n\n| Feature | Pinecone | Qdrant | Comments |\n|---|---|---|---|\n|  **Deployment Modes**  | SaaS-only | Local, on-premise, Cloud | Qdrant offers more flexibility in deployment modes |\n|  **Supported Technologies**  | Python, JavaScript/TypeScript | Python, JavaScript/TypeScript, Rust, Go | Qdrant supports a broader range of programming languages |\n|  **Performance** (e.g., query speed) | TnC Prohibit Benchmarking | [ Benchmark result ](https://qdrant.tech/benchmarks/) | Compare performance metrics |\n|  **Pricing**  | Starts at $70/mo | Free and Open Source, Cloud starts at $25/mo | Pricing as of May 2023 |\n\n\n## Prototyping options\n\nQdrant offers multiple ways of deployment, including local mode, on-premise, and[ Qdrant Cloud ](https://cloud.qdrant.io/).\nYou can[ get started with local mode quickly ](https://qdrant.tech/documentation/quick-start/)and without signing up for SaaS. With Pinecone you will have to connect your development environment to the cloud service just to test the product.\n\nWhen it comes to SaaS, both Pinecone and[ Qdrant Cloud ](https://cloud.qdrant.io/)offer a free cloud tier to check out the services, and you don\u2019t have to give credit card details for either. Qdrant\u2019s free tier should be enough to keep around 1M of 768-dimensional vectors, but it may vary depending on the additional attributes stored with vectors. Pinecone\u2019s starter plan supports approximately 200k 768-dimensional embeddings and metadata, stored within a single index. With Qdrant Cloud, however, you can experiment with different models as you may create several collections or keep multiple vectors per each point. That means Qdrant Cloud allows you building several small demos, even on a free tier.\n\n## Terminology\n\nAlthough both tools serve similar purposes, there are some differences in the terms used. This dictionary may come\nin handy during the transition.\n\n| Pinecone | Qdrant | Comments |\n|---|---|---|\n|  **Index**  | [ Collection ](../../concepts/collections/) | Pinecone\u2019s index is an organizational unit for storing and managing vectors of the same size. The index is tightly coupled with hardware (pods). Qdrant uses the collection to describe a similar concept, however, a single instance may handle multiple collections at once. |\n|  **Collection**  | N/A | A collection in Pinecone is a static copy of an *index* that you cannot query, mostly used as some sort of backup. There is no such concept in Qdrant, but if you want to back your collection up, you may always create a[ snapshot ](../../concepts/snapshots/). |\n|  **Namespace**  | [ User-defined sharding ](../../guides/distributed_deployment/#user-defined-sharding) | Namespaces allow the partitioning of the vectors in an index into subsets. Qdrant features user-defined sharding for this, which is more versatile as operations can be over multiple shards. |\n|  **Metadata**  | [ Payload ](../../concepts/payload/) | Additional attributes describing a particular object, other than the embedding vector. Both engines support various data types, but Pinecone metadata is key-value, while Qdrant supports any JSON-like objects. |\n|  **Query**  | [ Search ](../../concepts/search/) | Name of the method used to find the nearest neighbors for a given vector, possibly with some additional filters applied on top. |\n| N/A | [ Scroll ](../../concepts/points/#scroll-points) | Pinecone does not offer a way to iterate through all the vectors in a particular index. Qdrant has a `scroll` method to get them all without using search. |\n\n\n## Known limitations\n\n1. Pinecone does not support arbitrary JSON metadata, but a flat structure with strings, numbers, booleans, or lists of strings used as values. Qdrant accepts any JSON object as a payload, even nested structures.\n2. NULL values are not supported in Pinecone metadata but are handled properly by Qdrant.\n3. The maximum size of Pinecone metadata is 40kb per vector.\n4. Pinecone, unlike Qdrant, does not support geolocation and filtering based on geographical criteria.\n5. Qdrant allows storing multiple vectors per point, and those might be of a different dimensionality. Pinecone doesn\u2019t support anything similar.\n6. Vectors in Pinecone are mandatory for each point. Qdrant supports optional vectors.\n\n\nIt is worth mentioning, that **Pinecone will automatically create metadata indexes for all the fields** . Qdrant assumes you know\nyour data and your future queries best, so it\u2019s up to you to choose the fields to be indexed. Thus, **you need to explicitly define the payload indexes while using Qdrant** .\n\n## Supported technologies\n\nBoth tools support various programming languages providing official SDKs.\n\n|  | Pinecone | Qdrant |\n|---|---|---|\n|  **Python**  | \u2705 | \u2705 |\n|  **JavaScript/TypeScript**  | \u2705 | \u2705 |\n|  **Rust**  | \u274c | \u2705 |\n|  **Go**  | \u274c | \u2705 |\n\n\nThere are also various community-driven projects aimed to provide the support for the other languages, but those are not officially\nmaintained, thus not mentioned here. However, it is still possible to interact with both engines through the HTTP REST or gRPC API.\nThat makes it easy to integrate with any technology of your choice.\n\nIf you are a Python user, then both tools are well-integrated with the most popular libraries like[ LangChain ](../integrations/langchain/),[ LlamaIndex ](../integrations/llama-index/),[ Haystack ](../integrations/haystack/), and more.\nUsing any of those libraries makes it easier to experiment with different vector databases, as the transition should be seamless.\n\n## Planning to migrate?\n\nWe strongly recommend you use[ Qdrant Tools ](https://github.com/NirantK/qdrant_tools)to migrate from Qdrant to Pinecone.\n\nMigrating from Pinecone to Qdrant involves a series of well-planned steps to ensure that the transition is smooth and disruption-free. Here is a suggested migration plan:\n\n1. Understanding Qdrant: It\u2019s important to first get a solid grasp of Qdrant, its functions, and its APIs. Take time to understand how to establish collections, add points, and query these collections.\n2. Migration strategy: Create a comprehensive migration strategy, incorporating data migration (copying your vectors and associated metadata from Pinecone to Qdrant), feature migration (verifying the availability and setting up of features currently in use with Pinecone in Qdrant), and a contingency plan (should there be any unexpected issues).\n3. Establishing a parallel Qdrant system: Set up a Qdrant system to run concurrently with your current Pinecone system. This step will let you begin testing Qdrant without disturbing your ongoing operations on Pinecone.\n4. Data migration: Shift your vectors and metadata from Pinecone to Qdrant. The timeline for this step could vary, depending on the size of your data and Pinecone API\u2019s rate limitations.\n5. Testing and transition: Following the data migration, thoroughly test the Qdrant system. Once you\u2019re assured of the Qdrant system\u2019s stability and performance, you can make the switch.\n6. Monitoring and fine-tuning: After transitioning to Qdrant, maintain a close watch on its performance. It\u2019s key to continue refining the system for optimal results as needed.\n\n\nUnderstanding Qdrant: It\u2019s important to first get a solid grasp of Qdrant, its functions, and its APIs. Take time to understand how to establish collections, add points, and query these collections.\n\nMigration strategy: Create a comprehensive migration strategy, incorporating data migration (copying your vectors and associated metadata from Pinecone to Qdrant), feature migration (verifying the availability and setting up of features currently in use with Pinecone in Qdrant), and a contingency plan (should there be any unexpected issues).\n\nEstablishing a parallel Qdrant system: Set up a Qdrant system to run concurrently with your current Pinecone system. This step will let you begin testing Qdrant without disturbing your ongoing operations on Pinecone.\n\nData migration: Shift your vectors and metadata from Pinecone to Qdrant. The timeline for this step could vary, depending on the size of your data and Pinecone API\u2019s rate limitations.\n\nTesting and transition: Following the data migration, thoroughly test the Qdrant system. Once you\u2019re assured of the Qdrant system\u2019s stability and performance, you can make the switch.\n\nMonitoring and fine-tuning: After transitioning to Qdrant, maintain a close watch on its performance. It\u2019s key to continue refining the system for optimal results as needed.\n\n## Next steps\n\n1. If you aren\u2019t ready yet,[ try out Qdrant locally ](https://qdrant.tech/documentation/quick-start/)or sign up for[ Qdrant Cloud ](https://cloud.qdrant.io/).\n2. For more basic information on Qdrant read our[ Overview ](overview/)section or learn more about Qdrant Cloud\u2019s[ Free Tier ](documentation/cloud/).\n3. If ready to migrate, please consult our[ Comprehensive Guide ](https://github.com/NirantK/qdrant_tools)for further details on migration steps.\n\n\nIf you aren\u2019t ready yet,[ try out Qdrant locally ](https://qdrant.tech/documentation/quick-start/)or sign up for[ Qdrant Cloud ](https://cloud.qdrant.io/).\n\nFor more basic information on Qdrant read our[ Overview ](overview/)section or learn more about Qdrant Cloud\u2019s[ Free Tier ](documentation/cloud/).\n\nIf ready to migrate, please consult our[ Comprehensive Guide ](https://github.com/NirantK/qdrant_tools)for further details on migration steps.\n\n##### Table of contents\n\n- [ Feature comparison ](https://qdrant.tech/documentation/overview/qdrant-alternatives/#feature-comparison)\n- [ Prototyping options ](https://qdrant.tech/documentation/overview/qdrant-alternatives/#prototyping-options)\n- [ Terminology ](https://qdrant.tech/documentation/overview/qdrant-alternatives/#terminology)\n- [ Known limitations ](https://qdrant.tech/documentation/overview/qdrant-alternatives/#known-limitations)\n- [ Supported technologies ](https://qdrant.tech/documentation/overview/qdrant-alternatives/#supported-technologies)\n- [ Planning to migrate? ](https://qdrant.tech/documentation/overview/qdrant-alternatives/#planning-to-migrate)\n- [ Next steps ](https://qdrant.tech/documentation/overview/qdrant-alternatives/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/overview/qdrant-alternatives.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/quick-start/": "# Quickstart\n\nIn this short example, you will use the Python Client to create a Collection, load data into it and run a basic search query.\n\n## Download and run\n\nFirst, download the latest Qdrant image from Dockerhub:\n\n`docker pull qdrant/qdrant\n`\n\nThen, run the service:\n\n```\ndocker run -p 6333:6333 -p 6334:6334  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage:z  \\\n\n    qdrant/qdrant\n\n```\n\nUnder the default configuration all data will be stored in the `./qdrant_storage` directory. This will also be the only directory that both the Container and the host machine can both see.\n\nQdrant is now accessible:\n\n- REST API:[ localhost:6333 ](http://localhost:6333)\n- Web UI:[ localhost:6333/dashboard ](http://localhost:6333/dashboard)\n- GRPC API:[ localhost:6334 ](http://localhost:6334)\n\n\n## Initialize the client\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\n// The Rust client uses Qdrant's GRPC interface\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n```\n\n## Create a collection\n\nYou will be storing all of your vector data in a Qdrant collection. Let\u2019s call it `test_collection` . This collection will be using a dot product distance metric to compare vectors.\n\n```\nfrom   qdrant_client.http.models   import  Distance, VectorParams\n\n\n\nclient . create_collection(\n\n    collection_name = \"test_collection\" ,\n\n    vectors_config = VectorParams(size = 4 , distance = Distance . DOT),\n\n)\n\n```\n\n```\nawait  client.createCollection( \"test_collection\" , {\n\n  vectors :  { size:  4 , distance :   \"Dot\"  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{vectors_config::Config,   VectorParams,   VectorsConfig}; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  4 , \n\n                 distance:  Distance ::Dot.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n## Add vectors\n\nLet\u2019s now add a few vectors with a payload. Payloads are other data you want to associate with the vector:\n\n```\nfrom   qdrant_client.http.models   import  PointStruct\n\n\n\noperation_info  =  client . upsert(\n\n    collection_name = \"test_collection\" ,\n\n    wait = True ,\n\n    points = [\n\n        PointStruct( id = 1 , vector = [ 0.05 ,  0.61 ,  0.76 ,  0.74 ], payload = { \"city\" :  \"Berlin\" }),\n\n        PointStruct( id = 2 , vector = [ 0.19 ,  0.81 ,  0.75 ,  0.11 ], payload = { \"city\" :  \"London\" }),\n\n        PointStruct( id = 3 , vector = [ 0.36 ,  0.55 ,  0.47 ,  0.94 ], payload = { \"city\" :  \"Moscow\" }),\n\n        PointStruct( id = 4 , vector = [ 0.18 ,  0.01 ,  0.85 ,  0.80 ], payload = { \"city\" :  \"New York\" }),\n\n        PointStruct( id = 5 , vector = [ 0.24 ,  0.18 ,  0.22 ,  0.44 ], payload = { \"city\" :  \"Beijing\" }),\n\n        PointStruct( id = 6 , vector = [ 0.35 ,  0.08 ,  0.11 ,  0.44 ], payload = { \"city\" :  \"Mumbai\" }),\n\n    ],\n\n)\n\n\n\nprint (operation_info)\n\n```\n\n```\nconst  operationInfo  =   await  client.upsert( \"test_collection\" , {\n\n  wait:  true ,\n\n  points :  [\n\n    { id:  1 , vector :  [ 0.05 ,  0.61 ,  0.76 ,  0.74 ], payload :  { city :   \"Berlin\"  } },\n\n    { id:  2 , vector :  [ 0.19 ,  0.81 ,  0.75 ,  0.11 ], payload :  { city :   \"London\"  } },\n\n    { id:  3 , vector :  [ 0.36 ,  0.55 ,  0.47 ,  0.94 ], payload :  { city :   \"Moscow\"  } },\n\n    { id:  4 , vector :  [ 0.18 ,  0.01 ,  0.85 ,  0.80 ], payload :  { city :   \"New York\"  } },\n\n    { id:  5 , vector :  [ 0.24 ,  0.18 ,  0.22 ,  0.44 ], payload :  { city :   \"Beijing\"  } },\n\n    { id:  6 , vector :  [ 0.35 ,  0.08 ,  0.11 ,  0.44 ], payload :  { city :   \"Mumbai\"  } },\n\n  ],\n\n});\n\n\n\nconsole.debug(operationInfo);\n\n```\n\n```\nuse   qdrant_client::qdrant::PointStruct; \n\nuse   serde_json::json; \n\n\n\nlet   points   =   vec![ \n\n     PointStruct::new( \n\n         1 , \n\n         vec![ 0.05 ,   0.61 ,   0.76 ,   0.74 ], \n\n         json ! ( \n\n             { \"city\" :  \"Berlin\" } \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n     PointStruct::new( \n\n         2 , \n\n         vec![ 0.19 ,   0.81 ,   0.75 ,   0.11 ], \n\n         json ! ( \n\n             { \"city\" :  \"London\" } \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n     // ..truncated\n\n]; \n\nlet   operation_info   =   client \n\n     .upsert_points_blocking( \"test_collection\" .to_string(),   None ,   points,   None ) \n\n     . await ? ; \n\n\n\ndbg!(operation_info); \n\n```\n\n **Response:** \n\n`operation_id = 0  status =< UpdateStatus . COMPLETED:  'completed' > \n`\n\n`{ operation_id:  0 , status :   'completed'  }\n`\n\n```\nPointsOperationResponse   { \n\n     result:  Some (UpdateResult   { \n\n         operation_id:  0 , \n\n         status:  Completed , \n\n     }), \n\n     time:  0.006347708 , \n\n} \n\n```\n\n## Run a query\n\nLet\u2019s ask a basic question - Which of our stored vectors are most similar to the query vector `[0.2, 0.1, 0.9, 0.7]` ?\n\n```\nsearch_result  =  client . search(\n\n    collection_name = \"test_collection\" , query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ], limit = 3 \n\n)\n\n\n\nprint (search_result)\n\n```\n\n```\nlet  searchResult  =   await  client.search( \"test_collection\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  limit:  3 ,\n\n});\n\n\n\nconsole.debug(searchResult);\n\n```\n\n```\nuse   qdrant_client::qdrant::SearchPoints; \n\n\n\nlet   search_result   =   client \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         limit:  3 , \n\n         with_payload:  Some ( true .into()), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n\n\ndbg!(search_result); \n\n```\n\n **Response:** \n\n```\nScoredPoint( id = 4 , version = 0 , score = 1.362 , payload = { \"city\" :  \"New York\" }, vector = None ),\n\nScoredPoint( id = 1 , version = 0 , score = 1.273 , payload = { \"city\" :  \"Berlin\" }, vector = None ),\n\nScoredPoint( id = 3 , version = 0 , score = 1.208 , payload = { \"city\" :  \"Moscow\" }, vector = None )\n\n```\n\n```\n[\n\n  {\n\n    id:  4 ,\n\n    version:  0 ,\n\n    score:  1.362 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n  {\n\n    id:  1 ,\n\n    version:  0 ,\n\n    score:  1.273 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n  {\n\n    id:  3 ,\n\n    version:  0 ,\n\n    score:  1.208 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n];\n\n```\n\n```\nSearchResponse   { \n\n     result: [ \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 4 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.362 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 1 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.273 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 3 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.208 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n     ], \n\n     time:  0.003635125 , \n\n} \n\n```\n\nThe results are returned in decreasing similarity order. Note that payload and vector data is missing in these results by default.\nSee[ payload and vector in the result ](../concepts/search#payload-and-vector-in-the-result)on how to enable it.\n\n## Add a filter\n\nWe can narrow down the results further by filtering by payload. Let\u2019s find the closest results that include \u201cLondon\u201d.\n\n```\nfrom   qdrant_client.http.models   import  Filter, FieldCondition, MatchValue\n\n\n\nsearch_result  =  client . search(\n\n    collection_name = \"test_collection\" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    query_filter = Filter(\n\n        must = [FieldCondition(key = \"city\" , match = MatchValue(value = \"London\" ))]\n\n    ),\n\n    with_payload = True ,\n\n    limit = 3 ,\n\n)\n\n\n\nprint (search_result)\n\n```\n\n```\nsearchResult  =   await  client.search( \"test_collection\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  filter :  {\n\n    must :  [{ key :   \"city\" , match :  { value :   \"London\"  } }],\n\n  },\n\n  with_payload:  true ,\n\n  limit:  3 ,\n\n});\n\n\n\nconsole.debug(searchResult);\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   SearchPoints}; \n\n\n\nlet   search_result   =   client \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         filter:  Some (Filter::all([Condition::matches( \n\n             \"city\" , \n\n             \"London\" .to_string(), \n\n         )])), \n\n         limit:  2 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n\n\ndbg!(search_result); \n\n```\n\n **Response:** \n\n`ScoredPoint( id = 2 , version = 0 , score = 0.871 , payload = { \"city\" :  \"London\" }, vector = None )\n`\n\n```\n[\n\n  {\n\n    id:  2 ,\n\n    version:  0 ,\n\n    score:  0.871 ,\n\n    payload :  { city :   \"London\"  },\n\n    vector:  null ,\n\n  },\n\n];\n\n```\n\n```\nSearchResponse   { \n\n     result: [ \n\n         ScoredPoint   { \n\n             id:  Some ( \n\n                 PointId   { \n\n                     point_id_options:  Some ( \n\n                         Num( \n\n                             2 , \n\n                         ), \n\n                     ), \n\n                 }, \n\n             ), \n\n             payload: { \n\n                 \"city\" :  Value   { \n\n                     kind:  Some ( \n\n                         StringValue( \n\n                             \"London\" , \n\n                         ), \n\n                     ), \n\n                 }, \n\n             }, \n\n             score:  0.871 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n     ], \n\n     time:  0.004001083 , \n\n} \n\n```\n\nYou have just conducted vector search. You loaded vectors into a database and queried the database with a vector of your own. Qdrant found the closest results and presented you with a similarity score.\n\n## Next steps\n\nNow you know how Qdrant works. Getting started with[ Qdrant Cloud ](../cloud/quickstart-cloud/)is just as easy.[ Create an account ](https://qdrant.to/cloud)and use our SaaS completely free. We will take care of infrastructure maintenance and software updates.\n\nTo move onto some more complex examples of vector search, read our[ Tutorials ](../tutorials/)and create your own app with the help of our[ Examples ](../examples/).\n\n **Note:** There is another way of running Qdrant locally. If you are a Python developer, we recommend that you try Local Mode in[ Qdrant Client ](https://github.com/qdrant/qdrant-client), as it only takes a few moments to get setup.\n\n##### Table of contents\n\n- [ Download and run ](https://qdrant.tech/documentation/quick-start/#download-and-run)\n- [ Initialize the client ](https://qdrant.tech/documentation/quick-start/#initialize-the-client)\n- [ Create a collection ](https://qdrant.tech/documentation/quick-start/#create-a-collection)\n- [ Add vectors ](https://qdrant.tech/documentation/quick-start/#add-vectors)\n- [ Run a query ](https://qdrant.tech/documentation/quick-start/#run-a-query)\n- [ Add a filter ](https://qdrant.tech/documentation/quick-start/#add-a-filter)\n- [ Next steps ](https://qdrant.tech/documentation/quick-start/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/quick-start.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/interfaces/": "# Interfaces\n\n **Note:** If you are using a language that is not listed here, you can use the REST API directly or generate a client for your language\nusing[ OpenAPI ](https://github.com/qdrant/qdrant/blob/master/docs/redoc/master/openapi.json)or[ protobuf ](https://github.com/qdrant/qdrant/tree/master/lib/api/src/grpc/proto)definitions.\n\n## Client Libraries\n\n|  | Client Repository | Installation | Version |\n|---|---|---|---|\n| [  ](https://python-client.qdrant.tech/) |  **Python**  |  `pip install qdrant-client[fastembed]`  |  **Latest Release** ,[ API Docs ](https://python-client.qdrant.tech/) |\n| Image: [ typescript ](https://qdrant.tech/docs/misc/ts.webp) |  **Typescript**  |  `npm install @qdrant/js-client-rest`  |  **Latest Release**  |\n| Image: [ rust ](https://qdrant.tech/docs/misc/rust.webp) |  **Rust**  |  `cargo add qdrant-client`  |  **Latest Release**  |\n| Image: [ golang ](https://qdrant.tech/docs/misc/go.webp) |  **Go**  |  `go get github.com/qdrant/go-client`  |  **Latest Release**  |\n| Image: [ .net ](https://qdrant.tech/docs/misc/dotnet.webp) |  **.NET**  |  `dotnet add package Qdrant.Client`  |  **Latest Release**  |\n\n\nImage: [ python ](https://qdrant.tech/docs/misc/python.webp)\n\nImage: [ typescript ](https://qdrant.tech/docs/misc/ts.webp)\n\nImage: [ rust ](https://qdrant.tech/docs/misc/rust.webp)\n\nImage: [ golang ](https://qdrant.tech/docs/misc/go.webp)\n\nImage: [ .net ](https://qdrant.tech/docs/misc/dotnet.webp)\n\n## API Reference\n\nAll interaction with Qdrant takes place via the REST API. We recommend using REST API if you are using Qdrant for the first time or if you are working on a prototype.\n\n| API | Documentation |\n|---|---|\n| REST API | [ OpenAPI Specification ](https://qdrant.github.io/qdrant/redoc/index.html) |\n| gRPC API | [ gRPC Documentation ](https://github.com/qdrant/qdrant/blob/master/docs/grpc/docs.md) |\n\n\n### gRPC Interface\n\nThe gRPC methods follow the same principles as REST. For each REST endpoint, there is a corresponding gRPC method.\n\nAs per the[ configuration file ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml), the gRPC interface is available on the specified port.\n\n```\nservice : \n\n   grpc_port :   6334 \n\n```\n\nRunning the service inside of Docker will look like this:\n\n```\ndocker run -p 6333:6333 -p 6334:6334  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage:z  \\\n\n    qdrant/qdrant\n\n```\n\n **When to use gRPC:** The choice between gRPC and the REST API is a trade-off between convenience and speed. gRPC is a binary protocol and can be more challenging to debug. We recommend using gRPC if you are already familiar with Qdrant and are trying to optimize the performance of your application.\n\n## Qdrant Web UI\n\nQdrant\u2019s Web UI is an intuitive and efficient graphic interface for your Qdrant Collections, REST API and data points.\n\nIn the **Console** , you may use the REST API to interact with Qdrant, while in **Collections** , you can manage all the collections and upload Snapshots.\n\nImage: [ Qdrant Web UI ](https://qdrant.tech/articles_data/qdrant-1.3.x/web-ui.png)\n\nImage: [ Qdrant Web UI ](https://qdrant.tech/articles_data/qdrant-1.3.x/web-ui.png)\n\n### Accessing the Web UI\n\nFirst, run the Docker container:\n\n```\ndocker run -p 6333:6333 -p 6334:6334  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage:z  \\\n\n    qdrant/qdrant\n\n```\n\nThe GUI is available at `http://localhost:6333/dashboard` \n\n##### Table of contents\n\n- [ Client Libraries ](https://qdrant.tech/documentation/interfaces/#client-libraries)\n- [ API Reference ](https://qdrant.tech/documentation/interfaces/#api-reference)\n    - [ gRPC Interface ](https://qdrant.tech/documentation/interfaces/#grpc-interface)\n- [ Qdrant Web UI ](https://qdrant.tech/documentation/interfaces/#qdrant-web-ui)\n    - [ Accessing the Web UI ](https://qdrant.tech/documentation/interfaces/#accessing-the-web-ui)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/interfaces.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/": "# About Qdrant Cloud\n\nQdrant Cloud is our SaaS (software-as-a-service) solution, providing managed Qdrant instances on the cloud.\nWe provide you with the same fast and reliable similarity search engine, but without the need to maintain your own infrastructure.\n\nTransitioning from on-premise to the cloud version of Qdrant does not require changing anything in the way you interact with the service. All you have to do is[ create a Qdrant Cloud account ](https://qdrant.to/cloud)and[ provide a new API key ](https://qdrant.tech/documentation/cloud/authentication/)to each request.\n\nThe transition is even easier if you use the official client libraries. For example, the[ Python Client ](https://github.com/qdrant/qdrant-client)has the support of the API key already built-in, so you only need to provide it once, when the QdrantClient instance is created.\n\n### Cluster configuration\n\nEach instance comes pre-configured with the following tools, features and support services:\n\n- Automatically created with the latest available version of Qdrant.\n- Upgradeable to later versions of Qdrant as they are released.\n- Equipped with monitoring and logging to observe the health of each cluster.\n- Accessible through the Qdrant Cloud Console.\n- Vertically scalable.\n- Offered on AWS and GCP, with Azure currently in development.\n\n\n### Getting started with Qdrant Cloud\n\nTo use Qdrant Cloud, you will need to create at least one cluster. There are two ways to start:\n\n1. [ Create a Free Tier cluster ](https://qdrant.tech/documentation/cloud/quickstart-cloud/)with 1 node and a default configuration (1GB RAM, 0.5 CPU and 4GB Disk). This option is perfect for prototyping and you don\u2019t need a credit card to join.\n2. [ Configure a custom cluster ](https://qdrant.tech/documentation/cloud/create-cluster/)with additional nodes and more resources. For this option, you will have to provide billing information.\n\n\nWe recommend that you use the Free Tier cluster for testing purposes. The capacity should be enough to serve up to 1M vectors of 768dim. To calculate your needs, refer to[ capacity planning ](https://qdrant.tech/documentation/cloud/capacity-sizing/).\n\n### Support & Troubleshooting\n\nAll Qdrant Cloud users are welcome to join our[ Discord community ](https://qdrant.to/discord). Our Support Engineers are available to help you anytime.\n\nAdditionally, paid customers can also contact support via channels provided during cluster creation and/or on-boarding.\n\n##### Table of contents\n\n- - [ Cluster configuration ](https://qdrant.tech/documentation/cloud/#cluster-configuration)\n\n- [ Getting started with Qdrant Cloud ](https://qdrant.tech/documentation/cloud/#getting-started-with-qdrant-cloud)\n\n- [ Support & Troubleshooting ](https://qdrant.tech/documentation/cloud/#support--troubleshooting)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/_index.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/quickstart-cloud/": "# Quickstart\n\nThis page shows you how to use the Qdrant Cloud Console to create a free tier cluster and then connect to it with Qdrant Client.\n\n## Step 1: Create a Free Tier cluster\n\n1. Start in the **Overview** section of the[ Cloud Dashboard ](https://cloud.qdrant.io).\n2. Under **Set a Cluster Up** enter a **Cluster name** .\n3. Click **Create Free Tier** and then **Continue** .\n4. Under **Get an API Key** , select the cluster and click **Get API Key** .\n5. Save the API key, as you won\u2019t be able to request it again. Click **Continue** .\n6. Save the code snippet provided to access your cluster. Click **Complete** to finish setup.\n\n\nImage: [ Embeddings ](https://qdrant.tech/docs/cloud/quickstart-cloud.png)\n\nImage: [ Embeddings ](https://qdrant.tech/docs/cloud/quickstart-cloud.png)\n\n## Step 2: Test cluster access\n\nAfter creation, you will receive a code snippet to access your cluster. Your generated request should look very similar to this one:\n\n```\ncurl  \\\n\n  -X GET  'https://xyz-example.eu-central.aws.cloud.qdrant.io:6333'   \\\n\n  --header  'api-key: <paste-your-api-key-here>' \n\n```\n\nOpen Terminal and run the request. You should get a response that looks like this:\n\n`{ \"title\" : \"qdrant - vector search engine\" , \"version\" : \"1.4.1\" } \n`\n\n **Note:** The API key needs to be present in the request header every time you make a request via Rest or gRPC interface.\n\n## Step 3: Authenticate via SDK\n\nNow that you have created your first cluster and key, you might want to access Qdrant Cloud from within your application.\nOur official Qdrant clients for Python, TypeScript, Go, Rust, and .NET all support the API key parameter.\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nqdrant_client  =  QdrantClient(\n\n     \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n    api_key = \"<paste-your-api-key-here>\" ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({\n\n  host :   \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n  apiKey :   \"<paste-your-api-key-here>\" ,\n\n});\n\n```\n\n```\nusing   Qdrant.Client ;\n\n\n\nvar  client =  new  QdrantClient(\n\n   \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n  https:  true ,\n\n  apiKey:  \"<paste-your-api-key-here>\" \n\n);\n\n```\n\n##### Table of contents\n\n- [ Step 1: Create a Free Tier cluster ](https://qdrant.tech/documentation/cloud/quickstart-cloud/#step-1-create-a-free-tier-cluster)\n- [ Step 2: Test cluster access ](https://qdrant.tech/documentation/cloud/quickstart-cloud/#step-2-test-cluster-access)\n- [ Step 3: Authenticate via SDK ](https://qdrant.tech/documentation/cloud/quickstart-cloud/#step-3-authenticate-via-sdk)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/quickstart-cloud.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/create-cluster/": "# Create a cluster\n\nThis page shows you how to use the Qdrant Cloud Console to create a custom Qdrant Cloud cluster.\n\n **Prerequisite:** Please make sure you have provided billing information before creating a custom cluster.\n\n1. Start in the **Clusters** section of the[ Cloud Dashboard ](https://cloud.qdrant.io).\n2. Select **Clusters** and then click **+ Create** .\n3. A window will open. Enter a cluster **Name** .\n4. Currently, you can deploy to AWS or GCP. We are developing support for Azure.\n5. Choose your data center region. If you have latency concerns or other topology-related requirements,[ let us know ](mailto:cloud@qdrant.io).\n6. Configure RAM size for each node (1GB to 64GB).\n\n\nPlease read[ Capacity and Sizing ](../../cloud/capacity-sizing/)to make the right choice. If you need more capacity per node,[ let us know ](mailto:cloud@qdrant.io).\n\n1. Choose the number of CPUs per node (0.5 core to 16 cores). The max/min number of CPUs is coupled to the chosen RAM size.\n2. Select the number of nodes you want the cluster to be deployed on.\n\n\nEach node is automatically attached with a disk space offering enough space for your data if you decide to put the metadata or even the index on the disk storage.\n\n1. Click **Create** and wait for your cluster to be provisioned.\n\n\nYour cluster will be reachable on port 443 and 6333 (Rest) and 6334 (gRPC).\n\nImage: [ Embeddings ](https://qdrant.tech/docs/cloud/create-cluster.png)\n\nImage: [ Embeddings ](https://qdrant.tech/docs/cloud/create-cluster.png)\n\n## Next steps\n\nYou will need to connect to your new Qdrant Cloud cluster. Follow[ Authentication ](../../cloud/authentication/)to create one or more API keys.\n\nYour new cluster is highly available and responsive to your application requirements and resource load. Read more in[ Cluster Scaling ](../../cloud/cluster-scaling/).\n\n##### Table of contents\n\n- [ Next steps ](https://qdrant.tech/documentation/cloud/create-cluster/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/create-cluster.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/authentication/": "# Authentication\n\nThis page shows you how to use the Qdrant Cloud Console to create a custom API key for a cluster. You will learn how to connect to your cluster using the new API key.\n\n## Create API keys\n\nThe API key is only shown once after creation. If you lose it, you will need to create a new one.\nHowever, we recommend rotating the keys from time to time. To create additional API keys do the following.\n\n1. Go to the[ Cloud Dashboard ](https://qdrant.to/cloud).\n2. Select **Access Management** to display available API keys.\n3. Click **Create** and choose a cluster name from the dropdown menu.\n\n\n **Note:** You can create a key that provides access to multiple clusters. Select desired clusters in the dropdown box.\n\n1. Click **OK** and retrieve your API key.\n\n\n## Authenticate via SDK\n\nNow that you have created your first cluster and key, you might want to access Qdrant Cloud from within your application.\nOur official Qdrant clients for Python, TypeScript, Go, Rust, and .NET all support the API key parameter.\n\n```\ncurl  \\\n\n  -X GET https://xyz-example.eu-central.aws.cloud.qdrant.io:6333  \\\n\n  --header  'api-key: <provide-your-own-key>' \n\n\n\n# Alternatively, you can use the `Authorization` header with the `Bearer` prefix \n\ncurl  \\\n\n  -X GET https://xyz-example.eu-central.aws.cloud.qdrant.io:6333  \\\n\n  --header  'Authorization: Bearer <provide-your-own-key>' \n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nqdrant_client  =  QdrantClient(\n\n     \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n    api_key = \"<paste-your-api-key-here>\" ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({\n\n  host :   \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n  apiKey :   \"<paste-your-api-key-here>\" ,\n\n});\n\n```\n\n```\nusing   Qdrant.Client ;\n\n\n\nvar  client =  new  QdrantClient(\n\n   \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n  https:  true ,\n\n  apiKey:  \"<paste-your-api-key-here>\" \n\n);\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"xyz-example.eu-central.aws.cloud.qdrant.io:6334\" ) \n\n     .with_api_key( \"<paste-your-api-key-here>\" ) \n\n     .build() \n\n     .unwrap(); \n\n```\n\n##### Table of contents\n\n- [ Create API keys ](https://qdrant.tech/documentation/cloud/authentication/#create-api-keys)\n- [ Authenticate via SDK ](https://qdrant.tech/documentation/cloud/authentication/#authenticate-via-sdk)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/authentication.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/backups/": "# Backups\n\nThere are situations where you need to restore your cluster because of application or system failure.\nIn most cases you will have a source of truth for your data in a regular database and would be able to reindex the data into your Qdrant vector search cluster.\nHowever, encoding and uploading a big amount of data might require a long time.\nFor high availability critical projects we highly recommend relying on replication, which is always a better option, because it guarantees the proper cluster functionality as long as at least one replica is running.\nFor less critical use-cases you can make use of one of the available options.\n\n## Automatic backups\n\nThe cloud platform offers an option for automatic backups of your clusters. It is possible to configure periodical file system level snapshots to restore a cluster from a hard copy.\nOn the cluster settings section you can choose how often a backup should be taken and how many copies you want to keep.\n\nTo restore a Qdrant cluster from backup, you can select a desired backup copy version and start the restore process.\nAttention: during the restoring process the affected cluster will not be available because the cluster will be deleted and created from scratch from the backup copy.\nPlease also note, that if you changed the cluster setup after the copy was created, the new cluster will reset to the previous configuration.\n\n## Self-service backups\n\nQdrant engine offers a snapshot API that allows to create a snapshot of a particular collection or even the whole storage.\nPlease refer to the[ snapshot documentation ](../../concepts/snapshots/)for details.\n\nHere is how you can quickly snapshot and recover a collection:\n\n1. Take a snapshot\n    - In case of a single node cluster, simply call the snapshot endpoint on the exposed url.\n\n- In case of a multi node cluster you\u2019d need to take a snapshot on each node that the collection resides upon. To achieve this, you simply prepend `node-{num}-` to your cluster url and call the[ snapshot endpoint ](../../concepts/snapshots/#create-snapshot)on the individual hosts, starting with node 0 up to the number of nodes minus one.\n\n- In the response you\u2019ll get the name of the snapshot taken.\n\n2. In case of a single node cluster, simply call the snapshot endpoint on the exposed url.\n\n3. In case of a multi node cluster you\u2019d need to take a snapshot on each node that the collection resides upon. To achieve this, you simply prepend `node-{num}-` to your cluster url and call the[ snapshot endpoint ](../../concepts/snapshots/#create-snapshot)on the individual hosts, starting with node 0 up to the number of nodes minus one.\n\n4. In the response you\u2019ll get the name of the snapshot taken.\n5. Delete and recreate the collection.\n6. Recover the snapshot\n    - Call the[ recover endpoint ](../../concepts/snapshots/#recover-in-cluster-deployment)with location pointing to the snapshot file ( `file:///qdrant/snapshots/{collection_name}/{snapshot_file_name}` ) you got for each host.\n\n7. Call the[ recover endpoint ](../../concepts/snapshots/#recover-in-cluster-deployment)with location pointing to the snapshot file ( `file:///qdrant/snapshots/{collection_name}/{snapshot_file_name}` ) you got for each host.\n\n\n##### Table of contents\n\n- [ Automatic backups ](https://qdrant.tech/documentation/cloud/backups/#automatic-backups)\n- [ Self-service backups ](https://qdrant.tech/documentation/cloud/backups/#self-service-backups)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/backups.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/capacity-sizing/": "# Capacity and sizing\n\nWe have been asked a lot about the optimal cluster configuration to serve a number of vectors.\nThe only right answer is \u201cIt depends\u201d.\n\nIt depends on a number of factors and options you can choose for your collections.\n\n## Basic configuration\n\nIf you need to keep all vectors in memory for maximum performance, there is a very rough formula for estimating the needed memory size looks like this:\n\n`memory_size = number_of_vectors * vector_dimension * 4 bytes * 1.5\n`\n\nExtra 50% is needed for metadata (indexes, point versions, etc.) as well as for temporary segments constructed during the optimization process.\n\nIf you need to have payloads along with the vectors, it is recommended to store it on the disc, and only keep[ indexed fields ](../../concepts/indexing/#payload-index)in RAM.\nRead more about the payload storage in the[ Storage ](../../concepts/storage/#payload-storage)section.\n\n## Storage focused configuration\n\nIf your priority is to serve large amount of vectors with an average search latency, it is recommended to configure[ mmap storage ](../../concepts/storage/#configuring-memmap-storage).\nIn this case vectors will be stored on the disc in memory-mapped files, and only the most frequently used vectors will be kept in RAM.\n\nThe amount of available RAM will significantly affect the performance of the search.\nAs a rule of thumb, if you keep 2 times less vectors in RAM, the search latency will be 2 times lower.\n\nThe speed of disks is also important.[ Let us know ](mailto:cloud@qdrant.io)if you have special requirements for a high-volume search.\n\n## Sub-groups oriented configuration\n\nIf your use case assumes that the vectors are split into multiple collections or sub-groups based on payload values,\nit is recommended to configure memory-map storage.\nFor example, if you serve search for multiple users, but each of them has an subset of vectors which they use independently.\n\nIn this scenatio only the active subset of vectors will be kept in RAM, which allows\nthe fast search for the most active and recent users.\n\nIn this case you can estimate required memory size as follows:\n\n`memory_size = number_of_active_vectors * vector_dimension * 4 bytes * 1.5\n`\n\n##### Table of contents\n\n- [ Basic configuration ](https://qdrant.tech/documentation/cloud/capacity-sizing/#basic-configuration)\n- [ Storage focused configuration ](https://qdrant.tech/documentation/cloud/capacity-sizing/#storage-focused-configuration)\n- [ Sub-groups oriented configuration ](https://qdrant.tech/documentation/cloud/capacity-sizing/#sub-groups-oriented-configuration)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/capacity-sizing.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/cluster-scaling/": "# Cluster scaling\n\nThe amount of data is always growing and at some point you might need to upgrade the capacity of your cluster.\nThere are different options for how it can be done.\n\n## Vertical scaling\n\nVertical scaling, also known as vertical expansion, is the process of increasing the capacity of a cluster by adding more resources, such as memory, storage, or processing power.\n\nYou can start with a minimal cluster configuration of 2GB of RAM and resize it up to 64GB of RAM (or even more if desired) over the time step by step with the growing amount of data in your application.\nIf your cluster consists of several nodes each node will need to be scaled to the same size.\nPlease note that vertical cluster scaling will require a short downtime period to restart your cluster.\nIn order to avoid a downtime you can make use of data replication, which can be configured on the collection level.\nVertical scaling can be initiated on the cluster detail page via the button \u201cscale up\u201d.\n\n## Horizontal scaling\n\nVertical scaling can be an effective way to improve the performance of a cluster and extend the capacity, but it has some limitations.\nThe main disadvantage of vertical scaling is that there are limits to how much a cluster can be expanded.\nAt some point, adding more resources to a cluster can become impractical or cost-prohibitive.\nIn such cases, horizontal scaling may be a more effective solution.\nHorizontal scaling, also known as horizontal expansion, is the process of increasing the capacity of a cluster by adding more nodes and distributing the load and data among them.\nThe horizontal scaling at Qdrant starts on the collection level.\nYou have to choose the number of shards you want to distribute your collection around while creating the collection.\nPlease refer to the[ sharding documentation ](../../guides/distributed_deployment/#sharding)section for details.\n\nImportant: The number of shards means the maximum amount of nodes you can add to your cluster. In the beginning, all the shards can reside on one node.\nWith the growing amount of data you can add nodes to your cluster and move shards to the dedicated nodes using the[ cluster setup API ](../../guides/distributed_deployment/#cluster-scaling).\n\nWe will be glad to consult you on an optimal strategy for scaling.[ Let us know ](mailto:cloud@qdrant.io)your needs and decide together on a proper solution. We plan to introduce an auto-scaling functionality. Since it is one of most desired features, it has a high priority on our Cloud roadmap.\n\n##### Table of contents\n\n- [ Vertical scaling ](https://qdrant.tech/documentation/cloud/cluster-scaling/#vertical-scaling)\n- [ Horizontal scaling ](https://qdrant.tech/documentation/cloud/cluster-scaling/#horizontal-scaling)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/cluster-scaling.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/aws-marketplace/": "# Qdrant Cloud on AWS Marketplace\n\n## Overview\n\nOur[ AWS Marketplace ](https://aws.amazon.com/marketplace/pp/prodview-rtphb42tydtzg)listing streamlines access to Qdrant for users who rely on Amazon Web Services for hosting and application development. Please note that, while Qdrant\u2019s clusters run on AWS, you will still use the Qdrant Cloud infrastructure.\n\n## Billing\n\nYou don\u2019t need to use a credit card to sign up for Qdrant Cloud. Instead, all billing is processed through the AWS Marketplace and the usage of Qdrant is added to your existing billing for AWS services. It is common for AWS to abstract usage based pricing in the AWS marketplace, as there are too many factors to model when calculating billing from the AWS side.\n\nImage: [ pricing ](https://qdrant.tech/docs/cloud/pricing.png)\n\nImage: [ pricing ](https://qdrant.tech/docs/cloud/pricing.png)\n\nThe payment is carried out via your AWS Account. To get a clearer idea for the pricing structure, please use our[ Billing Calculator ](https://cloud.qdrant.io/calculator).\n\n## How to subscribe\n\n1. Go to[ Qdrant\u2019s AWS Marketplace listing ](https://aws.amazon.com/marketplace/pp/prodview-rtphb42tydtzg).\n2. Click the bright orange button - **View purchase options** .\n3. On the next screen, under Purchase, click **Subscribe** .\n4. Up top, on the green banner, click **Set up your account** .Image: [ setup ](https://qdrant.tech/docs/cloud/setup.png)\n\n\nImage: [ setup ](https://qdrant.tech/docs/cloud/setup.png)\n\nYou will be transferred outside of AWS to[ Qdrant Cloud ](https://qdrant.to/cloud)via your unique AWS Offer ID.\n\nThe Billing Details screen will open in Qdrant Cloud Console. Stay in this console if you want to create your first Qdrant Cluster hosted on AWS.\n\n **Note:** You do not have to return to the AWS Control Panel. All Qdrant infrastructure is provisioned from the Qdrant Cloud Console.\n\n## Next steps\n\nNow that you have signed up via AWS Marketplace, please read our instructions to get started:\n\n1. Learn more about[ cluster creation and basic config ](../../cloud/create-cluster/)in Qdrant Cloud.\n2. Learn how to[ authenticate and access your cluster ](../../cloud/authentication/).\n3. Additional open source[ documentation ](../../troubleshooting/).\n\n\nLearn more about[ cluster creation and basic config ](../../cloud/create-cluster/)in Qdrant Cloud.\n\nLearn how to[ authenticate and access your cluster ](../../cloud/authentication/).\n\nAdditional open source[ documentation ](../../troubleshooting/).\n\n##### Table of contents\n\n- [ Overview ](https://qdrant.tech/documentation/cloud/aws-marketplace/#overview)\n- [ Billing ](https://qdrant.tech/documentation/cloud/aws-marketplace/#billing)\n- [ How to subscribe ](https://qdrant.tech/documentation/cloud/aws-marketplace/#how-to-subscribe)\n- [ Next steps ](https://qdrant.tech/documentation/cloud/aws-marketplace/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/aws-marketplace.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/collections/": "# Collections\n\nA collection is a named set of points (vectors with a payload) among which you can search. The vector of each point within the same collection must have the same dimensionality and be compared by a single metric.[ Named vectors ](https://qdrant.tech/documentation/concepts/collections/#collection-with-multiple-vectors)can be used to have multiple vectors in a single point, each of which can have their own dimensionality and metric requirements.\n\nDistance metrics are used to measure similarities among vectors.\nThe choice of metric depends on the way vectors obtaining and, in particular, on the method of neural network encoder training.\n\nQdrant supports these most popular types of metrics:\n\n- Dot product: `Dot` -[ [wiki] ](https://en.wikipedia.org/wiki/Dot_product)\n- Cosine similarity: `Cosine` -[ [wiki] ](https://en.wikipedia.org/wiki/Cosine_similarity)\n- Euclidean distance: `Euclid` -[ [wiki] ](https://en.wikipedia.org/wiki/Euclidean_distance)\n- Manhattan distance: `Manhattan` -[ [wiki] ](https://en.wikipedia.org/wiki/Taxicab_geometry)\n\n\nIn addition to metrics and vector size, each collection uses its own set of parameters that controls collection optimization, index construction, and vacuum.\nThese settings can be changed at any time by a corresponding request.\n\n## Setting up multitenancy\n\n **How many collections should you create?** In most cases, you should only use a single collection with payload-based partitioning. This approach is called[ multitenancy ](https://en.wikipedia.org/wiki/Multitenancy). It is efficient for most of users, but it requires additional configuration.[ Learn how to set it up ](../../tutorials/multiple-partitions/)\n\n **When should you create multiple collections?** When you have a limited number of users and you need isolation. This approach is flexible, but it may be more costly, since creating numerous collections may result in resource overhead. Also, you need to ensure that they do not affect each other in any way, including performance-wise.\n\n## Create a collection\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 300,\n\n      \"distance\": \"Cosine\"\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 100 , distance = models . Distance . COSINE),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  { size:  100 , distance :   \"Cosine\"  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorsConfig}, \n\n}; \n\n\n\n//The Rust client uses Qdrant's GRPC interface\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  100 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nIn addition to the required options, you can also specify custom values for the following collection options:\n\n- `hnsw_config` - see[ indexing ](../indexing/#vector-index)for details.\n- `wal_config` - Write-Ahead-Log related configuration. See more details about[ WAL ](../storage/#versioning)\n- `optimizers_config` - see[ optimizer ](../optimizer)for details.\n- `shard_number` - which defines how many shards the collection should have. See[ distributed deployment ](../../guides/distributed_deployment#sharding)section for details.\n- `on_disk_payload` - defines where to store payload data. If `true` - payload will be stored on disk only. Might be useful for limiting the RAM usage in case of large payload.\n- `quantization_config` - see[ quantization ](../../guides/quantization/#setting-up-quantization-in-qdrant)for details.\n\n\nDefault parameters for the optional collection parameters are defined in[ configuration file ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml).\n\nSee[ schema definitions ](https://qdrant.github.io/qdrant/redoc/index.html#operation/create_collection)and a[ configuration file ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml)for more information about collection and vector parameters.\n\n *Available as of v1.2.0* \n\nVectors all live in RAM for very quick access. The `on_disk` parameter can be\nset in the vector configuration. If true, all vectors will live on disk. This\nwill enable the use of[ memmaps ](../../concepts/storage/#configuring-memmap-storage),\nwhich is suitable for ingesting a large amount of data.\n\n### Create collection from another collection\n\n *Available as of v1.0.0* \n\nIt is possible to initialize a collection from another existing collection.\n\nThis might be useful for experimenting quickly with different configurations for the same data set.\n\nMake sure the vectors have the same size and distance function when setting up the vectors configuration in the new collection.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 100,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"init_from\": {\n\n       \"collection\": \"{from_collection_name}\"\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 100 , distance = models . Distance . COSINE),\n\n    init_from = models . InitFrom(collection = \" {from_collection_name} \" ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  { size:  100 , distance :   \"Cosine\"  },\n\n  init_from :  { collection :   \"{from_collection_name}\"  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorsConfig}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  100 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         init_from_collection:  Some ( \"{from_collection_name}\" .to_string()), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n### Collection with multiple vectors\n\n *Available as of v0.10.0* \n\nIt is possible to have multiple vectors per record.\nThis feature allows for multiple vector storages per collection.\nTo distinguish vectors in one record, they should have a unique name defined when creating the collection.\nEach named vector in this mode has its distance and size:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"image\": {\n\n            \"size\": 4,\n\n            \"distance\": \"Dot\"\n\n        },\n\n        \"text\": {\n\n            \"size\": 8,\n\n            \"distance\": \"Cosine\"\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = {\n\n         \"image\" : models . VectorParams(size = 4 , distance = models . Distance . DOT),\n\n         \"text\" : models . VectorParams(size = 8 , distance = models . Distance . COSINE),\n\n    },\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    image :  { size:  4 , distance :   \"Dot\"  },\n\n    text :  { size:  8 , distance :   \"Cosine\"  },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorParamsMap, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::ParamsMap(VectorParamsMap   { \n\n                 map: [ \n\n                     ( \n\n                         \"image\" .to_string(), \n\n                         VectorParams   { \n\n                             size:  4 , \n\n                             distance:  Distance ::Dot.into(), \n\n                             .. Default ::default() \n\n                         }, \n\n                     ), \n\n                     ( \n\n                         \"text\" .to_string(), \n\n                         VectorParams   { \n\n                             size:  8 , \n\n                             distance:  Distance ::Cosine.into(), \n\n                             .. Default ::default() \n\n                         }, \n\n                     ), \n\n                 ] \n\n                 .into(), \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFor rare use cases, it is possible to create a collection without any vector storage.\n\n *Available as of v1.1.1* \n\nFor each named vector you can optionally specify[ hnsw_config ](../indexing/#vector-index)or[ quantization_config ](../../guides/quantization/#setting-up-quantization-in-qdrant)to\ndeviate from the collection configuration. This can be useful to fine-tune\nsearch performance on a vector level.\n\n *Available as of v1.2.0* \n\nVectors all live in RAM for very quick access. On a per-vector basis you can set `on_disk` to true to store all vectors on disk at all times. This will enable\nthe use of[ memmaps ](../../concepts/storage/#configuring-memmap-storage),\nwhich is suitable for ingesting a large amount of data.\n\n### Collection with sparse vectors\n\n *Available as of v1.7.0* \n\nQdrant supports sparse vectors as a first-class citizen.\n\nSparse vectors are useful for text search, where each word is represented as a separate dimension.\n\nCollections can contain sparse vectors as additional[ named vectors ](https://qdrant.tech/documentation/concepts/collections/#collection-with-multiple-vectors)along side regular dense vectors in a single point.\n\nUnlike dense vectors, sparse vectors must be named.\nAnd additionally, sparse vectors and dense vectors must have different names within a collection.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"sparse_vectors\": {\n\n        \"text\": { },\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    sparse_vectors_config = {\n\n         \"text\" : models . SparseVectorParams(),\n\n    },\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  sparse_vectors :  {\n\n    text :  { },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   SparseVectorParams,   VectorParamsMap, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         sparse_vectors_config:  Some (SparseVectorsConfig   { \n\n             map: [ \n\n                     ( \n\n                         \"text\" .to_string(), \n\n                         SparseVectorParams   {}, \n\n                     ), \n\n                 ] \n\n                 .into(), \n\n             }), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nOutside of a unique name, there are no required configuration parameters for sparse vectors.\n\nThe distance function for sparse vectors is always `Dot` and does not need to be specified.\n\nHowever, there are optional parameters to tune the underlying[ sparse vector index ](../indexing/#sparse-vector-index).\n\n### Delete collection\n\n`DELETE /collections/{collection_name}\n`\n\n`client . delete_collection(collection_name = \" {collection_name} \" )\n`\n\n`client.deleteCollection( \"{collection_name}\" );\n`\n\n`client.delete_collection( \"{collection_name}\" ). await ? ; \n`\n\n### Update collection parameters\n\nDynamic parameter updates may be helpful, for example, for more efficient initial loading of vectors.\nFor example, you can disable indexing during the upload process, and enable it immediately after the upload is finished.\nAs a result, you will not waste extra computation resources on rebuilding the index.\n\nThe following command enables indexing for segments that have more than 10000 kB of vectors stored:\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"optimizers_config\": {\n\n        \"indexing_threshold\": 10000\n\n    }\n\n}\n\n```\n\n```\nclient . update_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    optimizer_config = models . OptimizersConfigDiff(indexing_threshold = 10000 ),\n\n)\n\n```\n\n```\nclient.updateCollection( \"{collection_name}\" , {\n\n  optimizers_config :  {\n\n    indexing_threshold:  10000 ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::OptimizersConfigDiff; \n\n\n\nclient \n\n     .update_collection( \n\n         \"{collection_name}\" , \n\n         & OptimizersConfigDiff   { \n\n             indexing_threshold:  Some ( 10000 ), \n\n             .. Default ::default() \n\n         }, \n\n         None , \n\n         None , \n\n         None , \n\n         None , \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nThe following parameters can be updated:\n\n- `optimizers_config` - see[ optimizer ](../optimizer/)for details.\n- `hnsw_config` - see[ indexing ](../indexing/#vector-index)for details.\n- `quantization_config` - see[ quantization ](../../guides/quantization/#setting-up-quantization-in-qdrant)for details.\n- `vectors` - vector-specific configuration, including individual `hnsw_config` , `quantization_config` and `on_disk` settings.\n- `params` - other collection parameters, including `write_consistency_factor` and `on_disk_payload` .\n\n\nFull API specification is available in[ schema definitions ](https://qdrant.github.io/qdrant/redoc/index.html#tag/collections/operation/update_collection).\n\nCalls to this endpoint may be blocking as it waits for existing optimizers to\nfinish. We recommended against using this in a production database as it may\nintroduce huge overhead due to the rebuilding of the index.\n\n#### Update vector parameters\n\n *Available as of v1.4.0* \n\n`\"\"`\n\nQdrant 1.4 adds support for updating more collection parameters at runtime. HNSW\nindex, quantization and disk configurations can now be changed without\nrecreating a collection. Segments (with index and quantized data) will\nautomatically be rebuilt in the background to match updated parameters.\n\nTo put vector data on disk for a collection that **does not have** named vectors,\nuse `\"\"` as name:\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"\": {\n\n            \"on_disk\": true\n\n        }\n\n    },\n\n}\n\n```\n\nTo put vector data on disk for a collection that **does have** named vectors:\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"my_vector\": {\n\n            \"on_disk\": true\n\n        }\n\n    },\n\n}\n\n```\n\nIn the following example the HNSW index and quantization parameters are updated,\nboth for the whole collection, and for `my_vector` specifically:\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"my_vector\": {\n\n            \"hnsw_config\": {\n\n                \"m\": 32,\n\n                \"ef_construct\": 123\n\n            },\n\n            \"quantization_config\": {\n\n                \"product\": {\n\n                    \"compression\": \"x32\",\n\n                    \"always_ram\": true\n\n                }\n\n            },\n\n            \"on_disk\": true\n\n        }\n\n    },\n\n    \"hnsw_config\": {\n\n        \"ef_construct\": 123\n\n    },\n\n    \"quantization_config\": {\n\n        \"scalar\": {\n\n            \"type\": \"int8\",\n\n            \"quantile\": 0.8,\n\n            \"always_ram\": false\n\n        }\n\n    }\n\n}\n\n```\n\n```\nclient . update_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = {\n\n         \"my_vector\" : models . VectorParamsDiff(\n\n            hnsw_config = models . HnswConfigDiff(\n\n                m = 32 ,\n\n                ef_construct = 123 ,\n\n            ),\n\n            quantization_config = models . ProductQuantization(\n\n                product = models . ProductQuantizationConfig(\n\n                    compression = models . CompressionRatio . X32,\n\n                    always_ram = True ,\n\n                ),\n\n            ),\n\n            on_disk = True ,\n\n        ),\n\n    },\n\n    hnsw_config = models . HnswConfigDiff(\n\n        ef_construct = 123 ,\n\n    ),\n\n    quantization_config = models . ScalarQuantization(\n\n        scalar = models . ScalarQuantizationConfig(\n\n             type = models . ScalarType . INT8,\n\n            quantile = 0.8 ,\n\n            always_ram = False ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nclient.updateCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    my_vector :  {\n\n      hnsw_config :  {\n\n        m:  32 ,\n\n        ef_construct:  123 ,\n\n      },\n\n      quantization_config :  {\n\n        product :  {\n\n          compression :   \"x32\" ,\n\n          always_ram:  true ,\n\n        },\n\n      },\n\n      on_disk:  true ,\n\n    },\n\n  },\n\n  hnsw_config :  {\n\n    ef_construct:  123 ,\n\n  },\n\n  quantization_config :  {\n\n    scalar :  {\n\n       type :   \"int8\" ,\n\n      quantile:  0.8 ,\n\n      always_ram:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\nuse   qdrant_client::qdrant::{ \n\n     quantization_config_diff::Quantization,   vectors_config_diff::Config,   HnswConfigDiff, \n\n     QuantizationConfigDiff,   QuantizationType,   ScalarQuantization,   VectorParamsDiff, \n\n     VectorsConfigDiff, \n\n}; \n\n\n\nclient \n\n     .update_collection( \n\n         \"{collection_name}\" , \n\n         None , \n\n         None , \n\n         None , \n\n         Some ( & HnswConfigDiff   { \n\n             ef_construct:  Some ( 123 ), \n\n             .. Default ::default() \n\n         }), \n\n         Some ( & VectorsConfigDiff   { \n\n             config:  Some (Config::ParamsMap( \n\n                 qdrant_client::qdrant::VectorParamsDiffMap   { \n\n                     map:  HashMap ::from([( \n\n                         ( \"my_vector\" .into()), \n\n                         VectorParamsDiff   { \n\n                             hnsw_config:  Some (HnswConfigDiff   { \n\n                                 m:  Some ( 32 ), \n\n                                 ef_construct:  Some ( 123 ), \n\n                                 .. Default ::default() \n\n                             }), \n\n                             .. Default ::default() \n\n                         }, \n\n                     )]), \n\n                 }, \n\n             )), \n\n         }), \n\n         Some ( & QuantizationConfigDiff   { \n\n             quantization:  Some (Quantization::Scalar(ScalarQuantization   { \n\n                 r#type:  QuantizationType ::Int8   as   i32 , \n\n                 quantile:  Some ( 0.8 ), \n\n                 always_ram:  Some ( true ), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n     ) \n\n     . await ? ; \n\n```\n\n## Collection info\n\nQdrant allows determining the configuration parameters of an existing collection to better understand how the points are\ndistributed and indexed.\n\n```\nGET /collections/{collection_name}\n\n{\n\n    \"result\": {\n\n        \"status\": \"green\",\n\n        \"optimizer_status\": \"ok\",\n\n        \"vectors_count\": 1068786,\n\n        \"indexed_vectors_count\": 1024232,\n\n        \"points_count\": 1068786,\n\n        \"segments_count\": 31,\n\n        \"config\": {\n\n            \"params\": {\n\n                \"vectors\": {\n\n                    \"size\": 384,\n\n                    \"distance\": \"Cosine\"\n\n                },\n\n                \"shard_number\": 1,\n\n                \"replication_factor\": 1,\n\n                \"write_consistency_factor\": 1,\n\n                \"on_disk_payload\": false\n\n            },\n\n            \"hnsw_config\": {\n\n                \"m\": 16,\n\n                \"ef_construct\": 100,\n\n                \"full_scan_threshold\": 10000,\n\n                \"max_indexing_threads\": 0\n\n            },\n\n            \"optimizer_config\": {\n\n                \"deleted_threshold\": 0.2,\n\n                \"vacuum_min_vector_number\": 1000,\n\n                \"default_segment_number\": 0,\n\n                \"max_segment_size\": null,\n\n                \"memmap_threshold\": null,\n\n                \"indexing_threshold\": 20000,\n\n                \"flush_interval_sec\": 5,\n\n                \"max_optimization_threads\": 1\n\n            },\n\n            \"wal_config\": {\n\n                \"wal_capacity_mb\": 32,\n\n                \"wal_segments_ahead\": 0\n\n            }\n\n        },\n\n        \"payload_schema\": {}\n\n    },\n\n    \"status\": \"ok\",\n\n    \"time\": 0.00010143\n\n}\n\n```\n\n`client . get_collection(collection_name = \" {collection_name} \" )\n`\n\n`client.getCollection( \"{collection_name}\" );\n`\n\n`client.collection_info( \"{collection_name}\" ). await ? ; \n`\n\nIf you insert the vectors into the collection, the `status` field may become `yellow` whilst it is optimizing. It will become `green` once all the points are\nsuccessfully processed.\n\nThe following color statuses are possible:\n\n- \ud83d\udfe2 `green` : collection is ready\n- \ud83d\udfe1 `yellow` : collection is optimizing\n- \ud83d\udd34 `red` : an error occurred which the engine could not recover from\n\n\n### Approximate point and vector counts\n\nYou may be interested in the count attributes:\n\n- `points_count` - total number of objects (vectors and their payloads) stored in the collection\n- `vectors_count` - total number of vectors in a collection, useful if you have multiple vectors per point\n- `indexed_vectors_count` - total number of vectors stored in the HNSW or sparse index. Qdrant does not store all the vectors in the index, but only if an index segment might be created for a given configuration.\n\n\nThe above counts are not exact, but should be considered approximate. Depending\non how you use Qdrant these may give very different numbers than what you may\nexpect. It\u2019s therefore important **not** to rely on them.\n\nMore specifically, these numbers represent the count of points and vectors in\nQdrant\u2019s internal storage. Internally, Qdrant may temporarily duplicate points\nas part of automatic optimizations. It may keep changed or deleted points for a\nbit. And it may delay indexing of new points. All of that is for optimization\nreasons.\n\nUpdates you do are therefore not directly reflected in these numbers. If you see\na wildly different count of points, it will likely resolve itself once a new\nround of automatic optimizations has completed.\n\nTo clarify: these numbers don\u2019t represent the exact amount of points or vectors\nyou have inserted, nor does it represent the exact number of distinguishable\npoints or vectors you can query. If you want to know exact counts, refer to the[ count API ](../points/#counting-points).\n\n *Note: these numbers may be removed in a future version of Qdrant.* \n\n### Indexing vectors in HNSW\n\nIn some cases, you might be surprised the value of `indexed_vectors_count` is lower than `vectors_count` . This is an intended behaviour and\ndepends on the[ optimizer configuration ](../optimizer). A new index segment is built if the size of non-indexed vectors is higher than the\nvalue of `indexing_threshold` (in kB). If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW segment\ncreated and `indexed_vectors_count` might be equal to `0` .\n\nIt is possible to reduce the `indexing_threshold` for an existing collection by[ updating collection parameters ](https://qdrant.tech/documentation/concepts/collections/#update-collection-parameters).\n\n## Collection aliases\n\nIn a production environment, it is sometimes necessary to switch different versions of vectors seamlessly.\nFor example, when upgrading to a new version of the neural network.\n\nThere is no way to stop the service and rebuild the collection with new vectors in these situations.\nAliases are additional names for existing collections.\nAll queries to the collection can also be done identically, using an alias instead of the collection name.\n\nThus, it is possible to build a second collection in the background and then switch alias from the old to the new collection.\nSince all changes of aliases happen atomically, no concurrent requests will be affected during the switch.\n\n### Create alias\n\n```\nPOST /collections/aliases\n\n{\n\n    \"actions\": [\n\n        {\n\n            \"create_alias\": {\n\n                \"collection_name\": \"example_collection\",\n\n                \"alias_name\": \"production_collection\"\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . update_collection_aliases(\n\n    change_aliases_operations = [\n\n        models . CreateAliasOperation(\n\n            create_alias = models . CreateAlias(\n\n                collection_name = \"example_collection\" , alias_name = \"production_collection\" \n\n            )\n\n        )\n\n    ]\n\n)\n\n```\n\n```\nclient.updateCollectionAliases({\n\n  actions :  [\n\n    {\n\n      create_alias :  {\n\n        collection_name :   \"example_collection\" ,\n\n        alias_name :   \"production_collection\" ,\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n`client.create_alias( \"example_collection\" ,   \"production_collection\" ). await ? ; \n`\n\n### Remove alias\n\n```\nPOST /collections/aliases\n\n{\n\n    \"actions\": [\n\n        {\n\n            \"delete_alias\": {\n\n                \"alias_name\": \"production_collection\"\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . update_collection_aliases(\n\n    change_aliases_operations = [\n\n        models . DeleteAliasOperation(\n\n            delete_alias = models . DeleteAlias(alias_name = \"production_collection\" )\n\n        ),\n\n    ]\n\n)\n\n```\n\n```\nclient.updateCollectionAliases({\n\n  actions :  [\n\n    {\n\n      delete_alias :  {\n\n        alias_name :   \"production_collection\" ,\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n`client.delete_alias( \"production_collection\" ). await ? ; \n`\n\n### Switch collection\n\nMultiple alias actions are performed atomically.\nFor example, you can switch underlying collection with the following command:\n\n```\nPOST /collections/aliases\n\n{\n\n    \"actions\": [\n\n        {\n\n            \"delete_alias\": {\n\n                \"alias_name\": \"production_collection\"\n\n            }\n\n        },\n\n        {\n\n            \"create_alias\": {\n\n                \"collection_name\": \"example_collection\",\n\n                \"alias_name\": \"production_collection\"\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . update_collection_aliases(\n\n    change_aliases_operations = [\n\n        models . DeleteAliasOperation(\n\n            delete_alias = models . DeleteAlias(alias_name = \"production_collection\" )\n\n        ),\n\n        models . CreateAliasOperation(\n\n            create_alias = models . CreateAlias(\n\n                collection_name = \"example_collection\" , alias_name = \"production_collection\" \n\n            )\n\n        ),\n\n    ]\n\n)\n\n```\n\n```\nclient.updateCollectionAliases({\n\n  actions :  [\n\n    {\n\n      delete_alias :  {\n\n        alias_name :   \"production_collection\" ,\n\n      },\n\n    },\n\n    {\n\n      create_alias :  {\n\n        collection_name :   \"example_collection\" ,\n\n        alias_name :   \"production_collection\" ,\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nclient.delete_alias( \"production_collection\" ). await ? ; \n\nclient.create_alias( \"example_collection\" ,   \"production_collection\" ). await ? ; \n\n```\n\n### List collection aliases\n\n`GET /collections/{collection_name}/aliases\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . get_collection_aliases(collection_name = \" {collection_name} \" )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.getCollectionAliases( \"{collection_name}\" );\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.list_collection_aliases( \"{collection_name}\" ). await ? ; \n\n```\n\n### List all aliases\n\n`GET /aliases\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . get_aliases()\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.getAliases();\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.list_aliases(). await ? ; \n\n```\n\n### List all collections\n\n`GET /collections\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . get_collections()\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.getCollections();\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.list_collections(). await ? ; \n\n```\n\n##### Table of contents\n\n- [ Setting up multitenancy ](https://qdrant.tech/documentation/concepts/collections/#setting-up-multitenancy)\n- [ Create a collection ](https://qdrant.tech/documentation/concepts/collections/#create-a-collection)\n    - [ Create collection from another collection ](https://qdrant.tech/documentation/concepts/collections/#create-collection-from-another-collection)\n\n- [ Collection with multiple vectors ](https://qdrant.tech/documentation/concepts/collections/#collection-with-multiple-vectors)\n\n- [ Collection with sparse vectors ](https://qdrant.tech/documentation/concepts/collections/#collection-with-sparse-vectors)\n\n- [ Delete collection ](https://qdrant.tech/documentation/concepts/collections/#delete-collection)\n\n- [ Update collection parameters ](https://qdrant.tech/documentation/concepts/collections/#update-collection-parameters)\n- [ Collection info ](https://qdrant.tech/documentation/concepts/collections/#collection-info)\n    - [ Approximate point and vector counts ](https://qdrant.tech/documentation/concepts/collections/#approximate-point-and-vector-counts)\n\n- [ Indexing vectors in HNSW ](https://qdrant.tech/documentation/concepts/collections/#indexing-vectors-in-hnsw)\n- [ Collection aliases ](https://qdrant.tech/documentation/concepts/collections/#collection-aliases)\n    - [ Create alias ](https://qdrant.tech/documentation/concepts/collections/#create-alias)\n\n- [ Remove alias ](https://qdrant.tech/documentation/concepts/collections/#remove-alias)\n\n- [ Switch collection ](https://qdrant.tech/documentation/concepts/collections/#switch-collection)\n\n- [ List collection aliases ](https://qdrant.tech/documentation/concepts/collections/#list-collection-aliases)\n\n- [ List all aliases ](https://qdrant.tech/documentation/concepts/collections/#list-all-aliases)\n\n- [ List all collections ](https://qdrant.tech/documentation/concepts/collections/#list-all-collections)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/collections.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/payload/": "# Payload\n\nOne of the significant features of Qdrant is the ability to store additional information along with vectors.\nThis information is called `payload` in Qdrant terminology.\n\nQdrant allows you to store any information that can be represented using JSON.\n\nHere is an example of a typical payload:\n\n```\n{\n\n     \"name\" :  \"jacket\" ,\n\n     \"colors\" : [ \"red\" ,  \"blue\" ],\n\n     \"count\" :  10 ,\n\n     \"price\" :  11.99 ,\n\n     \"locations\" : [\n\n        {\n\n             \"lon\" :  52.5200 , \n\n             \"lat\" :  13.4050 \n\n        }\n\n    ],\n\n     \"reviews\" : [\n\n        {\n\n             \"user\" :  \"alice\" ,\n\n             \"score\" :  4 \n\n        },\n\n        {\n\n             \"user\" :  \"bob\" ,\n\n             \"score\" :  5 \n\n        }\n\n    ]\n\n}\n\n```\n\n## Payload types\n\nIn addition to storing payloads, Qdrant also allows you search based on certain kinds of values.\nThis feature is implemented as additional filters during the search and will enable you to incorporate custom logic on top of semantic similarity.\n\nDuring the filtering, Qdrant will check the conditions over those values that match the type of the filtering condition. If the stored value type does not fit the filtering condition - it will be considered not satisfied.\n\nFor example, you will get an empty output if you apply the[ range condition ](../filtering/#range)on the string data.\n\nHowever, arrays (multiple values of the same type) are treated a little bit different. When we apply a filter to an array, it will succeed if at least one of the values inside the array meets the condition.\n\nThe filtering process is discussed in detail in the section[ Filtering ](../filtering).\n\nLet\u2019s look at the data types that Qdrant supports for searching:\n\n### Integer\n\n `integer` - 64-bit integer in the range from `-9223372036854775808` to `9223372036854775807` .\n\nExample of single and multiple `integer` values:\n\n```\n{\n\n     \"count\" :  10 ,\n\n     \"sizes\" : [ 35 ,  36 ,  38 ]\n\n}\n\n```\n\n### Float\n\n `float` - 64-bit floating point number.\n\nExample of single and multiple `float` values:\n\n```\n{\n\n     \"price\" :  11.99 ,\n\n     \"ratings\" : [ 9.1 ,  9.2 ,  9.4 ]\n\n}\n\n```\n\n### Bool\n\nBool - binary value. Equals to `true` or `false` .\n\nExample of single and multiple `bool` values:\n\n```\n{\n\n     \"is_delivered\" :  true ,\n\n     \"responses\" : [ false ,  false ,  true ,  false ]\n\n}\n\n```\n\n### Keyword\n\n `keyword` - string value.\n\nExample of single and multiple `keyword` values:\n\n```\n{\n\n     \"name\" :  \"Alice\" ,\n\n     \"friends\" : [\n\n         \"bob\" ,\n\n         \"eva\" ,\n\n         \"jack\" \n\n    ]\n\n}\n\n```\n\n### Geo\n\n `geo` is used to represent geographical coordinates.\n\nExample of single and multiple `geo` values:\n\n```\n{\n\n     \"location\" : {\n\n         \"lon\" :  52.5200 ,\n\n         \"lat\" :  13.4050 \n\n    },\n\n     \"cities\" : [\n\n        {\n\n             \"lon\" :  51.5072 ,\n\n             \"lat\" :  0.1276 \n\n        },\n\n        {\n\n             \"lon\" :  40.7128 ,\n\n             \"lat\" :  74.0060 \n\n        }\n\n    ]\n\n}\n\n```\n\nCoordinate should be described as an object containing two fields: `lon` - for longitude, and `lat` - for latitude.\n\n## Create point with payload\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#tag/points/operation/upsert_points))\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1,\n\n            \"vector\": [0.05, 0.61, 0.76, 0.74],\n\n            \"payload\": {\"city\": \"Berlin\", \"price\": 1.99}\n\n        },\n\n        {\n\n            \"id\": 2,\n\n            \"vector\": [0.19, 0.81, 0.75, 0.11],\n\n            \"payload\": {\"city\": [\"Berlin\", \"London\"], \"price\": 1.99}\n\n        },\n\n        {\n\n            \"id\": 3,\n\n            \"vector\": [0.36, 0.55, 0.47, 0.94],\n\n            \"payload\": {\"city\": [\"Berlin\", \"Moscow\"], \"price\": [1.99, 2.99]}\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient(host = \"localhost\" , port = 6333 )\n\n\n\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1 ,\n\n            vector = [ 0.05 ,  0.61 ,  0.76 ,  0.74 ],\n\n            payload = {\n\n                 \"city\" :  \"Berlin\" ,\n\n                 \"price\" :  1.99 ,\n\n            },\n\n        ),\n\n        models . PointStruct(\n\n             id = 2 ,\n\n            vector = [ 0.19 ,  0.81 ,  0.75 ,  0.11 ],\n\n            payload = {\n\n                 \"city\" : [ \"Berlin\" ,  \"London\" ],\n\n                 \"price\" :  1.99 ,\n\n            },\n\n        ),\n\n        models . PointStruct(\n\n             id = 3 ,\n\n            vector = [ 0.36 ,  0.55 ,  0.47 ,  0.94 ],\n\n            payload = {\n\n                 \"city\" : [ \"Berlin\" ,  \"Moscow\" ],\n\n                 \"price\" : [ 1.99 ,  2.99 ],\n\n            },\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.upsert( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id:  1 ,\n\n      vector :  [ 0.05 ,  0.61 ,  0.76 ,  0.74 ],\n\n      payload :  {\n\n        city :   \"Berlin\" ,\n\n        price:  1.99 ,\n\n      },\n\n    },\n\n    {\n\n      id:  2 ,\n\n      vector :  [ 0.19 ,  0.81 ,  0.75 ,  0.11 ],\n\n      payload :  {\n\n        city :  [ \"Berlin\" ,  \"London\" ],\n\n        price:  1.99 ,\n\n      },\n\n    },\n\n    {\n\n      id:  3 ,\n\n      vector :  [ 0.36 ,  0.55 ,  0.47 ,  0.94 ],\n\n      payload :  {\n\n        city :  [ \"Berlin\" ,  \"Moscow\" ],\n\n        price :  [ 1.99 ,  2.99 ],\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::PointStruct}; \n\nuse   serde_json::json; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nlet   points   =   vec![ \n\n     PointStruct::new( \n\n         1 , \n\n         vec![ 0.05 ,   0.61 ,   0.76 ,   0.74 ], \n\n         json ! ( \n\n             { \"city\" :  \"Berlin\" ,   \"price\" :  1.99 } \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n     PointStruct::new( \n\n         2 , \n\n         vec![ 0.19 ,   0.81 ,   0.75 ,   0.11 ], \n\n         json ! ( \n\n             { \"city\" : [ \"Berlin\" ,   \"London\" ]} \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n     PointStruct::new( \n\n         3 , \n\n         vec![ 0.36 ,   0.55 ,   0.47 ,   0.94 ], \n\n         json ! ( \n\n             { \"city\" : [ \"Berlin\" ,   \"Moscow\" ],   \"price\" : [ 1.99 ,   2.99 ]} \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n]; \n\n\n\nclient \n\n     .upsert_points( \"{collection_name}\" .to_string(),   None ,   points,   None ) \n\n     . await ? ; \n\n```\n\n## Update payload\n\n### Set payload\n\nSet only the given payload values on a point.\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/set_payload)):\n\n```\nPOST /collections/{collection_name}/points/payload\n\n{\n\n    \"payload\": {\n\n        \"property1\": \"string\",\n\n        \"property2\": \"string\"\n\n    },\n\n    \"points\": [\n\n        0, 3, 100\n\n    ]\n\n}\n\n```\n\n```\nclient . set_payload(\n\n    collection_name = \" {collection_name} \" ,\n\n    payload = {\n\n         \"property1\" :  \"string\" ,\n\n         \"property2\" :  \"string\" ,\n\n    },\n\n    points = [ 0 ,  3 ,  10 ],\n\n)\n\n```\n\n```\nclient.setPayload( \"{collection_name}\" , {\n\n  payload :  {\n\n    property1 :   \"string\" ,\n\n    property2 :   \"string\" ,\n\n  },\n\n  points :  [ 0 ,  3 ,  10 ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   PointsIdsList,   PointsSelector, \n\n}; \n\nuse   serde_json::json; \n\n\n\nclient \n\n     .set_payload_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Points(PointsIdsList   { \n\n                 ids:  vec ! [ 0. into(),   3. into(),   10. into()], \n\n             })), \n\n         }, \n\n         json ! ({ \n\n             \"property1\" :  \"string\" , \n\n             \"property2\" :  \"string\" , \n\n         }) \n\n         .try_into() \n\n         .unwrap(), \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nYou don\u2019t need to know the ids of the points you want to modify. The alternative\nis to use filters.\n\n```\nPOST /collections/{collection_name}/points/payload\n\n{\n\n    \"payload\": {\n\n        \"property1\": \"string\",\n\n        \"property2\": \"string\"\n\n    },\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"color\",\n\n                \"match\": {\n\n                    \"value\": \"red\"\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . set_payload(\n\n    collection_name = \" {collection_name} \" ,\n\n    payload = {\n\n         \"property1\" :  \"string\" ,\n\n         \"property2\" :  \"string\" ,\n\n    },\n\n    points = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"color\" ,\n\n                match = models . MatchValue(value = \"red\" ),\n\n            ),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.setPayload( \"{collection_name}\" , {\n\n  payload :  {\n\n    property1 :   \"string\" ,\n\n    property2 :   \"string\" ,\n\n  },\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"color\" ,\n\n        match :  {\n\n          value :   \"red\" ,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   Condition,   Filter,   PointsSelector, \n\n}; \n\nuse   serde_json::json; \n\n\n\nclient \n\n     .set_payload_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Filter(Filter::must([ \n\n                 Condition::matches( \"color\" ,   \"red\" .to_string()), \n\n             ]))), \n\n         }, \n\n         json ! ({ \n\n             \"property1\" :  \"string\" , \n\n             \"property2\" :  \"string\" , \n\n         }) \n\n         .try_into() \n\n         .unwrap(), \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n### Overwrite payload\n\nFully replace any existing payload with the given one.\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/overwrite_payload)):\n\n```\nPUT /collections/{collection_name}/points/payload\n\n{\n\n    \"payload\": {\n\n        \"property1\": \"string\",\n\n        \"property2\": \"string\"\n\n    },\n\n    \"points\": [\n\n        0, 3, 100\n\n    ]\n\n}\n\n```\n\n```\nclient . overwrite_payload(\n\n    collection_name = \" {collection_name} \" ,\n\n    payload = {\n\n         \"property1\" :  \"string\" ,\n\n         \"property2\" :  \"string\" ,\n\n    },\n\n    points = [ 0 ,  3 ,  10 ],\n\n)\n\n```\n\n```\nclient.overwritePayload( \"{collection_name}\" , {\n\n  payload :  {\n\n    property1 :   \"string\" ,\n\n    property2 :   \"string\" ,\n\n  },\n\n  points :  [ 0 ,  3 ,  10 ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   PointsIdsList,   PointsSelector, \n\n}; \n\nuse   serde_json::json; \n\n\n\nclient \n\n     .overwrite_payload_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Points(PointsIdsList   { \n\n                 ids:  vec ! [ 0. into(),   3. into(),   10. into()], \n\n             })), \n\n         }, \n\n         json ! ({ \n\n             \"property1\" :  \"string\" , \n\n             \"property2\" :  \"string\" , \n\n         }) \n\n         .try_into() \n\n         .unwrap(), \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nLike[ set payload ](https://qdrant.tech/documentation/concepts/payload/#set-payload), you don\u2019t need to know the ids of the points\nyou want to modify. The alternative is to use filters.\n\n### Clear payload\n\nThis method removes all payload keys from specified points\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/clear_payload)):\n\n```\nPOST /collections/{collection_name}/points/payload/clear\n\n{\n\n    \"points\": [0, 3, 100]\n\n}\n\n```\n\n```\nclient . clear_payload(\n\n    collection_name = \" {collection_name} \" ,\n\n    points_selector = models . PointIdsList(\n\n        points = [ 0 ,  3 ,  100 ],\n\n    ),\n\n)\n\n```\n\n```\nclient.clearPayload( \"{collection_name}\" , {\n\n  points :  [ 0 ,  3 ,  100 ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   PointsIdsList,   PointsSelector, \n\n}; \n\n\n\nclient \n\n     .clear_payload( \n\n         \"{collection_name}\" , \n\n         None , \n\n         Some (PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Points(PointsIdsList   { \n\n                 ids:  vec ! [ 0. into(),   3. into(),   100. into()], \n\n             })), \n\n         }), \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n`models.FilterSelector`\n\n### Delete payload keys\n\nDelete specific payload keys from points.\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/delete_payload)):\n\n```\nPOST /collections/{collection_name}/points/payload/delete\n\n{\n\n    \"keys\": [\"color\", \"price\"],\n\n    \"points\": [0, 3, 100]\n\n}\n\n```\n\n```\nclient . delete_payload(\n\n    collection_name = \" {collection_name} \" ,\n\n    keys = [ \"color\" ,  \"price\" ],\n\n    points = [ 0 ,  3 ,  100 ],\n\n)\n\n```\n\n```\nclient.deletePayload( \"{collection_name}\" , {\n\n  keys :  [ \"color\" ,  \"price\" ],\n\n  points :  [ 0 ,  3 ,  100 ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   PointsIdsList,   PointsSelector, \n\n}; \n\n\n\nclient \n\n     .delete_payload_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Points(PointsIdsList   { \n\n                 ids:  vec ! [ 0. into(),   3. into(),   100. into()], \n\n             })), \n\n         }, \n\n         vec![ \"color\" .to_string(),   \"price\" .to_string()], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nAlternatively, you can use filters to delete payload keys from the points.\n\n```\nPOST /collections/{collection_name}/points/payload/delete\n\n{\n\n    \"keys\": [\"color\", \"price\"],\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"color\",\n\n                \"match\": {\n\n                    \"value\": \"red\"\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . delete_payload(\n\n    collection_name = \" {collection_name} \" ,\n\n    keys = [ \"color\" ,  \"price\" ],\n\n    points = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"color\" ,\n\n                match = models . MatchValue(value = \"red\" ),\n\n            ),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.deletePayload( \"{collection_name}\" , {\n\n  keys :  [ \"color\" ,  \"price\" ],\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"color\" ,\n\n        match :  {\n\n          value :   \"red\" ,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   Condition,   Filter,   PointsSelector, \n\n}; \n\n\n\nclient \n\n     .delete_payload_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Filter(Filter::must([ \n\n                 Condition::matches( \"color\" ,   \"red\" .to_string()), \n\n             ]))), \n\n         }, \n\n         vec![ \"color\" .to_string(),   \"price\" .to_string()], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n## Payload indexing\n\nTo search more efficiently with filters, Qdrant allows you to create indexes for payload fields by specifying the name and type of field it is intended to be.\n\nThe indexed fields also affect the vector index. See[ Indexing ](../indexing)for details.\n\nIn practice, we recommend creating an index on those fields that could potentially constrain the results the most.\nFor example, using an index for the object ID will be much more efficient, being unique for each record, than an index by its color, which has only a few possible values.\n\nIn compound queries involving multiple fields, Qdrant will attempt to use the most restrictive index first.\n\nTo create index for the field, you can use the following:\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#tag/collections/operation/create_field_index))\n\n```\nPUT /collections/{collection_name}/index\n\n{\n\n    \"field_name\": \"name_of_the_field_to_index\",\n\n    \"field_schema\": \"keyword\"\n\n}\n\n```\n\n```\nclient . create_payload_index(\n\n    collection_name = \" {collection_name} \" ,\n\n    field_name = \"name_of_the_field_to_index\" ,\n\n    field_schema = \"keyword\" ,\n\n)\n\n```\n\n```\nclient.createPayloadIndex( \"{collection_name}\" , {\n\n  field_name :   \"name_of_the_field_to_index\" ,\n\n  field_schema :   \"keyword\" ,\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::FieldType; \n\n\n\nclient \n\n     .create_field_index( \n\n         \"{collection_name}\" , \n\n         \"name_of_the_field_to_index\" , \n\n         FieldType::Keyword, \n\n         None , \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nThe index usage flag is displayed in the payload schema with the[ collection info API ](https://qdrant.github.io/qdrant/redoc/index.html#operation/get_collection).\n\nPayload schema example:\n\n```\n{\n\n     \"payload_schema\" : {\n\n         \"property1\" : {\n\n             \"data_type\" :  \"keyword\" \n\n        },\n\n         \"property2\" : {\n\n             \"data_type\" :  \"integer\" \n\n        }\n\n    }\n\n}\n\n```\n\n##### Table of contents\n\n- [ Payload types ](https://qdrant.tech/documentation/concepts/payload/#payload-types)\n    - [ Integer ](https://qdrant.tech/documentation/concepts/payload/#integer)\n\n- [ Float ](https://qdrant.tech/documentation/concepts/payload/#float)\n\n- [ Bool ](https://qdrant.tech/documentation/concepts/payload/#bool)\n\n- [ Keyword ](https://qdrant.tech/documentation/concepts/payload/#keyword)\n\n- [ Geo ](https://qdrant.tech/documentation/concepts/payload/#geo)\n- [ Create point with payload ](https://qdrant.tech/documentation/concepts/payload/#create-point-with-payload)\n- [ Update payload ](https://qdrant.tech/documentation/concepts/payload/#update-payload)\n    - [ Set payload ](https://qdrant.tech/documentation/concepts/payload/#set-payload)\n\n- [ Overwrite payload ](https://qdrant.tech/documentation/concepts/payload/#overwrite-payload)\n\n- [ Clear payload ](https://qdrant.tech/documentation/concepts/payload/#clear-payload)\n\n- [ Delete payload keys ](https://qdrant.tech/documentation/concepts/payload/#delete-payload-keys)\n- [ Payload indexing ](https://qdrant.tech/documentation/concepts/payload/#payload-indexing)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/payload.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/points/": "# Points\n\nThe points are the central entity that Qdrant operates with.\nA point is a record consisting of a vector and an optional[ payload ](../payload).\n\nYou can search among the points grouped in one[ collection ](../collections)based on vector similarity.\nThis procedure is described in more detail in the[ search ](../search)and[ filtering ](../filtering)sections.\n\nThis section explains how to create and manage vectors.\n\nAny point modification operation is asynchronous and takes place in 2 steps.\nAt the first stage, the operation is written to the Write-ahead-log.\n\nAfter this moment, the service will not lose the data, even if the machine loses power supply.\n\n## Awaiting result\n\nIf the API is called with the `&wait=false` parameter, or if it is not explicitly specified, the client will receive an acknowledgment of receiving data:\n\n```\n{\n\n     \"result\" : {\n\n         \"operation_id\" :  123 ,\n\n         \"status\" :  \"acknowledged\" \n\n    },\n\n     \"status\" :  \"ok\" ,\n\n     \"time\" :  0.000206061 \n\n}\n\n```\n\nThis response does not mean that the data is available for retrieval yet. This\nuses a form of eventual consistency. It may take a short amount of time before it\nis actually processed as updating the collection happens in the background. In\nfact, it is possible that such request eventually fails.\nIf inserting a lot of vectors, we also recommend using asynchronous requests to take advantage of pipelining.\n\nIf the logic of your application requires a guarantee that the vector will be available for searching immediately after the API responds, then use the flag `?wait=true` .\nIn this case, the API will return the result only after the operation is finished:\n\n```\n{\n\n     \"result\" : {\n\n         \"operation_id\" :  0 ,\n\n         \"status\" :  \"completed\" \n\n    },\n\n     \"status\" :  \"ok\" ,\n\n     \"time\" :  0.000206061 \n\n}\n\n```\n\n## Point IDs\n\nQdrant supports using both `64-bit unsigned integers` and `UUID` as identifiers for points.\n\nExamples of UUID string representations:\n\n- simple: `936DA01F9ABD4d9d80C702AF85C822A8`\n- hyphenated: `550e8400-e29b-41d4-a716-446655440000`\n- urn: `urn:uuid:F9168C5E-CEB2-4faa-B6BF-329BF39FA1E4`\n\n\nThat means that in every request UUID string could be used instead of numerical id.\nExample:\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": \"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\",\n\n            \"payload\": {\"color\": \"red\"},\n\n            \"vector\": [0.9, 0.1, 0.1]\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = \"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\" ,\n\n            payload = {\n\n                 \"color\" :  \"red\" ,\n\n            },\n\n            vector = [ 0.9 ,  0.1 ,  0.1 ],\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.upsert( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id :   \"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\" ,\n\n      payload :  {\n\n        color :   \"red\" ,\n\n      },\n\n      vector :  [ 0.9 ,  0.1 ,  0.1 ],\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::PointStruct}; \n\nuse   serde_json::json; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .upsert_points_blocking( \n\n         \"{collection_name}\" .to_string(), \n\n         None , \n\n         vec![PointStruct::new( \n\n             \"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\" .to_string(), \n\n             vec![ 0.05 ,   0.61 ,   0.76 ,   0.74 ], \n\n             json ! ( \n\n                 { \"color\" :  \"Red\" } \n\n             ) \n\n             .try_into() \n\n             .unwrap(), \n\n         )], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nand\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1,\n\n            \"payload\": {\"color\": \"red\"},\n\n            \"vector\": [0.9, 0.1, 0.1]\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1 ,\n\n            payload = {\n\n                 \"color\" :  \"red\" ,\n\n            },\n\n            vector = [ 0.9 ,  0.1 ,  0.1 ],\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nclient.upsert( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id:  1 ,\n\n      payload :  {\n\n        color :   \"red\" ,\n\n      },\n\n      vector :  [ 0.9 ,  0.1 ,  0.1 ],\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::PointStruct; \n\nuse   serde_json::json; \n\n\n\nclient \n\n     .upsert_points_blocking( \n\n         1 , \n\n         None , \n\n         vec![PointStruct::new( \n\n             \"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\" .to_string(), \n\n             vec![ 0.05 ,   0.61 ,   0.76 ,   0.74 ], \n\n             json ! ( \n\n                 { \"color\" :  \"Red\" } \n\n             ) \n\n             .try_into() \n\n             .unwrap(), \n\n         )], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nare both possible.\n\n## Upload points\n\nTo optimize performance, Qdrant supports batch loading of points. I.e., you can load several points into the service in one API call.\nBatching allows you to minimize the overhead of creating a network connection.\n\nThe Qdrant API supports two ways of creating batches - record-oriented and column-oriented.\nInternally, these options do not differ and are made only for the convenience of interaction.\n\nCreate points with batch:\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"batch\": {\n\n        \"ids\": [1, 2, 3],\n\n        \"payloads\": [\n\n            {\"color\": \"red\"},\n\n            {\"color\": \"green\"},\n\n            {\"color\": \"blue\"}\n\n        ],\n\n        \"vectors\": [\n\n            [0.9, 0.1, 0.1],\n\n            [0.1, 0.9, 0.1],\n\n            [0.1, 0.1, 0.9]\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = models . Batch(\n\n        ids = [ 1 ,  2 ,  3 ],\n\n        payloads = [\n\n            { \"color\" :  \"red\" },\n\n            { \"color\" :  \"green\" },\n\n            { \"color\" :  \"blue\" },\n\n        ],\n\n        vectors = [\n\n            [ 0.9 ,  0.1 ,  0.1 ],\n\n            [ 0.1 ,  0.9 ,  0.1 ],\n\n            [ 0.1 ,  0.1 ,  0.9 ],\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.upsert( \"{collection_name}\" , {\n\n  batch :  {\n\n    ids :  [ 1 ,  2 ,  3 ],\n\n    payloads :  [{ color :   \"red\"  }, { color :   \"green\"  }, { color :   \"blue\"  }],\n\n    vectors :  [\n\n      [ 0.9 ,  0.1 ,  0.1 ],\n\n      [ 0.1 ,  0.9 ,  0.1 ],\n\n      [ 0.1 ,  0.1 ,  0.9 ],\n\n    ],\n\n  },\n\n});\n\n```\n\nor record-oriented equivalent:\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1,\n\n            \"payload\": {\"color\": \"red\"},\n\n            \"vector\": [0.9, 0.1, 0.1]\n\n        },\n\n        {\n\n            \"id\": 2,\n\n            \"payload\": {\"color\": \"green\"},\n\n            \"vector\": [0.1, 0.9, 0.1]\n\n        },\n\n        {\n\n            \"id\": 3,\n\n            \"payload\": {\"color\": \"blue\"},\n\n            \"vector\": [0.1, 0.1, 0.9]\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1 ,\n\n            payload = {\n\n                 \"color\" :  \"red\" ,\n\n            },\n\n            vector = [ 0.9 ,  0.1 ,  0.1 ],\n\n        ),\n\n        models . PointStruct(\n\n             id = 2 ,\n\n            payload = {\n\n                 \"color\" :  \"green\" ,\n\n            },\n\n            vector = [ 0.1 ,  0.9 ,  0.1 ],\n\n        ),\n\n        models . PointStruct(\n\n             id = 3 ,\n\n            payload = {\n\n                 \"color\" :  \"blue\" ,\n\n            },\n\n            vector = [ 0.1 ,  0.1 ,  0.9 ],\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nclient.upsert( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id:  1 ,\n\n      payload :  { color :   \"red\"  },\n\n      vector :  [ 0.9 ,  0.1 ,  0.1 ],\n\n    },\n\n    {\n\n      id:  2 ,\n\n      payload :  { color :   \"green\"  },\n\n      vector :  [ 0.1 ,  0.9 ,  0.1 ],\n\n    },\n\n    {\n\n      id:  3 ,\n\n      payload :  { color :   \"blue\"  },\n\n      vector :  [ 0.1 ,  0.1 ,  0.9 ],\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::PointStruct; \n\nuse   serde_json::json; \n\n\n\nclient \n\n     .upsert_points_batch_blocking( \n\n         \"{collection_name}\" .to_string(), \n\n         None , \n\n         vec![ \n\n             PointStruct::new( \n\n                 1 , \n\n                 vec![ 0.9 ,   0.1 ,   0.1 ], \n\n                 json ! ( \n\n                     { \"color\" :  \"red\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n             PointStruct::new( \n\n                 2 , \n\n                 vec![ 0.1 ,   0.9 ,   0.1 ], \n\n                 json ! ( \n\n                     { \"color\" :  \"green\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n             PointStruct::new( \n\n                 3 , \n\n                 vec![ 0.1 ,   0.1 ,   0.9 ], \n\n                 json ! ( \n\n                     { \"color\" :  \"blue\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n         ], \n\n         None , \n\n         100 , \n\n     ) \n\n     . await ? ; \n\n```\n\nAll APIs in Qdrant, including point loading, are idempotent.\nIt means that executing the same method several times in a row is equivalent to a single execution.\n\nIn this case, it means that points with the same id will be overwritten when re-uploaded.\n\nIdempotence property is useful if you use, for example, a message queue that doesn\u2019t provide an exactly-ones guarantee.\nEven with such a system, Qdrant ensures data consistency.\n\n *Available as of v0.10.0* \n\nIf the collection was created with multiple vectors, each vector data can be provided using the vector\u2019s name:\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1,\n\n            \"vector\": {\n\n                \"image\": [0.9, 0.1, 0.1, 0.2],\n\n                \"text\": [0.4, 0.7, 0.1, 0.8, 0.1, 0.1, 0.9, 0.2]\n\n            }\n\n        },\n\n        {\n\n            \"id\": 2,\n\n            \"vector\": {\n\n                \"image\": [0.2, 0.1, 0.3, 0.9],\n\n                \"text\": [0.5, 0.2, 0.7, 0.4, 0.7, 0.2, 0.3, 0.9]\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1 ,\n\n            vector = {\n\n                 \"image\" : [ 0.9 ,  0.1 ,  0.1 ,  0.2 ],\n\n                 \"text\" : [ 0.4 ,  0.7 ,  0.1 ,  0.8 ,  0.1 ,  0.1 ,  0.9 ,  0.2 ],\n\n            },\n\n        ),\n\n        models . PointStruct(\n\n             id = 2 ,\n\n            vector = {\n\n                 \"image\" : [ 0.2 ,  0.1 ,  0.3 ,  0.9 ],\n\n                 \"text\" : [ 0.5 ,  0.2 ,  0.7 ,  0.4 ,  0.7 ,  0.2 ,  0.3 ,  0.9 ],\n\n            },\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nclient.upsert( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id:  1 ,\n\n      vector :  {\n\n        image :  [ 0.9 ,  0.1 ,  0.1 ,  0.2 ],\n\n        text :  [ 0.4 ,  0.7 ,  0.1 ,  0.8 ,  0.1 ,  0.1 ,  0.9 ,  0.2 ],\n\n      },\n\n    },\n\n    {\n\n      id:  2 ,\n\n      vector :  {\n\n        image :  [ 0.2 ,  0.1 ,  0.3 ,  0.9 ],\n\n        text :  [ 0.5 ,  0.2 ,  0.7 ,  0.4 ,  0.7 ,  0.2 ,  0.3 ,  0.9 ],\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::PointStruct; \n\nuse   std::collections::HashMap; \n\n\n\nclient \n\n     .upsert_points_blocking( \n\n         \"{collection_name}\" .to_string(), \n\n         None , \n\n         vec![ \n\n             PointStruct::new( \n\n                 1 , \n\n                 HashMap::from([ \n\n                     ( \"image\" .to_string(),   vec![ 0.9 ,   0.1 ,   0.1 ,   0.2 ]), \n\n                     ( \n\n                         \"text\" .to_string(), \n\n                         vec![ 0.4 ,   0.7 ,   0.1 ,   0.8 ,   0.1 ,   0.1 ,   0.9 ,   0.2 ], \n\n                     ), \n\n                 ]), \n\n                 HashMap::new().into(), \n\n             ), \n\n             PointStruct::new( \n\n                 2 , \n\n                 HashMap::from([ \n\n                     ( \"image\" .to_string(),   vec![ 0.2 ,   0.1 ,   0.3 ,   0.9 ]), \n\n                     ( \n\n                         \"text\" .to_string(), \n\n                         vec![ 0.5 ,   0.2 ,   0.7 ,   0.4 ,   0.7 ,   0.2 ,   0.3 ,   0.9 ], \n\n                     ), \n\n                 ]), \n\n                 HashMap::new().into(), \n\n             ), \n\n         ], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n *Available as of v1.2.0* \n\nNamed vectors are optional. When uploading points, some vectors may be omitted.\nFor example, you can upload one point with only the `image` vector and a second\none with only the `text` vector.\n\nWhen uploading a point with an existing ID, the existing point is deleted first,\nthen it is inserted with just the specified vectors. In other words, the entire\npoint is replaced, and any unspecified vectors are set to null. To keep existing\nvectors unchanged and only update specified vectors, see[ update vectors ](https://qdrant.tech/documentation/concepts/points/#update-vectors).\n\n *Available as of v1.7.0* \n\nPoints can contain dense and sparse vectors.\n\nA sparse vector is an array in which most of the elements have a value of zero.\n\nIt is possible to take advantage of this property to have an optimized representation, for this reason they have a different shape than dense vectors.\n\nThey are represented as a list of `(index, value)` pairs, where `index` is an integer and `value` is a floating point number. The `index` is the position of the non-zero value in the vector. The `values` is the value of the non-zero element.\n\nFor example, the following vector:\n\n`[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0]`\n\ncan be represented as a sparse vector:\n\n`[(6, 1.0), (7, 2.0)]`\n\nQdrant uses the following JSON representation throughout its APIs.\n\n```\n{\n\n   \"indices\" : [ 6 ,  7 ],\n\n   \"values\" : [ 1.0 ,  2.0 ]\n\n}\n\n```\n\nThe `indices` and `values` arrays must have the same length.\nAnd the `indices` must be unique.\n\nIf the `indices` are not sorted, Qdrant will sort them internally so you may not rely on the order of the elements.\n\nSparse vectors must be named and can be uploaded in the same way as dense vectors.\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1,\n\n            \"vector\": {\n\n                \"text\": {\n\n                    \"indices\": [6, 7],\n\n                    \"values\": [1.0, 2.0]\n\n                }\n\n            }\n\n        },\n\n        {\n\n            \"id\": 2,\n\n            \"vector\": {\n\n                \"text\": {\n\n                    \"indices\": [1, 1, 2, 3, 4, 5],\n\n                    \"values\": [0.1, 0.2, 0.3, 0.4, 0.5]\n\n                }\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1 ,\n\n            vector = {\n\n                 \"text\" : models . SparseVector(\n\n                    indices = [ 6 ,  7 ],\n\n                    values = [ 1.0 ,  2.0 ],\n\n                )\n\n            },\n\n        ),\n\n        models . PointStruct(\n\n             id = 2 ,\n\n            vector = {\n\n                 \"text\" : models . SparseVector(\n\n                    indices = [ 1 ,  2 ,  3 ,  4 ,  5 ],\n\n                    values =  [ 0.1 ,  0.2 ,  0.3 ,  0.4 ,  0.5 ],\n\n                )\n\n            },\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nclient.upsert( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id:  1 ,\n\n      vector :  {\n\n        text :  {\n\n          indices :  [ 6 ,  7 ],\n\n          values :  [ 1.0 ,  2.0 ]\n\n        },\n\n      },\n\n    },\n\n    {\n\n      id:  2 ,\n\n      vector :  {\n\n        text :  {\n\n          indices = [ 1 ,  2 ,  3 ,  4 ,  5 ],\n\n          values =  [ 0.1 ,  0.2 ,  0.3 ,  0.4 ,  0.5 ],\n\n        },\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{PointStruct,   Vector}; \n\nuse   std::collections::HashMap; \n\n\n\nclient \n\n     .upsert_points_blocking( \n\n         \"{collection_name}\" .to_string(), \n\n         vec![ \n\n             PointStruct::new( \n\n                 1 , \n\n                 HashMap::from([ \n\n                     ( \n\n                         \"text\" .to_string(), \n\n                         Vector::from( \n\n                             (vec![ 6 ,   7 ],   vec![ 1.0 ,   2.0 ]) \n\n                         ), \n\n                     ), \n\n                 ]), \n\n                 HashMap::new().into(), \n\n             ), \n\n             PointStruct::new( \n\n                 2 , \n\n                 HashMap::from([ \n\n                     ( \n\n                         \"text\" .to_string(), \n\n                         Vector::from( \n\n                             (vec![ 1 ,   2 ,   3 ,   4 ,   5 ],   vec![ 0.1 ,   0.2 ,   0.3 ,   0.4 ,   0.5 ]) \n\n                         ), \n\n                     ), \n\n                 ]), \n\n                 HashMap::new().into(), \n\n             ), \n\n         ], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n## Modify points\n\nTo change a point, you can modify its vectors or its payload. There are several\nways to do this.\n\n### Update vectors\n\n *Available as of v1.2.0* \n\nThis method updates the specified vectors on the given points. Unspecified\nvectors are kept unchanged. All given points must exist.\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/update_vectors)):\n\n```\nPUT /collections/{collection_name}/points/vectors\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1,\n\n            \"vector\": {\n\n                \"image\": [0.1, 0.2, 0.3, 0.4]\n\n            }\n\n        },\n\n        {\n\n            \"id\": 2,\n\n            \"vector\": {\n\n                \"text\": [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . update_vectors(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1 ,\n\n            vector = {\n\n                 \"image\" : [ 0.1 ,  0.2 ,  0.3 ,  0.4 ],\n\n            },\n\n        ),\n\n        models . PointStruct(\n\n             id = 2 ,\n\n            vector = {\n\n                 \"text\" : [ 0.9 ,  0.8 ,  0.7 ,  0.6 ,  0.5 ,  0.4 ,  0.3 ,  0.2 ],\n\n            },\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nclient.updateVectors( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id:  1 ,\n\n      vector :  {\n\n        image :  [ 0.1 ,  0.2 ,  0.3 ,  0.4 ],\n\n      },\n\n    },\n\n    {\n\n      id:  2 ,\n\n      vector :  {\n\n        text :  [ 0.9 ,  0.8 ,  0.7 ,  0.6 ,  0.5 ,  0.4 ,  0.3 ,  0.2 ],\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::PointVectors; \n\nuse   std::collections::HashMap; \n\n\n\nclient \n\n     .update_vectors_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & [ \n\n             PointVectors   { \n\n                 id:  Some ( 1. into()), \n\n                 vectors:  Some ( \n\n                     HashMap::from([( \"image\" .to_string(),   vec![ 0.1 ,   0.2 ,   0.3 ,   0.4 ])]).into(), \n\n                 ), \n\n             }, \n\n             PointVectors   { \n\n                 id:  Some ( 2. into()), \n\n                 vectors:  Some ( \n\n                     HashMap::from([( \n\n                         \"text\" .to_string(), \n\n                         vec![ 0.9 ,   0.8 ,   0.7 ,   0.6 ,   0.5 ,   0.4 ,   0.3 ,   0.2 ], \n\n                     )]) \n\n                     .into(), \n\n                 ), \n\n             }, \n\n         ], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nTo update points and replace all of its vectors, see[ uploading\npoints ](https://qdrant.tech/documentation/concepts/points/#upload-points).\n\n### Delete vectors\n\n *Available as of v1.2.0* \n\nThis method deletes just the specified vectors from the given points. Other\nvectors are kept unchanged. Points are never deleted.\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/deleted_vectors)):\n\n```\nPOST /collections/{collection_name}/points/vectors/delete\n\n{\n\n    \"points\": [0, 3, 100],\n\n    \"vectors\": [\"text\", \"image\"]\n\n}\n\n```\n\n```\nclient . delete_vectors(\n\n    collection_name = \" {collection_name} \" ,\n\n    points_selector = models . PointIdsList(\n\n        points = [ 0 ,  3 ,  100 ],\n\n    ),\n\n    vectors = [ \"text\" ,  \"image\" ],\n\n)\n\n```\n\n```\nclient.deleteVectors( \"{collection_name}\" , {\n\n  points :  [ 0 ,  3 ,  10 ],\n\n  vectors :  [ \"text\" ,  \"image\" ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   PointsIdsList,   PointsSelector,   VectorsSelector, \n\n}; \n\n\n\nclient \n\n     .delete_vectors_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Points(PointsIdsList   { \n\n                 ids:  vec ! [ 0. into(),   3. into(),   10. into()], \n\n             })), \n\n         }, \n\n         & VectorsSelector   { \n\n             names:  vec ! [ \"text\" .into(),   \"image\" .into()], \n\n         }, \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nTo delete entire points, see[ deleting points ](https://qdrant.tech/documentation/concepts/points/#delete-points).\n\n### Update payload\n\nLearn how to modify the payload of a point in the[ Payload ](../payload/#update-payload)section.\n\n## Delete points\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/delete_points)):\n\n```\nPOST /collections/{collection_name}/points/delete\n\n{\n\n    \"points\": [0, 3, 100]\n\n}\n\n```\n\n```\nclient . delete(\n\n    collection_name = \" {collection_name} \" ,\n\n    points_selector = models . PointIdsList(\n\n        points = [ 0 ,  3 ,  100 ],\n\n    ),\n\n)\n\n```\n\n```\nclient. delete ( \"{collection_name}\" , {\n\n  points :  [ 0 ,  3 ,  100 ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   PointsIdsList,   PointsSelector, \n\n}; \n\n\n\nclient \n\n     .delete_points_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Points(PointsIdsList   { \n\n                 ids:  vec ! [ 0. into(),   3. into(),   100. into()], \n\n             })), \n\n         }, \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nAlternative way to specify which points to remove is to use filter.\n\n```\nPOST /collections/{collection_name}/points/delete\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"color\",\n\n                \"match\": {\n\n                    \"value\": \"red\"\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . delete(\n\n    collection_name = \" {collection_name} \" ,\n\n    points_selector = models . FilterSelector(\n\n         filter = models . Filter(\n\n            must = [\n\n                models . FieldCondition(\n\n                    key = \"color\" ,\n\n                    match = models . MatchValue(value = \"red\" ),\n\n                ),\n\n            ],\n\n        )\n\n    ),\n\n)\n\n```\n\n```\nclient. delete ( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"color\" ,\n\n        match :  {\n\n          value :   \"red\" ,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf,   Condition,   Filter,   PointsSelector, \n\n}; \n\n\n\nclient \n\n     .delete_points_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & PointsSelector   { \n\n             points_selector_one_of:  Some (PointsSelectorOneOf::Filter(Filter::must([ \n\n                 Condition::matches( \"color\" ,   \"red\" .to_string()), \n\n             ]))), \n\n         }, \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nThis example removes all points with `{ \"color\": \"red\" }` from the collection.\n\n## Retrieve points\n\nThere is a method for retrieving points by their ids.\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/get_points)):\n\n```\nPOST /collections/{collection_name}/points\n\n{\n\n    \"ids\": [0, 3, 100]\n\n}\n\n```\n\n```\nclient . retrieve(\n\n    collection_name = \" {collection_name} \" ,\n\n    ids = [ 0 ,  3 ,  100 ],\n\n)\n\n```\n\n```\nclient.retrieve( \"{collection_name}\" , {\n\n  ids :  [ 0 ,  3 ,  100 ],\n\n});\n\n```\n\n```\nclient \n\n     .get_points( \n\n         \"{collection_name}\" , \n\n         None , \n\n         & [ 0. into(),   30. into(),   100. into()], \n\n         Some ( false ), \n\n         Some ( false ), \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nThis method has additional parameters `with_vectors` and `with_payload` .\nUsing these parameters, you can select parts of the point you want as a result.\nExcluding helps you not to waste traffic transmitting useless data.\n\nThe single point can also be retrieved via the API:\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/get_point)):\n\n`GET /collections/{collection_name}/points/{point_id}\n`\n\n## Scroll points\n\nSometimes it might be necessary to get all stored points without knowing ids, or iterate over points that correspond to a filter.\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#operation/scroll_points)):\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"color\",\n\n                \"match\": {\n\n                    \"value\": \"red\"\n\n                }\n\n            }\n\n        ]\n\n    },\n\n    \"limit\": 1,\n\n    \"with_payload\": true,\n\n    \"with_vector\": false\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(key = \"color\" , match = models . MatchValue(value = \"red\" )),\n\n        ]\n\n    ),\n\n    limit = 1 ,\n\n    with_payload = True ,\n\n    with_vectors = False ,\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"color\" ,\n\n        match :  {\n\n          value :   \"red\" ,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n  limit:  1 ,\n\n  with_payload:  true ,\n\n  with_vector:  false ,\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must([Condition::matches( \n\n             \"color\" , \n\n             \"red\" .to_string(), \n\n         )])), \n\n         limit:  Some ( 1 ), \n\n         with_payload:  Some ( true .into()), \n\n         with_vectors:  Some ( false .into()), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nReturns all point with `color` = `red` .\n\n```\n{\n\n     \"result\" : {\n\n         \"next_page_offset\" :  1 ,\n\n         \"points\" : [\n\n            {\n\n                 \"id\" :  0 ,\n\n                 \"payload\" : {\n\n                     \"color\" :  \"red\" \n\n                }\n\n            }\n\n        ]\n\n    },\n\n     \"status\" :  \"ok\" ,\n\n     \"time\" :  0.0001 \n\n}\n\n```\n\nThe Scroll API will return all points that match the filter in a page-by-page manner.\n\nAll resulting points are sorted by ID. To query the next page it is necessary to specify the largest seen ID in the `offset` field.\nFor convenience, this ID is also returned in the field `next_page_offset` .\nIf the value of the `next_page_offset` field is `null` - the last page is reached.\n\n## Counting points\n\n *Available as of v0.8.4* \n\nSometimes it can be useful to know how many points fit the filter conditions without doing a real search.\n\nAmong others, for example, we can highlight the following scenarios:\n\n- Evaluation of results size for faceted search\n- Determining the number of pages for pagination\n- Debugging the query execution speed\n\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#tag/points/operation/count_points)):\n\n```\nPOST /collections/{collection_name}/points/count\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"color\",\n\n                \"match\": {\n\n                    \"value\": \"red\"\n\n                }\n\n            }\n\n        ]\n\n    },\n\n    \"exact\": true\n\n}\n\n```\n\n```\nclient . count(\n\n    collection_name = \" {collection_name} \" ,\n\n    count_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(key = \"color\" , match = models . MatchValue(value = \"red\" )),\n\n        ]\n\n    ),\n\n    exact = True ,\n\n)\n\n```\n\n```\nclient.count( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"color\" ,\n\n        match :  {\n\n          value :   \"red\" ,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n  exact:  true ,\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   CountPoints,   Filter}; \n\n\n\nclient \n\n     .count( & CountPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must([Condition::matches( \n\n             \"color\" , \n\n             \"red\" .to_string(), \n\n         )])), \n\n         exact:  Some ( true ), \n\n     }) \n\n     . await ? ; \n\n```\n\nReturns number of counts matching given filtering conditions:\n\n```\n{\n\n     \"count\" :  3811 \n\n}\n\n```\n\n## Batch update\n\n *Available as of v1.5.0* \n\nYou can batch multiple point update operations. This includes inserting,\nupdating and deleting points, vectors and payload.\n\nA batch update request consists of a list of operations. These are executed in\norder. These operations can be batched:\n\n- [ Upsert points ](https://qdrant.tech/documentation/concepts/points/#upload-points): `upsert` or `UpsertOperation`\n- [ Delete points ](https://qdrant.tech/documentation/concepts/points/#delete-points): `delete_points` or `DeleteOperation`\n- [ Update vectors ](https://qdrant.tech/documentation/concepts/points/#update-vectors): `update_vectors` or `UpdateVectorsOperation`\n- [ Delete vectors ](https://qdrant.tech/documentation/concepts/points/#delete-vectors): `delete_vectors` or `DeleteVectorsOperation`\n- [ Set payload ](https://qdrant.tech/documentation/concepts/points/#set-payload): `set_payload` or `SetPayloadOperation`\n- [ Overwrite payload ](https://qdrant.tech/documentation/concepts/points/#overwrite-payload): `overwrite_payload` or `OverwritePayload`\n- [ Delete payload ](https://qdrant.tech/documentation/concepts/points/#delete-payload-keys): `delete_payload` or `DeletePayloadOperation`\n- [ Clear payload ](https://qdrant.tech/documentation/concepts/points/#clear-payload): `clear_payload` or `ClearPayloadOperation`\n\n\nThe following example snippet makes use of all operations.\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#tag/points/operation/batch_update)):\n\n```\nPOST /collections/{collection_name}/points/batch\n\n{\n\n    \"operations\": [\n\n        {\n\n            \"upsert\": {\n\n                \"points\": [\n\n                    {\n\n                        \"id\": 1,\n\n                        \"vector\": [1.0, 2.0, 3.0, 4.0],\n\n                        \"payload\": {}\n\n                    }\n\n                ]\n\n            }\n\n        },\n\n        {\n\n            \"update_vectors\": {\n\n                \"points\": [\n\n                    {\n\n                        \"id\": 1,\n\n                        \"vector\": [1.0, 2.0, 3.0, 4.0]\n\n                    }\n\n                ]\n\n            }\n\n        },\n\n        {\n\n            \"delete_vectors\": {\n\n                \"points\": [1],\n\n                \"vector\": [\"\"]\n\n            }\n\n        },\n\n        {\n\n            \"overwrite_payload\": {\n\n                \"payload\": {\n\n                    \"test_payload\": \"1\"\n\n                },\n\n                \"points\": [1]\n\n            }\n\n        },\n\n        {\n\n            \"set_payload\": {\n\n                \"payload\": {\n\n                    \"test_payload_2\": \"2\",\n\n                    \"test_payload_3\": \"3\"\n\n                },\n\n                \"points\": [1]\n\n            }\n\n        },\n\n        {\n\n            \"delete_payload\": {\n\n                \"keys\": [\"test_payload_2\"],\n\n                \"points\": [1]\n\n            }\n\n        },\n\n        {\n\n            \"clear_payload\": {\n\n                \"points\": [1]\n\n            }\n\n        },\n\n        {\"delete\": {\"points\": [1]}}\n\n    ]\n\n}\n\n```\n\n```\nclient . batch_update_points(\n\n    collection_name = collection_name,\n\n    update_operations = [\n\n        models . UpsertOperation(\n\n            upsert = models . PointsList(\n\n                points = [\n\n                    models . PointStruct(\n\n                         id = 1 ,\n\n                        vector = [ 1.0 ,  2.0 ,  3.0 ,  4.0 ],\n\n                        payload = {},\n\n                    ),\n\n                ]\n\n            )\n\n        ),\n\n        models . UpdateVectorsOperation(\n\n            update_vectors = models . UpdateVectors(\n\n                points = [\n\n                    models . PointVectors(\n\n                         id = 1 ,\n\n                        vector = [ 1.0 ,  2.0 ,  3.0 ,  4.0 ],\n\n                    )\n\n                ]\n\n            )\n\n        ),\n\n        models . DeleteVectorsOperation(\n\n            delete_vectors = models . DeleteVectors(points = [ 1 ], vector = [ \"\" ])\n\n        ),\n\n        models . OverwritePayloadOperation(\n\n            overwrite_payload = models . SetPayload(\n\n                payload = { \"test_payload\" :  1 },\n\n                points = [ 1 ],\n\n            )\n\n        ),\n\n        models . SetPayloadOperation(\n\n            set_payload = models . SetPayload(\n\n                payload = {\n\n                     \"test_payload_2\" :  2 ,\n\n                     \"test_payload_3\" :  3 ,\n\n                },\n\n                points = [ 1 ],\n\n            )\n\n        ),\n\n        models . DeletePayloadOperation(\n\n            delete_payload = models . DeletePayload(keys = [ \"test_payload_2\" ], points = [ 1 ])\n\n        ),\n\n        models . ClearPayloadOperation(clear_payload = models . PointIdsList(points = [ 1 ])),\n\n        models . DeleteOperation(delete = models . PointIdsList(points = [ 1 ])),\n\n    ],\n\n)\n\n```\n\n```\nclient.batchUpdate( \"{collection_name}\" , {\n\n  operations :  [\n\n    {\n\n      upsert :  {\n\n        points :  [\n\n          {\n\n            id:  1 ,\n\n            vector :  [ 1.0 ,  2.0 ,  3.0 ,  4.0 ],\n\n            payload :  {},\n\n          },\n\n        ],\n\n      },\n\n    },\n\n    {\n\n      update_vectors :  {\n\n        points :  [\n\n          {\n\n            id:  1 ,\n\n            vector :  [ 1.0 ,  2.0 ,  3.0 ,  4.0 ],\n\n          },\n\n        ],\n\n      },\n\n    },\n\n    {\n\n      delete_vectors :  {\n\n        points :  [ 1 ],\n\n        vector :  [ \"\" ],\n\n      },\n\n    },\n\n    {\n\n      overwrite_payload :  {\n\n        payload :  {\n\n          test_payload:  1 ,\n\n        },\n\n        points :  [ 1 ],\n\n      },\n\n    },\n\n    {\n\n      set_payload :  {\n\n        payload :  {\n\n          test_payload_2:  2 ,\n\n          test_payload_3:  3 ,\n\n        },\n\n        points :  [ 1 ],\n\n      },\n\n    },\n\n    {\n\n      delete_payload :  {\n\n        keys :  [ \"test_payload_2\" ],\n\n        points :  [ 1 ],\n\n      },\n\n    },\n\n    {\n\n      clear_payload :  {\n\n        points :  [ 1 ],\n\n      },\n\n    },\n\n    {\n\n       delete :  {\n\n        points :  [ 1 ],\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{ \n\n     points_selector::PointsSelectorOneOf, \n\n     points_update_operation::{ \n\n         DeletePayload,   DeleteVectors,   Operation,   PointStructList,   SetPayload,   UpdateVectors, \n\n     }, \n\n     PointStruct,   PointVectors,   PointsIdsList,   PointsSelector,   PointsUpdateOperation, \n\n     VectorsSelector, \n\n}; \n\nuse   serde_json::json; \n\nuse   std::collections::HashMap; \n\n\n\nclient \n\n     .batch_updates_blocking( \n\n         \"{collection_name}\" , \n\n         & [ \n\n             PointsUpdateOperation   { \n\n                 operation:  Some (Operation::Upsert(PointStructList   { \n\n                     points:  vec ! [PointStruct::new( \n\n                         1 , \n\n                         vec![ 1.0 ,   2.0 ,   3.0 ,   4.0 ], \n\n                         json ! ({}).try_into().unwrap(), \n\n                     )], \n\n                 })), \n\n             }, \n\n             PointsUpdateOperation   { \n\n                 operation:  Some (Operation::UpdateVectors(UpdateVectors   { \n\n                     points:  vec ! [PointVectors   { \n\n                         id:  Some ( 1. into()), \n\n                         vectors:  Some (vec![ 1.0 ,   2.0 ,   3.0 ,   4.0 ].into()), \n\n                     }], \n\n                 })), \n\n             }, \n\n             PointsUpdateOperation   { \n\n                 operation:  Some (Operation::DeleteVectors(DeleteVectors   { \n\n                     points_selector:  Some (PointsSelector   { \n\n                         points_selector_one_of:  Some (PointsSelectorOneOf::Points( \n\n                             PointsIdsList   { \n\n                                 ids:  vec ! [ 1. into()], \n\n                             }, \n\n                         )), \n\n                     }), \n\n                     vectors:  Some (VectorsSelector   { \n\n                         names:  vec ! [ \"\" .into()], \n\n                     }), \n\n                 })), \n\n             }, \n\n             PointsUpdateOperation   { \n\n                 operation:  Some (Operation::OverwritePayload(SetPayload   { \n\n                     points_selector:  Some (PointsSelector   { \n\n                         points_selector_one_of:  Some (PointsSelectorOneOf::Points( \n\n                             PointsIdsList   { \n\n                                 ids:  vec ! [ 1. into()], \n\n                             }, \n\n                         )), \n\n                     }), \n\n                     payload:  HashMap ::from([( \"test_payload\" .to_string(),   1. into())]), \n\n                 })), \n\n             }, \n\n             PointsUpdateOperation   { \n\n                 operation:  Some (Operation::SetPayload(SetPayload   { \n\n                     points_selector:  Some (PointsSelector   { \n\n                         points_selector_one_of:  Some (PointsSelectorOneOf::Points( \n\n                             PointsIdsList   { \n\n                                 ids:  vec ! [ 1. into()], \n\n                             }, \n\n                         )), \n\n                     }), \n\n                     payload:  HashMap ::from([ \n\n                         ( \"test_payload_2\" .to_string(),   2. into()), \n\n                         ( \"test_payload_3\" .to_string(),   3. into()), \n\n                     ]), \n\n                 })), \n\n             }, \n\n             PointsUpdateOperation   { \n\n                 operation:  Some (Operation::DeletePayload(DeletePayload   { \n\n                     points_selector:  Some (PointsSelector   { \n\n                         points_selector_one_of:  Some (PointsSelectorOneOf::Points( \n\n                             PointsIdsList   { \n\n                                 ids:  vec ! [ 1. into()], \n\n                             }, \n\n                         )), \n\n                     }), \n\n                     keys:  vec ! [ \"test_payload_2\" .to_string()], \n\n                 })), \n\n             }, \n\n             PointsUpdateOperation   { \n\n                 operation:  Some (Operation::ClearPayload(PointsSelector   { \n\n                     points_selector_one_of:  Some (PointsSelectorOneOf::Points(PointsIdsList   { \n\n                         ids:  vec ! [ 1. into()], \n\n                     })), \n\n                 })), \n\n             }, \n\n             PointsUpdateOperation   { \n\n                 operation:  Some (Operation::Delete(PointsSelector   { \n\n                     points_selector_one_of:  Some (PointsSelectorOneOf::Points(PointsIdsList   { \n\n                         ids:  vec ! [ 1. into()], \n\n                     })), \n\n                 })), \n\n             }, \n\n         ], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nTo batch many points with a single operation type, please use batching\nfunctionality in that operation directly.\n\n##### Table of contents\n\n- [ Awaiting result ](https://qdrant.tech/documentation/concepts/points/#awaiting-result)\n- [ Point IDs ](https://qdrant.tech/documentation/concepts/points/#point-ids)\n- [ Upload points ](https://qdrant.tech/documentation/concepts/points/#upload-points)\n- [ Modify points ](https://qdrant.tech/documentation/concepts/points/#modify-points)\n    - [ Update vectors ](https://qdrant.tech/documentation/concepts/points/#update-vectors)\n\n- [ Delete vectors ](https://qdrant.tech/documentation/concepts/points/#delete-vectors)\n\n- [ Update payload ](https://qdrant.tech/documentation/concepts/points/#update-payload)\n- [ Delete points ](https://qdrant.tech/documentation/concepts/points/#delete-points)\n- [ Retrieve points ](https://qdrant.tech/documentation/concepts/points/#retrieve-points)\n- [ Scroll points ](https://qdrant.tech/documentation/concepts/points/#scroll-points)\n- [ Counting points ](https://qdrant.tech/documentation/concepts/points/#counting-points)\n- [ Batch update ](https://qdrant.tech/documentation/concepts/points/#batch-update)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/points.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/search/": "# Similarity search\n\nSearching for the nearest vectors is at the core of many representational learning applications.\nModern neural networks are trained to transform objects into vectors so that objects close in the real world appear close in vector space.\nIt could be, for example, texts with similar meanings, visually similar pictures, or songs of the same genre.\n\nImage: [ Embeddings ](https://qdrant.tech/docs/encoders.png)\n\nImage: [ Embeddings ](https://qdrant.tech/docs/encoders.png)\n\n## Metrics\n\nThere are many ways to estimate the similarity of vectors with each other.\nIn Qdrant terms, these ways are called metrics.\nThe choice of metric depends on vectors obtaining and, in particular, on the method of neural network encoder training.\n\nQdrant supports these most popular types of metrics:\n\n- Dot product: `Dot` -[ https://en.wikipedia.org/wiki/Dot_product ](https://en.wikipedia.org/wiki/Dot_product)\n- Cosine similarity: `Cosine` -[ https://en.wikipedia.org/wiki/Cosine_similarity ](https://en.wikipedia.org/wiki/Cosine_similarity)\n- Euclidean distance: `Euclid` -[ https://en.wikipedia.org/wiki/Euclidean_distance ](https://en.wikipedia.org/wiki/Euclidean_distance)\n- Manhattan distance: `Manhattan` * -[ https://en.wikipedia.org/wiki/Taxicab_geometry ](https://en.wikipedia.org/wiki/Taxicab_geometry)\n\n\nThe most typical metric used in similarity learning models is the cosine metric.\n\nImage: [ Embeddings ](https://qdrant.tech/docs/cos.png)\n\nImage: [ Embeddings ](https://qdrant.tech/docs/cos.png)\n\nQdrant counts this metric in 2 steps, due to which a higher search speed is achieved.\nThe first step is to normalize the vector when adding it to the collection.\nIt happens only once for each vector.\n\nThe second step is the comparison of vectors.\nIn this case, it becomes equivalent to dot production - a very fast operation due to SIMD.\n\n## Query planning\n\nDepending on the filter used in the search - there are several possible scenarios for query execution.\nQdrant chooses one of the query execution options depending on the available indexes, the complexity of the conditions and the cardinality of the filtering result.\nThis process is called query planning.\n\nThe strategy selection process relies heavily on heuristics and can vary from release to release.\nHowever, the general principles are:\n\n- planning is performed for each segment independently (see[ storage ](../storage)for more information about segments)\n- prefer a full scan if the amount of points is below a threshold\n- estimate the cardinality of a filtered result before selecting a strategy\n- retrieve points using payload index (see[ indexing ](../indexing)) if cardinality is below threshold\n- use filterable vector index if the cardinality is above a threshold\n\n\nYou can adjust the threshold using a[ configuration file ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml), as well as independently for each collection.\n\n## Search API\n\nLet\u2019s look at an example of a search query.\n\nREST API - API Schema definition is available[ here ](https://qdrant.github.io/qdrant/redoc/index.html#operation/search_points)\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"city\",\n\n                \"match\": {\n\n                    \"value\": \"London\"\n\n                }\n\n            }\n\n        ]\n\n    },\n\n    \"params\": {\n\n        \"hnsw_ef\": 128,\n\n        \"exact\": false\n\n    },\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"limit\": 3\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"city\" ,\n\n                match = models . MatchValue(\n\n                    value = \"London\" ,\n\n                ),\n\n            )\n\n        ]\n\n    ),\n\n    search_params = models . SearchParams(hnsw_ef = 128 , exact = False ),\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    limit = 3 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"city\" ,\n\n        match :  {\n\n          value :   \"London\" ,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n  params :  {\n\n    hnsw_ef:  128 ,\n\n    exact:  false ,\n\n  },\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  limit:  3 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{Condition,   Filter,   SearchParams,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must([Condition::matches( \n\n             \"city\" , \n\n             \"London\" .to_string(), \n\n         )])), \n\n         params:  Some (SearchParams   { \n\n             hnsw_ef:  Some ( 128 ), \n\n             exact:  Some ( false ), \n\n             .. Default ::default() \n\n         }), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nIn this example, we are looking for vectors similar to vector `[0.2, 0.1, 0.9, 0.7]` .\nParameter `limit` (or its alias - `top` ) specifies the amount of most similar results we would like to retrieve.\n\nValues under the key `params` specify custom parameters for the search.\nCurrently, it could be:\n\n- `hnsw_ef` - value that specifies `ef` parameter of the HNSW algorithm.\n- `exact` - option to not use the approximate search (ANN). If set to true, the search may run for a long as it performs a full scan to retrieve exact results.\n- `indexed_only` - With this option you can disable the search in those segments where vector index is not built yet. This may be useful if you want to minimize the impact to the search performance whilst the collection is also being updated. Using this option may lead to a partial result if the collection is not fully indexed yet, consider using it only if eventual consistency is acceptable for your use case.\n\n\nSince the `filter` parameter is specified, the search is performed only among those points that satisfy the filter condition.\nSee details of possible filters and their work in the[ filtering ](../filtering)section.\n\nExample result of this API would be\n\n```\n{\n\n   \"result\" : [\n\n    {  \"id\" :  10 ,  \"score\" :  0.81  },\n\n    {  \"id\" :  14 ,  \"score\" :  0.75  },\n\n    {  \"id\" :  11 ,  \"score\" :  0.73  }\n\n  ],\n\n   \"status\" :  \"ok\" ,\n\n   \"time\" :  0.001 \n\n}\n\n```\n\nThe `result` contains ordered by `score` list of found point ids.\n\nNote that payload and vector data is missing in these results by default.\nSee[ payload and vector in the result ](https://qdrant.tech/documentation/concepts/search/#payload-and-vector-in-the-result)on how\nto include it.\n\n *Available as of v0.10.0* \n\nIf the collection was created with multiple vectors, the name of the vector to use for searching should be provided:\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"vector\": {\n\n        \"name\": \"image\",\n\n        \"vector\": [0.2, 0.1, 0.9, 0.7]\n\n    },\n\n    \"limit\": 3\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = ( \"image\" , [ 0.2 ,  0.1 ,  0.9 ,  0.7 ]),\n\n    limit = 3 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  {\n\n    name :   \"image\" ,\n\n    vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  },\n\n  limit:  3 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::SearchPoints}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         vector_name:  Some ( \"image\" .to_string()), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nSearch is processing only among vectors with the same name.\n\n *Available as of v1.7.0* \n\nIf the collection was created with sparse vectors, the name of the sparse vector to use for searching should be provided:\n\nYou can still use payload filtering and other features of the search API with sparse vectors.\n\nThere are however important differences between dense and sparse vector search:\n\n| Index | Sparse Query | Dense Query |\n|---|---|---|\n| Scoring Metric | Default is `Dot product` , no need to specify it |  `Distance` has supported metrics e.g. Dot, Cosine |\n| Search Type | Always exact in Qdrant | HNSW is an approximate NN |\n| Return Behaviour | Returns only vectors with non-zero values in the same indices as the query vector | Returns `limit` vectors |\n\n\nIn general, the speed of the search is proportional to the number of non-zero values in the query vector.\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"vector\": {\n\n        \"name\": \"text\",\n\n        \"vector\": {\n\n            \"indices\": [6, 7],\n\n            \"values\": [1.0, 2.0]\n\n        }    \n\n    },\n\n    \"limit\": 3\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = models . NamedSparseVector(\n\n        name = \"text\" ,\n\n        vector = models . SparseVector(\n\n            indices = [ 1 ,  7 ],\n\n            values = [ 2.0 ,  1.0 ],\n\n        ),\n\n    ),\n\n    limit = 3 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  {\n\n    name :   \"text\" ,\n\n    vector :  {\n\n        indices :  [ 1 ,  7 ],\n\n        values :  [ 2.0 ,  1.0 ]\n\n    },\n\n  },\n\n  limit:  3 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   client::Vector,   qdrant::SearchPoints}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nlet   sparse_vector:  Vector   =   vec![( 1 ,   2.0 ),   ( 7 ,   1.0 )].into(); \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector_name:  Some ( \"text\" .to_string()), \n\n         sparse_indices:  sparse_vector .indices, \n\n         vector:  sparse_vector .data, \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n### Filtering results by score\n\nIn addition to payload filtering, it might be useful to filter out results with a low similarity score.\nFor example, if you know the minimal acceptance score for your model and do not want any results which are less similar than the threshold.\nIn this case, you can use `score_threshold` parameter of the search query.\nIt will exclude all results with a score worse than the given.\n\n### Payload and vector in the result\n\nBy default, retrieval methods do not return any stored information such as\npayload and vectors. Additional parameters `with_vectors` and `with_payload` alter this behavior.\n\nExample:\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"with_vectors\": true,\n\n    \"with_payload\": true\n\n}\n\n```\n\n```\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    with_vectors = True ,\n\n    with_payload = True ,\n\n)\n\n```\n\n```\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  with_vector:  true ,\n\n  with_payload:  true ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::SearchPoints}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         with_payload:  Some ( true .into()), \n\n         with_vectors:  Some ( true .into()), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nYou can use `with_payload` to scope to or filter a specific payload subset.\nYou can even specify an array of items to include, such as `city` , `village` , and `town` :\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"with_payload\": [\"city\", \"village\", \"town\"]\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    with_payload = [ \"city\" ,  \"village\" ,  \"town\" ],\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  with_payload :  [ \"city\" ,  \"village\" ,  \"town\" ],\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::SearchPoints}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         with_payload:  Some (vec![ \"city\" ,   \"village\" ,   \"town\" ].into()), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nOr use `include` or `exclude` explicitly. For example, to exclude `city` :\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"with_payload\": {\n\n      \"exclude\": [\"city\"]\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    with_payload = models . PayloadSelectorExclude(\n\n        exclude = [ \"city\" ],\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  with_payload :  {\n\n    exclude :  [ \"city\" ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         with_payload_selector::SelectorOptions,   PayloadIncludeSelector,   SearchPoints, \n\n         WithPayloadSelector, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         with_payload:  Some (WithPayloadSelector   { \n\n             selector_options:  Some (SelectorOptions::Include(PayloadIncludeSelector   { \n\n                 fields:  vec ! [ \"city\" .to_string()], \n\n             })), \n\n         }), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nIt is possible to target nested fields using a dot notation:\n\n- `payload.nested_field` - for a nested field\n- `payload.nested_array[].sub_field` - for projecting nested fields within an array\n\n\nAccessing array elements by index is currently not supported.\n\n## Batch search API\n\n *Available as of v0.10.0* \n\nThe batch search API enables to perform multiple search requests via a single request.\n\nIts semantic is straightforward, `n` batched search requests are equivalent to `n` singular search requests.\n\nThis approach has several advantages. Logically, fewer network connections are required which can be very beneficial on its own.\n\nMore importantly, batched requests will be efficiently processed via the query planner which can detect and optimize requests if they have the same `filter` .\n\nThis can have a great effect on latency for non trivial filters as the intermediary results can be shared among the request.\n\nIn order to use it, simply pack together your search requests. All the regular attributes of a search request are of course available.\n\n```\nPOST /collections/{collection_name}/points/search/batch\n\n{\n\n    \"searches\": [\n\n        {\n\n            \"filter\": {\n\n                \"must\": [\n\n                    {\n\n                        \"key\": \"city\",\n\n                        \"match\": {\n\n                            \"value\": \"London\"\n\n                        }\n\n                    }\n\n                ]\n\n            },\n\n            \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n            \"limit\": 3\n\n        },\n\n        {\n\n            \"filter\": {\n\n                \"must\": [\n\n                    {\n\n                        \"key\": \"city\",\n\n                        \"match\": {\n\n                            \"value\": \"London\"\n\n                        }\n\n                    }\n\n                ]\n\n            },\n\n            \"vector\": [0.5, 0.3, 0.2, 0.3],\n\n            \"limit\": 3\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nfilter   =  models . Filter(\n\n    must = [\n\n        models . FieldCondition(\n\n            key = \"city\" ,\n\n            match = models . MatchValue(\n\n                value = \"London\" ,\n\n            ),\n\n        )\n\n    ]\n\n)\n\n\n\nsearch_queries  =  [\n\n    models . SearchRequest(vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],  filter = filter , limit = 3 ),\n\n    models . SearchRequest(vector = [ 0.5 ,  0.3 ,  0.2 ,  0.3 ],  filter = filter , limit = 3 ),\n\n]\n\n\n\nclient . search_batch(collection_name = \" {collection_name} \" , requests = search_queries)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nconst  filter  =  {\n\n  must :  [\n\n    {\n\n      key :   \"city\" ,\n\n      match :  {\n\n        value :   \"London\" ,\n\n      },\n\n    },\n\n  ],\n\n};\n\n\n\nconst  searches  =  [\n\n  {\n\n    vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    filter,\n\n    limit:  3 ,\n\n  },\n\n  {\n\n    vector :  [ 0.5 ,  0.3 ,  0.2 ,  0.3 ],\n\n    filter,\n\n    limit:  3 ,\n\n  },\n\n];\n\n\n\nclient.searchBatch( \"{collection_name}\" , {\n\n  searches,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{Condition,   Filter,   SearchBatchPoints,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nlet   filter   =   Filter::must([Condition::matches( \"city\" ,   \"London\" .to_string())]); \n\n\n\nlet   searches   =   vec![ \n\n     SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         filter:  Some (filter.clone()), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }, \n\n     SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.5 ,   0.3 ,   0.2 ,   0.3 ], \n\n         filter:  Some (filter), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }, \n\n]; \n\n\n\nclient \n\n     .search_batch_points( & SearchBatchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         search_points:  searches , \n\n         read_consistency:  None , \n\n     }) \n\n     . await ? ; \n\n```\n\nThe result of this API contains one array per search requests.\n\n```\n{\n\n   \"result\" : [\n\n    [\n\n        {  \"id\" :  10 ,  \"score\" :  0.81  },\n\n        {  \"id\" :  14 ,  \"score\" :  0.75  },\n\n        {  \"id\" :  11 ,  \"score\" :  0.73  }\n\n    ],\n\n    [\n\n        {  \"id\" :  1 ,  \"score\" :  0.92  },\n\n        {  \"id\" :  3 ,  \"score\" :  0.89  },\n\n        {  \"id\" :  9 ,  \"score\" :  0.75  }\n\n    ]\n\n  ],\n\n   \"status\" :  \"ok\" ,\n\n   \"time\" :  0.001 \n\n}\n\n```\n\n## Pagination\n\n *Available as of v0.8.3* \n\nSearch and[ recommendation ](../explore/#recommendation-api)APIs allow to skip first results of the search and return only the result starting from some specified offset:\n\nExample:\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"with_vectors\": true,\n\n    \"with_payload\": true,\n\n    \"limit\": 10,\n\n    \"offset\": 100\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    with_vectors = True ,\n\n    with_payload = True ,\n\n    limit = 10 ,\n\n    offset = 100 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  with_vector:  true ,\n\n  with_payload:  true ,\n\n  limit:  10 ,\n\n  offset:  100 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::SearchPoints}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         with_vectors:  Some ( true .into()), \n\n         with_payload:  Some ( true .into()), \n\n         limit:  10 , \n\n         offset:  Some ( 100 ), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nIs equivalent to retrieving the 11th page with 10 records per page.\n\nVector-based retrieval in general and HNSW index in particular, are not designed to be paginated.\nIt is impossible to retrieve Nth closest vector without retrieving the first N vectors first.\n\nHowever, using the offset parameter saves the resources by reducing network traffic and the number of times the storage is accessed.\n\nUsing an `offset` parameter, will require to internally retrieve `offset + limit` points, but only access payload and vector from the storage those points which are going to be actually returned.\n\n## Grouping API\n\n *Available as of v1.2.0* \n\nIt is possible to group results by a certain field. This is useful when you have multiple points for the same item, and you want to avoid redundancy of the same item in the results.\n\nFor example, if you have a large document split into multiple chunks, and you want to search or[ recommend ](../explore/#recommendation-api)on a per-document basis, you can group the results by the document ID.\n\nConsider having points with the following payloads:\n\n```\n[\n\n    {\n\n         \"id\" :  0 ,\n\n         \"payload\" : {\n\n             \"chunk_part\" :  0 , \n\n             \"document_id\" :  \"a\" \n\n        },\n\n         \"vector\" : [ 0.91 ]\n\n    },\n\n    {\n\n         \"id\" :  1 ,\n\n         \"payload\" : {\n\n             \"chunk_part\" :  1 , \n\n             \"document_id\" : [ \"a\" ,  \"b\" ]\n\n        },\n\n         \"vector\" : [ 0.8 ]\n\n    },\n\n    {\n\n         \"id\" :  2 ,\n\n         \"payload\" : {\n\n             \"chunk_part\" :  2 , \n\n             \"document_id\" :  \"a\" \n\n        },\n\n         \"vector\" : [ 0.2 ]\n\n    },\n\n    {\n\n         \"id\" :  3 ,\n\n         \"payload\" : {\n\n             \"chunk_part\" :  0 , \n\n             \"document_id\" :  123 \n\n        },\n\n         \"vector\" : [ 0.79 ]\n\n    },\n\n    {\n\n         \"id\" :  4 ,\n\n         \"payload\" : {\n\n             \"chunk_part\" :  1 , \n\n             \"document_id\" :  123 \n\n        },\n\n         \"vector\" : [ 0.75 ]\n\n    },\n\n    {\n\n         \"id\" :  5 ,\n\n         \"payload\" : {\n\n             \"chunk_part\" :  0 , \n\n             \"document_id\" :  -10 \n\n        },\n\n         \"vector\" : [ 0.6 ]\n\n    }\n\n]\n\n```\n\nWith the *groups* API, you will be able to get the best *N* points for each document, assuming that the payload of the points contains the document ID. Of course there will be times where the best *N* points cannot be fulfilled due to lack of points or a big distance with respect to the query. In every case, the `group_size` is a best-effort parameter, akin to the `limit` parameter.\n\n### Search groups\n\nREST API ([ Schema ](https://qdrant.github.io/qdrant/redoc/index.html#tag/points/operation/search_point_groups)):\n\n```\nPOST /collections/{collection_name}/points/search/groups\n\n{\n\n    // Same as in the regular search API\n\n    \"vector\": [1.1],\n\n\n\n    // Grouping parameters\n\n    \"group_by\": \"document_id\",  // Path of the field to group by\n\n    \"limit\": 4,                 // Max amount of groups\n\n    \"group_size\": 2,            // Max amount of points per group\n\n}\n\n```\n\n```\nclient . search_groups(\n\n    collection_name = \" {collection_name} \" ,\n\n     # Same as in the regular search() API \n\n    query_vector = g,\n\n     # Grouping parameters \n\n    group_by = \"document_id\" ,   # Path of the field to group by \n\n    limit = 4 ,   # Max amount of groups \n\n    group_size = 2 ,   # Max amount of points per group \n\n)\n\n```\n\n```\nclient.searchPointGroups( \"{collection_name}\" , {\n\n  vector :  [ 1.1 ],\n\n  group_by :   \"document_id\" ,\n\n  limit:  4 ,\n\n  group_size:  2 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::SearchPointGroups; \n\n\n\nclient \n\n     .search_groups( & SearchPointGroups   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 1.1 ], \n\n         group_by:  \"document_id\" .to_string(), \n\n         limit:  4 , \n\n         group_size:  2 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThe output of a *groups* call looks like this:\n\n```\n{\n\n     \"result\" : {\n\n         \"groups\" : [\n\n            {\n\n                 \"id\" :  \"a\" ,\n\n                 \"hits\" : [\n\n                    {  \"id\" :  0 ,  \"score\" :  0.91  },\n\n                    {  \"id\" :  1 ,  \"score\" :  0.85  }\n\n                ]\n\n            },\n\n            {\n\n                 \"id\" :  \"b\" ,\n\n                 \"hits\" : [\n\n                    {  \"id\" :  1 ,  \"score\" :  0.85  }\n\n                ]\n\n            },\n\n            {\n\n                 \"id\" :  123 ,\n\n                 \"hits\" : [\n\n                    {  \"id\" :  3 ,  \"score\" :  0.79  },\n\n                    {  \"id\" :  4 ,  \"score\" :  0.75  }\n\n                ]\n\n            },\n\n            {\n\n                 \"id\" :  -10 ,\n\n                 \"hits\" : [\n\n                    {  \"id\" :  5 ,  \"score\" :  0.6  }\n\n                ]\n\n            }\n\n        ]\n\n    },\n\n     \"status\" :  \"ok\" ,\n\n     \"time\" :  0.001 \n\n}\n\n```\n\nThe groups are ordered by the score of the top point in the group. Inside each group the points are sorted too.\n\nIf the `group_by` field of a point is an array (e.g. `\"document_id\": [\"a\", \"b\"]` ), the point can be included in multiple groups (e.g. `\"document_id\": \"a\"` and `document_id: \"b\"` ).\n\n **Limitations** :\n\n- Only[ keyword ](../payload/#keyword)and[ integer ](../payload/#integer)payload values are supported for the `group_by` parameter. Payload values with other types will be ignored.\n- At the moment, pagination is not enabled when using **groups** , so the `offset` parameter is not allowed.\n\n\n### Lookup in groups\n\n *Available as of v1.3.0* \n\nHaving multiple points for parts of the same item often introduces redundancy in the stored data. Which may be fine if the information shared by the points is small, but it can become a problem if the payload is large, because it multiplies the storage space needed to store the points by a factor of the amount of points we have per group.\n\nOne way of optimizing storage when using groups is to store the information shared by the points with the same group id in a single point in another collection. Then, when using the[ groups API ](https://qdrant.tech/documentation/concepts/search/#grouping-api), add the `with_lookup` parameter to bring the information from those points into each group.\n\nImage: [ Group id matches point id ](https://qdrant.tech/docs/lookup_id_linking.png)\n\nImage: [ Group id matches point id ](https://qdrant.tech/docs/lookup_id_linking.png)\n\nThis has the extra benefit of having a single point to update when the information shared by the points in a group changes.\n\nFor example, if you have a collection of documents, you may want to chunk them and store the points for the chunks in a separate collection, making sure that you store the point id from the document it belongs in the payload of the chunk point.\n\nIn this case, to bring the information from the documents into the chunks grouped by the document id, you can use the `with_lookup` parameter:\n\n```\nPOST /collections/chunks/points/search/groups\n\n{\n\n    // Same as in the regular search API\n\n    \"vector\": [1.1],\n\n\n\n    // Grouping parameters\n\n    \"group_by\": \"document_id\",\n\n    \"limit\": 2,\n\n    \"group_size\": 2,\n\n\n\n    // Lookup parameters\n\n    \"with_lookup\": {\n\n        // Name of the collection to look up points in\n\n        \"collection\": \"documents\",\n\n\n\n        // Options for specifying what to bring from the payload \n\n        // of the looked up point, true by default\n\n        \"with_payload\": [\"title\", \"text\"],\n\n\n\n        // Options for specifying what to bring from the vector(s) \n\n        // of the looked up point, true by default\n\n        \"with_vectors: false\n\n    }\n\n}\n\n```\n\n```\nclient . search_groups(\n\n    collection_name = \"chunks\" ,\n\n     # Same as in the regular search() API \n\n    query_vector = [ 1.1 ],\n\n     # Grouping parameters \n\n    group_by = \"document_id\" ,   # Path of the field to group by \n\n    limit = 2 ,   # Max amount of groups \n\n    group_size = 2 ,   # Max amount of points per group \n\n     # Lookup parameters \n\n    with_lookup = models . WithLookup(\n\n         # Name of the collection to look up points in \n\n        collection = \"documents\" ,\n\n         # Options for specifying what to bring from the payload \n\n         # of the looked up point, True by default \n\n        with_payload = [ \"title\" ,  \"text\" ],\n\n         # Options for specifying what to bring from the vector(s) \n\n         # of the looked up point, True by default \n\n        with_vectors = False ,\n\n    ),\n\n)\n\n```\n\n```\nclient.searchPointGroups( \"{collection_name}\" , {\n\n  vector :  [ 1.1 ],\n\n  group_by :   \"document_id\" ,\n\n  limit:  2 ,\n\n  group_size:  2 ,\n\n  with_lookup :  {\n\n    collection:  w ,\n\n    with_payload :  [ \"title\" ,  \"text\" ],\n\n    with_vectors:  false ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{SearchPointGroups,   WithLookup}; \n\n\n\nclient \n\n     .search_groups( & SearchPointGroups   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 1.1 ], \n\n         group_by:  \"document_id\" .to_string(), \n\n         limit:  2 , \n\n         group_size:  2 , \n\n         with_lookup:  Some (WithLookup   { \n\n             collection:  \"documents\" .to_string(), \n\n             with_payload:  Some (vec![ \"title\" ,   \"text\" ].into()), \n\n             with_vectors:  Some ( false .into()), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFor the `with_lookup` parameter, you can also use the shorthand `with_lookup=\"documents\"` to bring the whole payload and vector(s) without explicitly specifying it.\n\nThe looked up result will show up under `lookup` in each group.\n\n```\n{\n\n     \"result\" : {\n\n         \"groups\" : [\n\n            {\n\n                 \"id\" :  1 ,\n\n                 \"hits\" : [\n\n                    {  \"id\" :  0 ,  \"score\" :  0.91  },\n\n                    {  \"id\" :  1 ,  \"score\" :  0.85  }\n\n                ],\n\n                 \"lookup\" : {\n\n                     \"id\" :  1 ,\n\n                     \"payload\" : {\n\n                         \"title\" :  \"Document A\" ,\n\n                         \"text\" :  \"This is document A\" \n\n                    }\n\n                }\n\n            },\n\n            {\n\n                 \"id\" :  2 ,\n\n                 \"hits\" : [\n\n                    {  \"id\" :  1 ,  \"score\" :  0.85  }\n\n                ],\n\n                 \"lookup\" : {\n\n                     \"id\" :  2 ,\n\n                     \"payload\" : {\n\n                         \"title\" :  \"Document B\" ,\n\n                         \"text\" :  \"This is document B\" \n\n                    }\n\n                }\n\n            }\n\n        ]\n\n    },\n\n     \"status\" :  \"ok\" ,\n\n     \"time\" :  0.001 \n\n}\n\n```\n\nSince the lookup is done by matching directly with the point id, any group id that is not an existing (and valid) point id in the lookup collection will be ignored, and the `lookup` field will be empty.\n\n##### Table of contents\n\n- [ Metrics ](https://qdrant.tech/documentation/concepts/search/#metrics)\n- [ Query planning ](https://qdrant.tech/documentation/concepts/search/#query-planning)\n- [ Search API ](https://qdrant.tech/documentation/concepts/search/#search-api)\n    - [ Filtering results by score ](https://qdrant.tech/documentation/concepts/search/#filtering-results-by-score)\n\n- [ Payload and vector in the result ](https://qdrant.tech/documentation/concepts/search/#payload-and-vector-in-the-result)\n- [ Batch search API ](https://qdrant.tech/documentation/concepts/search/#batch-search-api)\n- [ Pagination ](https://qdrant.tech/documentation/concepts/search/#pagination)\n- [ Grouping API ](https://qdrant.tech/documentation/concepts/search/#grouping-api)\n    - [ Search groups ](https://qdrant.tech/documentation/concepts/search/#search-groups)\n\n- [ Lookup in groups ](https://qdrant.tech/documentation/concepts/search/#lookup-in-groups)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/search.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/explore/": "# Explore the data\n\nAfter mastering the concepts in[ search ](../search), you can start exploring your data in other ways. Qdrant provides a stack of APIs that allow you to find similar vectors in a different fashion, as well as to find the most dissimilar ones. These are useful tools for recommendation systems, data exploration, and data cleaning.\n\n## Recommendation API\n\nIn addition to the regular search, Qdrant also allows you to search based on multiple positive and negative examples. The API is called *recommend* , and the examples can be point IDs, so that you can leverage the already encoded objects; and, as of v1.6, you can also use raw vectors as input, so that you can create your vectors on the fly without uploading them as points.\n\nREST API - API Schema definition is available[ here ](https://qdrant.github.io/qdrant/redoc/index.html#operation/recommend_points)\n\n```\nPOST /collections/{collection_name}/points/recommend\n\n{\n\n  \"positive\": [100, 231],\n\n  \"negative\": [718, [0.2, 0.3, 0.4, 0.5]],\n\n  \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"city\",\n\n                \"match\": {\n\n                    \"value\": \"London\"\n\n                }\n\n            }\n\n        ]\n\n  },\n\n  \"strategy\": \"average_vector\",\n\n  \"limit\": 3\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . recommend(\n\n    collection_name = \" {collection_name} \" ,\n\n    positive = [ 100 ,  231 ],\n\n    negative = [ 718 , [ 0.2 ,  0.3 ,  0.4 ,  0.5 ]],\n\n    strategy = models . RecommendStrategy . AVERAGE_VECTOR,\n\n    query_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"city\" ,\n\n                match = models . MatchValue(\n\n                    value = \"London\" ,\n\n                ),\n\n            )\n\n        ]\n\n    ),\n\n    limit = 3 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.recommend( \"{collection_name}\" , {\n\n  positive :  [ 100 ,  231 ],\n\n  negative :  [ 718 , [ 0.2 ,  0.3 ,  0.4 ,  0.5 ]],\n\n  strategy :   \"average_vector\" ,\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"city\" ,\n\n        match :  {\n\n          value :   \"London\" ,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n  limit:  3 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{Condition,   Filter,   RecommendPoints,   RecommendStrategy}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .recommend( & RecommendPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         positive:  vec ! [ 100. into(),   200. into()], \n\n         positive_vectors:  vec ! [vec![ 100.0 ,   231.0 ].into()], \n\n         negative:  vec ! [ 718. into()], \n\n         negative_vectors:  vec ! [vec![ 0.2 ,   0.3 ,   0.4 ,   0.5 ].into()], \n\n         strategy:  Some (RecommendStrategy::AverageVector.into()), \n\n         filter:  Some (Filter::must([Condition::matches( \n\n             \"city\" , \n\n             \"London\" .to_string(), \n\n         )])), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nExample result of this API would be\n\n```\n{\n\n   \"result\" : [\n\n    {  \"id\" :  10 ,  \"score\" :  0.81  },\n\n    {  \"id\" :  14 ,  \"score\" :  0.75  },\n\n    {  \"id\" :  11 ,  \"score\" :  0.73  }\n\n  ],\n\n   \"status\" :  \"ok\" ,\n\n   \"time\" :  0.001 \n\n}\n\n```\n\nThe algorithm used to get the recommendations is selected from the available `strategy` options. Each of them has its own strengths and weaknesses, so experiment and choose the one that works best for your case.\n\n### Average vector strategy\n\nThe default and first strategy added to Qdrant is called `average_vector` . It preprocesses the input examples to create a single vector that is used for the search. Since the preprocessing step happens very fast, the performance of this strategy is on-par with regular search. The intuition behind this kind of recommendation is that each vector component represents an independent feature of the data, so, by averaging the examples, we should get a good recommendation.\n\nThe way to produce the searching vector is by first averaging all the positive and negative examples separately, and then combining them into a single vector using the following formula:\n\n`avg_positive   +   avg_positive   -   avg_negative \n`\n\nIn the case of not having any negative examples, the search vector will simply be equal to `avg_positive` .\n\nThis is the default strategy that\u2019s going to be set implicitly, but you can explicitly define it by setting `\"strategy\": \"average_vector\"` in the recommendation request.\n\n### Best score strategy\n\n *Available as of v1.6.0* \n\nA new strategy introduced in v1.6, is called `best_score` . It is based on the idea that the best way to find similar vectors is to find the ones that are closer to a positive example, while avoiding the ones that are closer to a negative one.\nThe way it works is that each candidate is measured against every example, then we select the best positive and best negative scores. The final score is chosen with this step formula:\n\n```\nlet   score   =   if   best_positive_score   >   best_negative_score   { \n\n     best_positive_score; \n\n}   else   { \n\n     - (best_negative_score   *   best_negative_score); \n\n}; \n\n```\n\n`best_score`\n\nSince we are computing similarities to every example at each step of the search, the performance of this strategy will be linearly impacted by the amount of examples. This means that the more examples you provide, the slower the search will be. However, this strategy can be very powerful and should be more embedding-agnostic.\n\n`ef`\n\n`\"params\": { \"ef\": 64 }`\n\nTo use this algorithm, you need to set `\"strategy\": \"best_score\"` in the recommendation request.\n\n#### Using only negative examples\n\nA beneficial side-effect of `best_score` strategy is that you can use it with only negative examples. This will allow you to find the most dissimilar vectors to the ones you provide. This can be useful for finding outliers in your data, or for finding the most dissimilar vectors to a given one.\n\nCombining negative-only examples with filtering can be a powerful tool for data exploration and cleaning.\n\n### Multiple vectors\n\n *Available as of v0.10.0* \n\nIf the collection was created with multiple vectors, the name of the vector should be specified in the recommendation request:\n\n```\nPOST /collections/{collection_name}/points/recommend\n\n{\n\n  \"positive\": [100, 231],\n\n  \"negative\": [718],\n\n  \"using\": \"image\",\n\n  \"limit\": 10\n\n }\n\n```\n\n```\nclient . recommend(\n\n    collection_name = \" {collection_name} \" ,\n\n    positive = [ 100 ,  231 ],\n\n    negative = [ 718 ],\n\n    using = \"image\" ,\n\n    limit = 10 ,\n\n)\n\n```\n\n```\nclient.recommend( \"{collection_name}\" , {\n\n  positive :  [ 100 ,  231 ],\n\n  negative :  [ 718 ],\n\n  using :   \"image\" ,\n\n  limit:  10 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::RecommendPoints; \n\n\n\nclient \n\n     .recommend( & RecommendPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         positive:  vec ! [ 100. into(),   231. into()], \n\n         negative:  vec ! [ 718. into()], \n\n         using:  Some ( \"image\" .to_string()), \n\n         limit:  10 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nParameter `using` specifies which stored vectors to use for the recommendation.\n\n### Lookup vectors from another collection\n\n *Available as of v0.11.6* \n\nIf you have collections with vectors of the same dimensionality,\nand you want to look for recommendations in one collection based on the vectors of another collection,\nyou can use the `lookup_from` parameter.\n\nIt might be useful, e.g. in the item-to-user recommendations scenario.\nWhere user and item embeddings, although having the same vector parameters (distance type and dimensionality), are usually stored in different collections.\n\n```\nPOST /collections/{collection_name}/points/recommend\n\n\n\n{\n\n  \"positive\": [100, 231],\n\n  \"negative\": [718],\n\n  \"using\": \"image\",\n\n  \"limit\": 10,\n\n  \"lookup_from\": {\n\n    \"collection\":\"{external_collection_name}\",\n\n    \"vector\":\"{external_vector_name}\"\n\n }\n\n}\n\n```\n\n```\nclient . recommend(\n\n    collection_name = \" {collection_name} \" ,\n\n    positive = [ 100 ,  231 ],\n\n    negative = [ 718 ],\n\n    using = \"image\" ,\n\n    limit = 10 ,\n\n    lookup_from = models . LookupLocation(\n\n        collection = \" {external_collection_name} \" ,\n\n        vector = \" {external_vector_name} \" \n\n    ),\n\n)\n\n```\n\n```\nclient.recommend( \"{collection_name}\" , {\n\n  positive :  [ 100 ,  231 ],\n\n  negative :  [ 718 ],\n\n  using :   \"image\" ,\n\n  limit:  10 ,\n\n  lookup_from :  {\n\n         \"collection\"   :   \"{external_collection_name}\" ,\n\n         \"vector\"   :   \"{external_vector_name}\" \n\n    },\n\n});\n\n```\n\nVectors are retrieved from the external collection by ids provided in the `positive` and `negative` lists.\nThese vectors then used to perform the recommendation in the current collection, comparing against the \u201cusing\u201d or default vector.\n\n## Batch recommendation API\n\n *Available as of v0.10.0* \n\nSimilar to the batch search API in terms of usage and advantages, it enables the batching of recommendation requests.\n\n```\nPOST /collections/{collection_name}/points/recommend/batch\n\n{\n\n    \"searches\": [\n\n        {\n\n            \"filter\": {\n\n                    \"must\": [\n\n                        {\n\n                            \"key\": \"city\",\n\n                            \"match\": {\n\n                                \"value\": \"London\"\n\n                            }\n\n                        }\n\n                    ]\n\n            },\n\n            \"negative\": [718],\n\n            \"positive\": [100, 231],\n\n            \"limit\": 10\n\n        },\n\n        {\n\n            \"filter\": {\n\n                \"must\": [\n\n                    {\n\n                        \"key\": \"city\",\n\n                        \"match\": {\n\n                            \"value\": \"London\"\n\n                        }\n\n                    }\n\n                    ]\n\n            },\n\n            \"negative\": [300],\n\n            \"positive\": [200, 67],\n\n            \"limit\": 10\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nfilter   =  models . Filter(\n\n    must = [\n\n        models . FieldCondition(\n\n            key = \"city\" ,\n\n            match = models . MatchValue(\n\n                value = \"London\" ,\n\n            ),\n\n        )\n\n    ]\n\n)\n\n\n\nrecommend_queries  =  [\n\n    models . RecommendRequest(\n\n        positive = [ 100 ,  231 ], negative = [ 718 ],  filter = filter , limit = 3 \n\n    ),\n\n    models . RecommendRequest(positive = [ 200 ,  67 ], negative = [ 300 ],  filter = filter , limit = 3 ),\n\n]\n\n\n\nclient . recommend_batch(collection_name = \" {collection_name} \" , requests = recommend_queries)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nconst  filter  =  {\n\n  must :  [\n\n    {\n\n      key :   \"city\" ,\n\n      match :  {\n\n        value :   \"London\" ,\n\n      },\n\n    },\n\n  ],\n\n};\n\n\n\nconst  searches  =  [\n\n  {\n\n    positive :  [ 100 ,  231 ],\n\n    negative :  [ 718 ],\n\n    filter,\n\n    limit:  3 ,\n\n  },\n\n  {\n\n    positive :  [ 200 ,  67 ],\n\n    negative :  [ 300 ],\n\n    filter,\n\n    limit:  3 ,\n\n  },\n\n];\n\n\n\nclient.recommend_batch( \"{collection_name}\" , {\n\n  searches,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{Condition,   Filter,   RecommendBatchPoints,   RecommendPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nlet   filter   =   Filter::must([Condition::matches( \"city\" ,   \"London\" .to_string())]); \n\n\n\nlet   recommend_queries   =   vec![ \n\n     RecommendPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         positive:  vec ! [ 100. into(),   231. into()], \n\n         negative:  vec ! [ 718. into()], \n\n         filter:  Some (filter.clone()), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }, \n\n     RecommendPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         positive:  vec ! [ 200. into(),   67. into()], \n\n         negative:  vec ! [ 300. into()], \n\n         filter:  Some (filter), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }, \n\n]; \n\n\n\nclient \n\n     .recommend_batch( & RecommendBatchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         recommend_points:  recommend_queries , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThe result of this API contains one array per recommendation requests.\n\n```\n{\n\n   \"result\" : [\n\n    [\n\n        {  \"id\" :  10 ,  \"score\" :  0.81  },\n\n        {  \"id\" :  14 ,  \"score\" :  0.75  },\n\n        {  \"id\" :  11 ,  \"score\" :  0.73  }\n\n    ],\n\n    [\n\n        {  \"id\" :  1 ,  \"score\" :  0.92  },\n\n        {  \"id\" :  3 ,  \"score\" :  0.89  },\n\n        {  \"id\" :  9 ,  \"score\" :  0.75  }\n\n    ]\n\n  ],\n\n   \"status\" :  \"ok\" ,\n\n   \"time\" :  0.001 \n\n}\n\n```\n\n## Discovery API\n\n *Available as of v1.7* \n\nREST API Schema definition available[ here ](https://qdrant.github.io/qdrant/redoc/index.html#tag/points/operation/discover_points)\n\nIn this API, Qdrant introduces the concept of `context` , which is used for splitting the space. Context is a set of positive-negative pairs, and each pair divides the space into positive and negative zones. In that mode, the search operation prefers points based on how many positive zones they belong to (or how much they avoid negative zones).\n\nThe interface for providing context is similar to the recommendation API (ids or raw vectors). Still, in this case, they need to be provided in the form of positive-negative pairs.\n\nDiscovery API lets you do two new types of search:\n\n- **Discovery search** : Uses a target and context pairs of examples to get the points closest to the target, but constrained by the context.\n- **Context search** : Using only the context pairs, get the points that live in the best zone, where loss is minimized\n\n\nThe way positive and negative examples should be arranged in the context pairs is completely up to you. So you can have the flexibility of trying out different permutation techniques based on your model and data.\n\n### Discovery search\n\nThis type of search works specially well for combining multimodal, vector-constrained searches. Qdrant already has extensive support for filters, which constrain the search based on its payload, but using discovery search, you can also constrain the vector space in which the search is performed.\n\nImage: [ Discovery search ](https://qdrant.tech/docs/discovery-search.png)\n\nImage: [ Discovery search ](https://qdrant.tech/docs/discovery-search.png)\n\nThe formula for the discovery score can be expressed as:\n\nwhererepresents a positive example,represents a negative example, andis the similarity score of a vectorto the target vector. The discovery score is then computed as:whereis the similarity function,is the target vector, and againandare the positive and negative examples, respectively. The sigmoid function is used to normalize the score between 0 and 1 and the sum of ranks is used to penalize vectors that are closer to the negative examples than to the positive ones. In other words, the sum of individual ranks determines how many positive zones a point is in, while the closeness hierarchy comes second.\n\nExample:\n\n```\nPOST /collections/{collection_name}/points/discover\n\n\n\n{\n\n  \"target\": [0.2, 0.1, 0.9, 0.7],\n\n  \"context\": [\n\n    {\n\n      \"positive\": 100,\n\n      \"negative\": 718\n\n    },\n\n    {\n\n      \"positive\": 200,\n\n      \"negative\": 300\n\n    }\n\n  ],\n\n  \"limit\": 10\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\ndiscover_queries  =  [\n\n    models . DiscoverRequest(\n\n        target = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n        context = [\n\n            models . ContextExamplePair(\n\n                positive = 100 ,\n\n                negative = 718 ,\n\n            ),\n\n            models . ContextExamplePair(\n\n                positive = 200 ,\n\n                negative = 300 ,\n\n            ),\n\n        ],\n\n        limit = 10 ,\n\n    ),\n\n]\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.discover( \"{collection_name}\" , {\n\n    target :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    context :  [\n\n    {\n\n        positive:  100 ,\n\n        negative:  718 ,\n\n    },\n\n    {\n\n        positive:  200 ,\n\n        negative:  300 ,\n\n    },\n\n    ],\n\n    limit:  10 ,\n\n});\n\n```\n\n- When providing ids as examples, they will be excluded from the results.\n- Score is always in descending order (larger is better), regardless of the metric used.\n- Since the space is hard-constrained by the context, accuracy is normal to drop when using default settings. To mitigate this, increasing the `ef` search parameter to something above 64 will already be much better than the default 16, e.g: `\"params\": { \"ef\": 128 }`\n\n\n### Context search\n\nConversely, in the absence of a target, a rigid integer-by-integer function doesn\u2019t provide much guidance for the search when utilizing a proximity graph like HNSW. Instead, context search employs a function derived from the[ triplet-loss ](https://qdrant.tech/articles/triplet-loss/)concept, which is usually applied during model training. For context search, this function is adapted to steer the search towards areas with fewer negative examples.\n\nImage: [ Context search ](https://qdrant.tech/docs/context-search.png)\n\nImage: [ Context search ](https://qdrant.tech/docs/context-search.png)\n\nWe can directly associate the score function to a loss function, where 0.0 is the maximum score a point can have, which means it is only in positive areas. As soon as a point exists closer to a negative example, its loss will simply be the difference of the positive and negative similarities.\n\nWhereandare the positive and negative examples of each pair, andis the similarity function.\n\nUsing this kind of search, you can expect the output to not necessarily be around a single point, but rather, to be any point that isn\u2019t closer to a negative example, which creates a constrained diverse result. So, even when the API is not called[ recommend ](https://qdrant.tech/documentation/concepts/explore/#recommendation-api), recommendation systems can also use this approach and adapt it for their specific use-cases.\n\nExample:\n\n```\nPOST /collections/{collection_name}/points/discover\n\n\n\n{\n\n  \"context\": [\n\n    {\n\n      \"positive\": 100,\n\n      \"negative\": 718\n\n    },\n\n    {\n\n      \"positive\": 200,\n\n      \"negative\": 300\n\n    }\n\n  ],\n\n  \"limit\": 10\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\ndiscover_queries  =  [\n\n    models . DiscoverRequest(\n\n        context = [\n\n            models . ContextExamplePair(\n\n                positive = 100 ,\n\n                negative = 718 ,\n\n            ),\n\n            models . ContextExamplePair(\n\n                positive = 200 ,\n\n                negative = 300 ,\n\n            ),\n\n        ],\n\n        limit = 10 ,\n\n    ),\n\n]\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.discover( \"{collection_name}\" , {\n\n    context :  [\n\n    {\n\n        positive:  100 ,\n\n        negative:  718 ,\n\n    },\n\n    {\n\n        positive:  200 ,\n\n        negative:  300 ,\n\n    },\n\n    ],\n\n    limit:  10 ,\n\n});\n\n```\n\n- When providing ids as examples, they will be excluded from the results.\n- Score is always in descending order (larger is better), regardless of the metric used.\n- Best possible score is `0.0` , and it is normal that many points get this score.\n\n\n##### Table of contents\n\n- [ Recommendation API ](https://qdrant.tech/documentation/concepts/explore/#recommendation-api)\n    - [ Average vector strategy ](https://qdrant.tech/documentation/concepts/explore/#average-vector-strategy)\n\n- [ Best score strategy ](https://qdrant.tech/documentation/concepts/explore/#best-score-strategy)\n\n- [ Multiple vectors ](https://qdrant.tech/documentation/concepts/explore/#multiple-vectors)\n\n- [ Lookup vectors from another collection ](https://qdrant.tech/documentation/concepts/explore/#lookup-vectors-from-another-collection)\n- [ Batch recommendation API ](https://qdrant.tech/documentation/concepts/explore/#batch-recommendation-api)\n- [ Discovery API ](https://qdrant.tech/documentation/concepts/explore/#discovery-api)\n    - [ Discovery search ](https://qdrant.tech/documentation/concepts/explore/#discovery-search)\n\n- [ Context search ](https://qdrant.tech/documentation/concepts/explore/#context-search)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/explore.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/filtering/": "# Filtering\n\nWith Qdrant, you can set conditions when searching or retrieving points.\nFor example, you can impose conditions on both the[ payload ](../payload)and the `id` of the point.\n\nSetting additional conditions is important when it is impossible to express all the features of the object in the embedding.\nExamples include a variety of business requirements: stock availability, user location, or desired price range.\n\n## Filtering clauses\n\nQdrant allows you to combine conditions in clauses.\nClauses are different logical operations, such as `OR` , `AND` , and `NOT` .\nClauses can be recursively nested into each other so that you can reproduce an arbitrary boolean expression.\n\nLet\u2019s take a look at the clauses implemented in Qdrant.\n\nSuppose we have a set of points with the following payload:\n\n```\n[\n\n  {  \"id\" :  1 ,  \"city\" :  \"London\" ,  \"color\" :  \"green\"  },\n\n  {  \"id\" :  2 ,  \"city\" :  \"London\" ,  \"color\" :  \"red\"  },\n\n  {  \"id\" :  3 ,  \"city\" :  \"London\" ,  \"color\" :  \"blue\"  },\n\n  {  \"id\" :  4 ,  \"city\" :  \"Berlin\" ,  \"color\" :  \"red\"  },\n\n  {  \"id\" :  5 ,  \"city\" :  \"Moscow\" ,  \"color\" :  \"green\"  },\n\n  {  \"id\" :  6 ,  \"city\" :  \"Moscow\" ,  \"color\" :  \"blue\"  }\n\n]\n\n```\n\n### Must\n\nExample:\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            { \"key\": \"city\", \"match\": { \"value\": \"London\" } },\n\n            { \"key\": \"color\", \"match\": { \"value\": \"red\" } }\n\n        ]\n\n    }\n\n    ...\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient(host = \"localhost\" , port = 6333 )\n\n\n\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"city\" ,\n\n                match = models . MatchValue(value = \"London\" ),\n\n            ),\n\n            models . FieldCondition(\n\n                key = \"color\" ,\n\n                match = models . MatchValue(value = \"red\" ),\n\n            ),\n\n        ]\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"city\" ,\n\n        match :  { value :   \"London\"  },\n\n      },\n\n      {\n\n        key :   \"color\" ,\n\n        match :  { value :   \"red\"  },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{Condition,   Filter,   ScrollPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         filter:  Some (Filter::must([ \n\n             Condition::matches( \"city\" ,   \"london\" .to_string()), \n\n             Condition::matches( \"color\" ,   \"red\" .to_string()), \n\n         ])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFiltered points would be:\n\n`[{  \"id\" :  2 ,  \"city\" :  \"London\" ,  \"color\" :  \"red\"  }]\n`\n\nWhen using `must` , the clause becomes `true` only if every condition listed inside `must` is satisfied.\nIn this sense, `must` is equivalent to the operator `AND` .\n\n### Should\n\nExample:\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"should\": [\n\n            { \"key\": \"city\", \"match\": { \"value\": \"London\" } },\n\n            { \"key\": \"color\", \"match\": { \"value\": \"red\" } }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        should = [\n\n            models . FieldCondition(\n\n                key = \"city\" ,\n\n                match = models . MatchValue(value = \"London\" ),\n\n            ),\n\n            models . FieldCondition(\n\n                key = \"color\" ,\n\n                match = models . MatchValue(value = \"red\" ),\n\n            ),\n\n        ]\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    should :  [\n\n      {\n\n        key :   \"city\" ,\n\n        match :  { value :   \"London\"  },\n\n      },\n\n      {\n\n        key :   \"color\" ,\n\n        match :  { value :   \"red\"  },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         filter:  Some (Filter::should([ \n\n             Condition::matches( \"city\" ,   \"london\" .to_string()), \n\n             Condition::matches( \"color\" ,   \"red\" .to_string()), \n\n         ])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFiltered points would be:\n\n```\n[\n\n  {  \"id\" :  1 ,  \"city\" :  \"London\" ,  \"color\" :  \"green\"  },\n\n  {  \"id\" :  2 ,  \"city\" :  \"London\" ,  \"color\" :  \"red\"  },\n\n  {  \"id\" :  3 ,  \"city\" :  \"London\" ,  \"color\" :  \"blue\"  },\n\n  {  \"id\" :  4 ,  \"city\" :  \"Berlin\" ,  \"color\" :  \"red\"  }\n\n]\n\n```\n\nWhen using `should` , the clause becomes `true` if at least one condition listed inside `should` is satisfied.\nIn this sense, `should` is equivalent to the operator `OR` .\n\n### Must Not\n\nExample:\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must_not\": [\n\n            { \"key\": \"city\", \"match\": { \"value\": \"London\" } },\n\n            { \"key\": \"color\", \"match\": { \"value\": \"red\" } }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must_not = [\n\n            models . FieldCondition(key = \"city\" , match = models . MatchValue(value = \"London\" )),\n\n            models . FieldCondition(key = \"color\" , match = models . MatchValue(value = \"red\" )),\n\n        ]\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must_not :  [\n\n      {\n\n        key :   \"city\" ,\n\n        match :  { value :   \"London\"  },\n\n      },\n\n      {\n\n        key :   \"color\" ,\n\n        match :  { value :   \"red\"  },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         filter:  Some (Filter::must_not([ \n\n             Condition::matches( \"city\" ,   \"london\" .to_string()), \n\n             Condition::matches( \"color\" ,   \"red\" .to_string()), \n\n         ])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFiltered points would be:\n\n```\n[\n\n  {  \"id\" :  5 ,  \"city\" :  \"Moscow\" ,  \"color\" :  \"green\"  },\n\n  {  \"id\" :  6 ,  \"city\" :  \"Moscow\" ,  \"color\" :  \"blue\"  }\n\n]\n\n```\n\nWhen using `must_not` , the clause becomes `true` if none if the conditions listed inside `should` is satisfied.\nIn this sense, `must_not` is equivalent to the expression `(NOT A) AND (NOT B) AND (NOT C)` .\n\n### Clauses combination\n\nIt is also possible to use several clauses simultaneously:\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            { \"key\": \"city\", \"match\": { \"value\": \"London\" } }\n\n        ],\n\n        \"must_not\": [\n\n            { \"key\": \"color\", \"match\": { \"value\": \"red\" } }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(key = \"city\" , match = models . MatchValue(value = \"London\" )),\n\n        ],\n\n        must_not = [\n\n            models . FieldCondition(key = \"color\" , match = models . MatchValue(value = \"red\" )),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"city\" ,\n\n        match :  { value :   \"London\"  },\n\n      },\n\n    ],\n\n    must_not :  [\n\n      {\n\n        key :   \"color\" ,\n\n        match :  { value :   \"red\"  },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter   { \n\n             must:  vec ! [Condition::matches( \"city\" ,   \"London\" .to_string())], \n\n             must_not:  vec ! [Condition::matches( \"color\" ,   \"red\" .to_string())], \n\n             .. Default ::default() \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFiltered points would be:\n\n```\n[\n\n  {  \"id\" :  1 ,  \"city\" :  \"London\" ,  \"color\" :  \"green\"  },\n\n  {  \"id\" :  3 ,  \"city\" :  \"London\" ,  \"color\" :  \"blue\"  }\n\n]\n\n```\n\nIn this case, the conditions are combined by `AND` .\n\nAlso, the conditions could be recursively nested. Example:\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must_not\": [\n\n            {\n\n                \"must\": [\n\n                    { \"key\": \"city\", \"match\": { \"value\": \"London\" } },\n\n                    { \"key\": \"color\", \"match\": { \"value\": \"red\" } }\n\n                ]\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must_not = [\n\n            models . Filter(\n\n                must = [\n\n                    models . FieldCondition(\n\n                        key = \"city\" , match = models . MatchValue(value = \"London\" )\n\n                    ),\n\n                    models . FieldCondition(\n\n                        key = \"color\" , match = models . MatchValue(value = \"red\" )\n\n                    ),\n\n                ],\n\n            ),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must_not :  [\n\n      {\n\n        must :  [\n\n          {\n\n            key :   \"city\" ,\n\n            match :  { value :   \"London\"  },\n\n          },\n\n          {\n\n            key :   \"color\" ,\n\n            match :  { value :   \"red\"  },\n\n          },\n\n        ],\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must_not([Filter::must([ \n\n             Condition::matches( \"city\" ,   \"London\" .to_string()), \n\n             Condition::matches( \"color\" ,   \"Red\" .to_string()), \n\n         ]) \n\n         .into()])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFiltered points would be:\n\n```\n[\n\n  {  \"id\" :  1 ,  \"city\" :  \"London\" ,  \"color\" :  \"green\"  },\n\n  {  \"id\" :  3 ,  \"city\" :  \"London\" ,  \"color\" :  \"blue\"  },\n\n  {  \"id\" :  4 ,  \"city\" :  \"Berlin\" ,  \"color\" :  \"red\"  },\n\n  {  \"id\" :  5 ,  \"city\" :  \"Moscow\" ,  \"color\" :  \"green\"  },\n\n  {  \"id\" :  6 ,  \"city\" :  \"Moscow\" ,  \"color\" :  \"blue\"  }\n\n]\n\n```\n\n## Filtering conditions\n\nDifferent types of values in payload correspond to different kinds of queries that we can apply to them.\nLet\u2019s look at the existing condition variants and what types of data they apply to.\n\n### Match\n\n```\n{\n\n   \"key\" :  \"color\" ,\n\n   \"match\" : {\n\n     \"value\" :  \"red\" \n\n  }\n\n}\n\n```\n\n```\nmodels . FieldCondition(\n\n    key = \"color\" ,\n\n    match = models . MatchValue(value = \"red\" ),\n\n)\n\n```\n\n```\n{\n\n    key :   'color' , \n\n    match :  {value :   'red' }\n\n}\n\n```\n\n`Condition::matches( \"color\" ,   \"red\" .to_string()) \n`\n\nFor the other types, the match condition will look exactly the same, except for the type used:\n\n```\n{\n\n   \"key\" :  \"count\" ,\n\n   \"match\" : {\n\n     \"value\" :  0 \n\n  }\n\n}\n\n```\n\n```\nmodels . FieldCondition(\n\n    key = \"count\" ,\n\n    match = models . MatchValue(value = 0 ),\n\n)\n\n```\n\n```\n{\n\n    key :   'count' ,\n\n    match :  {value:  0 }    \n\n}\n\n```\n\n`Condition::matches( \"count\" ,   0 ) \n`\n\nThe simplest kind of condition is one that checks if the stored value equals the given one.\nIf several values are stored, at least one of them should match the condition.\nYou can apply it to[ keyword ](../payload/#keyword),[ integer ](../payload/#integer)and[ bool ](../payload/#bool)payloads.\n\n### Match Any\n\n *Available as of v1.1.0* \n\nIn case you want to check if the stored value is one of multiple values, you can use the Match Any condition.\nMatch Any works as a logical OR for the given values. It can also be described as a `IN` operator.\n\nYou can apply it to[ keyword ](../payload/#keyword)and[ integer ](../payload/#integer)payloads.\n\nExample:\n\n```\n{\n\n   \"key\" :  \"color\" ,\n\n   \"match\" : {\n\n     \"any\" : [ \"black\" ,  \"yellow\" ]\n\n  }\n\n}\n\n```\n\n```\nFieldCondition(\n\n    key = \"color\" ,\n\n    match = models . MatchAny( any = [ \"black\" ,  \"yellow\" ]),\n\n)\n\n```\n\n```\n{\n\n    key :   'color' ,\n\n    match :  { any :  [ 'black' ,  'yellow' ]}    \n\n}\n\n```\n\n`Condition::matches( \"color\" ,   vec![ \"black\" .to_string(),   \"yellow\" .to_string()]) \n`\n\nIn this example, the condition will be satisfied if the stored value is either `black` or `yellow` .\n\nIf the stored value is an array, it should have at least one value matching any of the given values. E.g. if the stored value is `[\"black\", \"green\"]` , the condition will be satisfied, because `\"black\"` is in `[\"black\", \"yellow\"]` .\n\n### Match Except\n\n *Available as of v1.2.0* \n\nIn case you want to check if the stored value is not one of multiple values, you can use the Match Except condition.\nMatch Except works as a logical NOR for the given values.\nIt can also be described as a `NOT IN` operator.\n\nYou can apply it to[ keyword ](../payload/#keyword)and[ integer ](../payload/#integer)payloads.\n\nExample:\n\n```\n{\n\n   \"key\" :  \"color\" ,\n\n   \"match\" : {\n\n     \"except\" : [ \"black\" ,  \"yellow\" ]\n\n  }\n\n}\n\n```\n\n```\nFieldCondition(\n\n    key = \"color\" ,\n\n    match = models . MatchExcept( ** { \"except\" : [ \"black\" ,  \"yellow\" ]}),\n\n)\n\n```\n\n```\n{\n\n    key :   'color' ,\n\n    match :  {except :  [ 'black' ,  'yellow' ]}\n\n}\n\n```\n\n```\nCondition::matches( \n\n     \"color\" , \n\n     ! MatchValue::from(vec![ \"black\" .to_string(),   \"yellow\" .to_string()]), \n\n) \n\n```\n\nIn this example, the condition will be satisfied if the stored value is neither `black` nor `yellow` .\n\nIf the stored value is an array, it should have at least one value not matching any of the given values. E.g. if the stored value is `[\"black\", \"green\"]` , the condition will be satisfied, because `\"green\"` does not match `\"black\"` nor `\"yellow\"` .\n\n### Nested key\n\n *Available as of v1.1.0* \n\nPayloads being arbitrary JSON object, it is likely that you will need to filter on a nested field.\n\nFor convenience, we use a syntax similar to what can be found in the[ Jq ](https://stedolan.github.io/jq/manual/#Basicfilters)project.\n\nSuppose we have a set of points with the following payload:\n\n```\n[\n\n  {\n\n     \"id\" :  1 ,\n\n     \"country\" : {\n\n       \"name\" :  \"Germany\" ,\n\n       \"cities\" : [\n\n        {\n\n           \"name\" :  \"Berlin\" ,\n\n           \"population\" :  3.7 ,\n\n           \"sightseeing\" : [ \"Brandenburg Gate\" ,  \"Reichstag\" ]\n\n        },\n\n        {\n\n           \"name\" :  \"Munich\" ,\n\n           \"population\" :  1.5 ,\n\n           \"sightseeing\" : [ \"Marienplatz\" ,  \"Olympiapark\" ]\n\n        }\n\n      ]\n\n    }\n\n  },\n\n  {\n\n     \"id\" :  2 ,\n\n     \"country\" : {\n\n       \"name\" :  \"Japan\" ,\n\n       \"cities\" : [\n\n        {\n\n           \"name\" :  \"Tokyo\" ,\n\n           \"population\" :  9.3 ,\n\n           \"sightseeing\" : [ \"Tokyo Tower\" ,  \"Tokyo Skytree\" ]\n\n        },\n\n        {\n\n           \"name\" :  \"Osaka\" ,\n\n           \"population\" :  2.7 ,\n\n           \"sightseeing\" : [ \"Osaka Castle\" ,  \"Universal Studios Japan\" ]\n\n        }\n\n      ]\n\n    }\n\n  }\n\n]\n\n```\n\nYou can search on a nested field using a dot notation.\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"should\": [\n\n            {\n\n                \"key\": \"country.name\",\n\n                \"match\": {\n\n                    \"value\": \"Germany\"\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        should = [\n\n            models . FieldCondition(\n\n                key = \"country.name\" , match = models . MatchValue(value = \"Germany\" )\n\n            ),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    should :  [\n\n      {\n\n        key :   \"country.name\" ,\n\n        match :  { value :   \"Germany\"  },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::should([Condition::matches( \n\n             \"country.name\" , \n\n             \"Germany\" .to_string(), \n\n         )])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nYou can also search through arrays by projecting inner values using the `[]` syntax.\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"should\": [\n\n            {\n\n                \"key\": \"country.cities[].population\",\n\n                \"range\": {\n\n                    \"gte\": 9.0,\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        should = [\n\n            models . FieldCondition(\n\n                key = \"country.cities[].population\" ,\n\n                 range = models . Range(\n\n                    gt = None ,\n\n                    gte = 9.0 ,\n\n                    lt = None ,\n\n                    lte = None ,\n\n                ),\n\n            ),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    should :  [\n\n      {\n\n        key :   \"country.cities[].population\" ,\n\n        range :  {\n\n          gt:  null ,\n\n          gte:  9.0 ,\n\n          lt:  null ,\n\n          lte:  null ,\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   Range,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::should([Condition::range( \n\n             \"country.cities[].population\" , \n\n             Range   { \n\n                 gte:  Some ( 9.0 ), \n\n                 .. Default ::default() \n\n             }, \n\n         )])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThis query would only output the point with id 2 as only Japan has a city with population greater than 9.0.\n\nAnd the leaf nested field can also be an array.\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"should\": [\n\n            {\n\n                \"key\": \"country.cities[].sightseeing\",\n\n                \"match\": {\n\n                    \"value\": \"Osaka Castle\"\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        should = [\n\n            models . FieldCondition(\n\n                key = \"country.cities[].sightseeing\" ,\n\n                match = models . MatchValue(value = \"Osaka Castle\" ),\n\n            ),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    should :  [\n\n      {\n\n        key :   \"country.cities[].sightseeing\" ,\n\n        match :  { value :   \"Osaka Castle\"  },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::should([Condition::matches( \n\n             \"country.cities[].sightseeing\" , \n\n             \"Osaka Castle\" .to_string(), \n\n         )])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThis query would only output the point with id 2 as only Japan has a city with the \u201cOsaka castke\u201d as part of the sightseeing.\n\n### Nested object filter\n\n *Available as of v1.2.0* \n\nBy default, the conditions are taking into account the entire payload of a point.\n\nFor instance, given two points with the following payload:\n\n```\n[\n\n  {\n\n     \"id\" :  1 ,\n\n     \"dinosaur\" :  \"t-rex\" ,\n\n     \"diet\" : [\n\n      {  \"food\" :  \"leaves\" ,  \"likes\" :  false },\n\n      {  \"food\" :  \"meat\" ,  \"likes\" :  true }\n\n    ]\n\n  },\n\n  {\n\n     \"id\" :  2 ,\n\n     \"dinosaur\" :  \"diplodocus\" ,\n\n     \"diet\" : [\n\n      {  \"food\" :  \"leaves\" ,  \"likes\" :  true },\n\n      {  \"food\" :  \"meat\" ,  \"likes\" :  false }\n\n    ]\n\n  }\n\n]\n\n```\n\nThe following query would match both points:\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"diet[].food\",\n\n                  \"match\": {\n\n                    \"value\": \"meat\"\n\n                }\n\n            },\n\n            {\n\n                \"key\": \"diet[].likes\",\n\n                  \"match\": {\n\n                    \"value\": true\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"diet[].food\" , match = models . MatchValue(value = \"meat\" )\n\n            ),\n\n            models . FieldCondition(\n\n                key = \"diet[].likes\" , match = models . MatchValue(value = True )\n\n            ),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        key :   \"diet[].food\" ,\n\n        match :  { value :   \"meat\"  },\n\n      },\n\n      {\n\n        key :   \"diet[].likes\" ,\n\n        match :  { value:  true  },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         filter:  Some (Filter::must([ \n\n             Condition::matches( \"diet[].food\" ,   \"meat\" .to_string()), \n\n             Condition::matches( \"diet[].likes\" ,   true ), \n\n         ])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThis happens because both points are matching the two conditions:\n\n- the \u201ct-rex\u201d matches food=meat on `diet[1].food` and likes=true on `diet[1].likes`\n- the \u201cdiplodocus\u201d matches food=meat on `diet[1].food` and likes=true on `diet[0].likes`\n\n\nTo retrieve only the points which are matching the conditions on an array element basis, that is the point with id 1 in this example, you would need to use a nested object filter.\n\nNested object filters allow arrays of objects to be queried independently of each other.\n\nIt is achieved by using the `nested` condition type formed by a payload key to focus on and a filter to apply.\n\nThe key should point to an array of objects and can be used with or without the bracket notation (\u201cdata\u201d or \u201cdata[]\u201d).\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            \"nested\": {\n\n                {\n\n                    \"key\": \"diet\",\n\n                    \"filter\":{\n\n                        \"must\": [\n\n                            {\n\n                                \"key\": \"food\",\n\n                                \"match\": {\n\n                                    \"value\": \"meat\"\n\n                                }\n\n                            },\n\n                            {\n\n                                \"key\": \"likes\",\n\n                                \"match\": {\n\n                                    \"value\": true\n\n                                }\n\n                            }\n\n                        ]\n\n                    }\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must = [\n\n            models . NestedCondition(\n\n                nested = models . Nested(\n\n                    key = \"diet\" ,\n\n                     filter = models . Filter(\n\n                        must = [\n\n                            models . FieldCondition(\n\n                                key = \"food\" , match = models . MatchValue(value = \"meat\" )\n\n                            ),\n\n                            models . FieldCondition(\n\n                                key = \"likes\" , match = models . MatchValue(value = True )\n\n                            ),\n\n                        ]\n\n                    ),\n\n                )\n\n            )\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        nested :  {\n\n          key :   \"diet\" ,\n\n          filter :  {\n\n            must :  [\n\n              {\n\n                key :   \"food\" ,\n\n                match :  { value :   \"meat\"  },\n\n              },\n\n              {\n\n                key :   \"likes\" ,\n\n                match :  { value:  true  },\n\n              },\n\n            ],\n\n          },\n\n        },\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   NestedCondition,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must([NestedCondition   { \n\n             key:  \"diet\" .to_string(), \n\n             filter:  Some (Filter::must([ \n\n                 Condition::matches( \"food\" ,   \"meat\" .to_string()), \n\n                 Condition::matches( \"likes\" ,   true ), \n\n             ])), \n\n         } \n\n         .into()])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThe matching logic is modified to be applied at the level of an array element within the payload.\n\nNested filters work in the same way as if the nested filter was applied to a single element of the array at a time.\nParent document is considered to match the condition if at least one element of the array matches the nested filter.\n\n **Limitations** \n\nThe `has_id` condition is not supported within the nested object filter. If you need it, place it in an adjacent `must` clause.\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            \"nested\": {\n\n                {\n\n                    \"key\": \"diet\",\n\n                    \"filter\":{\n\n                        \"must\": [\n\n                            {\n\n                                \"key\": \"food\",\n\n                                \"match\": {\n\n                                    \"value\": \"meat\"\n\n                                }\n\n                            },\n\n                            {\n\n                                \"key\": \"likes\",\n\n                                \"match\": {\n\n                                    \"value\": true\n\n                                }\n\n                            }\n\n                        ]\n\n                    }\n\n                }\n\n            },\n\n            { \"has_id\": [1] }\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must = [\n\n            models . NestedCondition(\n\n                nested = models . Nested(\n\n                    key = \"diet\" ,\n\n                     filter = models . Filter(\n\n                        must = [\n\n                            models . FieldCondition(\n\n                                key = \"food\" , match = models . MatchValue(value = \"meat\" )\n\n                            ),\n\n                            models . FieldCondition(\n\n                                key = \"likes\" , match = models . MatchValue(value = True )\n\n                            ),\n\n                        ]\n\n                    ),\n\n                )\n\n            ),\n\n            models . HasIdCondition(has_id = [ 1 ]),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        nested :  {\n\n          key :   \"diet\" ,\n\n          filter :  {\n\n            must :  [\n\n              {\n\n                key :   \"food\" ,\n\n                match :  { value :   \"meat\"  },\n\n              },\n\n              {\n\n                key :   \"likes\" ,\n\n                match :  { value:  true  },\n\n              },\n\n            ],\n\n          },\n\n        },\n\n      },\n\n      {\n\n        has_id :  [ 1 ],\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   NestedCondition,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must([ \n\n             NestedCondition   { \n\n                 key:  \"diet\" .to_string(), \n\n                 filter:  Some (Filter::must([ \n\n                     Condition::matches( \"food\" ,   \"meat\" .to_string()), \n\n                     Condition::matches( \"likes\" ,   true ), \n\n                 ])), \n\n             } \n\n             .into(), \n\n             Condition::has_id([ 1 ]), \n\n         ])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n### Full Text Match\n\n *Available as of v0.10.0* \n\nA special case of the `match` condition is the `text` match condition.\nIt allows you to search for a specific substring, token or phrase within the text field.\n\nExact texts that will match the condition depend on full-text index configuration.\nConfiguration is defined during the index creation and describe at[ full-text index ](../indexing/#full-text-index).\n\nIf there is no full-text index for the field, the condition will work as exact substring match.\n\n```\n{\n\n   \"key\" :  \"description\" ,\n\n   \"match\" : {\n\n     \"text\" :  \"good cheap\" \n\n  }\n\n}\n\n```\n\n```\nmodels . FieldCondition(\n\n    key = \"description\" ,\n\n    match = models . MatchText(text = \"good cheap\" ),\n\n)\n\n```\n\n```\n{\n\n    key :   'description' ,\n\n    match :  {text :   'good cheap' }    \n\n}\n\n```\n\n```\n// If the match string contains a white-space, full text match is performed.\n\n// Otherwise a keyword match is performed.\n\nCondition::matches( \"description\" ,   \"good cheap\" .to_string()) \n\n```\n\nIf the query has several words, then the condition will be satisfied only if all of them are present in the text.\n\n### Range\n\n```\n{\n\n   \"key\" :  \"price\" ,\n\n   \"range\" : {\n\n     \"gt\" :  null ,\n\n     \"gte\" :  100.0 ,\n\n     \"lt\" :  null ,\n\n     \"lte\" :  450.0 \n\n  }\n\n}\n\n```\n\n```\nmodels . FieldCondition(\n\n    key = \"price\" ,\n\n     range = models . Range(\n\n        gt = None ,\n\n        gte = 100.0 ,\n\n        lt = None ,\n\n        lte = 450.0 ,\n\n    ),\n\n)\n\n```\n\n```\n{\n\n    key :   'price' ,\n\n    range :  {\n\n        gt:  null ,\n\n        gte:  100.0 ,\n\n        lt:  null ,\n\n        lte:  450.0     \n\n    }    \n\n}\n\n```\n\n```\nCondition::range( \n\n     \"price\" , \n\n     Range   { \n\n         gt:  None , \n\n         gte:  Some ( 100.0 ), \n\n         lt:  None , \n\n         lte:  Some ( 450.0 ), \n\n     }, \n\n) \n\n```\n\nThe `range` condition sets the range of possible values for stored payload values.\nIf several values are stored, at least one of them should match the condition.\n\nComparisons that can be used:\n\n- `gt` - greater than\n- `gte` - greater than or equal\n- `lt` - less than\n- `lte` - less than or equal\n\n\nCan be applied to[ float ](../payload/#float)and[ integer ](../payload/#integer)payloads.\n\n### Geo\n\n#### Geo Bounding Box\n\n```\n{\n\n   \"key\" :  \"location\" ,\n\n   \"geo_bounding_box\" : {\n\n     \"bottom_right\" : {\n\n       \"lon\" :  13.455868 ,\n\n       \"lat\" :  52.495862 \n\n    },\n\n     \"top_left\" : {\n\n       \"lon\" :  13.403683 ,\n\n       \"lat\" :  52.520711 \n\n    }\n\n  }\n\n}\n\n```\n\n```\nmodels . FieldCondition(\n\n    key = \"location\" ,\n\n    geo_bounding_box = models . GeoBoundingBox(\n\n        bottom_right = models . GeoPoint(\n\n            lon = 13.455868 ,\n\n            lat = 52.495862 ,\n\n        ),\n\n        top_left = models . GeoPoint(\n\n            lon = 13.403683 ,\n\n            lat = 52.520711 ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\n{\n\n    key :   'location' ,\n\n    geo_bounding_box :  {\n\n        bottom_right :  {\n\n            lon:  13.455868 ,\n\n            lat:  52.495862 \n\n        },\n\n        top_left :  {\n\n            lon:  13.403683 ,\n\n            lat:  52.520711 \n\n        }\n\n    }\n\n}\n\n```\n\n```\nCondition::geo_bounding_box( \n\n     \"location\" , \n\n     GeoBoundingBox   { \n\n         bottom_right:  Some (GeoPoint   { \n\n             lon:  13.455868 , \n\n             lat:  52.495862 , \n\n         }), \n\n         top_left:  Some (GeoPoint   { \n\n             lon:  13.403683 , \n\n             lat:  52.520711 , \n\n         }), \n\n     }, \n\n) \n\n```\n\nIt matches with `location` s inside a rectangle with the coordinates of the upper left corner in `bottom_right` and the coordinates of the lower right corner in `top_left` .\n\n#### Geo Radius\n\n```\n{\n\n   \"key\" :  \"location\" ,\n\n   \"geo_radius\" : {\n\n     \"center\" : {\n\n       \"lon\" :  13.403683 ,\n\n       \"lat\" :  52.520711 \n\n    },\n\n     \"radius\" :  1000.0 \n\n  }\n\n}\n\n```\n\n```\nmodels . FieldCondition(\n\n    key = \"location\" ,\n\n    geo_radius = models . GeoRadius(\n\n        center = models . GeoPoint(\n\n            lon = 13.403683 ,\n\n            lat = 52.520711 ,\n\n        ),\n\n        radius = 1000.0 ,\n\n    ),\n\n)\n\n```\n\n```\n{\n\n    key :   'location' ,\n\n    geo_radius :  {\n\n        center :  {\n\n            lon:  13.403683 ,\n\n            lat:  52.520711 \n\n        },\n\n        radius:  1000.0 \n\n    }    \n\n}\n\n```\n\n```\nCondition::geo_radius( \n\n     \"location\" , \n\n     GeoRadius   { \n\n         center:  Some (GeoPoint   { \n\n             lon:  13.403683 , \n\n             lat:  52.520711 , \n\n         }), \n\n         radius:  1000.0 , \n\n     }, \n\n) \n\n```\n\nIt matches with `location` s inside a circle with the `center` at the center and a radius of `radius` meters.\n\nIf several values are stored, at least one of them should match the condition.\nThese conditions can only be applied to payloads that match the[ geo-data format ](../payload/#geo).\n\n#### Geo Polygon\n\nGeo Polygons search is useful for when you want to find points inside an irregularly shaped area, for example a country boundary or a forest boundary. A polygon always has an exterior ring and may optionally include interior rings. A lake with an island would be an example of an interior ring. If you wanted to find points in the water but not on the island, you would make an interior ring for the island.\n\nWhen defining a ring, you must pick either a clockwise or counterclockwise ordering for your points. The first and last point of the polygon must be the same.\n\nCurrently, we only support unprojected global coordinates (decimal degrees longitude and latitude) and we are datum agnostic.\n\n```\n\n\n{\n\n   \"key\" :  \"location\" ,\n\n   \"geo_polygon\" : {\n\n     \"exterior\" : {\n\n       \"points\" : [\n\n        {  \"lon\" :  -70.0 ,  \"lat\" :  -70.0  },\n\n        {  \"lon\" :  60.0 ,  \"lat\" :  -70.0  },\n\n        {  \"lon\" :  60.0 ,  \"lat\" :  60.0  },\n\n        {  \"lon\" :  -70.0 ,  \"lat\" :  60.0  },\n\n        {  \"lon\" :  -70.0 ,  \"lat\" :  -70.0  }\n\n      ]\n\n    },\n\n     \"interiors\" : [\n\n      {\n\n         \"points\" : [\n\n          {  \"lon\" :  -65.0 ,  \"lat\" :  -65.0  },\n\n          {  \"lon\" :  0.0 ,  \"lat\" :  -65.0  },\n\n          {  \"lon\" :  0.0 ,  \"lat\" :  0.0  },\n\n          {  \"lon\" :  -65.0 ,  \"lat\" :  0.0  },\n\n          {  \"lon\" :  -65.0 ,  \"lat\" :  -65.0  }\n\n        ]\n\n      }\n\n    ]\n\n  }\n\n}\n\n```\n\n```\nmodels . FieldCondition(\n\n    key = \"location\" ,\n\n    geo_polygon = models . GeoPolygon(\n\n        exterior = models . GeoLineString(\n\n            points = [\n\n                models . GeoPoint(\n\n                    lon =- 70.0 ,\n\n                    lat =- 70.0 ,\n\n                ),\n\n                models . GeoPoint(\n\n                    lon = 60.0 ,\n\n                    lat =- 70.0 ,\n\n                ),\n\n                models . GeoPoint(\n\n                    lon = 60.0 ,\n\n                    lat = 60.0 ,\n\n                ),\n\n                models . GeoPoint(\n\n                    lon =- 70.0 ,\n\n                    lat = 60.0 ,\n\n                ),\n\n                models . GeoPoint(\n\n                    lon =- 70.0 ,\n\n                    lat =- 70.0 ,\n\n                ),\n\n            ]\n\n        ),\n\n        interiors = [\n\n            models . GeoLineString(\n\n                points = [\n\n                    models . GeoPoint(\n\n                        lon =- 65.0 ,\n\n                        lat =- 65.0 ,\n\n                    ),\n\n                    models . GeoPoint(\n\n                        lon = 0.0 ,\n\n                        lat =- 65.0 ,\n\n                    ),\n\n                    models . GeoPoint(\n\n                        lon = 0.0 ,\n\n                        lat = 0.0 ,\n\n                    ),\n\n                    models . GeoPoint(\n\n                        lon =- 65.0 ,\n\n                        lat = 0.0 ,\n\n                    ),\n\n                    models . GeoPoint(\n\n                        lon =- 65.0 ,\n\n                        lat =- 65.0 ,\n\n                    ),\n\n                ]\n\n            )\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\n{\n\n    key :   'location' , \n\n    geo_polygon :  {\n\n        exterior :  {\n\n            points :  [\n\n                {\n\n                    lon :   - 70.0 ,\n\n                    lat :   - 70.0 \n\n                },\n\n                {\n\n                    lon:  60.0 ,\n\n                    lat :   - 70.0 \n\n                },\n\n                {\n\n                    lon:  60.0 ,\n\n                    lat:  60.0 \n\n                },\n\n                {\n\n                    lon :   - 70.0 ,\n\n                    lat:  60.0 \n\n                },\n\n                {\n\n                    lon :   - 70.0 ,\n\n                    lat :   - 70.0 \n\n                }\n\n            ]\n\n        },\n\n        interiors :  {\n\n            points :  [\n\n                {\n\n                    lon :   - 65.0 ,\n\n                    lat :   - 65.0 \n\n                },\n\n                {\n\n                    lon:  0.0 ,\n\n                    lat :   - 65.0 \n\n                },\n\n                {\n\n                    lon:  0.0 ,\n\n                    lat:  0.0 \n\n                },\n\n                {\n\n                    lon :   - 65.0 ,\n\n                    lat:  0.0 \n\n                },\n\n                {\n\n                    lon :   - 65.0 ,\n\n                    lat :   - 65.0 \n\n                }\n\n            ]\n\n        }\n\n    }\n\n}\n\n```\n\n```\nCondition::geo_polygon( \n\n     \"location\" , \n\n     GeoPolygon   { \n\n         exterior:  Some (GeoLineString   { \n\n             points:  vec ! [ \n\n                 GeoPoint   { \n\n                     lon:  - 70.0 , \n\n                     lat:  - 70.0 , \n\n                 }, \n\n                 GeoPoint   { \n\n                     lon:  60.0 , \n\n                     lat:  - 70.0 , \n\n                 }, \n\n                 GeoPoint   { \n\n                     lon:  60.0 , \n\n                     lat:  60.0 , \n\n                 }, \n\n                 GeoPoint   { \n\n                     lon:  - 70.0 , \n\n                     lat:  60.0 , \n\n                 }, \n\n                 GeoPoint   { \n\n                     lon:  - 70.0 , \n\n                     lat:  - 70.0 , \n\n                 }, \n\n             ], \n\n         }), \n\n         interiors:  vec ! [GeoLineString   { \n\n             points:  vec ! [ \n\n                 GeoPoint   { \n\n                     lon:  - 65.0 , \n\n                     lat:  - 65.0 , \n\n                 }, \n\n                 GeoPoint   { \n\n                     lon:  0.0 , \n\n                     lat:  - 65.0 , \n\n                 }, \n\n                 GeoPoint   {   lon:  0.0 ,   lat:  0.0   }, \n\n                 GeoPoint   { \n\n                     lon:  - 65.0 , \n\n                     lat:  0.0 , \n\n                 }, \n\n                 GeoPoint   { \n\n                     lon:  - 65.0 , \n\n                     lat:  - 65.0 , \n\n                 }, \n\n             ], \n\n         }], \n\n     }, \n\n) \n\n```\n\nA match is considered any point location inside or on the boundaries of the given polygon\u2019s exterior but not inside any interiors.\n\nIf several location values are stored for a point, then any of them matching will include that point as a candidate in the resultset.\nThese conditions can only be applied to payloads that match the[ geo-data format ](../payload/#geo).\n\n### Values count\n\nIn addition to the direct value comparison, it is also possible to filter by the amount of values.\n\nFor example, given the data:\n\n```\n[\n\n  {  \"id\" :  1 ,  \"name\" :  \"product A\" ,  \"comments\" : [ \"Very good!\" ,  \"Excellent\" ] },\n\n  {  \"id\" :  2 ,  \"name\" :  \"product B\" ,  \"comments\" : [ \"meh\" ,  \"expected more\" ,  \"ok\" ] }\n\n]\n\n```\n\nWe can perform the search only among the items with more than two comments:\n\n```\n{\n\n   \"key\" :  \"comments\" ,\n\n   \"values_count\" : {\n\n     \"gt\" :  2 \n\n  }\n\n}\n\n```\n\n```\nmodels . FieldCondition(\n\n    key = \"comments\" ,\n\n    values_count = models . ValuesCount(gt = 2 ),\n\n)\n\n```\n\n```\n{\n\n    key :   'comments' ,\n\n    values_count :  {gt:  2 }    \n\n}\n\n```\n\n```\nCondition::values_count( \n\n     \"comments\" , \n\n     ValuesCount   { \n\n         gt:  Some ( 2 ), \n\n         .. Default ::default() \n\n     }, \n\n) \n\n```\n\nThe result would be:\n\n`[{  \"id\" :  2 ,  \"name\" :  \"product B\" ,  \"comments\" : [ \"meh\" ,  \"expected more\" ,  \"ok\" ] }]\n`\n\nIf stored value is not an array - it is assumed that the amount of values is equals to 1.\n\n### Is Empty\n\nSometimes it is also useful to filter out records that are missing some value.\nThe `IsEmpty` condition may help you with that:\n\n```\n{\n\n   \"is_empty\" : {\n\n     \"key\" :  \"reports\" \n\n  }\n\n}\n\n```\n\n```\nmodels . IsEmptyCondition(\n\n    is_empty = models . PayloadField(key = \"reports\" ),\n\n)\n\n```\n\n```\n{\n\n  is_empty :  {\n\n    key :   \"reports\" ;\n\n  }\n\n}\n\n```\n\n`Condition::is_empty( \"reports\" ) \n`\n\nThis condition will match all records where the field `reports` either does not exist, or has `null` or `[]` value.\n\n### Is Null\n\nIt is not possible to test for `NULL` values with thecondition.\nWe have to use `IsNull` condition instead:\n\n```\n{\n\n     \"is_null\" : {\n\n         \"key\" :  \"reports\" \n\n    }\n\n}\n\n```\n\n```\nmodels . IsNullCondition(\n\n    is_null = models . PayloadField(key = \"reports\" ),\n\n)\n\n```\n\n```\n{\n\n  is_null :  {\n\n    key :   \"reports\" ;\n\n  }\n\n}\n\n```\n\n`Condition::is_null( \"reports\" ) \n`\n\nThis condition will match all records where the field `reports` exists and has `NULL` value.\n\n### Has id\n\nThis type of query is not related to payload, but can be very useful in some situations.\nFor example, the user could mark some specific search results as irrelevant, or we want to search only among the specified points.\n\n```\nPOST /collections/{collection_name}/points/scroll\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            { \"has_id\": [1,3,5,7,9,11] }\n\n        ]\n\n    }\n\n    ...\n\n}\n\n```\n\n```\nclient . scroll(\n\n    collection_name = \" {collection_name} \" ,\n\n    scroll_filter = models . Filter(\n\n        must = [\n\n            models . HasIdCondition(has_id = [ 1 ,  3 ,  5 ,  7 ,  9 ,  11 ]),\n\n        ],\n\n    ),\n\n)\n\n```\n\n```\nclient.scroll( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [\n\n      {\n\n        has_id :  [ 1 ,  3 ,  5 ,  7 ,  9 ,  11 ],\n\n      },\n\n    ],\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   ScrollPoints}; \n\n\n\nclient \n\n     .scroll( & ScrollPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must([Condition::has_id([ 1 ,   3 ,   5 ,   7 ,   9 ,   11 ])])), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFiltered points would be:\n\n```\n[\n\n  {  \"id\" :  1 ,  \"city\" :  \"London\" ,  \"color\" :  \"green\"  },\n\n  {  \"id\" :  3 ,  \"city\" :  \"London\" ,  \"color\" :  \"blue\"  },\n\n  {  \"id\" :  5 ,  \"city\" :  \"Moscow\" ,  \"color\" :  \"green\"  }\n\n]\n\n```\n\n##### Table of contents\n\n- [ Filtering clauses ](https://qdrant.tech/documentation/concepts/filtering/#filtering-clauses)\n    - [ Must ](https://qdrant.tech/documentation/concepts/filtering/#must)\n\n- [ Should ](https://qdrant.tech/documentation/concepts/filtering/#should)\n\n- [ Must Not ](https://qdrant.tech/documentation/concepts/filtering/#must-not)\n\n- [ Clauses combination ](https://qdrant.tech/documentation/concepts/filtering/#clauses-combination)\n- [ Filtering conditions ](https://qdrant.tech/documentation/concepts/filtering/#filtering-conditions)\n    - [ Match ](https://qdrant.tech/documentation/concepts/filtering/#match)\n\n- [ Match Any ](https://qdrant.tech/documentation/concepts/filtering/#match-any)\n\n- [ Match Except ](https://qdrant.tech/documentation/concepts/filtering/#match-except)\n\n- [ Nested key ](https://qdrant.tech/documentation/concepts/filtering/#nested-key)\n\n- [ Nested object filter ](https://qdrant.tech/documentation/concepts/filtering/#nested-object-filter)\n\n- [ Full Text Match ](https://qdrant.tech/documentation/concepts/filtering/#full-text-match)\n\n- [ Range ](https://qdrant.tech/documentation/concepts/filtering/#range)\n\n- [ Geo ](https://qdrant.tech/documentation/concepts/filtering/#geo)\n\n- [ Values count ](https://qdrant.tech/documentation/concepts/filtering/#values-count)\n\n- [ Is Empty ](https://qdrant.tech/documentation/concepts/filtering/#is-empty)\n\n- [ Is Null ](https://qdrant.tech/documentation/concepts/filtering/#is-null)\n\n- [ Has id ](https://qdrant.tech/documentation/concepts/filtering/#has-id)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/filtering.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/optimizer/": "# Optimizer\n\nIt is much more efficient to apply changes in batches than perform each change individually, as many other databases do. Qdrant here is no exception. Since Qdrant operates with data structures that are not always easy to change, it is sometimes necessary to rebuild those structures completely.\n\nStorage optimization in Qdrant occurs at the segment level (see[ storage ](../storage)).\nIn this case, the segment to be optimized remains readable for the time of the rebuild.\n\nImage: [ Segment optimization ](https://qdrant.tech/docs/optimization.svg)\n\nImage: [ Segment optimization ](https://qdrant.tech/docs/optimization.svg)\n\nThe availability is achieved by wrapping the segment into a proxy that transparently handles data changes.\nChanged data is placed in the copy-on-write segment, which has priority for retrieval and subsequent updates.\n\n## Vacuum Optimizer\n\nThe simplest example of a case where you need to rebuild a segment repository is to remove points.\nLike many other databases, Qdrant does not delete entries immediately after a query.\nInstead, it marks records as deleted and ignores them for future queries.\n\nThis strategy allows us to minimize disk access - one of the slowest operations.\nHowever, a side effect of this strategy is that, over time, deleted records accumulate, occupy memory and slow down the system.\n\nTo avoid these adverse effects, Vacuum Optimizer is used.\nIt is used if the segment has accumulated too many deleted records.\n\nThe criteria for starting the optimizer are defined in the configuration file.\n\nHere is an example of parameter values:\n\n```\nstorage : \n\n   optimizers : \n\n     # The minimal fraction of deleted vectors in a segment, required to perform segment optimization \n\n     deleted_threshold :   0.2 \n\n     # The minimal number of vectors in a segment, required to perform segment optimization \n\n     vacuum_min_vector_number :   1000 \n\n```\n\n## Merge Optimizer\n\nThe service may require the creation of temporary segments.\nSuch segments, for example, are created as copy-on-write segments during optimization itself.\n\nIt is also essential to have at least one small segment that Qdrant will use to store frequently updated data.\nOn the other hand, too many small segments lead to suboptimal search performance.\n\nThere is the Merge Optimizer, which combines the smallest segments into one large segment. It is used if too many segments are created.\n\nThe criteria for starting the optimizer are defined in the configuration file.\n\nHere is an example of parameter values:\n\n```\nstorage : \n\n   optimizers : \n\n     # If the number of segments exceeds this value, the optimizer will merge the smallest segments. \n\n     max_segment_number :   5 \n\n```\n\n## Indexing Optimizer\n\nQdrant allows you to choose the type of indexes and data storage methods used depending on the number of records.\nSo, for example, if the number of points is less than 10000, using any index would be less efficient than a brute force scan.\n\nThe Indexing Optimizer is used to implement the enabling of indexes and memmap storage when the minimal amount of records is reached.\n\nThe criteria for starting the optimizer are defined in the configuration file.\n\nHere is an example of parameter values:\n\n```\nstorage : \n\n   optimizers : \n\n     # Maximum size (in kilobytes) of vectors to store in-memory per segment. \n\n     # Segments larger than this threshold will be stored as read-only memmaped file. \n\n     # Memmap storage is disabled by default, to enable it, set this threshold to a reasonable value. \n\n     # To disable memmap storage, set this to `0`. \n\n     # Note: 1Kb = 1 vector of size 256 \n\n     memmap_threshold_kb :   200000 \n\n\n\n     # Maximum size (in kilobytes) of vectors allowed for plain index, exceeding this threshold will enable vector indexing \n\n     # Default value is 20,000, based on <https://github.com/google-research/google-research/blob/master/scann/docs/algorithms.md>. \n\n     # To disable vector indexing, set to `0`. \n\n     # Note: 1kB = 1 vector of size 256. \n\n     indexing_threshold_kb :   20000 \n\n```\n\nIn addition to the configuration file, you can also set optimizer parameters separately for each[ collection ](../collections).\n\nDynamic parameter updates may be useful, for example, for more efficient initial loading of points. You can disable indexing during the upload process with these settings and enable it immediately after it is finished. As a result, you will not waste extra computation resources on rebuilding the index.\n\n##### Table of contents\n\n- [ Vacuum Optimizer ](https://qdrant.tech/documentation/concepts/optimizer/#vacuum-optimizer)\n- [ Merge Optimizer ](https://qdrant.tech/documentation/concepts/optimizer/#merge-optimizer)\n- [ Indexing Optimizer ](https://qdrant.tech/documentation/concepts/optimizer/#indexing-optimizer)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/optimizer.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/storage/": "# Storage\n\nAll data within one collection is divided into segments.\nEach segment has its independent vector and payload storage as well as indexes.\n\nData stored in segments usually do not overlap.\nHowever, storing the same point in different segments will not cause problems since the search contains a deduplication mechanism.\n\nThe segments consist of vector and payload storages, vector and payload[ indexes ](../indexing), and id mapper, which stores the relationship between internal and external ids.\n\nA segment can be `appendable` or `non-appendable` depending on the type of storage and index used.\nYou can freely add, delete and query data in the `appendable` segment.\nWith `non-appendable` segment can only read and delete data.\n\nThe configuration of the segments in the collection can be different and independent of one another, but at least one `appendable\u2019 segment must be present in a collection.\n\n## Vector storage\n\nDepending on the requirements of the application, Qdrant can use one of the data storage options.\nThe choice has to be made between the search speed and the size of the RAM used.\n\n **In-memory storage** - Stores all vectors in RAM, has the highest speed since disk access is required only for persistence.\n\n **Memmap storage** - Creates a virtual address space associated with the file on disk.[ Wiki ](https://en.wikipedia.org/wiki/Memory-mapped_file).\nMmapped files are not directly loaded into RAM. Instead, they use page cache to access the contents of the file.\nThis scheme allows flexible use of available memory. With sufficient RAM, it is almost as fast as in-memory storage.\n\n### Configuring Memmap storage\n\nThere are two ways to configure the usage of memmap(also known as on-disk) storage:\n\n- Set up `on_disk` option for the vectors in the collection create API:\n\n\n *Available as of v1.2.0* \n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\",\n\n      \"on_disk\": true\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(\n\n        size = 768 , distance = models . Distance . COSINE, on_disk = True \n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n    on_disk:  true ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorsConfig}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 on_disk:  Some ( true ), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThis will create a collection with all vectors immediately stored in memmap storage.\nThis is the recommended way, in case your Qdrant instance operates with fast disks and you are working with large collections.\n\n- Set up `memmap_threshold_kb` option. This option will set the threshold after which the segment will be converted to memmap storage.\n\n\nThere are two ways to do this:\n\n1. You can set the threshold globally in the[ configuration file ](../../guides/configuration/). The parameter is called `memmap_threshold_kb` .\n2. You can set the threshold for each collection separately during[ creation ](../collections/#create-collection)or[ update ](../collections/#update-collection-parameters).\n\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"memmap_threshold\": 20000\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(memmap_threshold = 20000 ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    memmap_threshold:  20000 ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   OptimizersConfigDiff,   VectorParams, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             memmap_threshold:  Some ( 20000 ), \n\n             .. Default ::default() \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThe rule of thumb to set the memmap threshold parameter is simple:\n\n- if you have a balanced use scenario - set memmap threshold the same as `indexing_threshold` (default is 20000). In this case the optimizer will not make any extra runs and will optimize all thresholds at once.\n- if you have a high write load and low RAM - set memmap threshold lower than `indexing_threshold` to e.g. 10000. In this case the optimizer will convert the segments to memmap storage first and will only apply indexing after that.\n\n\nIn addition, you can use memmap storage not only for vectors, but also for HNSW index.\nTo enable this, you need to set the `hnsw_config.on_disk` parameter to `true` during collection[ creation ](../collections/#create-a-collection)or[ updating ](../collections/#update-collection-parameters).\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"memmap_threshold\": 20000\n\n    },\n\n    \"hnsw_config\": {\n\n        \"on_disk\": true\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(memmap_threshold = 20000 ),\n\n    hnsw_config = models . HnswConfigDiff(on_disk = True ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    memmap_threshold:  20000 ,\n\n  },\n\n  hnsw_config :  {\n\n    on_disk:  true ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   HnswConfigDiff, \n\n         OptimizersConfigDiff,   VectorParams,   VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             memmap_threshold:  Some ( 20000 ), \n\n             .. Default ::default() \n\n         }), \n\n         hnsw_config:  Some (HnswConfigDiff   { \n\n             on_disk:  Some ( true ), \n\n             .. Default ::default() \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n## Payload storage\n\nQdrant supports two types of payload storages: InMemory and OnDisk.\n\nInMemory payload storage is organized in the same way as in-memory vectors.\nThe payload data is loaded into RAM at service startup while disk and[ RocksDB ](https://rocksdb.org/)are used for persistence only.\nThis type of storage works quite fast, but it may require a lot of space to keep all the data in RAM, especially if the payload has large values attached - abstracts of text or even images.\n\nIn the case of large payload values, it might be better to use OnDisk payload storage.\nThis type of storage will read and write payload directly to RocksDB, so it won\u2019t require any significant amount of RAM to store.\nThe downside, however, is the access latency.\nIf you need to query vectors with some payload-based conditions - checking values stored on disk might take too much time.\nIn this scenario, we recommend creating a payload index for each field used in filtering conditions to avoid disk access.\nOnce you create the field index, Qdrant will preserve all values of the indexed field in RAM regardless of the payload storage type.\n\nYou can specify the desired type of payload storage with[ configuration file ](../../guides/configuration/)or with collection parameter `on_disk_payload` during[ creation ](../collections/#create-collection)of the collection.\n\n## Versioning\n\nTo ensure data integrity, Qdrant performs all data changes in 2 stages.\nIn the first step, the data is written to the Write-ahead-log(WAL), which orders all operations and assigns them a sequential number.\n\nOnce a change has been added to the WAL, it will not be lost even if a power loss occurs.\nThen the changes go into the segments.\nEach segment stores the last version of the change applied to it as well as the version of each individual point.\nIf the new change has a sequential number less than the current version of the point, the updater will ignore the change.\nThis mechanism allows Qdrant to safely and efficiently restore the storage from the WAL in case of an abnormal shutdown.\n\n##### Table of contents\n\n- [ Vector storage ](https://qdrant.tech/documentation/concepts/storage/#vector-storage)\n    - [ Configuring Memmap storage ](https://qdrant.tech/documentation/concepts/storage/#configuring-memmap-storage)\n- [ Payload storage ](https://qdrant.tech/documentation/concepts/storage/#payload-storage)\n- [ Versioning ](https://qdrant.tech/documentation/concepts/storage/#versioning)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/storage.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/indexing/": "# Indexing\n\nA key feature of Qdrant is the effective combination of vector and traditional indexes. It is essential to have this because for vector search to work effectively with filters, having vector index only is not enough. In simpler terms, a vector index speeds up vector search, and payload indexes speed up filtering.\n\nThe indexes in the segments exist independently, but the parameters of the indexes themselves are configured for the whole collection.\n\nNot all segments automatically have indexes.\nTheir necessity is determined by the[ optimizer ](../optimizer)settings and depends, as a rule, on the number of stored points.\n\n## Payload Index\n\nPayload index in Qdrant is similar to the index in conventional document-oriented databases.\nThis index is built for a specific field and type, and is used for quick point requests by the corresponding filtering condition.\n\nThe index is also used to accurately estimate the filter cardinality, which helps the[ query planning ](../search#query-planning)choose a search strategy.\n\nCreating an index requires additional computational resources and memory, so choosing fields to be indexed is essential. Qdrant does not make this choice but grants it to the user.\n\nTo mark a field as indexable, you can use the following:\n\n```\nPUT /collections/{collection_name}/index\n\n{\n\n    \"field_name\": \"name_of_the_field_to_index\",\n\n    \"field_schema\": \"keyword\"\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient(host = \"localhost\" , port = 6333 )\n\n\n\nclient . create_payload_index(\n\n    collection_name = \" {collection_name} \" ,\n\n    field_name = \"name_of_the_field_to_index\" ,\n\n    field_schema = \"keyword\" ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createPayloadIndex( \"{collection_name}\" , {\n\n  field_name :   \"name_of_the_field_to_index\" ,\n\n  field_schema :   \"keyword\" ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::FieldType}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_field_index( \n\n         \"{collection_name}\" , \n\n         \"name_of_the_field_to_index\" , \n\n         FieldType::Keyword, \n\n         None , \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nAvailable field types are:\n\n- `keyword` - for[ keyword ](../payload/#keyword)payload, affects[ Match ](../filtering/#match)filtering conditions.\n- `integer` - for[ integer ](../payload/#integer)payload, affects[ Match ](../filtering/#match)and[ Range ](../filtering/#range)filtering conditions.\n- `float` - for[ float ](../payload/#float)payload, affects[ Range ](../filtering/#range)filtering conditions.\n- `bool` - for[ bool ](../payload/#bool)payload, affects[ Match ](../filtering/#match)filtering conditions (available as of 1.4.0).\n- `geo` - for[ geo ](../payload/#geo)payload, affects[ Geo Bounding Box ](../filtering/#geo-bounding-box)and[ Geo Radius ](../filtering/#geo-radius)filtering conditions.\n- `text` - a special kind of index, available for[ keyword ](../payload/#keyword)/ string payloads, affects[ Full Text search ](../filtering/#full-text-match)filtering conditions.\n\n\nPayload index may occupy some additional memory, so it is recommended to only use index for those fields that are used in filtering conditions.\nIf you need to filter by many fields and the memory limits does not allow to index all of them, it is recommended to choose the field that limits the search result the most.\nAs a rule, the more different values a payload value has, the more efficiently the index will be used.\n\n### Full-text index\n\n *Available as of v0.10.0* \n\nQdrant supports full-text search for string payload.\nFull-text index allows you to filter points by the presence of a word or a phrase in the payload field.\n\nFull-text index configuration is a bit more complex than other indexes, as you can specify the tokenization parameters.\nTokenization is the process of splitting a string into tokens, which are then indexed in the inverted index.\n\nTo create a full-text index, you can use the following:\n\n```\nPUT /collections/{collection_name}/index\n\n{\n\n    \"field_name\": \"name_of_the_field_to_index\",\n\n    \"field_schema\": {\n\n        \"type\": \"text\",\n\n        \"tokenizer\": \"word\",\n\n        \"min_token_len\": 2,\n\n        \"max_token_len\": 20,\n\n        \"lowercase\": true\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient(host = \"localhost\" , port = 6333 )\n\n\n\nclient . create_payload_index(\n\n    collection_name = \" {collection_name} \" ,\n\n    field_name = \"name_of_the_field_to_index\" ,\n\n    field_schema = models . TextIndexParams(\n\n         type = \"text\" ,\n\n        tokenizer = models . TokenizerType . WORD,\n\n        min_token_len = 2 ,\n\n        max_token_len = 15 ,\n\n        lowercase = True ,\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient, Schemas }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createPayloadIndex( \"{collection_name}\" , {\n\n  field_name :   \"name_of_the_field_to_index\" ,\n\n  field_schema :  {\n\n     type :   \"text\" ,\n\n    tokenizer :   \"word\" ,\n\n    min_token_len:  2 ,\n\n    max_token_len:  15 ,\n\n    lowercase:  true ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         payload_index_params::IndexParams,   FieldType,   PayloadIndexParams,   TextIndexParams, \n\n         TokenizerType, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_field_index( \n\n         \"{collection_name}\" , \n\n         \"name_of_the_field_to_index\" , \n\n         FieldType::Text, \n\n         Some ( & PayloadIndexParams   { \n\n             index_params:  Some (IndexParams::TextIndexParams(TextIndexParams   { \n\n                 tokenizer:  TokenizerType ::Word   as   i32 , \n\n                 min_token_len:  Some ( 2 ), \n\n                 max_token_len:  Some ( 10 ), \n\n                 lowercase:  Some ( true ), \n\n             })), \n\n         }), \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nAvailable tokenizers are:\n\n- `word` - splits the string into words, separated by spaces, punctuation marks, and special characters.\n- `whitespace` - splits the string into words, separated by spaces.\n- `prefix` - splits the string into words, separated by spaces, punctuation marks, and special characters, and then creates a prefix index for each word. For example: `hello` will be indexed as `h` , `he` , `hel` , `hell` , `hello` .\n- `multilingual` - special type of tokenizer based on[ charabia ](https://github.com/meilisearch/charabia)package. It allows proper tokenization and lemmatization for multiple languages, including those with non-latin alphabets and non-space delimiters. See[ charabia documentation ](https://github.com/meilisearch/charabia)for full list of supported languages supported normalization options. In the default build configuration, qdrant does not include support for all languages, due to the increasing size of the resulting binary. Chinese, Japanese and Korean languages are not enabled by default, but can be enabled by building qdrant from source with `--features multiling-chinese,multiling-japanese,multiling-korean` flags.\n\n\nSee[ Full Text match ](../filtering/#full-text-match)for examples of querying with full-text index.\n\n## Vector Index\n\nA vector index is a data structure built on vectors through a specific mathematical model.\nThrough the vector index, we can efficiently query several vectors similar to the target vector.\n\nQdrant currently only uses HNSW as a dense vector index.\n\n[ HNSW ](https://arxiv.org/abs/1603.09320)(Hierarchical Navigable Small World Graph) is a graph-based indexing algorithm. It builds a multi-layer navigation structure for an image according to certain rules. In this structure, the upper layers are more sparse and the distances between nodes are farther. The lower layers are denser and the distances between nodes are closer. The search starts from the uppermost layer, finds the node closest to the target in this layer, and then enters the next layer to begin another search. After multiple iterations, it can quickly approach the target position.\n\nIn order to improve performance, HNSW limits the maximum degree of nodes on each layer of the graph to `m` . In addition, you can use `ef_construct` (when building index) or `ef` (when searching targets) to specify a search range.\n\nThe corresponding parameters could be configured in the configuration file:\n\n```\nstorage : \n\n   # Default parameters of HNSW Index. Could be overridden for each collection or named vector individually \n\n   hnsw_index : \n\n     # Number of edges per node in the index graph. \n\n     # Larger the value - more accurate the search, more space required. \n\n     m :   16 \n\n     # Number of neighbours to consider during the index building. \n\n     # Larger the value - more accurate the search, more time required to build index. \n\n     ef_construct :   100 \n\n     # Minimal size (in KiloBytes) of vectors for additional payload-based indexing. \n\n     # If payload chunk is smaller than `full_scan_threshold_kb` additional indexing won't be used - \n\n     # in this case full-scan search should be preferred by query planner and additional indexing is not required. \n\n     # Note: 1Kb = 1 vector of size 256 \n\n     full_scan_threshold :   10000 \n\n```\n\nAnd so in the process of creating a[ collection ](../collections). The `ef` parameter is configured during[ the search ](../search)and by default is equal to `ef_construct` .\n\nHNSW is chosen for several reasons.\nFirst, HNSW is well-compatible with the modification that allows Qdrant to use filters during a search.\nSecond, it is one of the most accurate and fastest algorithms, according to[ public benchmarks ](https://github.com/erikbern/ann-benchmarks).\n\n *Available as of v1.1.1* \n\nThe HNSW parameters can also be configured on a collection and named vector\nlevel by setting[ hnsw_config ](../indexing/#vector-index)to fine-tune search\nperformance.\n\n## Sparse Vector Index\n\n *Available as of v1.7.0* \n\n### Key Features of Sparse Vector Index\n\n- **Support for Sparse Vectors:** Qdrant supports sparse vectors, characterized by a high proportion of zeroes.\n- **Efficient Indexing:** Utilizes an inverted index structure to store vectors for each non-zero dimension, optimizing memory and search speed.\n\n\n### Search Mechanism\n\n- **Index Usage:** The index identifies vectors with non-zero values in query dimensions during a search.\n- **Scoring Method:** Vectors are scored using the dot product.\n\n\n### Optimizations\n\n- **Reducing Vectors to Score:** Implementations are in place to minimize the number of vectors scored, especially for dimensions with numerous vectors.\n\n\n### Filtering and Configuration\n\n- **Filtering Support:** Similar to dense vectors, supports filtering by payload fields.\n- **full_scan_threshold  Configuration:** Allows control over when to switch search from the payload index to minimize scoring vectors.\n- **Threshold for Sparse Vectors:** Specifies the threshold in terms of the number of matching vectors found by the query planner.\n\n\n`full_scan_threshold`\n\n### Index Storage and Management\n\n- **Memory-Based Index:** The index resides in memory for appendable segments, ensuring fast search and update operations.\n- **Handling Immutable Segments:** For immutable segments, the sparse index can either stay in memory or be mapped to disk with the `on_disk` flag.\n\n\n **Example Configuration:** To enable on-disk storage for immutable segments and full scan for queries inspecting less than 5000 vectors:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"sparse_vectors\": {\n\n        \"text\": {\n\n            \"index\": {\n\n                \"on_disk\": true,\n\n                \"full_scan_threshold\": 5000\n\n            }\n\n         },\n\n    }\n\n}\n\n```\n\n## Filtrable Index\n\nSeparately, payload index and vector index cannot solve the problem of search using the filter completely.\n\nIn the case of weak filters, you can use the HNSW index as it is. In the case of stringent filters, you can use the payload index and complete rescore.\nHowever, for cases in the middle, this approach does not work well.\n\nOn the one hand, we cannot apply a full scan on too many vectors. On the other hand, the HNSW graph starts to fall apart when using too strict filters.\n\nImage: [ HNSW fail ](https://qdrant.tech/docs/precision_by_m.png)\n\nImage: [ HNSW fail ](https://qdrant.tech/docs/precision_by_m.png)\n\nImage: [ hnsw graph ](https://qdrant.tech/docs/graph.gif)\n\nImage: [ hnsw graph ](https://qdrant.tech/docs/graph.gif)\n\nYou can find more information on why this happens in our[ blog post ](https://blog.vasnetsov.com/posts/categorical-hnsw/).\nQdrant solves this problem by extending the HNSW graph with additional edges based on the stored payload values.\n\nExtra edges allow you to efficiently search for nearby vectors using the HNSW index and apply filters as you search in the graph.\n\nThis approach minimizes the overhead on condition checks since you only need to calculate the conditions for a small fraction of the points involved in the search.\n\n##### Table of contents\n\n- [ Payload Index ](https://qdrant.tech/documentation/concepts/indexing/#payload-index)\n    - [ Full-text index ](https://qdrant.tech/documentation/concepts/indexing/#full-text-index)\n- [ Vector Index ](https://qdrant.tech/documentation/concepts/indexing/#vector-index)\n- [ Sparse Vector Index ](https://qdrant.tech/documentation/concepts/indexing/#sparse-vector-index)\n    - [ Key Features of Sparse Vector Index ](https://qdrant.tech/documentation/concepts/indexing/#key-features-of-sparse-vector-index)\n\n- [ Search Mechanism ](https://qdrant.tech/documentation/concepts/indexing/#search-mechanism)\n\n- [ Optimizations ](https://qdrant.tech/documentation/concepts/indexing/#optimizations)\n\n- [ Filtering and Configuration ](https://qdrant.tech/documentation/concepts/indexing/#filtering-and-configuration)\n\n- [ Index Storage and Management ](https://qdrant.tech/documentation/concepts/indexing/#index-storage-and-management)\n- [ Filtrable Index ](https://qdrant.tech/documentation/concepts/indexing/#filtrable-index)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/indexing.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/snapshots/": "# Snapshots\n\n *Available as of v0.8.4* \n\nSnapshots are performed on a per-collection basis and consist in a `tar` archive file containing the necessary data to restore the collection at the time of the snapshot.\n\nThis feature can be used to archive data or easily replicate an existing deployment.\n\n## Store snapshots\n\nThe target directory used to store generated snapshots is controlled through the[ configuration ](../../guides/configuration)or using the ENV variable: `QDRANT__STORAGE__SNAPSHOTS_PATH=./snapshots` .\n\nYou can set the snapshots storage directory from the[ config.yaml ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml)file. If no value is given, default is `./snapshots` .\n\n```\nstorage : \n\n   # Specify where you want to store snapshots. \n\n   snapshots_path :   ./snapshots \n\n```\n\n *Available as of v1.3.0* \n\nWhile a snapshot is being created, temporary files are by default placed in the configured storage directory.\nThis location may have limited capacity or be on a slow network-attached disk. You may specify a separate location for temporary files:\n\n```\nstorage : \n\n   # Where to store temporary files \n\n   temp_path :   /tmp \n\n```\n\n## Create snapshot\n\nTo create a new snapshot for an existing collection:\n\n`POST /collections/{collection_name}/snapshots\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_snapshot(collection_name = \" {collection_name} \" )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createSnapshot( \"{collection_name}\" );\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.create_snapshot( \"{collection_name}\" ). await ? ; \n\n```\n\nThis is a synchronous operation for which a `tar` archive file will be generated into the `snapshot_path` .\n\n### Delete snapshot\n\n *Available as of v1.0.0* \n\n`DELETE /collections/{collection_name}/snapshots/{snapshot_name}\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . delete_snapshot(\n\n    collection_name = \" {collection_name} \" , snapshot_name = \" {snapshot_name} \" \n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.deleteSnapshot( \"{collection_name}\" ,  \"{snapshot_name}\" );\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.delete_snapshot( \"{collection_name}\" ,   \"{snapshot_name}\" ). await ? ; \n\n```\n\n## List snapshot\n\nList of snapshots for a collection:\n\n`GET /collections/{collection_name}/snapshots\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . list_snapshots(collection_name = \" {collection_name} \" )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.listSnapshots( \"{collection_name}\" );\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.list_snapshots( \"{collection_name}\" ). await ? ; \n\n```\n\n## Retrieve snapshot\n\nTo download a specified snapshot from a collection as a file:\n\n`GET /collections/{collection_name}/snapshots/{snapshot_name}\n`\n\n## Restore snapshot\n\nThere is a difference in recovering snapshots in single-deployment node and distributed deployment mode.\n\n### Recover during start-up\n\nSingle deployment is simpler, you can recover any collection on the start-up and it will be immediately available in the service.\nRestoring snapshots is done through the Qdrant CLI at startup time.\n\nThe main entry point is the `--snapshot` argument which accepts a list of pairs `<snapshot_file_path>:<target_collection_name>` \n\nFor example:\n\n`./qdrant --snapshot /snapshots/test-collection-archive.snapshot:test-collection --snapshot /snapshots/test-collection-archive.snapshot:test-copy-collection \n`\n\nThe target collection **must** be absent otherwise the program will exit with an error.\n\nIf you wish instead to overwrite an existing collection, use the `--force_snapshot` flag with caution.\n\n### Recover via API\n\n *Available as of v0.11.3* \n\nRecovering in cluster mode is more sophisticated, as Qdrant should maintain consistency across peers even during the recovery process.\nAs the information about created collections is stored in the consensus, even a newly attached cluster node will automatically create collections.\nRecovering non-existing collections with snapshots won\u2019t make this collection known to the consensus.\n\nTo recover snapshot via API one can use snapshot recovery endpoint:\n\n```\nPUT /collections/{collection_name}/snapshots/recover\n\n{\n\n  \"location\": \"http://qdrant-node-1:6333/collections/{collection_name}/snapshots/snapshot-2022-10-10.shapshot\"\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"qdrant-node-2\" , port = 6333 )\n\n\n\nclient . recover_snapshot(\n\n     \" {collection_name} \" ,\n\n     \"http://qdrant-node-1:6333/collections/collection_name/snapshots/snapshot-2022-10-10.shapshot\" ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.recoverSnapshot( \"{collection_name}\" , {\n\n  location :   \"http://qdrant-node-1:6333/collections/collection_name/snapshots/snapshot-2022-10-10.shapshot\" ,\n\n});\n\n```\n\nThe recovery snapshot can also be uploaded as a file to the Qdrant server:\n\n```\ncurl -X POST  'http://qdrant-node-1:6333/collections/collection_name/snapshots/upload'   \\\n\n    -H  'Content-Type:multipart/form-data'   \\\n\n    -F  'snapshot=@/path/to/snapshot-2022-10-10.shapshot' \n\n```\n\nQdrant will extract shard data from the snapshot and properly register shards in the cluster.\nIf there are other active replicas of the recovered shards in the cluster, Qdrant will replicate them to the newly recovered node by default to maintain data consistency.\n\n### Snapshot priority\n\nWhen recovering a snapshot, you can specify what source of data is prioritized\nduring recovery. It is important because different priorities can give very\ndifferent end results. The default priority is probably not what you expect.\n\nThe available snapshot recovery priorities are:\n\n- `replica` : *(default)* prefer existing data over the snapshot.\n- `snapshot` : prefer snapshot data over existing data.\n- `no_sync` : restore snapshot without any additional synchronization.\n\n\nTo recover a new collection from a snapshot on a Qdrant cluster, you need to set\nthe `snapshot` priority. With `snapshot` priority, all data from the snapshot\nwill be recovered onto the cluster. With `replica` priority *(default)* , you\u2019d\nend up with an empty collection because the collection on the cluster did not\ncontain any points and that source was preferred.\n\n `no_sync` is for specialized use cases and is not commonly used. It allows\nmanaging shards and transferring shards between clusters manually without any\nadditional synchronization. Using it incorrectly will leave your cluster in a\nbroken state.\n\nTo recover from an URL you specify a request parameter:\n\n```\nPUT /collections/{collection_name}/snapshots/recover\n\n{\n\n  \"location\": \"http://qdrant-node-1:6333/collections/{collection_name}/snapshots/snapshot-2022-10-10.shapshot\",\n\n  \"priority\": \"snapshot\"\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"qdrant-node-2\" , port = 6333 )\n\n\n\nclient . recover_snapshot(\n\n     \" {collection_name} \" ,\n\n     \"http://qdrant-node-1:6333/collections/collection_name/snapshots/snapshot-2022-10-10.shapshot\" ,\n\n    priority = models . SnapshotPriority . SNAPSHOT,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.recoverSnapshot( \"{collection_name}\" , {\n\n  location :   \"http://qdrant-node-1:6333/collections/collection_name/snapshots/snapshot-2022-10-10.shapshot\" ,\n\n  priority :   \"snapshot\" \n\n});\n\n```\n\nTo upload a multipart file you specify it as URL parameter:\n\n```\ncurl -X POST  'http://qdrant-node-1:6333/collections/collection_name/snapshots/upload?priority=snapshot'   \\\n\n    -H  'Content-Type:multipart/form-data'   \\\n\n    -F  'snapshot=@/path/to/snapshot-2022-10-10.shapshot' \n\n```\n\n## Snapshots for the whole storage\n\n *Available as of v0.8.5* \n\nSometimes it might be handy to create snapshot not just for a single collection, but for the whole storage, including collection aliases.\nQdrant provides a dedicated API for that as well. It is similar to collection-level snapshots, but does not require `collecton_name` :\n\n### Create full storage snapshot\n\n`POST /snapshots\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_full_snapshot()\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createFullSnapshot();\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.create_full_snapshot(). await ? ; \n\n```\n\n### Delete full storage snapshot\n\n *Available as of v1.0.0* \n\n`DELETE /snapshots/{snapshot_name}\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . delete_full_snapshot(snapshot_name = \" {snapshot_name} \" )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.deleteFullSnapshot( \"{snapshot_name}\" );\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.delete_full_snapshot( \"{snapshot_name}\" ). await ? ; \n\n```\n\n### List full storage snapshots\n\n`GET /snapshots\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . list_full_snapshots()\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.listFullSnapshots();\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.list_full_snapshots(). await ? ; \n\n```\n\n### Download full storage snapshot\n\n`GET /snapshots/{snapshot_name}\n`\n\n## Restore full storage snapshot\n\nRestoring snapshots is done through the Qdrant CLI at startup time.\n\nFor example:\n\n`./qdrant --storage-snapshot /snapshots/full-snapshot-2022-07-18-11-20-51.snapshot \n`\n\n##### Table of contents\n\n- [ Store snapshots ](https://qdrant.tech/documentation/concepts/snapshots/#store-snapshots)\n- [ Create snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#create-snapshot)\n    - [ Delete snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#delete-snapshot)\n- [ List snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#list-snapshot)\n- [ Retrieve snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#retrieve-snapshot)\n- [ Restore snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#restore-snapshot)\n    - [ Recover during start-up ](https://qdrant.tech/documentation/concepts/snapshots/#recover-during-start-up)\n\n- [ Recover via API ](https://qdrant.tech/documentation/concepts/snapshots/#recover-via-api)\n\n- [ Snapshot priority ](https://qdrant.tech/documentation/concepts/snapshots/#snapshot-priority)\n- [ Snapshots for the whole storage ](https://qdrant.tech/documentation/concepts/snapshots/#snapshots-for-the-whole-storage)\n    - [ Create full storage snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#create-full-storage-snapshot)\n\n- [ Delete full storage snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#delete-full-storage-snapshot)\n\n- [ List full storage snapshots ](https://qdrant.tech/documentation/concepts/snapshots/#list-full-storage-snapshots)\n\n- [ Download full storage snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#download-full-storage-snapshot)\n- [ Restore full storage snapshot ](https://qdrant.tech/documentation/concepts/snapshots/#restore-full-storage-snapshot)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/snapshots.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/administration/": "# Administration\n\nQdrant exposes administration tools which enable to modify at runtime the behavior of a qdrant instance without changing its configuration manually.\n\n## Locking\n\nA locking API enables users to restrict the possible operations on a qdrant process.\nIt is important to mention that:\n\n- The configuration is not persistent therefore it is necessary to lock again following a restart.\n- Locking applies to a single node only. It is necessary to call lock on all the desired nodes in a distributed deployment setup.\n\n\nLock request sample:\n\n```\nPOST /locks\n\n{\n\n    \"error_message\": \"write is forbidden\",\n\n    \"write\": true\n\n}\n\n```\n\nWrite flags enables/disables write lock.\nIf the write lock is set to true, qdrant doesn\u2019t allow creating new collections or adding new data to the existing storage.\nHowever, deletion operations or updates are not forbidden under the write lock.\nThis feature enables administrators to prevent a qdrant process from using more disk space while permitting users to search and delete unnecessary data.\n\nYou can optionally provide the error message that should be used for error responses to users.\n\n## Recovery mode\n\n *Available as of v1.2.0* \n\nRecovery mode can help in situations where Qdrant fails to start repeatedly.\nWhen starting in recovery mode, Qdrant only loads collection metadata to prevent\ngoing out of memory. This allows you to resolve out of memory situations, for\nexample, by deleting a collection. After resolving Qdrant can be restarted\nnormally to continue operation.\n\nIn recovery mode, collection operations are limited to[ deleting ](../../concepts/collections/#delete-collection)a\ncollection. That is because only collection metadata is loaded during recovery.\n\nTo enable recovery mode with the Qdrant Docker image you must set the\nenvironment variable `QDRANT_ALLOW_RECOVERY_MODE=true` . The container will try\nto start normally first, and restarts in recovery mode if initialisation fails\ndue to an out of memory error. This behavior is disabled by default.\n\nIf using a Qdrant binary, recovery mode can be enabled by setting a recovery\nmessage in an environment variable, such as `QDRANT__STORAGE__RECOVERY_MODE=\"My recovery message\"` .\n\n##### Table of contents\n\n- [ Locking ](https://qdrant.tech/documentation/guides/administration/#locking)\n- [ Recovery mode ](https://qdrant.tech/documentation/guides/administration/#recovery-mode)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/administration.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/installation/": "# Installation options\n\n## Docker\n\nThe easiest way to start using Qdrant is to run it from a ready-made Docker image.\nThe latest versions are always available on[ DockerHub ](https://hub.docker.com/r/qdrant/qdrant/tags?page=1&ordering=last_updated).\n\nMake sure that Docker daemon is installed and running:\n\n`sudo docker info\n`\n\n- If you do not see the server listed, start the Docker daemon.\n- On Linux, Docker needs `sudo` privileges. To run Docker commands without `sudo` privileges, create a docker group and add your users (see[ Post-installation Steps for Linux ](https://docs.docker.com/engine/install/linux-postinstall/)for details).\n\n\nPull the image:\n\n`docker pull qdrant/qdrant\n`\n\nRun the container:\n\n```\ndocker run -p 6333:6333  \\\n\n    -v  $( pwd ) /path/to/data:/qdrant/storage  \\\n\n    qdrant/qdrant\n\n```\n\nWith this command, you will start a Qdrant instance with the default configuration.\nIt will store all data in `./path/to/data` directory.\n\nBy default, Qdrant uses port 6333, so at[ localhost:6333 ](http://localhost:6333)you should see the welcome message.\n\n## From source\n\nQdrant is written in Rust and can be compiled into a binary executable.\nThis installation method can be helpful if you want to compile Qdrant for a specific processor architecture or if you do not want to use Docker for some reason.\n\nBefore compiling, make sure that the necessary libraries and the[ rust toolchain ](https://www.rust-lang.org/tools/install)are installed.\nThe current list of required libraries can be found in the[ Dockerfile ](https://github.com/qdrant/qdrant/blob/master/Dockerfile).\n\nBuild Qdrant with Cargo:\n\n`cargo build --release --bin qdrant\n`\n\nAfter a successful build, the binary is available at `./target/release/qdrant` .\n\n## Python client\n\nIn addition to the service itself, Qdrant has a distinct python client, which has some additional features compared to[ clients ](https://qdrant.tech/documentation/quick_start/#clients)generated from OpenAPI directly.\n\nTo install this client, just run the following command:\n\n`pip install qdrant-client\n`\n\n## Kubernetes\n\nYou can use a ready-made[ Helm Chart ](https://helm.sh/docs/)to run Qdrant in your Kubeternetes cluster.\n\n```\nhelm repo add qdrant https://qdrant.to/helm\n\nhelm install qdrant-release qdrant/qdrant\n\n```\n\nRead further instructions in[ qdrant-helm ](https://github.com/qdrant/qdrant-helm)repository.\n\n##### Table of contents\n\n- [ Docker ](https://qdrant.tech/documentation/guides/installation/#docker)\n- [ From source ](https://qdrant.tech/documentation/guides/installation/#from-source)\n- [ Python client ](https://qdrant.tech/documentation/guides/installation/#python-client)\n- [ Kubernetes ](https://qdrant.tech/documentation/guides/installation/#kubernetes)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/installation.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/optimize/": "# Optimize Qdrant\n\nDifferent use cases have different requirements for balancing between memory, speed, and precision.\nQdrant is designed to be flexible and customizable so you can tune it to your needs.\n\nImage: [ Trafeoff ](https://qdrant.tech/docs/tradeoff.png)\n\nImage: [ Trafeoff ](https://qdrant.tech/docs/tradeoff.png)\n\nLet\u2019s look deeper into each of those possible optimization scenarios.\n\n## Prefer low memory footprint with high speed search\n\nThe main way to achieve high speed search with low memory footprint is to keep vectors on disk while at the same time minimizing the number of disk reads.\n\nVector quantization is one way to achieve this. Quantization converts vectors into a more compact representation, which can be stored in memory and used for search. With smaller vectors you can cache more in RAM and reduce the number of disk reads.\n\nTo configure in-memory quantization, with on-disk original vectors, you need to create a collection with the following configuration:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"size\": 768,\n\n        \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"memmap_threshold\": 20000\n\n    },\n\n    \"quantization_config\": {\n\n        \"scalar\": {\n\n            \"type\": \"int8\",\n\n            \"always_ram\": true\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(memmap_threshold = 20000 ),\n\n    quantization_config = models . ScalarQuantization(\n\n        scalar = models . ScalarQuantizationConfig(\n\n             type = models . ScalarType . INT8,\n\n            always_ram = True ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    memmap_threshold:  20000 ,\n\n  },\n\n  quantization_config :  {\n\n    scalar :  {\n\n       type :   \"int8\" ,\n\n      always_ram:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         quantization_config::Quantization,   vectors_config::Config,   CreateCollection,   Distance, \n\n         OptimizersConfigDiff,   QuantizationConfig,   QuantizationType,   ScalarQuantization, \n\n         VectorParams,   VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             memmap_threshold:  Some ( 20000 ), \n\n               .. Default ::default() \n\n         }), \n\n         quantization_config:  Some (QuantizationConfig   { \n\n             quantization:  Some (Quantization::Scalar(ScalarQuantization   { \n\n                 r#type:  QuantizationType ::Int8.into(), \n\n                 always_ram:  Some ( true ), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n `mmmap_threshold` will ensure that vectors will be stored on disk, while `always_ram` will ensure that quantized vectors will be stored in RAM.\n\nOptionally, you can disable rescoring with search `params` , which will reduce the number of disk reads even further, but potentially slightly decrease the precision.\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"params\": {\n\n        \"quantization\": {\n\n            \"rescore\": false\n\n        }\n\n    },\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"limit\": 10\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    search_params = models . SearchParams(\n\n        quantization = models . QuantizationSearchParams(rescore = False )\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  params :  {\n\n    quantization :  {\n\n      rescore:  false ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{QuantizationSearchParams,   SearchParams,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         params:  Some (SearchParams   { \n\n             quantization:  Some (QuantizationSearchParams   { \n\n                 rescore:  Some ( false ), \n\n                 .. Default ::default() \n\n             }), \n\n             .. Default ::default() \n\n         }), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n## Prefer high precision with low memory footprint\n\nIn case you need high precision, but don\u2019t have enough RAM to store vectors in memory, you can enable on-disk vectors and HNSW index.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"memmap_threshold\": 20000\n\n    },\n\n    \"hnsw_config\": {\n\n        \"on_disk\": true\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(memmap_threshold = 20000 ),\n\n    hnsw_config = models . HnswConfigDiff(on_disk = True ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    memmap_threshold:  20000 ,\n\n  },\n\n  hnsw_config :  {\n\n    on_disk:  true ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   HnswConfigDiff,   OptimizersConfigDiff, \n\n         VectorParams,   VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             memmap_threshold:  Some ( 20000 ), \n\n             .. Default ::default() \n\n         }), \n\n         hnsw_config:  Some (HnswConfigDiff   { \n\n             on_disk:  Some ( true ), \n\n             .. Default ::default() \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nIn this scenario you can increase the precision of the search by increasing the `ef` and `m` parameters of the HNSW index, even with limited RAM.\n\n```\n... \n\n\"hnsw_config\" :  {\n\n     \"m\" :  64 ,\n\n     \"ef_construct\" :  512 ,\n\n     \"on_disk\" :  true \n\n}\n\n... \n\n```\n\nThe disk IOPS is a critical factor in this scenario, it will determine how fast you can perform search.\nYou can use[ fio ](https://gist.github.com/superboum/aaa45d305700a7873a8ebbab1abddf2b)to measure disk IOPS.\n\n## Prefer high precision with high speed search\n\nFor high speed and high precision search it is critical to keep as much data in RAM as possible.\nBy default, Qdrant follows this approach, but you can tune it to your needs.\n\nIs is possible to achieve high search speed and tunable accuracy by applying quantization with re-scoring.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"memmap_threshold\": 20000\n\n    },\n\n    \"quantization_config\": {\n\n        \"scalar\": {\n\n            \"type\": \"int8\",\n\n            \"always_ram\": true\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(memmap_threshold = 20000 ),\n\n    quantization_config = models . ScalarQuantization(\n\n        scalar = models . ScalarQuantizationConfig(\n\n             type = models . ScalarType . INT8,\n\n            always_ram = True ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    memmap_threshold:  20000 ,\n\n  },\n\n  quantization_config :  {\n\n    scalar :  {\n\n       type :   \"int8\" ,\n\n      always_ram:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         quantization_config::Quantization,   vectors_config::Config,   CreateCollection,   Distance, \n\n         OptimizersConfigDiff,   QuantizationConfig,   QuantizationType,   ScalarQuantization, \n\n         VectorParams,   VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             memmap_threshold:  Some ( 20000 ), \n\n             .. Default ::default() \n\n         }), \n\n         quantization_config:  Some (QuantizationConfig   { \n\n             quantization:  Some (Quantization::Scalar(ScalarQuantization   { \n\n                 r#type:  QuantizationType ::Int8.into(), \n\n                 always_ram:  Some ( true ), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThere are also some search-time parameters you can use to tune the search accuracy and speed:\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"params\": {\n\n        \"hnsw_ef\": 128,\n\n        \"exact\": false\n\n    },\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"limit\": 3\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    search_params = models . SearchParams(hnsw_ef = 128 , exact = False ),\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    limit = 3 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  params :  {\n\n    hnsw_ef:  128 ,\n\n    exact:  false ,\n\n  },\n\n  limit:  3 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{SearchParams,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         params:  Some (SearchParams   { \n\n             hnsw_ef:  Some ( 128 ), \n\n             exact:  Some ( false ), \n\n             .. Default ::default() \n\n         }), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n- `hnsw_ef` - controls the number of neighbors to visit during search. The higher the value, the more accurate and slower the search will be. Recommended range is 32-512.\n- `exact` - if set to `true` , will perform exact search, which will be slower, but more accurate. You can use it to compare results of the search with different `hnsw_ef` values versus the ground truth.\n\n\n## Latency vs Throughput\n\n- There are two main approaches to measure the speed of search:\n    - latency of the request - the time from the moment request is submitted to the moment a response is received\n\n- throughput - the number of requests per second the system can handle\n\n\nThose approaches are not mutually exclusive, but in some cases it might be preferable to optimize for one or another.\n\nTo prefer minimizing latency, you can set up Qdrant to use as many cores as possible for a single request.\nYou can do this by setting the number of segments in the collection to be equal to the number of cores in the system. In this case, each segment will be processed in parallel, and the final result will be obtained faster.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"default_segment_number\": 16\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(default_segment_number = 16 ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    default_segment_number:  16 ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   OptimizersConfigDiff,   VectorParams, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             default_segment_number:  Some ( 16 ), \n\n             .. Default ::default() \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nTo prefer throughput, you can set up Qdrant to use as many cores as possible for processing multiple requests in parallel.\nTo do that, you can configure qdrant to use minimal number of segments, which is usually 2.\nLarge segments benefit from the size of the index and overall smaller number of vector comparisons required to find the nearest neighbors. But at the same time require more time to build index.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"default_segment_number\": 2\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(default_segment_number = 2 ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    default_segment_number:  2 ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   OptimizersConfigDiff,   VectorParams, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             default_segment_number:  Some ( 2 ), \n\n             .. Default ::default() \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n##### Table of contents\n\n- [ Prefer low memory footprint with high speed search ](https://qdrant.tech/documentation/guides/optimize/#prefer-low-memory-footprint-with-high-speed-search)\n- [ Prefer high precision with low memory footprint ](https://qdrant.tech/documentation/guides/optimize/#prefer-high-precision-with-low-memory-footprint)\n- [ Prefer high precision with high speed search ](https://qdrant.tech/documentation/guides/optimize/#prefer-high-precision-with-high-speed-search)\n- [ Latency vs Throughput ](https://qdrant.tech/documentation/guides/optimize/#latency-vs-throughput)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/optimize.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/multiple-partitions/": "# Configure Multitenancy\n\n **How many collections should you create?** In most cases, you should only use a single collection with payload-based partitioning. This approach is called multitenancy. It is efficient for most of users, but it requires additional configuration. This document will show you how to set it up.\n\n **When should you create multiple collections?** When you have a limited number of users and you need isolation. This approach is flexible, but it may be more costly, since creating numerous collections may result in resource overhead. Also, you need to ensure that they do not affect each other in any way, including performance-wise.\n\n## Partition by payload\n\nWhen an instance is shared between multiple users, you may need to partition vectors by user. This is done so that each user can only access their own vectors and can\u2019t see the vectors of other users.\n\n1. Add a `group_id` field to each vector in the collection.\n\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1,\n\n            \"payload\": {\"group_id\": \"user_1\"},\n\n            \"vector\": [0.9, 0.1, 0.1]\n\n        },\n\n        {\n\n            \"id\": 2,\n\n            \"payload\": {\"group_id\": \"user_1\"},\n\n            \"vector\": [0.1, 0.9, 0.1]\n\n        },\n\n        {\n\n            \"id\": 3,\n\n            \"payload\": {\"group_id\": \"user_2\"},\n\n            \"vector\": [0.1, 0.1, 0.9]\n\n        },\n\n    ]\n\n}\n\n```\n\n```\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1 ,\n\n            payload = { \"group_id\" :  \"user_1\" },\n\n            vector = [ 0.9 ,  0.1 ,  0.1 ],\n\n        ),\n\n        models . PointStruct(\n\n             id = 2 ,\n\n            payload = { \"group_id\" :  \"user_1\" },\n\n            vector = [ 0.1 ,  0.9 ,  0.1 ],\n\n        ),\n\n        models . PointStruct(\n\n             id = 3 ,\n\n            payload = { \"group_id\" :  \"user_2\" },\n\n            vector = [ 0.1 ,  0.1 ,  0.9 ],\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.upsert( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id:  1 ,\n\n      payload :  { group_id :   \"user_1\"  },\n\n      vector :  [ 0.9 ,  0.1 ,  0.1 ],\n\n    },\n\n    {\n\n      id:  2 ,\n\n      payload :  { group_id :   \"user_1\"  },\n\n      vector :  [ 0.1 ,  0.9 ,  0.1 ],\n\n    },\n\n    {\n\n      id:  3 ,\n\n      payload :  { group_id :   \"user_2\"  },\n\n      vector :  [ 0.1 ,  0.1 ,  0.9 ],\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::PointStruct}; \n\nuse   serde_json::json; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .upsert_points_blocking( \n\n         \"{collection_name}\" .to_string(), \n\n         None , \n\n         vec![ \n\n             PointStruct::new( \n\n                 1 , \n\n                 vec![ 0.9 ,   0.1 ,   0.1 ], \n\n                 json ! ( \n\n                     { \"group_id\" :  \"user_1\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n             PointStruct::new( \n\n                 2 , \n\n                 vec![ 0.1 ,   0.9 ,   0.1 ], \n\n                 json ! ( \n\n                     { \"group_id\" :  \"user_1\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n             PointStruct::new( \n\n                 3 , \n\n                 vec![ 0.1 ,   0.1 ,   0.9 ], \n\n                 json ! ( \n\n                     { \"group_id\" :  \"user_2\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n         ], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n1. Use a filter along with `group_id` to filter vectors for each user.\n\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"group_id\",\n\n                \"match\": {\n\n                    \"value\": \"user_1\"\n\n                }\n\n            }\n\n        ]\n\n    },\n\n    \"vector\": [0.1, 0.1, 0.9],\n\n    \"limit\": 10\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"group_id\" ,\n\n                match = models . MatchValue(\n\n                    value = \"user_1\" ,\n\n                ),\n\n            )\n\n        ]\n\n    ),\n\n    query_vector = [ 0.1 ,  0.1 ,  0.9 ],\n\n    limit = 10 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [{ key :   \"group_id\" , match :  { value :   \"user_1\"  } }],\n\n  },\n\n  vector :  [ 0.1 ,  0.1 ,  0.9 ],\n\n  limit:  10 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{Condition,   Filter,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must([Condition::matches( \n\n             \"group_id\" , \n\n             \"user_1\" .to_string(), \n\n         )])), \n\n         vector:  vec ! [ 0.1 ,   0.1 ,   0.9 ], \n\n         limit:  10 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n## Calibrate performance\n\nThe speed of indexation may become a bottleneck in this case, as each user\u2019s vector will be indexed into the same collection. To avoid this bottleneck, consider *bypassing the construction of a global vector index* for the entire collection and building it only for individual groups instead.\n\nBy adopting this strategy, Qdrant will index vectors for each user independently, significantly accelerating the process.\n\nTo implement this approach, you should:\n\n1. Set `payload_m` in the HNSW configuration to a non-zero value, such as 16.\n2. Set `m` in hnsw config to 0. This will disable building global index for the whole collection.\n\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"hnsw_config\": {\n\n        \"payload_m\": 16,\n\n        \"m\": 0\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    hnsw_config = models . HnswConfigDiff(\n\n        payload_m = 16 ,\n\n        m = 0 ,\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  hnsw_config :  {\n\n    payload_m:  16 ,\n\n    m:  0 ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   HnswConfigDiff,   VectorParams, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         hnsw_config:  Some (HnswConfigDiff   { \n\n             payload_m:  Some ( 16 ), \n\n             m:  Some ( 0 ), \n\n             .. Default ::default() \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n1. Create keyword payload index for `group_id` field.\n\n\n```\nPUT /collections/{collection_name}/index\n\n{\n\n    \"field_name\": \"group_id\",\n\n    \"field_schema\": \"keyword\"\n\n}\n\n```\n\n```\nclient . create_payload_index(\n\n    collection_name = \" {collection_name} \" ,\n\n    field_name = \"group_id\" ,\n\n    field_schema = models . PayloadSchemaType . KEYWORD,\n\n)\n\n```\n\n```\nclient.createPayloadIndex( \"{collection_name}\" , {\n\n  field_name :   \"group_id\" ,\n\n  field_schema :   \"keyword\" ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::FieldType}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_field_index( \n\n         \"{collection_name}\" , \n\n         \"group_id\" , \n\n         FieldType::Keyword, \n\n         None , \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n## Limitations\n\nOne downside to this approach is that global requests (without the `group_id` filter) will be slower since they will necessitate scanning all groups to identify the nearest neighbors.\n\n##### Table of contents\n\n- [ Partition by payload ](https://qdrant.tech/documentation/guides/multiple-partitions/#partition-by-payload)\n- [ Calibrate performance ](https://qdrant.tech/documentation/guides/multiple-partitions/#calibrate-performance)\n- [ Limitations ](https://qdrant.tech/documentation/guides/multiple-partitions/#limitations)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/multiple-partitions.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/distributed_deployment/": "# Distributed deployment\n\nSince version v0.8.0 Qdrant supports a distributed deployment mode.\nIn this mode, multiple Qdrant services communicate with each other to distribute the data across the peers to extend the storage capabilities and increase stability.\n\nTo enable distributed deployment - enable the cluster mode in the[ configuration ](../configuration)or using the ENV variable: `QDRANT__CLUSTER__ENABLED=true` .\n\n```\ncluster : \n\n   # Use `enabled: true` to run Qdrant in distributed deployment mode \n\n   enabled :   true \n\n   # Configuration of the inter-cluster communication \n\n   p2p : \n\n     # Port for internal communication between peers \n\n     port :   6335 \n\n\n\n   # Configuration related to distributed consensus algorithm \n\n   consensus : \n\n     # How frequently peers should ping each other. \n\n     # Setting this parameter to lower value will allow consensus \n\n     # to detect disconnected node earlier, but too frequent \n\n     # tick period may create significant network and CPU overhead. \n\n     # We encourage you NOT to change this parameter unless you know what you are doing. \n\n     tick_period_ms :   100 \n\n```\n\nBy default, Qdrant will use port `6335` for its internal communication.\nAll peers should be accessible on this port from within the cluster, but make sure to isolate this port from outside access, as it might be used to perform write operations.\n\nAdditionally, you must provide the `--uri` flag to the first peer so it can tell other nodes how it should be reached:\n\n`./qdrant --uri  'http://qdrant_node_1:6335' \n`\n\nSubsequent peers in a cluster must know at least one node of the existing cluster to synchronize through it with the rest of the cluster.\n\nTo do this, they need to be provided with a bootstrap URL:\n\n`./qdrant --bootstrap  'http://qdrant_node_1:6335' \n`\n\nThe URL of the new peers themselves will be calculated automatically from the IP address of their request.\nBut it is also possible to provide them individually using the `--uri` argument.\n\n```\nUSAGE:\n\n    qdrant [OPTIONS]\n\n\n\nOPTIONS:\n\n        --bootstrap <URI>\n\n            Uri of the peer to bootstrap from in case of multi-peer deployment. If not specified -\n\n            this peer will be considered as a first in a new deployment\n\n\n\n        --uri <URI>\n\n            Uri of this peer. Other peers should be able to reach it by this uri.\n\n\n\n            This value has to be supplied if this is the first peer in a new deployment.\n\n\n\n            In case this is not the first peer and it bootstraps the value is optional. If not\n\n            supplied then qdrant will take internal grpc port from config and derive the IP address\n\n            of this peer on bootstrap peer (receiving side)\n\n```\n\nAfter a successful synchronization you can observe the state of the cluster through the[ REST API ](https://qdrant.github.io/qdrant/redoc/index.html?v=master#tag/cluster):\n\n`GET /cluster\n`\n\nExample result:\n\n```\n{\n\n   \"result\" : {\n\n     \"status\" :  \"enabled\" ,\n\n     \"peer_id\" :  11532566549086892000 ,\n\n     \"peers\" : {\n\n       \"9834046559507417430\" : {\n\n         \"uri\" :  \"http://172.18.0.3:6335/\" \n\n      },\n\n       \"11532566549086892528\" : {\n\n         \"uri\" :  \"http://qdrant_node_1:6335/\" \n\n      }\n\n    },\n\n     \"raft_info\" : {\n\n       \"term\" :  1 ,\n\n       \"commit\" :  4 ,\n\n       \"pending_operations\" :  1 ,\n\n       \"leader\" :  11532566549086892000 ,\n\n       \"role\" :  \"Leader\" \n\n    }\n\n  },\n\n   \"status\" :  \"ok\" ,\n\n   \"time\" :  5.731e-06 \n\n}\n\n```\n\n## Raft\n\nQdrant uses the[ Raft ](https://raft.github.io/)consensus protocol to maintain consistency regarding the cluster topology and the collections structure.\n\nOperations on points, on the other hand, do not go through the consensus infrastructure.\nQdrant is not intended to have strong transaction guarantees, which allows it to perform point operations with low overhead.\nIn practice, it means that Qdrant does not guarantee atomic distributed updates but allows you to wait until the[ operation is complete ](../../concepts/points/#awaiting-result)to see the results of your writes.\n\nOperations on collections, on the contrary, are part of the consensus which guarantees that all operations are durable and eventually executed by all nodes.\nIn practice it means that a majority of nodes agree on what operations should be applied before the service will perform them.\n\nPractically, it means that if the cluster is in a transition state - either electing a new leader after a failure or starting up, the collection update operations will be denied.\n\nYou may use the cluster[ REST API ](https://qdrant.github.io/qdrant/redoc/index.html?v=master#tag/cluster)to check the state of the consensus.\n\n## Sharding\n\nA Collection in Qdrant is made of one or more shards.\nA shard is an independent store of points which is able to perform all operations provided by collections.\nThere are two methods of distributing points across shards:\n\n- **Automatic sharding** : Points are distributed among shards by using a[ consistent hashing ](https://en.wikipedia.org/wiki/Consistent_hashing)algorithm, so that shards are managing non-intersecting subsets of points. This is the default behavior.\n- **User-defined sharding** : *Available as of v1.7.0* - Each point is uploaded to a specific shard, so that operations can hit only the shard or shards they need. Even with this distribution, shards still ensure having non-intersecting subsets of points.[ See more\u2026 ](https://qdrant.tech/documentation/guides/distributed_deployment/#user-defined-sharding)\n\n\n **Automatic sharding** : Points are distributed among shards by using a[ consistent hashing ](https://en.wikipedia.org/wiki/Consistent_hashing)algorithm, so that shards are managing non-intersecting subsets of points. This is the default behavior.\n\n **User-defined sharding** : *Available as of v1.7.0* - Each point is uploaded to a specific shard, so that operations can hit only the shard or shards they need. Even with this distribution, shards still ensure having non-intersecting subsets of points.[ See more\u2026 ](https://qdrant.tech/documentation/guides/distributed_deployment/#user-defined-sharding)\n\nEach node knows where all parts of the collection are stored through the[ consensus protocol ](./#raft), so when you send a search request to one Qdrant node, it automatically queries all other nodes to obtain the full search result.\n\nWhen you create a collection, Qdrant splits the collection into `shard_number` shards. If left unset, `shard_number` is set to the number of nodes in your cluster:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 300,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"shard_number\": 6\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 300 , distance = models . Distance . COSINE),\n\n    shard_number = 6 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n    vectors :  {\n\n        size:  300 ,\n\n        distance :   \"Cosine\" ,\n\n    },\n\n    shard_number:  6 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorsConfig}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .into(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  300 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         shard_number:  Some ( 6 ), \n\n     }) \n\n     . await ? ; \n\n```\n\nWe recommend setting the number of shards to be a multiple of the number of nodes you are currently running in your cluster.\n\nFor example, if you have 3 nodes, 6 shards could be a good option.\n\nShards are evenly distributed across all existing nodes when a collection is first created, but Qdrant does not automatically rebalance shards if your cluster size or replication factor changes (since this is an expensive operation on large clusters). See the next section for how to move shards after scaling operations.\n\n### Moving shards\n\n *Available as of v0.9.0* \n\nQdrant allows moving shards between nodes in the cluster and removing nodes from the cluster. This functionality unlocks the ability to dynamically scale the cluster size without downtime. It also allows you to upgrade or migrate nodes without downtime.\n\nQdrant provides the information regarding the current shard distribution in the cluster with the[ Collection Cluster info API ](https://qdrant.github.io/qdrant/redoc/index.html#tag/cluster/operation/collection_cluster_info).\n\nUse the[ Update collection cluster setup API ](https://qdrant.github.io/qdrant/redoc/index.html#tag/cluster/operation/update_collection_cluster)to initiate the shard transfer:\n\n```\nPOST /collections/{collection_name}/cluster\n\n{\n\n    \"move_shard\": {\n\n        \"shard_id\": 0,\n\n        \"from_peer_id\": 381894127,\n\n        \"to_peer_id\": 467122995\n\n    }\n\n}\n\n```\n\nAfter the transfer is initiated, the service will process it based on the used[ transfer method ](https://qdrant.tech/documentation/guides/distributed_deployment/#shard-transfer-method)keeping both shards in sync. Once the\ntransfer is completed, the old shard is deleted from the source node.\n\nIn case you want to downscale the cluster, you can move all shards away from a peer and then remove the peer using the[ remove peer API ](https://qdrant.github.io/qdrant/redoc/index.html#tag/cluster/operation/remove_peer).\n\n`DELETE /cluster/peer/{peer_id}\n`\n\nAfter that, Qdrant will exclude the node from the consensus, and the instance will be ready for shutdown.\n\n### User-defined sharding\n\n *Available as of v1.7.0* \n\nQdrant allows you to specify the shard for each point individually. This feature is useful if you want to control the shard placement of your data, so that operations can hit only the subset of shards they actually need. In big clusters, this can significantly improve the performance of operations that do not require the whole collection to be scanned.\n\nA clear use-case for this feature is managing a multi-tenant collection, where each tenant (let it be a user or organization) is assumed to be segregated, so they can have their data stored in separate shards.\n\nTo enable user-defined sharding, set `sharding_method` to `custom` during collection creation:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"shard_number\": 1,\n\n    \"sharding_method\": \"custom\"\n\n    // ... other collection parameters\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    shard_number = 1 ,\n\n    sharding_method = models . ShardingMethod . CUSTOM,\n\n     # ... other collection parameters \n\n)\n\nclient . create_shard_key( \" {collection_name} \" ,  \"user_1\" )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n    shard_number:  1 ,\n\n    sharding_method :   \"custom\" ,\n\n     // ... other collection parameters\n\n});\n\n```\n\n```\n\n\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{CreateCollection,   ShardingMethod}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .into(), \n\n         shard_number:  Some ( 1 ), \n\n         sharding_method:  Some (ShardingMethod::Custom), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nIn this mode, the `shard_number` means the number of shards per shard key, where points will be distributed evenly. For example, if you have 10 shard keys and a collection config with these settings:\n\n```\n{\n\n     \"shard_number\" :  1 ,\n\n     \"sharding_method\" :  \"custom\" ,\n\n     \"replication_factor\" :  2 \n\n}\n\n```\n\nThen you will have `1 * 10 * 2 = 20` total physical shards in the collection.\n\nTo specify the shard for each point, you need to provide the `shard_key` field in the upsert request:\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1111,\n\n            \"vector\": [0.1, 0.2, 0.3]\n\n        },\n\n    ]\n\n    \"shard_key\": \"user_1\"\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1111 ,\n\n            vector = [ 0.1 ,  0.2 ,  0.3 ],\n\n        ),\n\n    ],\n\n    shard_key_selector = \"user_1\" ,\n\n)\n\n```\n\n```\n\n\nclient.upsertPoints( \"{collection_name}\" , {\n\n    points :  [\n\n        {\n\n            id:  1111 ,\n\n            vector :  [ 0.1 ,  0.2 ,  0.3 ],\n\n        },\n\n    ],\n\n    shard_key :   \"user_1\" ,\n\n});\n\n```\n\n```\n\n\nuse   qdrant_client::qdrant::{PointStruct,   WriteOrdering,   WriteOrderingType}; \n\n\n\nclient \n\n     .upsert_points_blocking( \n\n         \"{collection_name}\" , \n\n         Some (vec![shard_key::Key:: String ( \"user_1\" .into())]), \n\n         vec![ \n\n             PointStruct::new( \n\n                 1111 , \n\n                 vec![ 0.1 ,   0.2 ,   0.3 ], \n\n                 Default ::default(), \n\n             ), \n\n         ], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nNow you can target the operations to specific shard(s) by specifying the `shard_key` on any operation you do. Operations that do not specify the shard key will be executed on **all** shards.\n\nAnother use-case would be to have shards that track the data chronologically, so that you can do more complex itineraries like uploading live data in one shard and archiving it once a certain age has passed.\n\nImage: [ Sharding per day ](https://qdrant.tech/docs/sharding-per-day.png)\n\n### Shard transfer method\n\n *Available as of v1.7.0* \n\nThere are different methods for transferring, such as moving or replicating, a\nshard to another node. Depending on what performance and guarantees you\u2019d like\nto have and how you\u2019d like to manage your cluster, you likely want to choose a\nspecific method. Each method has its own pros and cons. Which is fastest depends\non the size and state of a shard.\n\nAvailable shard transfer methods are:\n\n- `stream_records` : *(default)* transfer shard by streaming just its records to the target node in batches.\n- `snapshot` : transfer shard including its index and quantized data by utilizing a[ snapshot ](../../concepts/snapshots)automatically.\n\n\nEach has pros, cons and specific requirements, which are:\n\n| Method: | Stream records | Snapshot |\n|---|---|---|\n|  **Connection**  |     - Requires internal gRPC API\n |     - Requires internal gRPC API\n    - Requires REST API\n |\n|  **HNSW index**  |     - Doesn\u2019t transfer index\n    - Will reindex on target node\n |     - Index is transferred with a snapshot\n    - Immediately ready on target node\n |\n|  **Quantization**  |     - Doesn\u2019t transfer quantized data\n    - Will re-quantize on target node\n |     - Quantized data is transferred with a snapshot\n    - Immediately ready on target node\n |\n|  **Consistency**  |     - Weak data consistency\n    - Unordered updates on target node\n |     - Strong data consistency\n    - Ordered updates on target node\n |\n|  **Disk space**  |     - No extra disk space required\n |     - Extra disk space required for snapshot on both nodes\n |\n\n\n- Requires internal gRPC API\n\n\n- Requires internal gRPC API\n- Requires REST API\n\n\n- Doesn\u2019t transfer index\n- Will reindex on target node\n\n\n- Index is transferred with a snapshot\n- Immediately ready on target node\n\n\n- Doesn\u2019t transfer quantized data\n- Will re-quantize on target node\n\n\n- Quantized data is transferred with a snapshot\n- Immediately ready on target node\n\n\n- Weak data consistency\n- Unordered updates on target node\n\n\n- Strong data consistency\n- Ordered updates on target node\n\n\n- No extra disk space required\n\n\n- Extra disk space required for snapshot on both nodes\n\n\nTo select a shard transfer method, specify the `method` like:\n\n```\nPOST /collections/{collection_name}/cluster\n\n{\n\n    \"move_shard\": {\n\n        \"shard_id\": 0,\n\n        \"from_peer_id\": 381894127,\n\n        \"to_peer_id\": 467122995,\n\n        \"method\": \"snapshot\"\n\n    }\n\n}\n\n```\n\nThe `stream_records` transfer method is the simplest available. It simply\ntransfers all shard records in batches to the target node until it has\ntransferred all of them, keeping both shards in sync. It will also make sure the\ntransferred shard indexing process is keeping up before performing a final\nswitch. The method has two common disadvantages: 1. It does not transfer index\nor quantization data, meaning that the shard has to be optimized again on the\nnew node, which can be very expensive. 2. The consistency and ordering\nguarantees are `weak` , which is not suitable for some applications.\nBecause it is so simple, it\u2019s also very robust, making it a reliable choice if\nthe above cons are acceptable in your use case. If your cluster is unstable and\nout of resources, it\u2019s probably best to use the `stream_records` transfer\nmethod, because it is unlikely to fail.\n\nThe `snapshot` transfer method utilizes[ snapshots ](../../concepts/snapshots)to\ntransfer a shard. A snapshot is created automatically. It is then transferred\nand restored on the target node. After this is done, the snapshot is removed\nfrom both nodes. While the snapshot/transfer/restore operation is happening, the\nsource node queues up all new operations. All queued updates are then sent in\norder to the target shard to bring it into the same state as the source. There\nare two important benefits: 1. It transfers index and quantization data, so that\nthe shard does not have to be optimized again on the target node, making them\nimmediately available. This way, Qdrant ensures that there will be no\ndegradation in performance at the end of the transfer. Especially on large\nshards, this can give a huge performance improvement. 2. The consistency and\nordering guarantees can be `strong` , required for some applications.\n\nThe `stream_records` method is currently used as default. This may change in the\nfuture.\n\n## Replication\n\n *Available as of v0.11.0* \n\nQdrant allows you to replicate shards between nodes in the cluster.\n\nShard replication increases the reliability of the cluster by keeping several copies of a shard spread across the cluster.\nThis ensures the availability of the data in case of node failures, except if all replicas are lost.\n\n### Replication factor\n\nWhen you create a collection, you can control how many shard replicas you\u2019d like to store by changing the `replication_factor` . By default, `replication_factor` is set to \u201c1\u201d, meaning no additional copy is maintained automatically. You can change that by setting the `replication_factor` when you create a collection.\n\nCurrently, the replication factor of a collection can only be configured at creation time.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"size\": 300,\n\n        \"distance\": \"Cosine\"\n\n    },\n\n    \"shard_number\": 6,\n\n    \"replication_factor\": 2,\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 300 , distance = models . Distance . COSINE),\n\n    shard_number = 6 ,\n\n    replication_factor = 2 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  300 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  shard_number:  6 ,\n\n  replication_factor:  2 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorsConfig}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .into(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  300 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         shard_number:  Some ( 6 ), \n\n         replication_factor:  Some ( 2 ), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThis code sample creates a collection with a total of 6 logical shards backed by a total of 12 physical shards.\n\nSince a replication factor of \u201c2\u201d would require twice as much storage space, it is advised to make sure the hardware can host the additional shard replicas beforehand.\n\n### Creating new shard replicas\n\nIt is possible to create or delete replicas manually on an existing collection using the[ Update collection cluster setup API ](https://qdrant.github.io/qdrant/redoc/index.html?v=v0.11.0#tag/cluster/operation/update_collection_cluster).\n\nA replica can be added on a specific peer by specifying the peer from which to replicate.\n\n```\nPOST /collections/{collection_name}/cluster\n\n{\n\n    \"replicate_shard\": {\n\n        \"shard_id\": 0,\n\n        \"from_peer_id\": 381894127,\n\n        \"to_peer_id\": 467122995\n\n    }\n\n}\n\n```\n\nAnd a replica can be removed on a specific peer.\n\n```\nPOST /collections/{collection_name}/cluster\n\n{\n\n    \"drop_replica\": {\n\n        \"shard_id\": 0,\n\n        \"peer_id\": 381894127\n\n    }\n\n}\n\n```\n\nKeep in mind that a collection must contain at least one active replica of a shard.\n\n### Error handling\n\nReplicas can be in different states:\n\n- Active: healthy and ready to serve traffic\n- Dead: unhealthy and not ready to serve traffic\n- Partial: currently under resynchronization before activation\n\n\nA replica is marked as dead if it does not respond to internal healthchecks or if it fails to serve traffic.\n\nA dead replica will not receive traffic from other peers and might require a manual intervention if it does not recover automatically.\n\nThis mechanism ensures data consistency and availability if a subset of the replicas fail during an update operation.\n\n### Node Failure Recovery\n\nSometimes hardware malfunctions might render some nodes of the Qdrant cluster unrecoverable.\nNo system is immune to this.\n\nBut several recovery scenarios allow qdrant to stay available for requests and even avoid performance degradation.\nLet\u2019s walk through them from best to worst.\n\n **Recover with replicated collection** \n\nIf the number of failed nodes is less than the replication factor of the collection, then no data is lost.\nYour cluster should still be able to perform read, search and update queries.\n\nNow, if the failed node restarts, consensus will trigger the replication process to update the recovering node with the newest updates it has missed.\n\n **Recreate node with replicated collections** \n\nIf a node fails and it is impossible to recover it, you should exclude the dead node from the consensus and create an empty node.\n\nTo exclude failed nodes from the consensus, use[ remove peer ](https://qdrant.github.io/qdrant/redoc/index.html#tag/cluster/operation/remove_peer)API.\nApply the `force` flag if necessary.\n\nWhen you create a new node, make sure to attach it to the existing cluster by specifying `--bootstrap` CLI parameter with the URL of any of the running cluster nodes.\n\nOnce the new node is ready and synchronized with the cluster, you might want to ensure that the collection shards are replicated enough. Remember that Qdrant will not automatically balance shards since this is an expensive operation.\nUse the[ Replicate Shard Operation ](https://qdrant.github.io/qdrant/redoc/index.html#tag/cluster/operation/update_collection_cluster)to create another copy of the shard on the newly connected node.\n\nIt\u2019s worth mentioning that Qdrant only provides the necessary building blocks to create an automated failure recovery.\nBuilding a completely automatic process of collection scaling would require control over the cluster machines themself.\nCheck out our[ cloud solution ](https://qdrant.to/cloud), where we made exactly that.\n\n **Recover from snapshot** \n\nIf there are no copies of data in the cluster, it is still possible to recover from a snapshot.\n\nFollow the same steps to detach failed node and create a new one in the cluster:\n\n- To exclude failed nodes from the consensus, use[ remove peer ](https://qdrant.github.io/qdrant/redoc/index.html#tag/cluster/operation/remove_peer)API. Apply the `force` flag if necessary.\n- Create a new node, making sure to attach it to the existing cluster by specifying the `--bootstrap` CLI parameter with the URL of any of the running cluster nodes.\n\n\nSnapshot recovery, used in single-node deployment, is different from cluster one.\nConsensus manages all metadata about all collections and does not require snapshots to recover it.\nBut you can use snapshots to recover missing shards of the collections.\n\nUse the[ Collection Snapshot Recovery API ](../../concepts/snapshots/#recover-in-cluster-deployment)to do it.\nThe service will download the specified snapshot of the collection and recover shards with data from it.\n\nOnce all shards of the collection are recovered, the collection will become operational again.\n\n## Consistency guarantees\n\nBy default, Qdrant focuses on availability and maximum throughput of search operations.\nFor the majority of use cases, this is a preferable trade-off.\n\nDuring the normal state of operation, it is possible to search and modify data from any peers in the cluster.\n\nBefore responding to the client, the peer handling the request dispatches all operations according to the current topology in order to keep the data synchronized across the cluster.\n\n- reads are using a partial fan-out strategy to optimize latency and availability\n- writes are executed in parallel on all active sharded replicas\n\n\nImage: [ Embeddings ](https://qdrant.tech/docs/concurrent-operations-replicas.png)\n\nImage: [ Embeddings ](https://qdrant.tech/docs/concurrent-operations-replicas.png)\n\nHowever, in some cases, it is necessary to ensure additional guarantees during possible hardware instabilities, mass concurrent updates of same documents, etc.\n\nQdrant provides a few options to control consistency guarantees:\n\n- `write_consistency_factor` - defines the number of replicas that must acknowledge a write operation before responding to the client. Increasing this value will make write operations tolerant to network partitions in the cluster, but will require a higher number of replicas to be active to perform write operations.\n- Read `consistency` param, can be used with search and retrieve operations to ensure that the results obtained from all replicas are the same. If this option is used, Qdrant will perform the read operation on multiple replicas and resolve the result according to the selected strategy. This option is useful to avoid data inconsistency in case of concurrent updates of the same documents. This options is preferred if the update operations are frequent and the number of replicas is low.\n- Write `ordering` param, can be used with update and delete operations to ensure that the operations are executed in the same order on all replicas. If this option is used, Qdrant will route the operation to the leader replica of the shard and wait for the response before responding to the client. This option is useful to avoid data inconsistency in case of concurrent updates of the same documents. This options is preferred if read operations are more frequent than update and if search performance is critical.\n\n\n### Write consistency factor\n\nThe `write_consistency_factor` represents the number of replicas that must acknowledge a write operation before responding to the client. It is set to one by default.\nIt can be configured at the collection\u2019s creation time.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"size\": 300,\n\n        \"distance\": \"Cosine\"\n\n    },\n\n    \"shard_number\": 6,\n\n    \"replication_factor\": 2,\n\n    \"write_consistency_factor\": 2,\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 300 , distance = models . Distance . COSINE),\n\n    shard_number = 6 ,\n\n    replication_factor = 2 ,\n\n    write_consistency_factor = 2 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  300 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  shard_number:  6 ,\n\n  replication_factor:  2 ,\n\n  write_consistency_factor:  2 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorsConfig}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .into(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  300 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         shard_number:  Some ( 6 ), \n\n         replication_factor:  Some ( 2 ), \n\n         write_consistency_factor:  Some ( 2 ), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nWrite operations will fail if the number of active replicas is less than the `write_consistency_factor` .\n\n### Read consistency\n\nRead `consistency` can be specified for most read requests and will ensure that the returned result\nis consistent across cluster nodes.\n\n- `all` will query all nodes and return points, which present on all of them\n- `majority` will query all nodes and return points, which present on the majority of them\n- `quorum` will query randomly selected majority of nodes and return points, which present on all of them\n- `1` / `2` / `3` /etc - will query specified number of randomly selected nodes and return points which present on all of them\n- default `consistency` is `1`\n\n\n```\nPOST /collections/{collection_name}/points/search?consistency=majority\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"city\",\n\n                \"match\": {\n\n                    \"value\": \"London\"\n\n                }\n\n            }\n\n        ]\n\n    },\n\n    \"params\": {\n\n        \"hnsw_ef\": 128,\n\n        \"exact\": false\n\n    },\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"limit\": 3\n\n}\n\n```\n\n```\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"city\" ,\n\n                match = models . MatchValue(\n\n                    value = \"London\" ,\n\n                ),\n\n            )\n\n        ]\n\n    ),\n\n    search_params = models . SearchParams(hnsw_ef = 128 , exact = False ),\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    limit = 3 ,\n\n    consistency = \"majority\" ,\n\n)\n\n```\n\n```\nclient.search( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [{ key :   \"city\" , match :  { value :   \"London\"  } }],\n\n  },\n\n  params :  {\n\n    hnsw_ef:  128 ,\n\n    exact:  false ,\n\n  },\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  limit:  3 ,\n\n  consistency :   \"majority\" ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         read_consistency::Value,   Condition,   Filter,   ReadConsistency,   ReadConsistencyType, \n\n         SearchParams,   SearchPoints, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .into(), \n\n         filter:  Some (Filter::must([Condition::matches( \n\n             \"city\" , \n\n             \"London\" .into(), \n\n         )])), \n\n         params:  Some (SearchParams   { \n\n             hnsw_ef:  Some ( 128 ), \n\n             exact:  Some ( false ), \n\n             .. Default ::default() \n\n         }), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         limit:  3 , \n\n         read_consistency:  Some (ReadConsistency   { \n\n             value:  Some (Value::Type(ReadConsistencyType::Majority.into())), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n### Write ordering\n\nWrite `ordering` can be specified for any write request to serialize it through a single \u201cleader\u201d node,\nwhich ensures that all write operations (issued with the same `ordering` ) are performed and observed\nsequentially.\n\n- `weak`  *(default)* ordering does not provide any additional guarantees, so write operations can be freely reordered.\n- `medium` ordering serializes all write operations through a dynamically elected leader, which might cause minor inconsistencies in case of leader change.\n- `strong` ordering serializes all write operations through the permanent leader, which provides strong consistency, but write operations may be unavailable if the leader is down.\n\n\n```\nPUT /collections/{collection_name}/points?ordering=strong\n\n{\n\n    \"batch\": {\n\n        \"ids\": [1, 2, 3],\n\n        \"payloads\": [\n\n            {\"color\": \"red\"},\n\n            {\"color\": \"green\"},\n\n            {\"color\": \"blue\"}\n\n        ],\n\n        \"vectors\": [\n\n            [0.9, 0.1, 0.1],\n\n            [0.1, 0.9, 0.1],\n\n            [0.1, 0.1, 0.9]\n\n        ]\n\n    }\n\n}\n\n```\n\n```\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = models . Batch(\n\n        ids = [ 1 ,  2 ,  3 ],\n\n        payloads = [\n\n            { \"color\" :  \"red\" },\n\n            { \"color\" :  \"green\" },\n\n            { \"color\" :  \"blue\" },\n\n        ],\n\n        vectors = [\n\n            [ 0.9 ,  0.1 ,  0.1 ],\n\n            [ 0.1 ,  0.9 ,  0.1 ],\n\n            [ 0.1 ,  0.1 ,  0.9 ],\n\n        ],\n\n    ),\n\n    ordering = \"strong\" ,\n\n)\n\n```\n\n```\nclient.upsert( \"{collection_name}\" , {\n\n  batch :  {\n\n    ids :  [ 1 ,  2 ,  3 ],\n\n    payloads :  [{ color :   \"red\"  }, { color :   \"green\"  }, { color :   \"blue\"  }],\n\n    vectors :  [\n\n      [ 0.9 ,  0.1 ,  0.1 ],\n\n      [ 0.1 ,  0.9 ,  0.1 ],\n\n      [ 0.1 ,  0.1 ,  0.9 ],\n\n    ],\n\n  },\n\n  ordering :   \"strong\" ,\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{PointStruct,   WriteOrdering,   WriteOrderingType}; \n\nuse   serde_json::json; \n\n\n\nclient \n\n     .upsert_points_blocking( \n\n         \"{collection_name}\" , \n\n         None , \n\n         vec![ \n\n             PointStruct::new( \n\n                 1 , \n\n                 vec![ 0.9 ,   0.1 ,   0.1 ], \n\n                 json ! ({ \n\n                     \"color\" :  \"red\" \n\n                 }) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n             PointStruct::new( \n\n                 2 , \n\n                 vec![ 0.1 ,   0.9 ,   0.1 ], \n\n                 json ! ({ \n\n                     \"color\" :  \"green\" \n\n                 }) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n             PointStruct::new( \n\n                 3 , \n\n                 vec![ 0.1 ,   0.1 ,   0.9 ], \n\n                 json ! ({ \n\n                     \"color\" :  \"blue\" \n\n                 }) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n         ], \n\n         Some (WriteOrdering   { \n\n             r#type:  WriteOrderingType ::Strong.into(), \n\n         }), \n\n     ) \n\n     . await ? ; \n\n```\n\n## Listener mode\n\nIn some cases it might be useful to have a Qdrant node that only accumulates data and does not participate in search operations.\nThere are several scenarios where this can be useful:\n\n- Listener option can be used to store data in a separate node, which can be used for backup purposes or to store data for a long time.\n- Listener node can be used to syncronize data into another region, while still performing search operations in the local region.\n\n\nTo enable listener mode, set `node_type` to `Listener` in the config file:\n\n```\nstorage : \n\n   node_type :   \"Listener\" \n\n```\n\nListener node will not participate in search operations, but will still accept write operations and will store the data in the local storage.\n\nAll shards, stored on the listener node, will be converted to the `Listener` state.\n\nAdditionally, all write requests sent to the listener node will be processed with `wait=false` option, which means that the write oprations will be considered successful once they are written to WAL.\nThis mechanism should allow to minimize upsert latency in case of parallel snapshotting.\n\n## Consensus Checkpointing\n\nConsensus checkpointing is a technique used in Raft to improve performance and simplify log management by periodically creating a consistent snapshot of the system state.\nThis snapshot represents a point in time where all nodes in the cluster have reached agreement on the state, and it can be used to truncate the log, reducing the amount of data that needs to be stored and transferred between nodes.\n\nFor example, if you attach a new node to the cluster, it should replay all the log entries to catch up with the current state.\nIn long-running clusters, this can take a long time, and the log can grow very large.\n\nTo prevent this, one can use a special checkpointing mechanism, that will truncate the log and create a snapshot of the current state.\n\nTo use this feature, simply call the `/cluster/recover` API on required node:\n\n`POST /cluster/recover\n`\n\nThis API can be triggered on any non-leader node, it will send a request to the current consensus leader to create a snapshot. The leader will in turn send the snapshot back to the requesting node for application.\n\nIn some cases, this API can be used to recover from an inconsistent cluster state by forcing a snapshot creation.\n\n1. Weak data consistency and unordered updates: All records are streamed to the target node in order.\nNew updates are received on the target node in parallel, while the transfer\nof records is still happening. We therefore have `weak` ordering, regardless\nof what[ ordering ](https://qdrant.tech/documentation/guides/distributed_deployment/#write-ordering)is used for updates.[ \u21a9\ufe0e ](https://qdrant.tech/documentation/guides/distributed_deployment/#fnref:1)\n2. Strong data consistency and ordered updates: A snapshot of the shard\nis created, it is transferred and recovered on the target node. That ensures\nthe state of the shard is kept consistent. New updates are queued on the\nsource node, and transferred in order to the target node. Updates therefore\nhave the same[ ordering ](https://qdrant.tech/documentation/guides/distributed_deployment/#write-ordering)as the user selects, making `strong` ordering possible.[ \u21a9\ufe0e ](https://qdrant.tech/documentation/guides/distributed_deployment/#fnref:2)\n\n\nWeak data consistency and unordered updates: All records are streamed to the target node in order.\nNew updates are received on the target node in parallel, while the transfer\nof records is still happening. We therefore have `weak` ordering, regardless\nof what[ ordering ](https://qdrant.tech/documentation/guides/distributed_deployment/#write-ordering)is used for updates.[ \u21a9\ufe0e ](https://qdrant.tech/documentation/guides/distributed_deployment/#fnref:1)\n\nStrong data consistency and ordered updates: A snapshot of the shard\nis created, it is transferred and recovered on the target node. That ensures\nthe state of the shard is kept consistent. New updates are queued on the\nsource node, and transferred in order to the target node. Updates therefore\nhave the same[ ordering ](https://qdrant.tech/documentation/guides/distributed_deployment/#write-ordering)as the user selects, making `strong` ordering possible.[ \u21a9\ufe0e ](https://qdrant.tech/documentation/guides/distributed_deployment/#fnref:2)\n\n##### Table of contents\n\n- [ Raft ](https://qdrant.tech/documentation/guides/distributed_deployment/#raft)\n- [ Sharding ](https://qdrant.tech/documentation/guides/distributed_deployment/#sharding)\n    - [ Moving shards ](https://qdrant.tech/documentation/guides/distributed_deployment/#moving-shards)\n\n- [ User-defined sharding ](https://qdrant.tech/documentation/guides/distributed_deployment/#user-defined-sharding)\n\n- [ Shard transfer method ](https://qdrant.tech/documentation/guides/distributed_deployment/#shard-transfer-method)\n- [ Replication ](https://qdrant.tech/documentation/guides/distributed_deployment/#replication)\n    - [ Replication factor ](https://qdrant.tech/documentation/guides/distributed_deployment/#replication-factor)\n\n- [ Creating new shard replicas ](https://qdrant.tech/documentation/guides/distributed_deployment/#creating-new-shard-replicas)\n\n- [ Error handling ](https://qdrant.tech/documentation/guides/distributed_deployment/#error-handling)\n\n- [ Node Failure Recovery ](https://qdrant.tech/documentation/guides/distributed_deployment/#node-failure-recovery)\n- [ Consistency guarantees ](https://qdrant.tech/documentation/guides/distributed_deployment/#consistency-guarantees)\n    - [ Write consistency factor ](https://qdrant.tech/documentation/guides/distributed_deployment/#write-consistency-factor)\n\n- [ Read consistency ](https://qdrant.tech/documentation/guides/distributed_deployment/#read-consistency)\n\n- [ Write ordering ](https://qdrant.tech/documentation/guides/distributed_deployment/#write-ordering)\n- [ Listener mode ](https://qdrant.tech/documentation/guides/distributed_deployment/#listener-mode)\n- [ Consensus Checkpointing ](https://qdrant.tech/documentation/guides/distributed_deployment/#consensus-checkpointing)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/distributed_deployment.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/quantization/": "# Quantization\n\nQuantization is an optional feature in Qdrant that enables efficient storage and search of high-dimensional vectors.\nBy transforming original vectors into a new representations, quantization compresses data while preserving close to original relative distances between vectors.\nDifferent quantization methods have different mechanics and tradeoffs. We will cover them in this section.\n\nQuantization is primarily used to reduce the memory footprint and accelerate the search process in high-dimensional vector spaces.\nIn the context of the Qdrant, quantization allows you to optimize the search engine for specific use cases, striking a balance between accuracy, storage efficiency, and search speed.\n\nThere are tradeoffs associated with quantization.\nOn the one hand, quantization allows for significant reductions in storage requirements and faster search times.\nThis can be particularly beneficial in large-scale applications where minimizing the use of resources is a top priority.\nOn the other hand, quantization introduces an approximation error, which can lead to a slight decrease in search quality.\nThe level of this tradeoff depends on the quantization method and its parameters, as well as the characteristics of the data.\n\n## Scalar Quantization\n\n *Available as of v1.1.0* \n\nScalar quantization, in the context of vector search engines, is a compression technique that compresses vectors by reducing the number of bits used to represent each vector component.\n\nFor instance, Qdrant uses 32-bit floating numbers to represent the original vector components. Scalar quantization allows you to reduce the number of bits used to 8.\nIn other words, Qdrant performs `float32 -> uint8` conversion for each vector component.\nEffectively, this means that the amount of memory required to store a vector is reduced by a factor of 4.\n\nIn addition to reducing the memory footprint, scalar quantization also speeds up the search process.\nQdrant uses a special SIMD CPU instruction to perform fast vector comparison.\nThis instruction works with 8-bit integers, so the conversion to `uint8` allows Qdrant to perform the comparison faster.\n\nThe main drawback of scalar quantization is the loss of accuracy. The `float32 -> uint8` conversion introduces an error that can lead to a slight decrease in search quality.\nHowever, this error is usually negligible, and tends to be less significant for high-dimensional vectors.\nIn our experiments, we found that the error introduced by scalar quantization is usually less than 1%.\n\nHowever, this value depends on the data and the quantization parameters.\nPlease refer to the[ Quantization Tips ](https://qdrant.tech/documentation/guides/quantization/#quantization-tips)section for more information on how to optimize the quantization parameters for your use case.\n\n## Binary Quantization\n\n *Available as of v1.5.0* \n\nBinary quantization is an extreme case of scalar quantization.\nThis feature lets you represent each vector component as a single bit, effectively reducing the memory footprint by a **factor of 32** .\n\nThis is the fastest quantization method, since it lets you perform a vector comparison with a few CPU instructions.\n\nBinary quantization can achieve up to a **40x** speedup compared to the original vectors.\n\nHowever, binary quantization is only efficient for high-dimensional vectors and require a centered distribution of vector components.\n\nAt the moment, binary quantization shows good accuracy results with the following models:\n\n- OpenAI `text-embedding-ada-002` - 1536d tested with[ dbpedia dataset ](https://huggingface.co/datasets/KShivendu/dbpedia-entities-openai-1M)achieving 0.98 recall@100 with 4x oversampling\n- Cohere AI `embed-english-v2.0` - 4096d tested on[ wikipedia embeddings ](https://huggingface.co/datasets/nreimers/wikipedia-22-12-large/tree/main)- 0.98 recall@50 with 2x oversampling\n\n\nModels with a lower dimensionality or a different distribution of vector components may require additional experiments to find the optimal quantization parameters.\n\nWe recommend using binary quantization only with rescoring enabled, as it can significantly improve the search quality\nwith just a minor performance impact.\nAdditionally, oversampling can be used to tune the tradeoff between search speed and search quality in the query time.\n\n### Binary Quantization as Hamming Distance\n\nThe additional benefit of this method is that you can efficiently emulate Hamming distance with dot product.\n\nSpecifically, if original vectors contain `{-1, 1}` as possible values, then the dot product of two vectors is equal to the Hamming distance by simply replacing `-1` with `0` and `1` with `1` .\n\n| Vector 1 | Vector 2 | Dot product |\n|---|---|---|\n| 1 | 1 | 1 |\n| 1 | -1 | -1 |\n| -1 | 1 | -1 |\n| -1 | -1 | 1 |\n\n\n| Vector 1 | Vector 2 | Hamming distance |\n|---|---|---|\n| 1 | 1 | 0 |\n| 1 | 0 | 1 |\n| 0 | 1 | 1 |\n| 0 | 0 | 0 |\n\n\nAs you can see, both functions are equal up to a constant factor, which makes similarity search equivalent.\nBinary quantization makes it efficient to compare vectors using this representation.\n\n## Product Quantization\n\n *Available as of v1.2.0* \n\nProduct quantization is a method of compressing vectors to minimize their memory usage by dividing them into\nchunks and quantizing each segment individually.\nEach chunk is approximated by a centroid index that represents the original vector component.\nThe positions of the centroids are determined through the utilization of a clustering algorithm such as k-means.\nFor now, Qdrant uses only 256 centroids, so each centroid index can be represented by a single byte.\n\nProduct quantization can compress by a more prominent factor than a scalar one.\nBut there are some tradeoffs. Product quantization distance calculations are not SIMD-friendly, so it is slower than scalar quantization.\nAlso, product quantization has a loss of accuracy, so it is recommended to use it only for high-dimensional vectors.\n\nPlease refer to the[ Quantization Tips ](https://qdrant.tech/documentation/guides/quantization/#quantization-tips)section for more information on how to optimize the quantization parameters for your use case.\n\n## How to choose the right quantization method\n\nHere is a brief table of the pros and cons of each quantization method:\n\n| Quantization method | Accuracy | Speed | Compression |\n|---|---|---|---|\n| Scalar | 0.99 | up to x2 | 4 |\n| Product | 0.7 | 0.5 | up to 64 |\n| Binary | 0.95* | up to x40 | 32 |\n\n\n `*` - for compatible models\n\n- **Binary Quantization** is the fastest method and the most memory-efficient, but it requires a centered distribution of vector components. It is recommended to use with tested models only.\n- **Scalar Quantization** is the most universal method, as it provides a good balance between accuracy, speed, and compression. It is recommended as default quantization if binary quantization is not applicable.\n- **Product Quantization** may provide a better compression ratio, but it has a significant loss of accuracy and is slower than scalar quantization. It is recommended if the memory footprint is the top priority and the search speed is not critical.\n\n\n## Setting up Quantization in Qdrant\n\nYou can configure quantization for a collection by specifying the quantization parameters in the `quantization_config` section of the collection configuration.\n\nQuantization will be automatically applied to all vectors during the indexation process.\nQuantized vectors are stored alongside the original vectors in the collection, so you will still have access to the original vectors if you need them.\n\n *Available as of v1.1.1* \n\nThe `quantization_config` can also be set on a per vector basis by specifying it in a named vector.\n\n### Setting up Scalar Quantization\n\nTo enable scalar quantization, you need to specify the quantization parameters in the `quantization_config` section of the collection configuration.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"quantization_config\": {\n\n        \"scalar\": {\n\n            \"type\": \"int8\",\n\n            \"quantile\": 0.99,\n\n            \"always_ram\": true\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    quantization_config = models . ScalarQuantization(\n\n        scalar = models . ScalarQuantizationConfig(\n\n             type = models . ScalarType . INT8,\n\n            quantile = 0.99 ,\n\n            always_ram = True ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  quantization_config :  {\n\n    scalar :  {\n\n       type :   \"int8\" ,\n\n      quantile:  0.99 ,\n\n      always_ram:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         quantization_config::Quantization,   vectors_config::Config,   CreateCollection,   Distance, \n\n         QuantizationConfig,   QuantizationType,   ScalarQuantization,   VectorParams,   VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         quantization_config:  Some (QuantizationConfig   { \n\n             quantization:  Some (Quantization::Scalar(ScalarQuantization   { \n\n                 r#type:  QuantizationType ::Int8.into(), \n\n                 quantile:  Some ( 0.99 ), \n\n                 always_ram:  Some ( true ), \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThere are 3 parameters that you can specify in the `quantization_config` section:\n\n `type` - the type of the quantized vector components. Currently, Qdrant supports only `int8` .\n\n `quantile` - the quantile of the quantized vector components.\nThe quantile is used to calculate the quantization bounds.\nFor instance, if you specify `0.99` as the quantile, 1% of extreme values will be excluded from the quantization bounds.\n\nUsing quantiles lower than `1.0` might be useful if there are outliers in your vector components.\nThis parameter only affects the resulting precision and not the memory footprint.\nIt might be worth tuning this parameter if you experience a significant decrease in search quality.\n\n `always_ram` - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors.\nHowever, in some setups you might want to keep quantized vectors in RAM to speed up the search process.\n\nIn this case, you can set `always_ram` to `true` to store quantized vectors in RAM.\n\n### Setting up Binary Quantization\n\nTo enable binary quantization, you need to specify the quantization parameters in the `quantization_config` section of the collection configuration.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 1536,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"quantization_config\": {\n\n        \"binary\": {\n\n            \"always_ram\": true\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 1536 , distance = models . Distance . COSINE),\n\n    quantization_config = models . BinaryQuantization(\n\n        binary = models . BinaryQuantizationConfig(\n\n            always_ram = True ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  1536 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  quantization_config :  {\n\n    binary :  {\n\n      always_ram:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         quantization_config::Quantization,   vectors_config::Config,   BinaryQuantization, \n\n         CreateCollection,   Distance,   QuantizationConfig,   VectorParams,   VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  1536 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         quantization_config:  Some (QuantizationConfig   { \n\n             quantization:  Some (Quantization::Binary(BinaryQuantization   { \n\n                 always_ram:  Some ( true ), \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n `always_ram` - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors.\nHowever, in some setups you might want to keep quantized vectors in RAM to speed up the search process.\n\nIn this case, you can set `always_ram` to `true` to store quantized vectors in RAM.\n\n### Setting up Product Quantization\n\nTo enable product quantization, you need to specify the quantization parameters in the `quantization_config` section of the collection configuration.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"quantization_config\": {\n\n        \"product\": {\n\n            \"compression\": \"x16\",\n\n            \"always_ram\": true\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    quantization_config = models . ProductQuantization(\n\n        product = models . ProductQuantizationConfig(\n\n            compression = models . CompressionRatio . X16,\n\n            always_ram = True ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  quantization_config :  {\n\n    product :  {\n\n      compression :   \"x16\" ,\n\n      always_ram:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         quantization_config::Quantization,   vectors_config::Config,   CompressionRatio, \n\n         CreateCollection,   Distance,   ProductQuantization,   QuantizationConfig,   VectorParams, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         quantization_config:  Some (QuantizationConfig   { \n\n             quantization:  Some (Quantization::Product(ProductQuantization   { \n\n                 compression:  CompressionRatio ::X16.into(), \n\n                 always_ram:  Some ( true ), \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nThere are two parameters that you can specify in the `quantization_config` section:\n\n `compression` - compression ratio.\nCompression ratio represents the size of the quantized vector in bytes divided by the size of the original vector in bytes.\nIn this case, the quantized vector will be 16 times smaller than the original vector.\n\n `always_ram` - whether to keep quantized vectors always cached in RAM or not. By default, quantized vectors are loaded in the same way as the original vectors.\nHowever, in some setups you might want to keep quantized vectors in RAM to speed up the search process. Then set `always_ram` to `true` .\n\n### Searching with Quantization\n\nOnce you have configured quantization for a collection, you don\u2019t need to do anything extra to search with quantization.\nQdrant will automatically use quantized vectors if they are available.\n\nHowever, there are a few options that you can use to control the search process:\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"params\": {\n\n        \"quantization\": {\n\n            \"ignore\": false,\n\n            \"rescore\": true,\n\n            \"oversampling\": 2.0\n\n        }\n\n    },\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"limit\": 10\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    search_params = models . SearchParams(\n\n        quantization = models . QuantizationSearchParams(\n\n            ignore = False ,\n\n            rescore = True ,\n\n            oversampling = 2.0 ,\n\n        )\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  params :  {\n\n    quantization :  {\n\n      ignore:  false ,\n\n      rescore:  true ,\n\n      oversampling:  2.0 ,\n\n    },\n\n  },\n\n  limit:  10 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{QuantizationSearchParams,   SearchParams,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         params:  Some (SearchParams   { \n\n             quantization:  Some (QuantizationSearchParams   { \n\n                 ignore:  Some ( false ), \n\n                 rescore:  Some ( true ), \n\n                 oversampling:  Some ( 2.0 ), \n\n                 .. Default ::default() \n\n             }), \n\n             .. Default ::default() \n\n         }), \n\n         limit:  10 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n `ignore` - Toggle whether to ignore quantized vectors during the search process. By default, Qdrant will use quantized vectors if they are available.\n\n `rescore` - Having the original vectors available, Qdrant can re-evaluate top-k search results using the original vectors.\nThis can improve the search quality, but may slightly decrease the search speed, compared to the search without rescore.\nIt is recommended to disable rescore only if the original vectors are stored on a slow storage (e.g. HDD or network storage).\nBy default, rescore is enabled.\n\n **Available as of v1.3.0** \n\n `oversampling` - Defines how many extra vectors should be pre-selected using quantized index, and then re-scored using original vectors.\nFor example, if oversampling is 2.4 and limit is 100, then 240 vectors will be pre-selected using quantized index, and then top-100 will be returned after re-scoring.\nOversampling is useful if you want to tune the tradeoff between search speed and search quality in the query time.\n\n## Quantization tips\n\n#### Accuracy tuning\n\nIn this section, we will discuss how to tune the search precision.\nThe fastest way to understand the impact of quantization on the search quality is to compare the search results with and without quantization.\n\nIn order to disable quantization, you can set `ignore` to `true` in the search request:\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"params\": {\n\n        \"quantization\": {\n\n            \"ignore\": true\n\n        }\n\n    },\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"limit\": 10\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    search_params = models . SearchParams(\n\n        quantization = models . QuantizationSearchParams(\n\n            ignore = True ,\n\n        )\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  params :  {\n\n    quantization :  {\n\n      ignore:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{QuantizationSearchParams,   SearchParams,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         params:  Some (SearchParams   { \n\n             quantization:  Some (QuantizationSearchParams   { \n\n                 ignore:  Some ( true ), \n\n                 .. Default ::default() \n\n             }), \n\n             .. Default ::default() \n\n         }), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n- **Adjust the quantile parameter** : The quantile parameter in scalar quantization determines the quantization bounds.\nBy setting it to a value lower than 1.0, you can exclude extreme values (outliers) from the quantization bounds.\nFor example, if you set the quantile to 0.99, 1% of the extreme values will be excluded.\nBy adjusting the quantile, you find an optimal value that will provide the best search quality for your collection.\n- **Enable rescore** : Having the original vectors available, Qdrant can re-evaluate top-k search results using the original vectors. On large collections, this can improve the search quality, with just minor performance impact.\n\n\n **Adjust the quantile parameter** : The quantile parameter in scalar quantization determines the quantization bounds.\nBy setting it to a value lower than 1.0, you can exclude extreme values (outliers) from the quantization bounds.\nFor example, if you set the quantile to 0.99, 1% of the extreme values will be excluded.\nBy adjusting the quantile, you find an optimal value that will provide the best search quality for your collection.\n\n **Enable rescore** : Having the original vectors available, Qdrant can re-evaluate top-k search results using the original vectors. On large collections, this can improve the search quality, with just minor performance impact.\n\n#### Memory and speed tuning\n\nIn this section, we will discuss how to tune the memory and speed of the search process with quantization.\n\nThere are 3 possible modes to place storage of vectors within the qdrant collection:\n\n- **All in RAM** - all vector, original and quantized, are loaded and kept in RAM. This is the fastest mode, but requires a lot of RAM. Enabled by default.\n- **Original on Disk, quantized in RAM** - this is a hybrid mode, allows to obtain a good balance between speed and memory usage. Recommended scenario if you are aiming to shrink the memory footprint while keeping the search speed.\n\n\n **All in RAM** - all vector, original and quantized, are loaded and kept in RAM. This is the fastest mode, but requires a lot of RAM. Enabled by default.\n\n **Original on Disk, quantized in RAM** - this is a hybrid mode, allows to obtain a good balance between speed and memory usage. Recommended scenario if you are aiming to shrink the memory footprint while keeping the search speed.\n\nThis mode is enabled by setting `always_ram` to `true` in the quantization config while using memmap storage:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"memmap_threshold\": 20000\n\n    },\n\n    \"quantization_config\": {\n\n        \"scalar\": {\n\n            \"type\": \"int8\",\n\n            \"always_ram\": true\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(memmap_threshold = 20000 ),\n\n    quantization_config = models . ScalarQuantization(\n\n        scalar = models . ScalarQuantizationConfig(\n\n             type = models . ScalarType . INT8,\n\n            always_ram = True ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    memmap_threshold:  20000 ,\n\n  },\n\n  quantization_config :  {\n\n    scalar :  {\n\n       type :   \"int8\" ,\n\n      always_ram:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         quantization_config::Quantization,   vectors_config::Config,   CreateCollection,   Distance, \n\n         OptimizersConfigDiff,   QuantizationConfig,   QuantizationType,   ScalarQuantization, \n\n         VectorParams,   VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             memmap_threshold:  Some ( 20000 ), \n\n             .. Default ::default() \n\n         }), \n\n         quantization_config:  Some (QuantizationConfig   { \n\n             quantization:  Some (Quantization::Scalar(ScalarQuantization   { \n\n                 r#type:  QuantizationType ::Int8.into(), \n\n                 always_ram:  Some ( true ), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nIn this scenario, the number of disk reads may play a significant role in the search speed.\nIn a system with high disk latency, the re-scoring step may become a bottleneck.\n\nConsider disabling `rescore` to improve the search speed:\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"params\": {\n\n        \"quantization\": {\n\n            \"rescore\": false\n\n        }\n\n    },\n\n    \"vector\": [0.2, 0.1, 0.9, 0.7],\n\n    \"limit\": 10\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    search_params = models . SearchParams(\n\n        quantization = models . QuantizationSearchParams(rescore = False )\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  params :  {\n\n    quantization :  {\n\n      rescore:  false ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{QuantizationSearchParams,   SearchParams,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         params:  Some (SearchParams   { \n\n             quantization:  Some (QuantizationSearchParams   { \n\n                 rescore:  Some ( true ), \n\n                 .. Default ::default() \n\n             }), \n\n             .. Default ::default() \n\n         }), \n\n         limit:  3 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n- **All on Disk** - all vectors, original and quantized, are stored on disk. This mode allows to achieve the smallest memory footprint, but at the cost of the search speed.\n\n\nIt is recommended to use this mode if you have a large collection and fast storage (e.g. SSD or NVMe).\n\nThis mode is enabled by setting `always_ram` to `false` in the quantization config while using mmap storage:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"memmap_threshold\": 20000\n\n    },\n\n    \"quantization_config\": {\n\n        \"scalar\": {\n\n            \"type\": \"int8\",\n\n            \"always_ram\": false\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(memmap_threshold = 20000 ),\n\n    quantization_config = models . ScalarQuantization(\n\n        scalar = models . ScalarQuantizationConfig(\n\n             type = models . ScalarType . INT8,\n\n            always_ram = False ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    memmap_threshold:  20000 ,\n\n  },\n\n  quantization_config :  {\n\n    scalar :  {\n\n       type :   \"int8\" ,\n\n      always_ram:  false ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         quantization_config::Quantization,   vectors_config::Config,   CreateCollection,   Distance, \n\n         OptimizersConfigDiff,   QuantizationConfig,   QuantizationType,   ScalarQuantization, \n\n         VectorParams,   VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         optimizers_config:  Some (OptimizersConfigDiff   { \n\n             memmap_threshold:  Some ( 20000 ), \n\n             .. Default ::default() \n\n         }), \n\n         quantization_config:  Some (QuantizationConfig   { \n\n             quantization:  Some (Quantization::Scalar(ScalarQuantization   { \n\n                 r#type:  QuantizationType ::Int8.into(), \n\n                 always_ram:  Some ( false ), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n##### Table of contents\n\n- [ Scalar Quantization ](https://qdrant.tech/documentation/guides/quantization/#scalar-quantization)\n- [ Binary Quantization ](https://qdrant.tech/documentation/guides/quantization/#binary-quantization)\n    - [ Binary Quantization as Hamming Distance ](https://qdrant.tech/documentation/guides/quantization/#binary-quantization-as-hamming-distance)\n- [ Product Quantization ](https://qdrant.tech/documentation/guides/quantization/#product-quantization)\n- [ How to choose the right quantization method ](https://qdrant.tech/documentation/guides/quantization/#how-to-choose-the-right-quantization-method)\n- [ Setting up Quantization in Qdrant ](https://qdrant.tech/documentation/guides/quantization/#setting-up-quantization-in-qdrant)\n    - [ Setting up Scalar Quantization ](https://qdrant.tech/documentation/guides/quantization/#setting-up-scalar-quantization)\n\n- [ Setting up Binary Quantization ](https://qdrant.tech/documentation/guides/quantization/#setting-up-binary-quantization)\n\n- [ Setting up Product Quantization ](https://qdrant.tech/documentation/guides/quantization/#setting-up-product-quantization)\n\n- [ Searching with Quantization ](https://qdrant.tech/documentation/guides/quantization/#searching-with-quantization)\n- [ Quantization tips ](https://qdrant.tech/documentation/guides/quantization/#quantization-tips)\n    -\n\n- \n\n\n\n- \n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/quantization.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/telemetry/": "# Telemetry\n\nQdrant collects anonymized usage statistics from users in order to improve the engine.\nYou can[ deactivate ](https://qdrant.tech/documentation/guides/telemetry/#deactivate-telemetry)at any time, and any data that has already been collected can be[ deleted on request ](https://qdrant.tech/documentation/guides/telemetry/#request-information-deletion).\n\n## Why do we collect telemetry?\n\nWe want to make Qdrant fast and reliable. To do this, we need to understand how it performs in real-world scenarios.\nWe do a lot of benchmarking internally, but it is impossible to cover all possible use cases, hardware, and configurations.\n\nIn order to identify bottlenecks and improve Qdrant, we need to collect information about how it is used.\n\nAdditionally, Qdrant uses a bunch of internal heuristics to optimize the performance.\nTo better set up parameters for these heuristics, we need to collect timings and counters of various pieces of code.\nWith this information, we can make Qdrant faster for everyone.\n\n## What information is collected?\n\nThere are 3 types of information that we collect:\n\n- System information - general information about the system, such as CPU, RAM, and disk type. As well as the configuration of the Qdrant instance.\n- Performance - information about timings and counters of various pieces of code.\n- Critical error reports - information about critical errors, such as backtraces, that occurred in Qdrant. This information would allow to identify problems nobody yet reported to us.\n\n\n### We never collect the following information:\n\n- User\u2019s IP address\n- Any data that can be used to identify the user or the user\u2019s organization\n- Any data, stored in the collections\n- Any names of the collections\n- Any URLs\n\n\n## How do we anonymize data?\n\nWe understand that some users may be concerned about the privacy of their data.\nThat is why we make an extra effort to ensure your privacy.\n\nThere are several different techniques that we use to anonymize the data:\n\n- We use a random UUID to identify instances. This UUID is generated on each startup and is not stored anywhere. There are no other ways to distinguish between different instances.\n- We round all big numbers, so that the last digits are always 0. For example, if the number is 123456789, we will store 123456000.\n- We replace all names with irreversibly hashed values. So no collection or field names will leak into the telemetry.\n- All urls are hashed as well.\n\n\nYou can see exact version of anomymized collected data by accessing the[ telemetry API ](https://qdrant.github.io/qdrant/redoc/index.html#tag/service/operation/telemetry)with `anonymize=true` parameter.\n\nFor example,[ http://localhost:6333/telemetry?details_level=6&anonymize=true ](http://localhost:6333/telemetry?details_level=6&anonymize=true)\n\n## Deactivate telemetry\n\nYou can deactivate telemetry by:\n\n- setting the `QDRANT__TELEMETRY_DISABLED` environment variable to `true`\n- setting the config option `telemetry_disabled` to `true` in the `config/production.yaml` or `config/config.yaml` files\n- using cli option `--disable-telemetry`\n\n\nAny of these options will prevent Qdrant from sending any telemetry data.\n\nIf you decide to deactivate telemetry, we kindly ask you to share your feedback with us in the[ Discord community ](https://qdrant.to/discord)or GitHub[ discussions ](https://github.com/qdrant/qdrant/discussions)\n\n## Request information deletion\n\nWe provide an email address so that users can request the complete removal of their data from all of our tools.\n\nTo do so, send an email to[ privacy@qdrant.com ](mailto:privacy@qdrant.com)containing the unique identifier generated for your Qdrant installation.\nYou can find this identifier in the telemetry API response ( `\"id\"` field), or in the logs of your Qdrant instance.\n\nAny questions regarding the management of the data we collect can also be sent to this email address.\n\n##### Table of contents\n\n- [ Why do we collect telemetry? ](https://qdrant.tech/documentation/guides/telemetry/#why-do-we-collect-telemetry)\n- [ What information is collected? ](https://qdrant.tech/documentation/guides/telemetry/#what-information-is-collected)\n    - [ We never collect the following information: ](https://qdrant.tech/documentation/guides/telemetry/#we-never-collect-the-following-information)\n- [ How do we anonymize data? ](https://qdrant.tech/documentation/guides/telemetry/#how-do-we-anonymize-data)\n- [ Deactivate telemetry ](https://qdrant.tech/documentation/guides/telemetry/#deactivate-telemetry)\n- [ Request information deletion ](https://qdrant.tech/documentation/guides/telemetry/#request-information-deletion)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/telemetry.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/monitoring/": "# Monitoring\n\nQdrant exposes its metrics in a Prometheus format, so you can integrate them easily\nwith the compatible tools and monitor Qdrant with your own monitoring system. You can\nuse the `/metrics` endpoint and configure it as a scrape target.\n\nMetrics endpoint:[ http://localhost:6333/metrics ](http://localhost:6333/metrics)\n\nThe integration with Qdrant is easy to[ configure ](https://prometheus.io/docs/prometheus/latest/getting_started/#configure-prometheus-to-monitor-the-sample-targets)with Prometheus and Grafana.\n\n## Exposed metric\n\nEach Qdrant server will expose the following metrics.\n\n| Name | Type | Meaning |\n|---|---|---|\n| app_info | counter | Information about Qdrant server |\n| app_status_recovery_mode | counter | If Qdrant is currently started in recovery mode |\n| collections_total | gauge | Number of collections |\n| collections_vector_total | gauge | Total number of vectors in all collections |\n| collections_full_total | gauge | Number of full collections |\n| collections_aggregated_total | gauge | Number of aggregated collections |\n| rest_responses_total | counter | Total number of responses through REST API |\n| rest_responses_fail_total | counter | Total number of failed responses through REST API |\n| rest_responses_avg_duration_seconds | gauge | Average response duration in REST API |\n| rest_responses_min_duration_seconds | gauge | Minimum response duration in REST API |\n| rest_responses_max_duration_seconds | gauge | Maximum response duration in REST API |\n| grpc_responses_total | counter | Total number of responses through gRPC API |\n| grpc_responses_fail_total | counter | Total number of failed responses through REST API |\n| grpc_responses_avg_duration_seconds | gauge | Average response duration in gRPC API |\n| grpc_responses_min_duration_seconds | gauge | Minimum response duration in gRPC API |\n| grpc_responses_max_duration_seconds | gauge | Maximum response duration in gRPC API |\n| cluster_enabled | gauge | Whether the cluster support is enabled |\n\n\n### Cluster related metrics\n\nThere are also some metrics which are exposed in distributed mode only.\n\n| Name | Type | Meaning |\n|---|---|---|\n| cluster_peers_total | gauge | Total number of cluster peers |\n| cluster_term | counter | Current cluster term |\n| cluster_commit | counter | Index of last committed (finalized) operation cluster peer is aware of |\n| cluster_pending_operations_total | gauge | Total number of pending operations for cluster peer |\n| cluster_voter | gauge | Whether the cluster peer is a voter or learner |\n\n\n## Kubernetes health endpoints\n\n *Available as of v1.5.0* \n\nQdrant exposes three endpoints, namely[ /healthz ](http://localhost:6333/healthz),[ /livez ](http://localhost:6333/livez)and[ /readyz ](http://localhost:6333/readyz), to indicate the current status of the\nQdrant server.\n\nThese currently provide the most basic status response, returning HTTP 200 if\nQdrant is started and ready to be used.\n\nRegardless of whether an[ API key ](../security#authentication)is configured,\nthe endpoints are always accessible.\n\nYou can read more about Kubernetes health endpoints[ here ](https://kubernetes.io/docs/reference/using-api/health-checks/).\n\n##### Table of contents\n\n- [ Exposed metric ](https://qdrant.tech/documentation/guides/monitoring/#exposed-metric)\n    - [ Cluster related metrics ](https://qdrant.tech/documentation/guides/monitoring/#cluster-related-metrics)\n- [ Kubernetes health endpoints ](https://qdrant.tech/documentation/guides/monitoring/#kubernetes-health-endpoints)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/monitoring.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/configuration/": "# Configuration\n\nTo change or correct Qdrant\u2019s behavior, default collection settings, and network interface parameters, you can use configuration files.\n\nThe default configuration file is located at[ config/config.yaml ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml).\n\nTo change the default configuration, add a new configuration file and specify\nthe path with `--config-path path/to/custom_config.yaml` . If running in\nproduction mode, you could also choose to overwrite `config/production.yaml` .\nSee[ ordering ](https://qdrant.tech/documentation/guides/configuration/#order-and-priority)for details on how configurations are\nloaded.\n\nTo use Qdrant in Docker and overwrite the production configuration use:\n\n```\ndocker run -p 6333:6333  \\\n\n    -v  $( pwd ) /path/to/custom_config.yaml:/qdrant/config/production.yaml  \\\n\n    qdrant/qdrant\n\n```\n\nOr use your own configuration file and specify it:\n\n```\ndocker run -p 6333:6333  \\\n\n    -v  $( pwd ) /path/to/custom_config.yaml:/qdrant/config/custom_config.yaml  \\\n\n    qdrant/qdrant  \\\n\n    ./qdrant --config-path config/custom_config.yaml\n\n```\n\n## Order and priority\n\n *Effective as of v1.2.1* \n\nMultiple configurations may be loaded on startup. All of them are merged into a\nsingle effective configuration that is used by Qdrant.\n\nConfigurations are loaded in the following order, if present:\n\n1. Embedded base configuration ([ source ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml))\n2. File `config/config.yaml`\n3. File `config/{RUN_MODE}.yaml` (such as `config/production.yaml` )\n4. File `config/local.yaml`\n5. Config provided with `--config-path PATH` (if set)\n6. [ Environment variables ](https://qdrant.tech/documentation/guides/configuration/#environment-variables)\n\n\nThis list is from least to most significant. Properties in later configurations\nwill overwrite those loaded before it. For example, a property set with `--config-path` will overwrite those in other files.\n\nMost of these files are included by default in the Docker container. But it is\nlikely that they are absent on your local machine if you run the `qdrant` binary\nmanually.\n\nIf file 2 or 3 are not found, a warning is shown on startup.\nIf file 5 is provided but not found, an error is shown on startup.\n\nOther supported configuration file formats and extensions include: `.toml` , `.json` , `.ini` .\n\n## Environment variables\n\nIt is possible to set configuration properties using environment variables.\nEnvironment variables are always the most significant and cannot be overwritten\n(see[ ordering ](https://qdrant.tech/documentation/guides/configuration/#order-and-priority)).\n\nAll environment variables are prefixed with `QDRANT__` and are separated with `__` .\n\nThese variables:\n\n```\nQDRANT__LOG_LEVEL = INFO\n\nQDRANT__SERVICE__HTTP_PORT = 6333 \n\nQDRANT__SERVICE__ENABLE_TLS = 1 \n\nQDRANT__TLS__CERT = ./tls/cert.pem\n\nQDRANT__TLS__CERT_TTL = 3600 \n\n```\n\nresult in this configuration:\n\n```\nlog_level :   INFO \n\nservice : \n\n   http_port :   6333 \n\n   enable_tls :   true \n\ntls : \n\n   cert :   ./tls/cert.pem \n\n   cert_ttl :   3600 \n\n```\n\nTo run Qdrant locally with a different HTTP port you could use:\n\n`QDRANT__SERVICE__HTTP_PORT = 1234  ./qdrant\n`\n\n## Configuration file example\n\n```\nlog_level :   INFO \n\n\n\nstorage : \n\n   # Where to store all the data \n\n   storage_path :   ./storage \n\n\n\n   # Where to store snapshots \n\n   snapshots_path :   ./snapshots \n\n\n\n   # Where to store temporary files \n\n   # If null, temporary snapshot are stored in: storage/snapshots_temp/ \n\n   temp_path :   null \n\n\n\n   # If true - point's payload will not be stored in memory. \n\n   # It will be read from the disk every time it is requested. \n\n   # This setting saves RAM by (slightly) increasing the response time. \n\n   # Note: those payload values that are involved in filtering and are indexed - remain in RAM. \n\n   on_disk_payload :   true \n\n\n\n   # Maximum number of concurrent updates to shard replicas \n\n   # If `null` - maximum concurrency is used. \n\n   update_concurrency :   null \n\n\n\n   # Write-ahead-log related configuration \n\n   wal : \n\n     # Size of a single WAL segment \n\n     wal_capacity_mb :   32 \n\n\n\n     # Number of WAL segments to create ahead of actual data requirement \n\n     wal_segments_ahead :   0 \n\n\n\n   # Normal node - receives all updates and answers all queries \n\n   node_type :   \"Normal\" \n\n\n\n   # Listener node - receives all updates, but does not answer search/read queries \n\n   # Useful for setting up a dedicated backup node \n\n   # node_type: \"Listener\" \n\n\n\n   performance : \n\n     # Number of parallel threads used for search operations. If 0 - auto selection. \n\n     max_search_threads :   0 \n\n     # Max total number of threads, which can be used for running optimization processes across all collections. \n\n     # Note: Each optimization thread will also use `max_indexing_threads` for index building. \n\n     # So total number of threads used for optimization will be `max_optimization_threads * max_indexing_threads` \n\n     max_optimization_threads :   1 \n\n\n\n     # Prevent DDoS of too many concurrent updates in distributed mode. \n\n     # One external update usually triggers multiple internal updates, which breaks internal \n\n     # timings. For example, the health check timing and consensus timing. \n\n     # If null - auto selection. \n\n     update_rate_limit :   null \n\n\n\n   optimizers : \n\n     # The minimal fraction of deleted vectors in a segment, required to perform segment optimization \n\n     deleted_threshold :   0.2 \n\n\n\n     # The minimal number of vectors in a segment, required to perform segment optimization \n\n     vacuum_min_vector_number :   1000 \n\n\n\n     # Target amount of segments optimizer will try to keep. \n\n     # Real amount of segments may vary depending on multiple parameters: \n\n     #  - Amount of stored points \n\n     #  - Current write RPS \n\n     # \n\n     # It is recommended to select default number of segments as a factor of the number of search threads, \n\n     # so that each segment would be handled evenly by one of the threads. \n\n     # If `default_segment_number = 0`, will be automatically selected by the number of available CPUs \n\n     default_segment_number :   0 \n\n\n\n     # Do not create segments larger this size (in KiloBytes). \n\n     # Large segments might require disproportionately long indexation times, \n\n     # therefore it makes sense to limit the size of segments. \n\n     # \n\n     # If indexation speed have more priority for your - make this parameter lower. \n\n     # If search speed is more important - make this parameter higher. \n\n     # Note: 1Kb = 1 vector of size 256 \n\n     # If not set, will be automatically selected considering the number of available CPUs. \n\n     max_segment_size_kb :   null \n\n\n\n     # Maximum size (in KiloBytes) of vectors to store in-memory per segment. \n\n     # Segments larger than this threshold will be stored as read-only memmaped file. \n\n     # To enable memmap storage, lower the threshold \n\n     # Note: 1Kb = 1 vector of size 256 \n\n     # To explicitly disable mmap optimization, set to `0`. \n\n     # If not set, will be disabled by default. \n\n     memmap_threshold_kb :   null \n\n\n\n     # Maximum size (in KiloBytes) of vectors allowed for plain index. \n\n     # Default value based on https://github.com/google-research/google-research/blob/master/scann/docs/algorithms.md \n\n     # Note: 1Kb = 1 vector of size 256 \n\n     # To explicitly disable vector indexing, set to `0`. \n\n     # If not set, the default value will be used. \n\n     indexing_threshold_kb :   20000 \n\n\n\n     # Interval between forced flushes. \n\n     flush_interval_sec :   5 \n\n\n\n     # Max number of threads, which can be used for optimization per collection. \n\n     # Note: Each optimization thread will also use `max_indexing_threads` for index building. \n\n     # So total number of threads used for optimization will be `max_optimization_threads * max_indexing_threads` \n\n     # If `max_optimization_threads = 0`, optimization will be disabled. \n\n     max_optimization_threads :   1 \n\n\n\n   # Default parameters of HNSW Index. Could be overridden for each collection or named vector individually \n\n   hnsw_index : \n\n     # Number of edges per node in the index graph. Larger the value - more accurate the search, more space required. \n\n     m :   16 \n\n     # Number of neighbours to consider during the index building. Larger the value - more accurate the search, more time required to build index. \n\n     ef_construct :   100 \n\n     # Minimal size (in KiloBytes) of vectors for additional payload-based indexing. \n\n     # If payload chunk is smaller than `full_scan_threshold_kb` additional indexing won't be used - \n\n     # in this case full-scan search should be preferred by query planner and additional indexing is not required. \n\n     # Note: 1Kb = 1 vector of size 256 \n\n     full_scan_threshold_kb :   10000 \n\n     # Number of parallel threads used for background index building. If 0 - auto selection. \n\n     max_indexing_threads :   0 \n\n     # Store HNSW index on disk. If set to false, index will be stored in RAM. Default: false \n\n     on_disk :   false \n\n     # Custom M param for hnsw graph built for payload index. If not set, default M will be used. \n\n     payload_m :   null \n\n\n\n\n\nservice : \n\n\n\n   # Maximum size of POST data in a single request in megabytes \n\n   max_request_size_mb :   32 \n\n\n\n   # Number of parallel workers used for serving the api. If 0 - equal to the number of available cores. \n\n   # If missing - Same as storage.max_search_threads \n\n   max_workers :   0 \n\n\n\n   # Host to bind the service on \n\n   host :   0.0.0.0 \n\n\n\n   # HTTP(S) port to bind the service on \n\n   http_port :   6333 \n\n\n\n   # gRPC port to bind the service on. \n\n   # If `null` - gRPC is disabled. Default: null \n\n   # Comment to disable gRPC: \n\n   grpc_port :   6334 \n\n\n\n   # Enable CORS headers in REST API. \n\n   # If enabled, browsers would be allowed to query REST endpoints regardless of query origin. \n\n   # More info: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS \n\n   # Default: true \n\n   enable_cors :   true \n\n\n\n   # Enable HTTPS for the REST and gRPC API \n\n   enable_tls :   false \n\n\n\n   # Check user HTTPS client certificate against CA file specified in tls config \n\n   verify_https_client_certificate :   false \n\n\n\n   # Set an api-key. \n\n   # If set, all requests must include a header with the api-key. \n\n   # example header: `api-key: <API-KEY>` \n\n   # \n\n   # If you enable this you should also enable TLS. \n\n   # (Either above or via an external service like nginx.) \n\n   # Sending an api-key over an unencrypted channel is insecure. \n\n   # \n\n   # Uncomment to enable. \n\n   # api_key: your_secret_api_key_here \n\n   \n\n   # Set an api-key for read-only operations. \n\n   # If set, all requests must include a header with the api-key. \n\n   # example header: `api-key: <API-KEY>` \n\n   # \n\n   # If you enable this you should also enable TLS. \n\n   # (Either above or via an external service like nginx.) \n\n   # Sending an api-key over an unencrypted channel is insecure. \n\n   # \n\n   # Uncomment to enable. \n\n   # read_only_api_key: your_secret_read_only_api_key_here \n\n\n\ncluster : \n\n   # Use `enabled: true` to run Qdrant in distributed deployment mode \n\n   enabled :   false \n\n\n\n   # Configuration of the inter-cluster communication \n\n   p2p : \n\n     # Port for internal communication between peers \n\n     port :   6335 \n\n\n\n     # Use TLS for communication between peers \n\n     enable_tls :   false \n\n\n\n   # Configuration related to distributed consensus algorithm \n\n   consensus : \n\n     # How frequently peers should ping each other. \n\n     # Setting this parameter to lower value will allow consensus \n\n     # to detect disconnected nodes earlier, but too frequent \n\n     # tick period may create significant network and CPU overhead. \n\n     # We encourage you NOT to change this parameter unless you know what you are doing. \n\n     tick_period_ms :   100 \n\n\n\n\n\n# Set to true to prevent service from sending usage statistics to the developers. \n\n# Read more: https://qdrant.tech/documentation/guides/telemetry \n\ntelemetry_disabled :   false \n\n\n\n\n\n# TLS configuration. \n\n# Required if either service.enable_tls or cluster.p2p.enable_tls is true. \n\ntls : \n\n   # Server certificate chain file \n\n   cert :   ./tls/cert.pem \n\n\n\n   # Server private key file \n\n   key :   ./tls/key.pem \n\n\n\n   # Certificate authority certificate file. \n\n   # This certificate will be used to validate the certificates \n\n   # presented by other nodes during inter-cluster communication. \n\n   # \n\n   # If verify_https_client_certificate is true, it will verify \n\n   # HTTPS client certificate \n\n   # \n\n   # Required if cluster.p2p.enable_tls is true. \n\n   ca_cert :   ./tls/cacert.pem \n\n\n\n   # TTL in seconds to reload certificate from disk, useful for certificate rotations. \n\n   # Only works for HTTPS endpoints. Does not support gRPC (and intra-cluster communication). \n\n   # If `null` - TTL is disabled. \n\n   cert_ttl :   3600 \n\n```\n\n## Validation\n\n *Available since v1.1.1* \n\nThe configuration is validated on startup. If a configuration is loaded but\nvalidation fails, a warning is logged. E.g.:\n\n```\nWARN Settings configuration file has validation errors:\n\nWARN - storage.optimizers.memmap_threshold: value 123 invalid, must be 1000 or larger\n\nWARN - storage.hnsw_index.m: value 1 invalid, must be from 4 to 10000\n\n```\n\nThe server will continue to operate. Any validation errors should be fixed as\nsoon as possible though to prevent problematic behavior.\n\n##### Table of contents\n\n- [ Order and priority ](https://qdrant.tech/documentation/guides/configuration/#order-and-priority)\n- [ Environment variables ](https://qdrant.tech/documentation/guides/configuration/#environment-variables)\n- [ Configuration file example ](https://qdrant.tech/documentation/guides/configuration/#configuration-file-example)\n- [ Validation ](https://qdrant.tech/documentation/guides/configuration/#validation)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/configuration.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/security/": "# Security\n\nPlease read this page carefully. Although there are various ways to secure your Qdrant instances, **they are unsecured by default** .\nYou need to enable security measures before production use. Otherwise, they are completely open to anyone\n\n## Authentication\n\n *Available as of v1.2.0* \n\nQdrant supports a simple form of client authentication using a static API key.\nThis can be used to secure your instance.\n\nTo enable API key based authentication in your own Qdrant instance you must\nspecify a key in the configuration:\n\n```\nservice : \n\n   # Set an api-key. \n\n   # If set, all requests must include a header with the api-key. \n\n   # example header: `api-key: <API-KEY>` \n\n   # \n\n   # If you enable this you should also enable TLS. \n\n   # (Either above or via an external service like nginx.) \n\n   # Sending an api-key over an unencrypted channel is insecure. \n\n   api_key :   your_secret_api_key_here \n\n```\n\nFor using API key based authentication in Qdrant cloud see the cloud[ Authentication ](https://qdrant.tech/documentation/cloud/authentication)section.\n\nThe API key then needs to be present in all REST or gRPC requests to your instance.\nAll official Qdrant clients for Python, Go, Rust, and .NET support the API key parameter.\n\n```\ncurl  \\\n\n  -X GET https://localhost:6333  \\\n\n  --header  'api-key: your_secret_api_key_here' \n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient(\n\n    url = \"https://localhost\" ,\n\n    port = 6333 ,\n\n    api_key = \"your_secret_api_key_here\" ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({\n\n  url :   \"http://localhost\" ,\n\n  port:  6333 ,\n\n  apiKey :   \"your_secret_api_key_here\" ,\n\n});\n\n```\n\n```\nusing   Qdrant.Client ;\n\n\n\nvar  client =  new  QdrantClient(\n\n   \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n  https:  true ,\n\n  apiKey:  \"<paste-your-api-key-here>\" \n\n);\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"https://xyz-example.eu-central.aws.cloud.qdrant.io:6334\" ) \n\n         .with_api_key( \"<paste-your-api-key-here>\" ) \n\n         .build() ? ; \n\n```\n\n### Read-only API key\n\nIn addition to the regular API key, Qdrant also supports a read-only API key.\nThis key can be used to access read-only operations on the instance.\n\n```\nservice : \n\n   read_only_api_key :   your_secret_read_only_api_key_here \n\n```\n\nOr with the environment variable:\n\n`export   QDRANT__SERVICE__READ_ONLY_API_KEY = your_secret_read_only_api_key_here\n`\n\nBoth API keys can be used simultaneously.\n\n## TLS\n\n *Available as of v1.2.0* \n\nTLS for encrypted connections can be enabled on your Qdrant instance to secure\nconnections.\n\nFirst make sure you have a certificate and private key for TLS, usually in `.pem` format. On your local machine you may use[ mkcert ](https://github.com/FiloSottile/mkcert#readme)to generate a self signed\ncertificate.\n\nTo enable TLS, set the following properties in the Qdrant configuration with the\ncorrect paths and restart:\n\n```\nservice : \n\n   # Enable HTTPS for the REST and gRPC API \n\n   enable_tls :   true \n\n\n\n# TLS configuration. \n\n# Required if either service.enable_tls or cluster.p2p.enable_tls is true. \n\ntls : \n\n   # Server certificate chain file \n\n   cert :   ./tls/cert.pem \n\n\n\n   # Server private key file \n\n   key :   ./tls/key.pem \n\n```\n\nFor internal communication when running cluster mode, TLS can be enabled with:\n\n```\ncluster : \n\n   # Configuration of the inter-cluster communication \n\n   p2p : \n\n     # Use TLS for communication between peers \n\n     enable_tls :   true \n\n```\n\nWith TLS enabled, you must start using HTTPS connections. For example:\n\n`curl -X GET https://localhost:6333\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient(\n\n    url = \"https://localhost\" ,\n\n    port = 6333 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ url :   \"https://localhost\" , port:  6333  });\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"https://localhost:6334\" ).build() ? ; \n\n```\n\nCertificate rotation is enabled with a default refresh time of one hour. This\nreloads certificate files every hour while Qdrant is running. This way changed\ncertificates are picked up when they get updated externally. The refresh time\ncan be tuned by changing the `tls.cert_ttl` setting. You can leave this on, even\nif you don\u2019t plan to update your certificates. Currently this is only supported\nfor the REST API.\n\nOptionally, you can enable client certificate validation on the server against a\nlocal certificate authority. Set the following properties and restart:\n\n```\nservice : \n\n   # Check user HTTPS client certificate against CA file specified in tls config \n\n   verify_https_client_certificate :   false \n\n\n\n# TLS configuration. \n\n# Required if either service.enable_tls or cluster.p2p.enable_tls is true. \n\ntls : \n\n   # Certificate authority certificate file. \n\n   # This certificate will be used to validate the certificates \n\n   # presented by other nodes during inter-cluster communication. \n\n   # \n\n   # If verify_https_client_certificate is true, it will verify \n\n   # HTTPS client certificate \n\n   # \n\n   # Required if cluster.p2p.enable_tls is true. \n\n   ca_cert :   ./tls/cacert.pem \n\n```\n\n##### Table of contents\n\n- [ Authentication ](https://qdrant.tech/documentation/guides/security/#authentication)\n    - [ Read-only API key ](https://qdrant.tech/documentation/guides/security/#read-only-api-key)\n- [ TLS ](https://qdrant.tech/documentation/guides/security/#tls)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/security.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/common-errors/": "# Solving common errors\n\n## Too many files open (OS error 24)\n\nEach collection segment needs some files to be open. At some point you may encounter the following errors in your server log:\n\n`Error: Too many files open (OS error 24)\n`\n\nIn such a case you may need to increase the limit of the open files. It might be done, for example, while you launch the Docker container:\n\n`docker run --ulimit  nofile = 10000:10000 qdrant/qdrant:latest\n`\n\nThe command above will set both soft and hard limits to `10000` .\n\nIf you are not using Docker, the following command will change the limit for the current user session:\n\n`ulimit  -n  10000 \n`\n\nPlease note, the command should be executed before you run Qdrant server.\n\n##### Table of contents\n\n- [ Too many files open (OS error 24) ](https://qdrant.tech/documentation/guides/common-errors/#too-many-files-open-os-error-24)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/common-errors.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/": "# Tutorials\n\nThese tutorials demonstrate different ways you can build vector search into your applications.\n\n| Tutorial | Description | Stack |\n|---|---|---|\n| [ Configure Optimal Use ](../tutorials/optimize/) | Configure Qdrant collections for best resource use. | Qdrant |\n| [ Separate Partitions ](../tutorials/multiple-partitions/) | Serve vectors for many independent users. | Qdrant |\n| [ Bulk Upload Vectors ](../tutorials/bulk-upload/) | Upload a large scale dataset. | Qdrant |\n| [ Create Dataset Snapshots ](../tutorials/create-snapshot/) | Turn a dataset into a snapshot by exporting it from a collection. | Qdrant |\n| [ Semantic Search for Beginners ](../tutorials/search-beginners/) | Create a simple search engine locally in minutes. | Qdrant |\n| [ Simple Neural Search ](../tutorials/neural-search/) | Build and deploy a neural search that browses startup data. | Qdrant, BERT, FastAPI |\n| [ Aleph Alpha Search ](../tutorials/aleph-alpha-search/) | Build a multimodal search that combines text and image data. | Qdrant, Aleph Alpha |\n| [ Mighty Semantic Search ](../tutorials/mighty/) | Build a simple semantic search with an on-demand NLP service. | Qdrant, Mighty |\n| [ Asynchronous API ](../tutorials/async-api/) | Communicate with Qdrant server asynchronously with Python SDK. | Qdrant, Python |\n| [ Multitenancy with LlamaIndex ](../tutorials/llama-index-multitenancy/) | Handle data coming from multiple users in LlamaIndex. | Qdrant, Python, LlamaIndex |\n| [ Troubleshooting ](../tutorials/common-errors/) | Solutions to common errors and fixes | Qdrant |\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/search-beginners/": "# Semantic Search for Beginners\n\n| Time: 5 - 15 min | Level: Beginner |  |  |\n|---|---|---|---|\n\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/AASiqmtKo54)\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/AASiqmtKo54)\n\n## Overview\n\nIf you are new to vector databases, this tutorial is for you. In 5 minutes you will build a semantic search engine for science fiction books. After you set it up, you will ask the engine about an impending alien threat. Your creation will recommend books as preparation for a potential space attack.\n\nBefore you begin, you need to have a[ recent version of Python ](https://www.python.org/downloads/)installed. If you don\u2019t know how to run this code in a virtual environment, follow Python documentation for[ Creating Virtual Environments ](https://docs.python.org/3/tutorial/venv.html#creating-virtual-environments)first.\n\nThis tutorial assumes you\u2019re in the bash shell. Use the Python documentation to activate a virtual environment, with commands such as:\n\n`source  tutorial-env/bin/activate\n`\n\n## 1. Installation\n\nYou need to process your data so that the search engine can work with it. The[ Sentence Transformers ](https://www.sbert.net/)framework gives you access to common Large Language Models that turn raw data into embeddings.\n\n`pip install -U sentence-transformers\n`\n\nOnce encoded, this data needs to be kept somewhere. Qdrant lets you store data as embeddings. You can also use Qdrant to run search queries against this data. This means that you can ask the engine to give you relevant answers that go way beyond keyword matching.\n\n`pip install qdrant-client\n`\n\n### Import the models\n\nOnce the two main frameworks are defined, you need to specify the exact models this engine will use. Before you do, activate the Python prompt ( `>>>` ) with the `python` command.\n\n```\nfrom   qdrant_client   import  models, QdrantClient\n\nfrom   sentence_transformers   import  SentenceTransformer\n\n```\n\nThe[ Sentence Transformers ](https://www.sbert.net/)framework contains many embedding models. However,[ all-MiniLM-L6-v2 ](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)is the fastest encoder for this tutorial.\n\n`encoder  =  SentenceTransformer( \"all-MiniLM-L6-v2\" )\n`\n\n## 2. Add the dataset\n\n[ all-MiniLM-L6-v2 ](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)will encode the data you provide. Here you will list all the science fiction books in your library. Each book has metadata, a name, author, publication year and a short description.\n\n```\ndocuments  =  [\n\n    {\n\n         \"name\" :  \"The Time Machine\" ,\n\n         \"description\" :  \"A man travels through time and witnesses the evolution of humanity.\" ,\n\n         \"author\" :  \"H.G. Wells\" ,\n\n         \"year\" :  1895 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Ender's Game\" ,\n\n         \"description\" :  \"A young boy is trained to become a military leader in a war against an alien race.\" ,\n\n         \"author\" :  \"Orson Scott Card\" ,\n\n         \"year\" :  1985 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Brave New World\" ,\n\n         \"description\" :  \"A dystopian society where people are genetically engineered and conditioned to conform to a strict social hierarchy.\" ,\n\n         \"author\" :  \"Aldous Huxley\" ,\n\n         \"year\" :  1932 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Hitchhiker's Guide to the Galaxy\" ,\n\n         \"description\" :  \"A comedic science fiction series following the misadventures of an unwitting human and his alien friend.\" ,\n\n         \"author\" :  \"Douglas Adams\" ,\n\n         \"year\" :  1979 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Dune\" ,\n\n         \"description\" :  \"A desert planet is the site of political intrigue and power struggles.\" ,\n\n         \"author\" :  \"Frank Herbert\" ,\n\n         \"year\" :  1965 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Foundation\" ,\n\n         \"description\" :  \"A mathematician develops a science to predict the future of humanity and works to save civilization from collapse.\" ,\n\n         \"author\" :  \"Isaac Asimov\" ,\n\n         \"year\" :  1951 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Snow Crash\" ,\n\n         \"description\" :  \"A futuristic world where the internet has evolved into a virtual reality metaverse.\" ,\n\n         \"author\" :  \"Neal Stephenson\" ,\n\n         \"year\" :  1992 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Neuromancer\" ,\n\n         \"description\" :  \"A hacker is hired to pull off a near-impossible hack and gets pulled into a web of intrigue.\" ,\n\n         \"author\" :  \"William Gibson\" ,\n\n         \"year\" :  1984 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The War of the Worlds\" ,\n\n         \"description\" :  \"A Martian invasion of Earth throws humanity into chaos.\" ,\n\n         \"author\" :  \"H.G. Wells\" ,\n\n         \"year\" :  1898 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Hunger Games\" ,\n\n         \"description\" :  \"A dystopian society where teenagers are forced to fight to the death in a televised spectacle.\" ,\n\n         \"author\" :  \"Suzanne Collins\" ,\n\n         \"year\" :  2008 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Andromeda Strain\" ,\n\n         \"description\" :  \"A deadly virus from outer space threatens to wipe out humanity.\" ,\n\n         \"author\" :  \"Michael Crichton\" ,\n\n         \"year\" :  1969 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Left Hand of Darkness\" ,\n\n         \"description\" :  \"A human ambassador is sent to a planet where the inhabitants are genderless and can change gender at will.\" ,\n\n         \"author\" :  \"Ursula K. Le Guin\" ,\n\n         \"year\" :  1969 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Three-Body Problem\" ,\n\n         \"description\" :  \"Humans encounter an alien civilization that lives in a dying system.\" ,\n\n         \"author\" :  \"Liu Cixin\" ,\n\n         \"year\" :  2008 ,\n\n    },\n\n]\n\n```\n\n## 3. Define storage location\n\nYou need to tell Qdrant where to store embeddings. This is a basic demo, so your local computer will use its memory as temporary storage.\n\n`qdrant  =  QdrantClient( \":memory:\" )\n`\n\n## 4. Create a collection\n\nAll data in Qdrant is organized by collections. In this case, you are storing books, so we are calling it `my_books` .\n\n```\nqdrant . recreate_collection(\n\n    collection_name = \"my_books\" ,\n\n    vectors_config = models . VectorParams(\n\n        size = encoder . get_sentence_embedding_dimension(),   # Vector size is defined by used model \n\n        distance = models . Distance . COSINE,\n\n    ),\n\n)\n\n```\n\n- Use `recreate_collection` if you are experimenting and running the script several times. This function will first try to remove an existing collection with the same name.\n- The `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. 384 is the encoder output dimensionality. You can also use model.get_sentence_embedding_dimension() to get the dimensionality of the model you are using.\n- The `distance` parameter lets you specify the function used to measure the distance between two points.\n\n\nUse `recreate_collection` if you are experimenting and running the script several times. This function will first try to remove an existing collection with the same name.\n\nThe `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. 384 is the encoder output dimensionality. You can also use model.get_sentence_embedding_dimension() to get the dimensionality of the model you are using.\n\nThe `distance` parameter lets you specify the function used to measure the distance between two points.\n\n## 5. Upload data to collection\n\nTell the database to upload `documents` to the `my_books` collection. This will give each record an id and a payload. The payload is just the metadata from the dataset.\n\n```\nqdrant . upload_records(\n\n    collection_name = \"my_books\" ,\n\n    records = [\n\n        models . Record(\n\n             id = idx, vector = encoder . encode(doc[ \"description\" ]) . tolist(), payload = doc\n\n        )\n\n         for  idx, doc  in   enumerate (documents)\n\n    ],\n\n)\n\n```\n\n## 6. Ask the engine a question\n\nNow that the data is stored in Qdrant, you can ask it questions and receive semantically relevant results.\n\n```\nhits  =  qdrant . search(\n\n    collection_name = \"my_books\" ,\n\n    query_vector = encoder . encode( \"alien invasion\" ) . tolist(),\n\n    limit = 3 ,\n\n)\n\nfor  hit  in  hits:\n\n     print (hit . payload,  \"score:\" , hit . score)\n\n```\n\n **Response:** \n\nThe search engine shows three of the most likely responses that have to do with the alien invasion. Each of the responses is assigned a score to show how close the response is to the original inquiry.\n\n```\n{'name': 'The War of the Worlds', 'description': 'A Martian invasion of Earth throws humanity into chaos.', 'author': 'H.G. Wells', 'year': 1898} score: 0.570093257022374\n\n{'name': \"The Hitchhiker's Guide to the Galaxy\", 'description': 'A comedic science fiction series following the misadventures of an unwitting human and his alien friend.', 'author': 'Douglas Adams', 'year': 1979} score: 0.5040468703143637\n\n{'name': 'The Three-Body Problem', 'description': 'Humans encounter an alien civilization that lives in a dying system.', 'author': 'Liu Cixin', 'year': 2008} score: 0.45902943411768216\n\n```\n\n### Narrow down the query\n\nHow about the most recent book from the early 2000s?\n\n```\nhits  =  qdrant . search(\n\n    collection_name = \"my_books\" ,\n\n    query_vector = encoder . encode( \"alien invasion\" ) . tolist(),\n\n    query_filter = models . Filter(\n\n        must = [models . FieldCondition(key = \"year\" ,  range = models . Range(gte = 2000 ))]\n\n    ),\n\n    limit = 1 ,\n\n)\n\nfor  hit  in  hits:\n\n     print (hit . payload,  \"score:\" , hit . score)\n\n```\n\n **Response:** \n\nThe query has been narrowed down to one result from 2008.\n\n`{'name': 'The Three-Body Problem', 'description': 'Humans encounter an alien civilization that lives in a dying system.', 'author': 'Liu Cixin', 'year': 2008} score: 0.45902943411768216\n`\n\n## Next Steps\n\nCongratulations, you have just created your very first search engine! Trust us, the rest of Qdrant is not that complicated, either. For your next tutorial you should try building an actual[ Neural Search Service with a complete API and a dataset ](../../tutorials/neural-search/).\n\n## Return to the bash shell\n\nTo return to the bash prompt:\n\n1. Press Ctrl+D to exit the Python prompt ( `>>>` ).\n2. Enter the `deactivate` command to deactivate the virtual environment.\n\n\n##### Table of contents\n\n- [ Overview ](https://qdrant.tech/documentation/tutorials/search-beginners/#overview)\n- [ 1. Installation ](https://qdrant.tech/documentation/tutorials/search-beginners/#1-installation)\n    - [ Import the models ](https://qdrant.tech/documentation/tutorials/search-beginners/#import-the-models)\n- [ 2. Add the dataset ](https://qdrant.tech/documentation/tutorials/search-beginners/#2-add-the-dataset)\n- [ 3. Define storage location ](https://qdrant.tech/documentation/tutorials/search-beginners/#3-define-storage-location)\n- [ 4. Create a collection ](https://qdrant.tech/documentation/tutorials/search-beginners/#4-create-a-collection)\n- [ 5. Upload data to collection ](https://qdrant.tech/documentation/tutorials/search-beginners/#5-upload-data-to-collection)\n- [ 6. Ask the engine a question ](https://qdrant.tech/documentation/tutorials/search-beginners/#6--ask-the-engine-a-question)\n    - [ Narrow down the query ](https://qdrant.tech/documentation/tutorials/search-beginners/#narrow-down-the-query)\n- [ Next Steps ](https://qdrant.tech/documentation/tutorials/search-beginners/#next-steps)\n- [ Return to the bash shell ](https://qdrant.tech/documentation/tutorials/search-beginners/#return-to-the-bash-shell)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/search-beginners.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/neural-search/": "# Create a Simple Neural Search Service\n\n| Time: 30 min | Level: Beginner | Output: GitHub |  |\n|---|---|---|---|\n\n\nImage: [ Open In Colab ](https://colab.research.google.com/assets/colab-badge.svg)\n\nThis tutorial shows you how to build and deploy your own neural search service to look through descriptions of companies from[ startups-list.com ](https://www.startups-list.com/)and pick the most similar ones to your query. The website contains the company names, descriptions, locations, and a picture for each entry.\n\nA neural search service uses artificial neural networks to improve the accuracy and relevance of search results. Besides offering simple keyword results, this system can retrieve results by meaning. It can understand and interpret complex search queries and provide more contextually relevant output, effectively enhancing the user\u2019s search experience.\n\n## Workflow\n\nTo create a neural search service, you will need to transform your raw data and then create a search function to manipulate it. First, you will 1) download and prepare a sample dataset using a modified version of the BERT ML model. Then, you will 2) load the data into Qdrant, 3) create a neural search API and 4) serve it using FastAPI.\n\nImage: [ Neural Search Workflow ](https://qdrant.tech/docs/workflow-neural-search.png)\n\nImage: [ Neural Search Workflow ](https://qdrant.tech/docs/workflow-neural-search.png)\n\n **Note** : The code for this tutorial can be found here: |[ Step 1: Data Preparation Process ](https://colab.research.google.com/drive/1kPktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing)|[ Step 2: Full Code for Neural Search ](https://github.com/qdrant/qdrant_demo/tree/sentense-transformers). |\n\n## Prerequisites\n\nTo complete this tutorial, you will need:\n\n- Docker - The easiest way to use Qdrant is to run a pre-built Docker image.\n- [ Raw parsed data ](https://storage.googleapis.com/generall-shared-data/startups_demo.json)from startups-list.com.\n- Python version >=3.8\n\n\n## Prepare sample dataset\n\nTo conduct a neural search on startup descriptions, you must first encode the description data into vectors. To process text, you can use a pre-trained models like[ BERT ](https://en.wikipedia.org/wiki/BERT_(language_model))or sentence transformers. The[ sentence-transformers ](https://github.com/UKPLab/sentence-transformers)library lets you conveniently download and use many pre-trained models, such as DistilBERT, MPNet, etc.\n\n1. First you need to download the dataset.\n\n\n`wget https://storage.googleapis.com/generall-shared-data/startups_demo.json\n`\n\n1. Install the SentenceTransformer library as well as other relevant packages.\n\n\n`pip install sentence-transformers numpy pandas tqdm\n`\n\n1. Import all relevant models.\n\n\n```\nfrom   sentence_transformers   import  SentenceTransformer\n\nimport   numpy   as   np \n\nimport   json \n\nimport   pandas   as   pd \n\nfrom   tqdm.notebook   import  tqdm\n\n```\n\nYou will be using a pre-trained model called `all-MiniLM-L6-v2` .\nThis is a performance-optimized sentence embedding model and you can read more about it and other available models[ here ](https://www.sbert.net/docs/pretrained_models.html).\n\n1. Download and create a pre-trained sentence encoder.\n\n\n```\nmodel  =  SentenceTransformer(\n\n     \"all-MiniLM-L6-v2\" , device = \"cuda\" \n\n)   # or device=\"cpu\" if you don't have a GPU \n\n```\n\n1. Read the raw data file.\n\n\n`df  =  pd . read_json( \"./startups_demo.json\" , lines = True )\n`\n\n1. Encode all startup descriptions to create an embedding vector for each. Internally, the `encode` function will split the input into batches, which will significantly speed up the process.\n\n\n```\nvectors  =  model . encode(\n\n    [row . alt  +   \". \"   +  row . description  for  row  in  df . itertuples()],\n\n    show_progress_bar = True ,\n\n)\n\n```\n\nAll of the descriptions are now converted into vectors. There are 40474 vectors of 384 dimensions. The output layer of the model has this dimension\n\n```\nvectors . shape\n\n# > (40474, 384) \n\n```\n\n1. Download the saved vectors into a new file named `startup_vectors.npy`\n\n\n`np . save( \"startup_vectors.npy\" , vectors, allow_pickle = False )\n`\n\n## Run Qdrant in Docker\n\nNext, you need to manage all of your data using a vector engine. Qdrant lets you store, update or delete created vectors. Most importantly, it lets you search for the nearest vectors via a convenient API.\n\n **Note:** Before you begin, create a project directory and a virtual python environment in it.\n\n1. Download the Qdrant image from DockerHub.\n\n\n`docker pull qdrant/qdrant\n`\n\n1. Start Qdrant inside of Docker.\n\n\n```\ndocker run -p 6333:6333  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage  \\\n\n    qdrant/qdrant\n\n```\n\nYou should see output like this\n\n```\n...\n\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting 12 workers\n\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting \"actix-web-service-0.0.0.0:6333\" service on 0.0.0.0:6333\n\n```\n\nTest the service by going to[ http://localhost:6333/ ](http://localhost:6333/). You should see the Qdrant version info in your browser.\n\nAll data uploaded to Qdrant is saved inside the `./qdrant_storage` directory and will be persisted even if you recreate the container.\n\n## Upload data to Qdrant\n\n1. Install the official Python client to best interact with Qdrant.\n\n\n`pip install qdrant-client\n`\n\nAt this point, you should have startup records in the `startups_demo.json` file, encoded vectors in `startup_vectors.npy` and Qdrant running on a local machine.\n\nNow you need to write a script to upload all startup data and vectors into the search engine.\n\n1. Create a client object for Qdrant.\n\n\n```\n# Import client library \n\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.models   import  VectorParams, Distance\n\n\n\nqdrant_client  =  QdrantClient( \"http://localhost:6333\" )\n\n```\n\n1. Related vectors need to be added to a collection. Create a new collection for your startup vectors.\n\n\n```\nqdrant_client . recreate_collection(\n\n    collection_name = \"startups\" ,\n\n    vectors_config = VectorParams(size = 384 , distance = Distance . COSINE),\n\n)\n\n```\n\n- Use `recreate_collection` if you are experimenting and running the script several times. This function will first try to remove an existing collection with the same name.\n- The `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. `384` is the encoder output dimensionality. You can also use `model.get_sentence_embedding_dimension()` to get the dimensionality of the model you are using.\n- The `distance` parameter lets you specify the function used to measure the distance between two points.\n\n\nUse `recreate_collection` if you are experimenting and running the script several times. This function will first try to remove an existing collection with the same name.\n\nThe `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. `384` is the encoder output dimensionality. You can also use `model.get_sentence_embedding_dimension()` to get the dimensionality of the model you are using.\n\nThe `distance` parameter lets you specify the function used to measure the distance between two points.\n\n1. Create an iterator over the startup data and vectors.\n\n\nThe Qdrant client library defines a special function that allows you to load datasets into the service.\nHowever, since there may be too much data to fit a single computer memory, the function takes an iterator over the data as input.\n\n```\nfd  =   open ( \"./startups_demo.json\" )\n\n\n\n# payload is now an iterator over startup data \n\npayload  =   map (json . loads, fd)\n\n\n\n# Load all vectors into memory, numpy array works as iterable for itself. \n\n# Other option would be to use Mmap, if you don't want to load all data into RAM \n\nvectors  =  np . load( \"./startup_vectors.npy\" )\n\n```\n\n1. Upload the data\n\n\n```\nqdrant_client . upload_collection(\n\n    collection_name = \"startups\" ,\n\n    vectors = vectors,\n\n    payload = payload,\n\n    ids = None ,   # Vector ids will be assigned automatically \n\n    batch_size = 256 ,   # How many vectors will be uploaded in a single request? \n\n)\n\n```\n\nVectors are now uploaded to Qdrant.\n\n## Build the search API\n\nNow that all the preparations are complete, let\u2019s start building a neural search class.\n\nIn order to process incoming requests, neural search will need 2 things: 1) a model to convert the query into a vector and 2) the Qdrant client to perform search queries.\n\n1. Create a file named `neural_searcher.py` and specify the following.\n\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   sentence_transformers   import  SentenceTransformer\n\n\n\n\n\nclass   NeuralSearcher :\n\n     def  __init__(self, collection_name):\n\n        self . collection_name  =  collection_name\n\n         # Initialize encoder model \n\n        self . model  =  SentenceTransformer( \"all-MiniLM-L6-v2\" , device = \"cpu\" )\n\n         # initialize Qdrant client \n\n        self . qdrant_client  =  QdrantClient( \"http://localhost:6333\" )\n\n```\n\n1. Write the search function.\n\n\n```\ndef   search (self, text:  str ):\n\n         # Convert text query into vector \n\n        vector  =  self . model . encode(text) . tolist()\n\n\n\n         # Use `vector` for search for closest vectors in the collection \n\n        search_result  =  self . qdrant_client . search(\n\n            collection_name = self . collection_name,\n\n            query_vector = vector,\n\n            query_filter = None ,   # If you don't want any filters for now \n\n            limit = 5    # 5 the most closest results is enough \n\n        )\n\n         # `search_result` contains found vector ids with similarity scores along with the stored payload \n\n         # In this function you are interested in payload only \n\n        payloads  =  [hit . payload  for  hit  in  search_result]\n\n         return  payloads\n\n```\n\n1. Add search filters.\n\n\nWith Qdrant it is also feasible to add some conditions to the search.\nFor example, if you wanted to search for startups in a certain city, the search query could look like this:\n\n```\nfrom   qdrant_client.models   import  Filter\n\n\n\n     ... \n\n\n\n    city_of_interest  =   \"Berlin\" \n\n\n\n     # Define a filter for cities \n\n    city_filter  =  Filter( ** {\n\n         \"must\" : [{\n\n             \"key\" :  \"city\" ,  # Store city information in a field of the same name  \n\n             \"match\" : {  # This condition checks if payload field has the requested value \n\n                 \"value\" : city_of_interest\n\n            }\n\n        }]\n\n    })\n\n\n\n    search_result  =  self . qdrant_client . search(\n\n        collection_name = self . collection_name,\n\n        query_vector = vector,\n\n        query_filter = city_filter,\n\n        limit = 5 \n\n    )\n\n     ... \n\n```\n\nYou have now created a class for neural search queries. Now wrap it up into a service.\n\n## Deploy the search with FastAPI\n\nTo build the service you will use the FastAPI framework.\n\n1. Install FastAPI.\n\n\nTo install it, use the command\n\n`pip install fastapi uvicorn\n`\n\n1. Implement the service.\n\n\nCreate a file named `service.py` and specify the following.\n\nThe service will have only one API endpoint and will look like this:\n\n```\nfrom   fastapi   import  FastAPI\n\n\n\n# The file where NeuralSearcher is stored \n\nfrom   neural_searcher   import  NeuralSearcher\n\n\n\napp  =  FastAPI()\n\n\n\n# Create a neural searcher instance \n\nneural_searcher  =  NeuralSearcher(collection_name = 'startups' )\n\n\n\n@app . get( \"/api/search\" )\n\ndef   search_startup (q:  str ):\n\n     return  {\n\n         \"result\" : neural_searcher . search(text = q)\n\n    }\n\n\n\n\n\nif  __name__  ==   \"__main__\" :\n\n     import   uvicorn \n\n    uvicorn . run(app, host = \"0.0.0.0\" , port = 8000 )\n\n```\n\n1. Run the service.\n\n\n`python service.py\n`\n\n1. Open your browser at[ http://localhost:8000/docs ](http://localhost:8000/docs).\n\n\nYou should be able to see a debug interface for your service.\n\nImage: [ FastAPI Swagger interface ](https://qdrant.tech/docs/fastapi_neural_search.png)\n\nImage: [ FastAPI Swagger interface ](https://qdrant.tech/docs/fastapi_neural_search.png)\n\nFeel free to play around with it, make queries regarding the companies in our corpus, and check out the results.\n\n## Next steps\n\nThe code from this tutorial has been used to develop a[ live online demo ](https://qdrant.to/semantic-search-demo).\nYou can try it to get an intuition for cases when the neural search is useful.\nThe demo contains a switch that selects between neural and full-text searches.\nYou can turn the neural search on and off to compare your result with a regular full-text search.\n\n **Note** : The code for this tutorial can be found here: |[ Step 1: Data Preparation Process ](https://colab.research.google.com/drive/1kPktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing)|[ Step 2: Full Code for Neural Search ](https://github.com/qdrant/qdrant_demo/tree/sentense-transformers). |\n\nJoin our[ Discord community ](https://qdrant.to/discord), where we talk about vector search and similarity learning, publish other examples of neural networks and neural search applications.\n\n##### Table of contents\n\n- [ Workflow ](https://qdrant.tech/documentation/tutorials/neural-search/#workflow)\n- [ Prerequisites ](https://qdrant.tech/documentation/tutorials/neural-search/#prerequisites)\n- [ Prepare sample dataset ](https://qdrant.tech/documentation/tutorials/neural-search/#prepare-sample-dataset)\n- [ Run Qdrant in Docker ](https://qdrant.tech/documentation/tutorials/neural-search/#run-qdrant-in-docker)\n- [ Upload data to Qdrant ](https://qdrant.tech/documentation/tutorials/neural-search/#upload-data-to-qdrant)\n- [ Build the search API ](https://qdrant.tech/documentation/tutorials/neural-search/#build-the-search-api)\n- [ Deploy the search with FastAPI ](https://qdrant.tech/documentation/tutorials/neural-search/#deploy-the-search-with-fastapi)\n- [ Next steps ](https://qdrant.tech/documentation/tutorials/neural-search/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/neural-search.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/neural-search-fastembed/": "# Create a Neural Search Service with Fastembed\n\n| Time: 20 min | Level: Beginner | Output: GitHub |  |\n|---|---|---|---|\n\n\nThis tutorial shows you how to build and deploy your own neural search service to look through descriptions of companies from[ startups-list.com ](https://www.startups-list.com/)and pick the most similar ones to your query.\nThe website contains the company names, descriptions, locations, and a picture for each entry.\n\nAlternatively, you can use datasources such as[ Crunchbase ](https://www.crunchbase.com/), but that would require obtaining an API key from them.\n\nOur neural search service will use[ Fastembed ](https://github.com/qdrant/fastembed)package to generate embeddings of text descriptions and[ FastAPI ](https://fastapi.tiangolo.com/)to serve the search API.\nFastembed natively integrates with Qdrant client, so you can easily upload the data into Qdrant and perform search queries.\n\n## Workflow\n\nTo create a neural search service, you will need to transform your raw data and then create a search function to manipulate it.\nFirst, you will 1) download and prepare a sample dataset using a modified version of the BERT ML model. Then, you will 2) load the data into Qdrant, 3) create a neural search API and 4) serve it using FastAPI.\n\nImage: [ Neural Search Workflow ](https://qdrant.tech/docs/workflow-neural-search.png)\n\nImage: [ Neural Search Workflow ](https://qdrant.tech/docs/workflow-neural-search.png)\n\n **Note** : The code for this tutorial can be found here:[ Step 2: Full Code for Neural Search ](https://github.com/qdrant/qdrant_demo/).\n\n## Prerequisites\n\nTo complete this tutorial, you will need:\n\n- Docker - The easiest way to use Qdrant is to run a pre-built Docker image.\n- [ Raw parsed data ](https://storage.googleapis.com/generall-shared-data/startups_demo.json)from startups-list.com.\n- Python version >=3.8\n\n\n## Prepare sample dataset\n\nTo conduct a neural search on startup descriptions, you must first encode the description data into vectors.\nFastembed integration into qdrant client combines encoding and uploading into a single step.\n\nIt also takes care of batching and parallelization, so you don\u2019t have to worry about it.\n\nLet\u2019s start by downloading the data and installing the necessary packages.\n\n1. First you need to download the dataset.\n\n\n`wget https://storage.googleapis.com/generall-shared-data/startups_demo.json\n`\n\n## Run Qdrant in Docker\n\nNext, you need to manage all of your data using a vector engine. Qdrant lets you store, update or delete created vectors. Most importantly, it lets you search for the nearest vectors via a convenient API.\n\n **Note:** Before you begin, create a project directory and a virtual python environment in it.\n\n1. Download the Qdrant image from DockerHub.\n\n\n`docker pull qdrant/qdrant\n`\n\n1. Start Qdrant inside of Docker.\n\n\n```\ndocker run -p 6333:6333  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage  \\\n\n    qdrant/qdrant\n\n```\n\nYou should see output like this\n\n```\n...\n\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting 12 workers\n\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting \"actix-web-service-0.0.0.0:6333\" service on 0.0.0.0:6333\n\n```\n\nTest the service by going to[ http://localhost:6333/ ](http://localhost:6333/). You should see the Qdrant version info in your browser.\n\nAll data uploaded to Qdrant is saved inside the `./qdrant_storage` directory and will be persisted even if you recreate the container.\n\n## Upload data to Qdrant\n\n1. Install the official Python client to best interact with Qdrant.\n\n\n`pip install qdrant-client [ fastembed ] \n`\n\nNote, that you need to install the `fastembed` extra to enable Fastembed integration.\nAt this point, you should have startup records in the `startups_demo.json` file and Qdrant running on a local machine.\n\nNow you need to write a script to upload all startup data and vectors into the search engine.\n\n1. Create a client object for Qdrant.\n\n\n```\n# Import client library \n\nfrom   qdrant_client   import  QdrantClient\n\n\n\nqdrant_client  =  QdrantClient( \"http://localhost:6333\" )\n\n```\n\n1. Select model to encode your data.\n\n\nYou will be using a pre-trained model called `sentence-transformers/all-MiniLM-L6-v2` .\n\n`qdrant_client . set_model( \"sentence-transformers/all-MiniLM-L6-v2\" )\n`\n\n1. Related vectors need to be added to a collection. Create a new collection for your startup vectors.\n\n\n```\nqdrant_client . recreate_collection(\n\n    collection_name = \"startups\" ,\n\n    vectors_config = qdrant_client . get_fastembed_vector_params(),\n\n)\n\n```\n\nNote, that we use `get_fastembed_vector_params` to get the vector size and distance function from the model.\nThis method automatically generates configuration, compatible with the model you are using.\nWithout fastembed integration, you would need to specify the vector size and distance function manually. Read more about it[ here ](https://qdrant.tech/documentation/tutorials/neural-search).\n\nAdditionally, you can specify extended configuration for our vectors, like `quantization_config` or `hnsw_config` .\n\n1. Read data from the file.\n\n\n```\npayload_path  =  os . path . join(DATA_DIR,  \"startups_demo.json\" )\n\nmetadata  =  []\n\ndocuments  =  []\n\n\n\nwith   open (payload_path)  as  fd:\n\n     for  line  in  fd:\n\n        obj  =  json . loads(line)\n\n        documents . append(obj . pop( \"description\" ))\n\n        metadata . append(obj)\n\n```\n\nIn this block of code, we read data we read data from `startups_demo.json` file and split it into 2 lists: `documents` and `metadata` .\nDocuments are the raw text descriptions of startups. Metadata is the payload associated with each startup, such as the name, location, and picture.\nWe will use `documents` to encode the data into vectors.\n\n1. Encode and upload data.\n\n\n```\nclient . add(\n\n    collection_name = \"startups\" ,\n\n    documents = documents,\n\n    metadata = metadata,\n\n    parallel = 0 ,   # Use all available CPU cores to encode data \n\n)\n\n```\n\nThe `add` method will encode all documents and upload them to Qdrant.\nThis is one of two fastembed-specific methods, that combines encoding and uploading into a single step.\n\nThe `parallel` parameter controls the number of CPU cores used to encode data.\n\nAdditionally, you can specify ids for each document, if you want to use them later to update or delete documents.\nIf you don\u2019t specify ids, they will be generated automatically and returned as a result of the `add` method.\n\nYou can monitor the progress of the encoding by passing tqdm progress bar to the `add` method.\n\n```\nfrom   tqdm   import  tqdm\n\n\n\nclient . add(\n\n    collection_name = \"startups\" ,\n\n    documents = documents,\n\n    metadata = metadata,\n\n    ids = tqdm( range ( len (documents))),\n\n)\n\n```\n\n **Note** : See the full code for this step[ here ](https://github.com/qdrant/qdrant_demo/blob/master/qdrant_demo/init_collection_startups.py).\n\n## Build the search API\n\nNow that all the preparations are complete, let\u2019s start building a neural search class.\n\nIn order to process incoming requests, neural search will need 2 things: 1) a model to convert the query into a vector and 2) the Qdrant client to perform search queries.\nFastembed integration into qdrant client combines encoding and uploading into a single method call.\n\n1. Create a file named `neural_searcher.py` and specify the following.\n\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\n\n\nclass   NeuralSearcher :\n\n     def  __init__(self, collection_name):\n\n        self . collection_name  =  collection_name\n\n         # initialize Qdrant client \n\n        self . qdrant_client  =  QdrantClient( \"http://localhost:6333\" )\n\n        self . qdrant_client . set_model( \"sentence-transformers/all-MiniLM-L6-v2\" )\n\n```\n\n1. Write the search function.\n\n\n```\ndef   search (self, text:  str ):\n\n        search_result  =  self . qdrant_client . query(\n\n            collection_name = self . collection_name,\n\n            query_text = text,\n\n            query_filter = None ,   # If you don't want any filters for now \n\n            limit = 5    # 5 the most closest results is enough \n\n        )\n\n         # `search_result` contains found vector ids with similarity scores along with the stored payload \n\n         # In this function you are interested in payload only \n\n        metadata  =  [hit . metadata  for  hit  in  search_result]\n\n         return  metadata\n\n```\n\n1. Add search filters.\n\n\nWith Qdrant it is also feasible to add some conditions to the search.\nFor example, if you wanted to search for startups in a certain city, the search query could look like this:\n\n```\nfrom   qdrant_client.models   import  Filter\n\n\n\n     ... \n\n\n\n    city_of_interest  =   \"Berlin\" \n\n\n\n     # Define a filter for cities \n\n    city_filter  =  Filter( ** {\n\n         \"must\" : [{\n\n             \"key\" :  \"city\" ,  # Store city information in a field of the same name  \n\n             \"match\" : {  # This condition checks if payload field has the requested value \n\n                 \"value\" :  \"city_of_interest\" \n\n            }\n\n        }]\n\n    })\n\n\n\n    search_result  =  self . qdrant_client . query(\n\n        collection_name = self . collection_name,\n\n        query_text = text,\n\n        query_filter = city_filter,\n\n        limit = 5 \n\n    )\n\n     ... \n\n```\n\nYou have now created a class for neural search queries. Now wrap it up into a service.\n\n## Deploy the search with FastAPI\n\nTo build the service you will use the FastAPI framework.\n\n1. Install FastAPI.\n\n\nTo install it, use the command\n\n`pip install fastapi uvicorn\n`\n\n1. Implement the service.\n\n\nCreate a file named `service.py` and specify the following.\n\nThe service will have only one API endpoint and will look like this:\n\n```\nfrom   fastapi   import  FastAPI\n\n\n\n# The file where NeuralSearcher is stored \n\nfrom   neural_searcher   import  NeuralSearcher\n\n\n\napp  =  FastAPI()\n\n\n\n# Create a neural searcher instance \n\nneural_searcher  =  NeuralSearcher(collection_name = 'startups' )\n\n\n\n@app . get( \"/api/search\" )\n\ndef   search_startup (q:  str ):\n\n     return  {\n\n         \"result\" : neural_searcher . search(text = q)\n\n    }\n\n\n\n\n\nif  __name__  ==   \"__main__\" :\n\n     import   uvicorn \n\n    uvicorn . run(app, host = \"0.0.0.0\" , port = 8000 )\n\n```\n\n1. Run the service.\n\n\n`python service.py\n`\n\n1. Open your browser at[ http://localhost:8000/docs ](http://localhost:8000/docs).\n\n\nYou should be able to see a debug interface for your service.\n\nImage: [ FastAPI Swagger interface ](https://qdrant.tech/docs/fastapi_neural_search.png)\n\nImage: [ FastAPI Swagger interface ](https://qdrant.tech/docs/fastapi_neural_search.png)\n\nFeel free to play around with it, make queries regarding the companies in our corpus, and check out the results.\n\n## Next steps\n\nThe code from this tutorial has been used to develop a[ live online demo ](https://qdrant.to/semantic-search-demo).\nYou can try it to get an intuition for cases when the neural search is useful.\nThe demo contains a switch that selects between neural and full-text searches.\nYou can turn the neural search on and off to compare your result with a regular full-text search.\n\n **Note** : The code for this tutorial can be found here:[ Full Code for Neural Search ](https://github.com/qdrant/qdrant_demo/).\n\nJoin our[ Discord community ](https://qdrant.to/discord), where we talk about vector search and similarity learning, publish other examples of neural networks and neural search applications.\n\n##### Table of contents\n\n- [ Workflow ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#workflow)\n- [ Prerequisites ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#prerequisites)\n- [ Prepare sample dataset ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#prepare-sample-dataset)\n- [ Run Qdrant in Docker ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#run-qdrant-in-docker)\n- [ Upload data to Qdrant ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#upload-data-to-qdrant)\n- [ Build the search API ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#build-the-search-api)\n- [ Deploy the search with FastAPI ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#deploy-the-search-with-fastapi)\n- [ Next steps ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/neural-search-fastembed.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/bulk-upload/": "# Bulk upload a large number of vectors\n\nUploading a large-scale dataset fast might be a challenge, but Qdrant has a few tricks to help you with that.\n\nThe first important detail about data uploading is that the bottleneck is usually located on the client side, not on the server side.\nThis means that if you are uploading a large dataset, you should prefer a high-performance client library.\n\nWe recommend using our[ Rust client library ](https://github.com/qdrant/rust-client)for this purpose, as it is the fastest client library available for Qdrant.\n\nIf you are not using Rust, you might want to consider parallelizing your upload process.\n\n## Disable indexing during upload\n\nIn case you are doing an initial upload of a large dataset, you might want to disable indexing during upload.\nIt will enable to avoid unnecessary indexing of vectors, which will be overwritten by the next batch.\n\nTo disable indexing during upload, set `indexing_threshold` to `0` :\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"optimizers_config\": {\n\n        \"indexing_threshold\": 0\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    optimizers_config = models . OptimizersConfigDiff(\n\n        indexing_threshold = 0 ,\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  optimizers_config :  {\n\n    indexing_threshold:  0 ,\n\n  },\n\n});\n\n```\n\nAfter upload is done, you can enable indexing by setting `indexing_threshold` to a desired value (default is 20000):\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"optimizers_config\": {\n\n        \"indexing_threshold\": 20000\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . update_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    optimizer_config = models . OptimizersConfigDiff(indexing_threshold = 20000 ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.updateCollection( \"{collection_name}\" , {\n\n  optimizers_config :  {\n\n    indexing_threshold:  20000 ,\n\n  },\n\n});\n\n```\n\n## Upload directly to disk\n\nWhen the vectors you upload do not all fit in RAM, you likely want to use[ memmap ](../../concepts/storage/#configuring-memmap-storage)support.\n\nDuring collection[ creation ](../../concepts/collections/#create-collection),\nmemmaps may be enabled on a per-vector basis using the `on_disk` parameter. This\nwill store vector data directly on disk at all times. It is suitable for\ningesting a large amount of data, essential for the billion scale benchmark.\n\nUsing `memmap_threshold_kb` is not recommended in this case. It would require\nthe[ optimizer ](../../concepts/optimizer/)to constantly\ntransform in-memory segments into memmap segments on disk. This process is\nslower, and the optimizer can be a bottleneck when ingesting a large amount of\ndata.\n\nRead more about this in[ Configuring Memmap Storage ](../../concepts/storage/#configuring-memmap-storage).\n\n## Parallel upload into multiple shards\n\nIn Qdrant, each collection is split into shards. Each shard has a separate Write-Ahead-Log (WAL), which is responsible for ordering operations.\nBy creating multiple shards, you can parallelize upload of a large dataset. From 2 to 4 shards per one machine is a reasonable number.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"shard_number\": 2\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    shard_number = 2 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  shard_number:  2 ,\n\n});\n\n```\n\n##### Table of contents\n\n- [ Disable indexing during upload ](https://qdrant.tech/documentation/tutorials/bulk-upload/#disable-indexing-during-upload)\n- [ Upload directly to disk ](https://qdrant.tech/documentation/tutorials/bulk-upload/#upload-directly-to-disk)\n- [ Parallel upload into multiple shards ](https://qdrant.tech/documentation/tutorials/bulk-upload/#parallel-upload-into-multiple-shards)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/bulk-upload.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/async-api/": "# Using Qdrant asynchronously\n\nAsynchronous programming is being broadly adopted in the Python ecosystem. Tools such as FastAPI[ have embraced this new\nparadigm ](https://fastapi.tiangolo.com/async/), but it is also becoming a standard for ML models served as SaaS. For example, the Cohere SDK[ provides an async client ](https://cohere-sdk.readthedocs.io/en/latest/cohere.html#asyncclient)next to its synchronous counterpart.\n\nDatabases are often launched as separate services and are accessed via a network. All the interactions with them are IO-bound and can\nbe performed asynchronously so as not to waste time actively waiting for a server response. In Python, this is achieved by\nusing[ async/await ](https://docs.python.org/3/library/asyncio-task.html)syntax. That lets the interpreter switch to another task\nwhile waiting for a response from the server.\n\n## When to use async API\n\nThere is no need to use async API if the application you are writing will never support multiple users at once (e.g it is a script that runs once per day). However, if you are writing a web service that multiple users will use simultaneously, you shouldn\u2019t be\nblocking the threads of the web server as it limits the number of concurrent requests it can handle. In this case, you should use\nthe async API.\n\nModern web frameworks like[ FastAPI ](https://fastapi.tiangolo.com/)and[ Quart ](https://quart.palletsprojects.com/en/latest/)support\nasync API out of the box. Mixing asynchronous code with an existing synchronous codebase might be a challenge. The `async/await` syntax\ncannot be used in synchronous functions. On the other hand, calling an IO-bound operation synchronously in async code is considered\nan antipattern. Therefore, if you build an async web service, exposed through an[ ASGI ](https://asgi.readthedocs.io/en/latest/)server,\nyou should use the async API for all the interactions with Qdrant.\n\n`asyncio.run`\n\n`asyncio.create_task`\n\n### Using Qdrant asynchronously\n\nThe simplest way of running asynchronous code is to use define `async` function and use the `asyncio.run` in the following way to run it:\n\n```\nfrom   qdrant_client   import  models\n\n\n\nimport   qdrant_client \n\nimport   asyncio \n\n\n\n\n\nasync   def   main ():\n\n    client  =  qdrant_client . AsyncQdrantClient( \"localhost\" )\n\n\n\n     # Create a collection \n\n     await  client . create_collection(\n\n        collection_name = \"my_collection\" ,\n\n        vectors_config = models . VectorParams(size = 4 , distance = models . Distance . COSINE),\n\n    )\n\n\n\n     # Insert a vector \n\n     await  client . upsert(\n\n        collection_name = \"my_collection\" ,\n\n        points = [\n\n            models . PointStruct(\n\n                 id = \"5c56c793-69f3-4fbf-87e6-c4bf54c28c26\" ,\n\n                payload = {\n\n                     \"color\" :  \"red\" ,\n\n                },\n\n                vector = [ 0.9 ,  0.1 ,  0.1 ,  0.5 ],\n\n            ),\n\n        ],\n\n    )\n\n\n\n     # Search for nearest neighbors \n\n    points  =   await  client . search(\n\n        collection_name = \"my_collection\" ,\n\n        query_vector = [ 0.9 ,  0.1 ,  0.1 ,  0.5 ],\n\n        limit = 2 ,\n\n    )\n\n\n\n     # Your async code using AsyncQdrantClient might be put here \n\n     # ... \n\n\n\n\n\nasyncio . run(main())\n\n```\n\nThe `AsyncQdrantClient` provides the same methods as the synchronous counterpart `QdrantClient` . If you already have a synchronous\ncodebase, switching to async API is as simple as replacing `QdrantClient` with `AsyncQdrantClient` and adding `await` before each\nmethod call.\n\n`qdrant-client`\n\n## Supported Python libraries\n\nQdrant integrates with numerous Python libraries. Until recently, only[ Langchain ](https://python.langchain.com)provided async Python API support.\nQdrant is the only vector database with full coverage of async API in Langchain. Their documentation[ describes how to use\nit ](https://python.langchain.com/docs/modules/data_connection/vectorstores/#asynchronous-operations).\n\n##### Table of contents\n\n- [ When to use async API ](https://qdrant.tech/documentation/tutorials/async-api/#when-to-use-async-api)\n    - [ Using Qdrant asynchronously ](https://qdrant.tech/documentation/tutorials/async-api/#using-qdrant-asynchronously-1)\n- [ Supported Python libraries ](https://qdrant.tech/documentation/tutorials/async-api/#supported-python-libraries)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/async-api.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/create-snapshot/": "# Exporting Qdrant collections into snapshots\n\n| Time: 20 min | Level: Beginner |  |  |\n|---|---|---|---|\n\n\nThe best way to export a Qdrant collection is to create a snapshot of it. Then, you may use the snapshot to backup or restore your collection to whichever environment you see fit.\nSnapshots contain vectors with their ids and payloads, as well as internal Qdrant data structures used to keep the search efficient.\n\nThis tutorial will show you how to import the data into a Qdrant collection and create a snapshot from it.\n\nPlease note that the process of importing the data strongly depends on the input data format. All the tips from the[ Bulk Upload Vectors ](https://qdrant.tech/documentation/tutorials/bulk-upload/)tutorial also apply here.\n\n## Prerequisites\n\nThe sample dataset for this tutorial is[ LAION-5B ](https://laion.ai/blog/laion-5b/). We are going to use the first 1000 entries from the subset -[ laion2b-en-vit-l-14-embeddings ](https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings). Since we don\u2019t want to download the whole dataset, we are going to download just the first batch:\n\n- metadata:[ https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings/resolve/main/metadata/metadata_0000.parquet ](https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings/resolve/main/metadata/metadata_0000.parquet)\n- image embeddings:[ https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings/resolve/main/img_emb/img_emb_0000.npy ](https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings/resolve/main/img_emb/img_emb_0000.npy)\n- text embeddings:[ https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings/resolve/main/text_emb/text_emb_0000.npy ](https://huggingface.co/datasets/laion/laion2b-en-vit-l-14-embeddings/resolve/main/text_emb/text_emb_0000.npy)\n\n\n## Initial setup\n\nInstall the required dependencies.\n\n`pip install qdrant-client numpy pandas pyarrow\n`\n\nCreate a subdirectory `data` in your working directory and download all the datasets there.\n\nNext, print the metadata from your dataset to see how it looks:\n\n```\nimport   pandas   as   pd \n\n\n\nmetadata_df  =  pd . read_parquet( \"data/metadata_0000.parquet\" )\n\nprint (metadata_df . iloc[ 0 ] . to_dict())\n\n```\n\nA single row should look like this:\n\n```\n{\n\n   'image_path':   '185120009',  \n\n   'caption':   'Color   version   PULP   FICTION   alternative   poster   art',  \n\n   'NSFW':   'UNLIKELY',  \n\n   'similarity':   0.33966901898384094,  \n\n   'LICENSE':   '?',  \n\n   'url':   'http: //cdn.shopify.com/s/files/1/0282/0804/products/pulp_1024x1024.jpg?v=1474264437', \n\n   'key':   '185120009',  \n\n   'status':   'success',  \n\n   'error_message':   null,  \n\n   'width':   384, \n\n   'height':   512,  \n\n   'original_width':   768,  \n\n   'original_height':   1024,  \n\n   'exif':   '{ \"Image Orientation\" :  \"Horizontal (normal)\" ,  \"Image XResolution\" :  \"100\" ,  \"Image YResolution\" :  \"100\" ,  \"Image ResolutionUnit\" :  \"Pixels/Inch\" ,  \"Image YCbCrPositioning\" :  \"Centered\" ,  \"Image ExifOffset\" :  \"102\" ,  \"EXIF ExifVersion\" :  \"0210\" ,  \"EXIF ComponentsConfiguration\" :  \"YCbCr\" ,  \"EXIF FlashPixVersion\" :  \"0100\" ,  \"EXIF ColorSpace\" :  \"Uncalibrated\" ,  \"EXIF ExifImageWidth\" :  \"768\" ,  \"EXIF ExifImageLength\" :  \"1024\" } ',  \n\n   'md 5 ':   ' 46 c 4 bbab 739 a 2 b 71639 fb 5 a 3 a 4035 b 36 ' \n\n} \n\n```\n\nNow, we can iterate through the rows and their corresponding embeddings to store them into Qdrant. We are not going to import a whole batch,\nbut upload just the first 1000 entries.\n\n```\nimport   numpy   as   np \n\n\n\nimage_embeddings  =  np . load( \"data/img_emb_0000.npy\" )\n\ntext_embeddings  =  np . load( \"data/text_emb_0000.npy\" )\n\n```\n\n## Create a collection\n\nFirst things first, we need to create our collection. We\u2019re not going to play with the configuration of it, but it makes sense do it right now.\nThe configuration is also a part of the collection snapshot.\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\ncollection_name  =   \"LAION-5B\" \n\n\n\nclient  =  QdrantClient( \"localhost\" )\n\nclient . recreate_collection(\n\n    collection_name = collection_name,\n\n    vectors_config = {\n\n         \"image\" : models . VectorParams(\n\n            size = image_embeddings . shape[ 1 ], distance = models . Distance . COSINE\n\n        ),\n\n         \"text\" : models . VectorParams(\n\n            size = text_embeddings . shape[ 1 ], distance = models . Distance . COSINE\n\n        ),\n\n    },\n\n)\n\n```\n\n## Upload the dataset\n\nWhile loaded, it is pretty straightforward to upload the collection from the precomputed embeddings. Calculating the embeddings is usually\na bottleneck of the vector search pipelines, but we are happy to have them in place already.\n\n```\nclient . upload_collection(\n\n    collection_name = collection_name,\n\n    vectors = {\n\n         \"image\" : image_embeddings[: 1000 ],\n\n         \"text\" : image_embeddings[: 1000 ],\n\n    },\n\n    payload = metadata_df . iloc[: 1000 ] . to_dict(orient = \"records\" ),\n\n    batch_size = 64 ,\n\n    parallel = 2 ,\n\n)\n\n```\n\n## Create a snapshot\n\nQdrant exposes HTTP endpoint to request creating a snapshot, but we can also call it with the Python SDK. Creating a snapshot may take a while. If you encounter any timeout, that doesn\u2019t mean the process is not running.\n\n```\nsnapshot_info  =  client . create_snapshot(collection_name = collection_name)\n\nprint (snapshot_info)\n\n```\n\nAs a response, we should see a similar output:\n\n`name = 'LAION-5B-1217055918586176-2023-07-04-11-51-24.snapshot'  creation_time = '2023-07-04T11:51:25'  size = 74202112 \n`\n\n## List all snapshots\n\nYou can always check what are the snapshots available for a particular collection.\n\n```\nsnapshots  =  client . list_snapshots(collection_name = dataset_name)\n\nprint (snapshots)\n\n```\n\nThis endpoint exposes all the snapshots in the same format as before:\n\n```\n[\n\n    SnapshotDescription(\n\n        name = \"LAION-5B-1217055918586176-2023-07-04-11-51-24.snapshot\" ,\n\n        creation_time = \"2023-07-04T11:51:25\" ,\n\n        size = 74202112 ,\n\n    )\n\n]\n\n```\n\nWe can use the same naming convention to create the URL to download it.\n\n## Download the snapshot\n\nWe can now build the URL to the snapshot in the following manner:\n\n`{ QDRANT_URL } /collections/ { collection_name } /snapshots/ { snapshot_name } \n`\n\nIn our case, since we are using a local Docker container, our `collection_name = \"LAION-5B\"` , and `snapshot_name = \"LAION-5B-1217055918586176-2023-07-04-11-51-24.snapshot\"` ,\nthe snapshot might be downloaded using the following URL:\n\n`http://localhost:6333/collections/LAION-5B/snapshots/LAION-5B-1217055918586176-2023-07-04-11-51-24.snapshot\n`\n\n##### Table of contents\n\n- [ Prerequisites ](https://qdrant.tech/documentation/tutorials/create-snapshot/#prerequisites)\n- [ Initial setup ](https://qdrant.tech/documentation/tutorials/create-snapshot/#initial-setup)\n- [ Create a collection ](https://qdrant.tech/documentation/tutorials/create-snapshot/#create-a-collection)\n- [ Upload the dataset ](https://qdrant.tech/documentation/tutorials/create-snapshot/#upload-the-dataset)\n- [ Create a snapshot ](https://qdrant.tech/documentation/tutorials/create-snapshot/#create-a-snapshot)\n- [ List all snapshots ](https://qdrant.tech/documentation/tutorials/create-snapshot/#list-all-snapshots)\n- [ Download the snapshot ](https://qdrant.tech/documentation/tutorials/create-snapshot/#download-the-snapshot)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/create-snapshot.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/aleph-alpha-search/": "# Multimodal Semantic Search with Aleph Alpha\n\n| Time: 30 min | Level: Beginner |  |  |\n|---|---|---|---|\n\n\nThis tutorial shows you how to run a proper multimodal semantic search system with a few lines of code, without the need to annotate the data or train your networks.\n\nIn most cases, semantic search is limited to homogenous data types for both documents and queries (text-text, image-image, audio-audio, etc.). With the recent growth of multimodal architectures, it is now possible to encode different data types into the same latent space. That opens up some great possibilities, as you can finally explore non-textual data, for example visual, with text queries.\n\nIn the past, this would require labelling every image with a description of what it presents. Right now, you can rely on vector embeddings, which can represent all\nthe inputs in the same space.\n\n *Figure 1: Two examples of text-image pairs presenting a similar object, encoded by a multimodal network into the same\n2D latent space. Both texts are examples of English pangrams.\nhttps://deepai.org generated the images with pangrams used as input prompts.* \n\n## Sample dataset\n\nYou will be using[ COCO ](https://cocodataset.org/), a large-scale object detection, segmentation, and captioning dataset. It provides\nvarious splits, 330,000 images in total. For demonstration purposes, this tutorials uses the[ 2017 validation split ](http://images.cocodataset.org/zips/train2017.zip)that contains 5000 images from different\ncategories with total size about 19GB.\n\n`wget http://images.cocodataset.org/zips/train2017.zip`\n\n## Prerequisites\n\nThere is no need to curate your datasets and train the models.[ Aleph Alpha ](https://www.aleph-alpha.com/), already has multimodality and multilinguality already built-in. There is an[ official Python client ](https://github.com/Aleph-Alpha/aleph-alpha-client)that simplifies the integration.\n\nIn order to enable the search capabilities, you need to build the search index to query on. For this example,\nyou are going to vectorize the images and store their embeddings along with the filenames. You can then return the most\nsimilar files for given query.\n\nThere are two things you need to set up before you start:\n\n1. You need to have a Qdrant instance running. If you want to launch it locally,[ Docker is the fastest way to do that ](https://qdrant.tech/documentation/quick_start/#installation).\n2. You need to have a registered[ Aleph Alpha account ](https://app.aleph-alpha.com/).\n3. Upon registration, create an API key (see:[ API Tokens ](https://app.aleph-alpha.com/profile)).\n\n\nNow you can store the Aleph Alpha API key in a variable and choose the model your are going to use.\n\n```\naa_token  =   \"<< your_token >>\" \n\nmodel  =   \"luminous-base\" \n\n```\n\n## Vectorize the dataset\n\nIn this example, images have been extracted and are stored in the `val2017` directory:\n\n```\nfrom   aleph_alpha_client   import  (\n\n    Prompt,\n\n    AsyncClient,\n\n    SemanticEmbeddingRequest,\n\n    SemanticRepresentation,\n\n    Image,\n\n)\n\n\n\nfrom   glob   import  glob\n\n\n\nids, vectors, payloads  =  [], [], []\n\nasync   with  AsyncClient(token = aa_token)  as  client:\n\n     for  i, image_path  in   enumerate (glob( \"./val2017/*.jpg\" )):\n\n         # Convert the JPEG file into the embedding by calling \n\n         # Aleph Alpha API \n\n        prompt  =  Image . from_file(image_path)\n\n        prompt  =  Prompt . from_image(prompt)\n\n        query_params  =  {\n\n             \"prompt\" : prompt,\n\n             \"representation\" : SemanticRepresentation . Symmetric,\n\n             \"compress_to_size\" :  128 ,\n\n        }\n\n        query_request  =  SemanticEmbeddingRequest( ** query_params)\n\n        query_response  =   await  client . semantic_embed(request = query_request, model = model)\n\n\n\n         # Finally store the id, vector and the payload \n\n        ids . append(i)\n\n        vectors . append(query_response . embedding)\n\n        payloads . append({ \"filename\" : image_path})\n\n```\n\n## Load embeddings into Qdrant\n\nAdd all created embeddings, along with their ids and payloads into the `COCO` collection.\n\n```\nimport   qdrant_client \n\nfrom   qdrant_client.http.models   import  Batch, VectorParams, Distance\n\n\n\nqdrant_client  =  qdrant_client . QdrantClient()\n\nqdrant_client . recreate_collection(\n\n    collection_name = \"COCO\" ,\n\n    vectors_config = VectorParams(\n\n        size = len (vectors[ 0 ]),\n\n        distance = Distance . COSINE,\n\n    )\n\n)\n\nqdrant_client . upsert(\n\n    collection_name = \"COCO\" ,\n\n    points = Batch(\n\n        ids = ids,\n\n        vectors = vectors,\n\n        payloads = payloads,\n\n    )\n\n)\n\n```\n\n## Query the database\n\nThe `luminous-base` , model can provide you the vectors for both texts and images, which means you can run both\ntext queries and reverse image search. Assume you want to find images similar to the one below:\n\nImage: [ An image used to query the database ](https://qdrant.tech/docs/integrations/aleph-alpha/visual_search_query.png)\n\nImage: [ An image used to query the database ](https://qdrant.tech/docs/integrations/aleph-alpha/visual_search_query.png)\n\nWith the following code snippet create its vector embedding and then perform the lookup in Qdrant:\n\n```\nasync   with  AsyncCliet(token = aa_token)  as  client:\n\n    prompt  =  ImagePrompt . from_file( \"query.jpg\" )\n\n    prompt  =  Prompt . from_image(prompt)\n\n\n\n    query_params  =  {\n\n         \"prompt\" : prompt,\n\n         \"representation\" : SemanticRepresentation . Symmetric,\n\n         \"compress_to_size\" :  128 ,\n\n    }\n\n    query_request  =  SemanticEmbeddingRequest( ** query_params)\n\n    query_response  =   await  client . semantic_embed(request = query_request, model = model)\n\n\n\n    results  =  qdrant . search(\n\n        collection_name = \"COCO\" ,\n\n        query_vector = query_response . embedding,\n\n        limit = 3 ,\n\n    )\n\n     print (results)\n\n```\n\nHere are the results:\n\nImage: [ Visual search results ](https://qdrant.tech/docs/integrations/aleph-alpha/visual_search_results.png)\n\nImage: [ Visual search results ](https://qdrant.tech/docs/integrations/aleph-alpha/visual_search_results.png)\n\n **Note:** AlephAlpha models can provide embeddings for English, French, German, Italian\nand Spanish. Your search is not only multimodal, but also multilingual, without any need for translations.\n\n```\ntext  =   \"Surfing\" \n\n\n\nasync   with  AsyncClient(token = aa_token)  as  client:\n\n    query_params  =  {\n\n         \"prompt\" : Prompt . from_text(text),\n\n         \"representation\" : SemanticRepresentation . Symmetric,\n\n         \"compres_to_size\" :  128 ,\n\n    }\n\n    query_request  =  SemanticEmbeddingRequest( ** query_params)\n\n    query_response  =   await  client . semantic_embed(request = query_request, model = model)\n\n\n\n    results  =  qdrant . search(\n\n        collection_name = \"COCO\" ,\n\n        query_vector = query_response . embedding,\n\n        limit = 3 ,\n\n    )\n\n     print (results)\n\n```\n\nHere are the top 3 results for \u201cSurfing\u201d:\n\nImage: [ Text search results ](https://qdrant.tech/docs/integrations/aleph-alpha/text_search_results.png)\n\nImage: [ Text search results ](https://qdrant.tech/docs/integrations/aleph-alpha/text_search_results.png)\n\n##### Table of contents\n\n- [ Sample dataset ](https://qdrant.tech/documentation/tutorials/aleph-alpha-search/#sample-dataset)\n- [ Prerequisites ](https://qdrant.tech/documentation/tutorials/aleph-alpha-search/#prerequisites)\n- [ Vectorize the dataset ](https://qdrant.tech/documentation/tutorials/aleph-alpha-search/#vectorize-the-dataset)\n- [ Load embeddings into Qdrant ](https://qdrant.tech/documentation/tutorials/aleph-alpha-search/#load-embeddings-into-qdrant)\n- [ Query the database ](https://qdrant.tech/documentation/tutorials/aleph-alpha-search/#query-the-database)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/aleph-alpha-search.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/mighty/": "# Semantic Search with Mighty and Qdrant\n\nMuch like Qdrant, the[ Mighty ](https://max.io/)inference server is written in Rust and promises to offer low latency and high scalability. This brief demo combines Mighty and Qdrant into a simple semantic search service that is efficient, affordable and easy to setup. We will use[ Rust ](https://rust-lang.org)and our[ qdrant_client crate ](https://docs.rs/qdrant_client)for this integration.\n\n## Initial setup\n\nFor Mighty, start up a[ docker container ](https://hub.docker.com/layers/maxdotio/mighty-sentence-transformers/0.9.9/images/sha256-0d92a89fbdc2c211d927f193c2d0d34470ecd963e8179798d8d391a4053f6caf?context=explore)with an open port 5050. Just loading the port in a window shows the following:\n\n```\n{\n\n   \"name\" :  \"sentence-transformers/all-MiniLM-L6-v2\" ,\n\n   \"architectures\" : [\n\n     \"BertModel\" \n\n  ],\n\n   \"model_type\" :  \"bert\" ,\n\n   \"max_position_embeddings\" :  512 ,\n\n   \"labels\" :  null ,\n\n   \"named_entities\" :  null ,\n\n   \"image_size\" :  null ,\n\n   \"source\" :  \"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\" \n\n}\n\n```\n\nNote that this uses the `MiniLM-L6-v2` model from Hugging Face. As per their website, the model \u201cmaps sentences & paragraphs to a 384 dimensional dense vector space and can be used for tasks like clustering or semantic search\u201d. The distance measure to use is cosine similarity.\n\nVerify that mighty works by calling `curl https://<address>:5050/sentence-transformer?q=hello+mighty` . This will give you a result like (formatted via `jq` ):\n\n```\n{\n\n     \"outputs\" : [\n\n        [\n\n             -0.05019686743617058 ,\n\n             0.051746174693107605 ,\n\n             0.048117730766534805 ,\n\n             ...   ( 381   values   skipped) \n\n        ]\n\n    ],\n\n     \"shape\" : [\n\n         1 ,\n\n         384 \n\n    ],\n\n     \"texts\" : [\n\n         \"Hello mighty\" \n\n    ],\n\n     \"took\" :  77 \n\n}\n\n```\n\nFor Qdrant, follow our[ cloud documentation ](../../cloud/cloud-quick-start/)to spin up a[ free tier ](https://cloud.qdrant.io/). Make sure to retrieve an API key.\n\n## Implement model API\n\nFor mighty, you will need a way to emit HTTP(S) requests. This version uses the[ reqwest ](https://docs.rs/reqwest)crate, so add the following to your `Cargo.toml` \u2019s dependencies section:\n\n```\n[dependencies]\n\nreqwest =  { version =  \"0.11.18\" , default-features =  false , features = [ \"json\" ,  \"rustls-tls\" ] }\n\n```\n\nMighty offers a variety of model APIs which will download and cache the model on first use. For semantic search, use the `sentence-transformer` API (as in the above `curl` command). The Rust code to make the call is:\n\n```\nuse   anyhow::anyhow; \n\nuse   reqwest::Client; \n\nuse   serde::Deserialize; \n\nuse   serde_json::Value   as   JsonValue; \n\n\n\n#[derive(Deserialize)] \n\nstruct   EmbeddingsResponse   { \n\n     pub   outputs:  Vec < Vec < f32 >> , \n\n} \n\n\n\npub   async   fn   get_mighty_embedding ( \n\n     client:  & Client , \n\n     url:  & str , \n\n     text:  & str \n\n)   ->  anyhow :: Result < Vec < f32 >>   { \n\n     let   response   =   client.get(url).query( & [( \"text\" ,   text)]).send(). await ? ; \n\n\n\n     if   ! response.status().is_success()   { \n\n         return   Err (anyhow ! ( \n\n             \"Mighty API returned status code {}\" , \n\n             response.status() \n\n         )); \n\n     } \n\n\n\n     let   embeddings:  EmbeddingsResponse   =   response.json(). await ? ; \n\n     // ignore multiple embeddings at the moment\n\n     embeddings.get( 0 ).ok_or_else( ||   anyhow ! ( \"mighty returned empty embedding\" )) \n\n} \n\n```\n\nNote that mighty can return multiple embeddings (if the input is too long to fit the model, it is automatically split).\n\n## Create embeddings and run a query\n\nUse this code to create embeddings both for insertion and search. On the Qdrant side, take the embedding and run a query:\n\n```\nuse   anyhow::anyhow; \n\nuse   qdrant_client::prelude:: * ; \n\n\n\npub   const   SEARCH_LIMIT:  u64   =   5 ; \n\nconst   COLLECTION_NAME:  & str   =   \"mighty\" ; \n\n\n\npub   async   fn   qdrant_search_embeddings ( \n\n     qdrant_client:  & QdrantClient , \n\n     vector:  Vec < f32 > , \n\n)   ->  anyhow :: Result < Vec < ScoredPoint >>   { \n\n     qdrant_client \n\n         .search_points( & SearchPoints   { \n\n             collection_name:  COLLECTION_NAME .to_string(), \n\n             vector, \n\n             limit:  SEARCH_LIMIT , \n\n             with_payload:  Some ( true .into()), \n\n             .. Default ::default() \n\n         }) \n\n         . await \n\n         .map_err( | err |   anyhow ! ( \"Failed to search Qdrant: {}\" ,   err)) \n\n} \n\n```\n\nYou can convert the[ ScoredPoint ](https://docs.rs/qdrant-client/latest/qdrant_client/qdrant/struct.ScoredPoint.html)s to fit your desired output format.\n\n##### Table of contents\n\n- [ Initial setup ](https://qdrant.tech/documentation/tutorials/mighty/#initial-setup)\n- [ Implement model API ](https://qdrant.tech/documentation/tutorials/mighty/#implement-model-api)\n- [ Create embeddings and run a query ](https://qdrant.tech/documentation/tutorials/mighty/#create-embeddings-and-run-a-query)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/mighty.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/": "# Multitenancy with LlamaIndex\n\nIf you are building a service that serves vectors for many independent users, and you want to isolate their\ndata, the best practice is to use a single collection with payload-based partitioning. This approach is\ncalled **multitenancy** . Our guide on the[ Separate Partitions ](https://qdrant.tech/documentation/guides/multiple-partitions/)describes\nhow to set it up in general, but if you use[ LlamaIndex ](https://qdrant.tech/documentation/integrations/llama-index/)as a\nbackend, you may prefer reading a more specific instruction. So here it is!\n\n## Prerequisites\n\nThis tutorial assumes that you have already installed Qdrant and LlamaIndex. If you haven\u2019t, please run the\nfollowing commands:\n\n`pip install qdrant-client llama-index\n`\n\nWe are going to use a local Docker-based instance of Qdrant. If you want to use a remote instance, please\nadjust the code accordingly. Here is how we can start a local instance:\n\n`docker run -d --name qdrant -p 6333:6333 -p 6334:6334 qdrant/qdrant:latest\n`\n\n## Setting up LlamaIndex pipeline\n\nWe are going to implement an end-to-end example of multitenant application using LlamaIndex. We\u2019ll be\nindexing the documentation of different Python libraries, and we definitely don\u2019t want any users to see the\nresults coming from a library they are not interested in. In real case scenarios, this is even more dangerous,\nas the documents may contain sensitive information.\n\n### Creating vector store\n\n[ QdrantVectorStore ](https://docs.llamaindex.ai/en/stable/examples/vector_stores/QdrantIndexDemo.html)is a\nwrapper around Qdrant that provides all the necessary methods to work with your vector database in LlamaIndex.\nLet\u2019s create a vector store for our collection. It requires setting a collection name and passing an instance\nof `QdrantClient` .\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   llama_index.vector_stores   import  QdrantVectorStore\n\n\n\nclient  =  QdrantClient( \"http://localhost:6333\" )\n\n\n\nvector_store  =  QdrantVectorStore(\n\n    collection_name = \"my_collection\" ,\n\n    client = client,\n\n)\n\n```\n\n### Defining chunking strategy and embedding model\n\nAny semantic search application requires a way to convert text queries into vectors - an embedding model. `ServiceContext` is a bundle of commonly used resources used during the indexing and querying stage in any\nLlamaIndex application. We can also use it to set up an embedding model - in our case, a local[ BAAI/bge-small-en-v1.5 ](https://huggingface.co/BAAI/bge-small-en-v1.5).\nset up\n\n```\nfrom   llama_index   import  ServiceContext\n\n\n\nservice_context  =  ServiceContext . from_defaults(\n\n    embed_model = \"local:BAAI/bge-small-en-v1.5\" ,\n\n)\n\n```\n\nWe can also control how our documents are split into chunks, or nodes using LLamaIndex\u2019s terminology.\nThe `SimpleNodeParser` splits documents into fixed length chunks with an overlap. The defaults are\nreasonable, but we can also adjust them if we want to. Both values are defined in tokens.\n\n```\nfrom   llama_index.node_parser   import  SimpleNodeParser\n\n\n\nnode_parser  =  SimpleNodeParser . from_defaults(chunk_size = 512 , chunk_overlap = 32 )\n\n```\n\nNow we also need to inform the `ServiceContext` about our choices:\n\n```\nservice_context  =  ServiceContext . from_defaults(\n\n    embed_model = \"local:BAAI/bge-large-en-v1.5\" ,\n\n    node_parser = node_parser,\n\n)\n\n```\n\nBoth embedding model and selected node parser will be implicitly used during the indexing and querying.\n\n### Combining everything together\n\nThe last missing piece, before we can start indexing, is the `VectorStoreIndex` . It is a wrapper around `VectorStore` that provides a convenient interface for indexing and querying. It also requires a `ServiceContext` to be initialized.\n\n```\nfrom   llama_index   import  VectorStoreIndex\n\n\n\nindex  =  VectorStoreIndex . from_vector_store(\n\n    vector_store = vector_store, service_context = service_context\n\n)\n\n```\n\n## Indexing documents\n\nNo matter how our documents are generated, LlamaIndex will automatically split them into nodes, if\nrequired, encode using selected embedding model, and then store in the vector store. Let\u2019s define\nsome documents manually and insert them into Qdrant collection. Our documents are going to have\na single metadata attribute - a library name they belong to.\n\n```\nfrom   llama_index.schema   import  Document\n\n\n\ndocuments  =  [\n\n    Document(\n\n        text = \"LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models.\" ,\n\n        metadata = {\n\n             \"library\" :  \"llama-index\" ,\n\n        },\n\n    ),\n\n    Document(\n\n        text = \"Qdrant is a vector database & vector similarity search engine.\" ,\n\n        metadata = {\n\n             \"library\" :  \"qdrant\" ,\n\n        },\n\n    ),\n\n]\n\n```\n\nNow we can index them using our `VectorStoreIndex` :\n\n```\nfor  document  in  documents:\n\n    index . insert(document)\n\n```\n\n### Performance considerations\n\nOur documents have been split into nodes, encoded using the embedding model, and stored in the vector\nstore. However, we don\u2019t want to allow our users to search for all the documents in the collection,\nbut only for the documents that belong to a library they are interested in. For that reason, we need\nto set up the Qdrant[ payload index ](https://qdrant.tech/documentation/concepts/indexing/#payload-index), so the search\nis more efficient.\n\n```\nfrom   qdrant_client   import  models\n\n\n\nclient . create_payload_index(\n\n    collection_name = \"my_collection\" ,\n\n    field_name = \"metadata.library\" ,\n\n    field_type = models . PayloadSchemaType . KEYWORD,\n\n)\n\n```\n\nThe payload index is not the only thing we want to change. Since none of the search\nqueries will be executed on the whole collection, we can also change its configuration, so the HNSW\ngraph is not built globally. This is also done due to[ performance reasons ](https://qdrant.tech/documentation/guides/multiple-partitions/#calibrate-performance). **You should not be changing these parameters, if you know there will be some global search operations\ndone on the collection.** \n\n```\nclient . update_collection(\n\n    collection_name = \"my_collection\" ,\n\n    hnsw_config = models . HnswConfigDiff(payload_m = 16 , m = 0 ),\n\n)\n\n```\n\nOnce both operations are completed, we can start searching for our documents.\n\n## Querying documents with constraints\n\nLet\u2019s assume we are searching for some information about large language models, but are only allowed to\nuse Qdrant documentation. LlamaIndex has a concept of retrievers, responsible for finding the most\nrelevant nodes for a given query. Our `VectorStoreIndex` can be used as a retriever, with some additional\nconstraints - in our case value of the `library` metadata attribute.\n\n```\nfrom   llama_index.vector_stores.types   import  MetadataFilters, ExactMatchFilter\n\n\n\nqdrant_retriever  =  index . as_retriever(\n\n    filters = MetadataFilters(\n\n        filters = [\n\n            ExactMatchFilter(\n\n                key = \"library\" ,\n\n                value = \"qdrant\" ,\n\n            )\n\n        ]\n\n    )\n\n)\n\n\n\nnodes_with_scores  =  qdrant_retriever . retrieve( \"large language models\" )\n\nfor  node  in  nodes_with_scores:\n\n     print (node . text, node . score)\n\n# Output: Qdrant is a vector database & vector similarity search engine. 0.60551536 \n\n```\n\nThe description of Qdrant was the best match, even though it didn\u2019t mention large language models\nat all. However, it was the only document that belonged to the `qdrant` library, so there was no\nother choice. Let\u2019s try to search for something that is not present in the collection.\n\nLet\u2019s define another retrieve, this time for the `llama-index` library:\n\n```\nllama_index_retriever  =  index . as_retriever(\n\n    filters = MetadataFilters(\n\n        filters = [\n\n            ExactMatchFilter(\n\n                key = \"library\" ,\n\n                value = \"llama-index\" ,\n\n            )\n\n        ]\n\n    )\n\n)\n\n\n\nnodes_with_scores  =  llama_index_retriever . retrieve( \"large language models\" )\n\nfor  node  in  nodes_with_scores:\n\n     print (node . text, node . score)\n\n# Output: LlamaIndex is a simple, flexible data framework for connecting custom data sources to large language models. 0.63576734 \n\n```\n\nThe results returned by both retrievers are different, due to the different constraints, so we implemented\na real multitenant search application!\n\n##### Table of contents\n\n- [ Prerequisites ](https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/#prerequisites)\n- [ Setting up LlamaIndex pipeline ](https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/#setting-up-llamaindex-pipeline)\n    - [ Creating vector store ](https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/#creating-vector-store)\n\n- [ Defining chunking strategy and embedding model ](https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/#defining-chunking-strategy-and-embedding-model)\n\n- [ Combining everything together ](https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/#combining-everything-together)\n- [ Indexing documents ](https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/#indexing-documents)\n    - [ Performance considerations ](https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/#performance-considerations)\n- [ Querying documents with constraints ](https://qdrant.tech/documentation/tutorials/llama-index-multitenancy/#querying-documents-with-constraints)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/llama-index-multitenancy.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/examples/": "# Sample Use Cases\n\nOur Notebooks offer complex instructions that are supported with a throrough explanation. Follow along by trying out the code and get the most out of each example.\n\n| Example | Description | Stack |\n|---|---|---|\n| [ Intro to Semantic Search and Recommendations Systems ](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_getting_started/getting_started.ipynb) | Learn how to get started building semantic search and recommendation systems. | Qdrant |\n| [ Search and Recommend Newspaper Articles ](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_text_data/qdrant_and_text_data.ipynb) | Work with text data to develop a semantic search and a recommendation engine for news articles. | Qdrant |\n| [ Recommendation System for Songs ](https://githubtocolab.com/qdrant/examples/blob/master/qdrant_101_audio_data/03_qdrant_101_audio.ipynb) | Use Qdrant to develop a music recommendation engine based on audio embeddings. | Qdrant |\n| [ Image Comparison System for Skin Conditions ](https://colab.research.google.com/github/qdrant/examples/blob/master/qdrant_101_image_data/04_qdrant_101_cv.ipynb) | Use Qdrant to compare challenging images with labels representing different skin diseases. | Qdrant |\n| [ Question and Answer System with LlamaIndex ](https://githubtocolab.com/qdrant/examples/blob/master/llama_index_recency/Qdrant%20and%20LlamaIndex%20%E2%80%94%20A%20new%20way%20to%20keep%20your%20Q%26A%20systems%20up-to-date.ipynb) | Combine Qdrant and LlamaIndex to create a self-updating Q&A system. | Qdrant, LlamaIndex, Cohere |\n| [ Extractive QA System ](https://githubtocolab.com/qdrant/examples/blob/master/extractive_qa/extractive-question-answering.ipynb) | Extract answers directly from context to generate highly relevant answers. | Qdrant |\n| [ Ecommerce Reverse Image Search ](https://githubtocolab.com/qdrant/examples/blob/master/ecommerce_reverse_image_search/ecommerce-reverse-image-search.ipynb) | Accept images as search queries to receive semantically appropriate answers. | Qdrant |\n| [ Basic RAG ](https://githubtocolab.com/qdrant/examples/blob/master/rag-openai-qdrant/rag-openai-qdrant.ipynb) | Basic RAG pipeline with Qdrant and OpenAI SDKs | OpenAI, Qdrant, FastEmbed |\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/embeddings/cohere/": "# Cohere\n\nQdrant is compatible with Cohere[ co.embed API ](https://docs.cohere.ai/reference/embed)and its official Python SDK that\nmight be installed as any other package:\n\n`pip install cohere\n`\n\nThe embeddings returned by co.embed API might be used directly in the Qdrant client\u2019s calls:\n\n```\nimport   cohere \n\nimport   qdrant_client \n\n\n\nfrom   qdrant_client.http.models   import  Batch\n\n\n\ncohere_client  =  cohere . Client( \"<< your_api_key >>\" )\n\nqdrant_client  =  qdrant_client . QdrantClient()\n\nqdrant_client . upsert(\n\n    collection_name = \"MyCollection\" ,\n\n    points = Batch(\n\n        ids = [ 1 ],\n\n        vectors = cohere_client . embed(\n\n            model = \"large\" ,\n\n            texts = [ \"The best vector database\" ],\n\n        ) . embeddings,\n\n    ),\n\n)\n\n```\n\nIf you are interested in seeing an end-to-end project created with co.embed API and Qdrant, please check out the\n\u201c[ Question Answering as a Service with Cohere and Qdrant ](https://qdrant.tech/articles/qa-with-cohere-and-qdrant/)\u201d article.\n\n## Embed v3\n\nEmbed v3 is a new family of Cohere models, released in November 2023. The new models require passing an additional\nparameter to the API call: `input_type` . It determines the type of task you want to use the embeddings for.\n\n- `input_type=\"search_document\"` - for documents to store in Qdrant\n- `input_type=\"search_query\"` - for search queries to find the most relevant documents\n- `input_type=\"classification\"` - for classification tasks\n- `input_type=\"clustering\"` - for text clustering\n\n\nWhile implementing semantic search applications, such as RAG, you should use `input_type=\"search_document\"` for the\nindexed documents and `input_type=\"search_query\"` for the search queries. The following example shows how to index\ndocuments with the Embed v3 model:\n\n```\nimport   cohere \n\nimport   qdrant_client \n\n\n\nfrom   qdrant_client.http.models   import  Batch\n\n\n\ncohere_client  =  cohere . Client( \"<< your_api_key >>\" )\n\nqdrant_client  =  qdrant_client . QdrantClient()\n\nqdrant_client . upsert(\n\n    collection_name = \"MyCollection\" ,\n\n    points = Batch(\n\n        ids = [ 1 ],\n\n        vectors = cohere_client . embed(\n\n            model = \"embed-english-v3.0\" ,   # New Embed v3 model \n\n            input_type = \"search_document\" ,   # Input type for documents \n\n            texts = [ \"Qdrant is the a vector database written in Rust\" ],\n\n        ) . embeddings,\n\n    ),\n\n)\n\n```\n\nOnce the documents are indexed, you can search for the most relevant documents using the Embed v3 model:\n\n```\nqdrant_client . search(\n\n    collection_name = \"MyCollection\" ,\n\n    query = cohere_client . embed(\n\n        model = \"embed-english-v3.0\" ,   # New Embed v3 model \n\n        input_type = \"search_query\" ,   # Input type for search queries \n\n        texts = [ \"The best vector database\" ],\n\n    ) . embeddings[ 0 ],\n\n)\n\n```\n\n##### Table of contents\n\n- [ Embed v3 ](https://qdrant.tech/documentation/embeddings/cohere/#embed-v3)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/embeddings/cohere.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/embeddings/gemini/": "# Gemini\n\nQdrant is compatible with Gemini Embedding Model API and its official Python SDK that can be installed as any other package:\n\nGemini is a new family of Google PaLM models, released in December 2023. The new embedding models succeed the previous Gecko Embedding Model.\n\nIn the latest models, an additional parameter, `task_type` , can be passed to the API call. This parameter serves to designate the intended purpose for the embeddings utilized.\n\nThe Embedding Model API supports various task types, outlined as follows:\n\n1. `retrieval_query` : Specifies the given text is a query in a search/retrieval setting.\n2. `retrieval_document` : Specifies the given text is a document from the corpus being searched.\n3. `semantic_similarity` : Specifies the given text will be used for Semantic Text Similarity.\n4. `classification` : Specifies that the given text will be classified.\n5. `clustering` : Specifies that the embeddings will be used for clustering.\n6. `task_type_unspecified` : Unset value, which will default to one of the other values.\n\n\nIf you\u2019re building a semantic search application, such as RAG, you should use `task_type=\"retrieval_document\"` for the indexed documents and `task_type=\"retrieval_query\"` for the search queries.\n\nThe following example shows how to do this with Qdrant:\n\n## Setup\n\n`pip install google-generativeai\n`\n\nLet\u2019s see how to use the Embedding Model API to embed a document for retrieval.\n\nThe following example shows how to embed a document with the `models/embedding-001` with the `retrieval_document` task type:\n\n## Embedding a document\n\n```\nimport   pathlib \n\nimport   google.generativeai   as   genai \n\nimport   qdrant_client \n\n\n\nGEMINI_API_KEY  =   \"YOUR GEMINI API KEY\"    # add your key here \n\n\n\ngenai . configure(api_key = GEMINI_API_KEY)\n\n\n\nresult  =  genai . embed_content(\n\n    model = \"models/embedding-001\" ,\n\n    content = \"Qdrant is the best vector search engine to use with Gemini\" ,\n\n    task_type = \"retrieval_document\" ,\n\n    title = \"Qdrant x Gemini\" ,\n\n)\n\n```\n\nThe returned result is a dictionary with a key: `embedding` . The value of this key is a list of floats representing the embedding of the document.\n\n## Indexing documents with Qdrant\n\n```\nfrom   qdrant_client.http.models   import  Batch\n\n\n\nqdrant_client  =  qdrant_client . QdrantClient()\n\nqdrant_client . upsert(\n\n    collection_name = \"GeminiCollection\" ,\n\n    points = Batch(\n\n        ids = [ 1 ],\n\n        vectors = genai . embed_content(\n\n            model = \"models/embedding-001\" ,\n\n            content = \"Qdrant is the best vector search engine to use with Gemini\" ,\n\n            task_type = \"retrieval_document\" ,\n\n            title = \"Qdrant x Gemini\" ,\n\n        )[ \"embedding\" ],\n\n    ),\n\n)\n\n```\n\n## Searching for documents with Qdrant\n\nOnce the documents are indexed, you can search for the most relevant documents using the same model with the `retrieval_query` task type:\n\n```\nqdrant_client . search(\n\n    collection_name = \"GeminiCollection\" ,\n\n    query = genai . embed_content(\n\n        model = \"models/embedding-001\" ,\n\n        content = \"What is the best vector database to use with Gemini?\" ,\n\n        task_type = \"retrieval_query\" ,\n\n    )[ \"embedding\" ],\n\n)\n\n```\n\n## Using Gemini Embedding Models with Binary Quantization\n\nYou can use Gemini Embedding Models with[ Binary Quantization ](https://qdrant.tech/articles/binary-quantization/)- a technique that allows you to reduce the size of the embeddings by 32 times without losing the quality of the search results too much.\n\nIn this table, you can see the results of the search with the `models/embedding-001` model with Binary Quantization in comparison with the original model:\n\nAt an oversampling of 3 and a limit of 100, we\u2019ve a 95% recall against the exact nearest neighbors with rescore enabled.\n\n| oversampling |  | 1 | 1 | 2 | 2 | 3 | 3 |\n|---|---|---|---|---|---|---|---|\n| limit |  |  |  |  |  |  |  |\n|  | rescore | False | True | False | True | False | True |\n| 10 |  | 0.523333 | 0.831111 | 0.523333 | 0.915556 | 0.523333 | 0.950000 |\n| 20 |  | 0.510000 | 0.836667 | 0.510000 | 0.912222 | 0.510000 | 0.937778 |\n| 50 |  | 0.489111 | 0.841556 | 0.489111 | 0.913333 | 0.488444 | 0.947111 |\n| 100 |  | 0.485778 | 0.846556 | 0.485556 | 0.929000 | 0.486000 |  **0.956333**  |\n\n\nThat\u2019s it! You can now use Gemini Embedding Models with Qdrant!\n\n##### Table of contents\n\n- [ Setup ](https://qdrant.tech/documentation/embeddings/gemini/#setup)\n- [ Embedding a document ](https://qdrant.tech/documentation/embeddings/gemini/#embedding-a-document)\n- [ Indexing documents with Qdrant ](https://qdrant.tech/documentation/embeddings/gemini/#indexing-documents-with-qdrant)\n- [ Searching for documents with Qdrant ](https://qdrant.tech/documentation/embeddings/gemini/#searching-for-documents-with-qdrant)\n- [ Using Gemini Embedding Models with Binary Quantization ](https://qdrant.tech/documentation/embeddings/gemini/#using-gemini-embedding-models-with-binary-quantization)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/embeddings/gemini.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/embeddings/jina-embeddings/": "# Jina Embeddings\n\nQdrant can also easily work with[ Jina embeddings ](https://jina.ai/embeddings/)which allow for model input lengths of up to 8192 tokens.\n\nTo call their endpoint, all you need is an API key obtainable[ here ](https://jina.ai/embeddings/).\n\n```\nimport   qdrant_client \n\nimport   requests \n\n\n\nfrom   qdrant_client.http.models   import  Distance, VectorParams\n\nfrom   qdrant_client.http.models   import  Batch\n\n\n\n# Provide Jina API key and choose one of the available models. \n\n# You can get a free trial key here: https://jina.ai/embeddings/ \n\nJINA_API_KEY  =   \"jina_xxxxxxxxxxx\" \n\nMODEL  =   \"jina-embeddings-v2-base-en\"    # or \"jina-embeddings-v2-base-en\" \n\nEMBEDDING_SIZE  =   768    # 512 for small variant \n\n\n\n# Get embeddings from the API \n\nurl  =   \"https://api.jina.ai/v1/embeddings\" \n\n\n\nheaders  =  {\n\n     \"Content-Type\" :  \"application/json\" ,\n\n     \"Authorization\" :  f \"Bearer  { JINA_API_KEY } \" ,\n\n}\n\n\n\ndata  =  {\n\n     \"input\" : [ \"Your text string goes here\" ,  \"You can send multiple texts\" ],\n\n     \"model\" : MODEL,\n\n}\n\n\n\nresponse  =  requests . post(url, headers = headers, json = data)\n\nembeddings  =  [d[ \"embedding\" ]  for  d  in  response . json()[ \"data\" ]]\n\n\n\n\n\n# Index the embeddings into Qdrant \n\nqdrant_client  =  qdrant_client . QdrantClient( \":memory:\" )\n\nqdrant_client . create_collection(\n\n    collection_name = \"MyCollection\" ,\n\n    vectors_config = VectorParams(size = EMBEDDING_SIZE, distance = Distance . DOT),\n\n)\n\n\n\n\n\nqdrant_client . upsert(\n\n    collection_name = \"MyCollection\" ,\n\n    points = Batch(\n\n        ids = list ( range ( len (embeddings))),\n\n        vectors = embeddings,\n\n    ),\n\n)\n\n```\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/embeddings/openai/": "# OpenAI\n\nQdrant can also easily work with[ OpenAI embeddings ](https://platform.openai.com/docs/guides/embeddings/embeddings).\n\nThere is an official OpenAI Python package that simplifies obtaining them, and it might be installed with pip:\n\n`pip install openai\n`\n\nOnce installed, the package exposes the method allowing to retrieve the embedding for given text. OpenAI requires an API key that has to be provided either as an environmental variable `OPENAI_API_KEY` or set in the source code directly, as presented below:\n\n```\nimport   openai \n\nimport   qdrant_client \n\n\n\nfrom   qdrant_client.http.models   import  Batch\n\n\n\n# Provide OpenAI API key and choose one of the available models: \n\n# https://beta.openai.com/docs/models/overview \n\nopenai . api_key  =   \"<< your_api_key >>\" \n\nembedding_model  =   \"text-embedding-ada-002\" \n\n\n\nresponse  =  openai . Embedding . create(\n\n     input = \"The best vector database\" ,\n\n    model = embedding_model,\n\n)\n\n\n\nqdrant_client  =  qdrant_client . QdrantClient()\n\nqdrant_client . upsert(\n\n    collection_name = \"MyCollection\" ,\n\n    points = Batch(\n\n        ids = [ 1 ],\n\n        vectors = [response[ \"data\" ][ 0 ][ \"embedding\" ]],\n\n    ),\n\n)\n\n```\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/langchain/": "# LangChain\n\nLangChain is a library that makes developing Large Language Models based applications much easier. It unifies the interfaces\nto different libraries, including major embedding providers and Qdrant. Using LangChain, you can focus on the business value\ninstead of writing the boilerplate.\n\nLangchain comes with the Qdrant integration by default. It might be installed with pip:\n\n`pip install langchain\n`\n\nQdrant acts as a vector index that may store the embeddings with the documents used to generate them. There are various ways\nhow to use it, but calling `Qdrant.from_texts` is probably the most straightforward way how to get started:\n\n```\nfrom   langchain.vectorstores   import  Qdrant\n\nfrom   langchain.embeddings   import  HuggingFaceEmbeddings\n\n\n\nembeddings  =  HuggingFaceEmbeddings(\n\n    model_name = \"sentence-transformers/all-mpnet-base-v2\" \n\n)\n\ndoc_store  =  Qdrant . from_texts(\n\n    texts, embeddings, url = \"<qdrant-url>\" , api_key = \"<qdrant-api-key>\" , collection_name = \"texts\" \n\n)\n\n```\n\nCalling `Qdrant.from_documents` or `Qdrant.from_texts` will always recreate the collection and remove all the existing points.\nThat\u2019s fine for some experiments, but you\u2019ll prefer not to start from scratch every single time in a real-world scenario.\nIf you prefer reusing an existing collection, you can create an instance of Qdrant on your own:\n\n```\nimport   qdrant_client \n\n\n\nembeddings  =  HuggingFaceEmbeddings(\n\n    model_name = \"sentence-transformers/all-mpnet-base-v2\" \n\n)\n\n\n\nclient  =  qdrant_client . QdrantClient(\n\n     \"<qdrant-url>\" ,\n\n    api_key = \"<qdrant-api-key>\" ,  # For Qdrant Cloud, None for local instance \n\n)\n\n\n\ndoc_store  =  Qdrant(\n\n    client = client, collection_name = \"texts\" , \n\n    embeddings = embeddings,\n\n)\n\n```\n\n## Local mode\n\nPython client allows you to run the same code in local mode without running the Qdrant server. That\u2019s great for testing things\nout and debugging or if you plan to store just a small amount of vectors. The embeddings might be fully kepy in memory or\npersisted on disk.\n\n### In-memory\n\nFor some testing scenarios and quick experiments, you may prefer to keep all the data in memory only, so it gets lost when the\nclient is destroyed - usually at the end of your script/notebook.\n\n```\nqdrant  =  Qdrant . from_documents(\n\n    docs, embeddings, \n\n    location = \":memory:\" ,   # Local mode with in-memory storage only \n\n    collection_name = \"my_documents\" ,\n\n)\n\n```\n\n### On-disk storage\n\nLocal mode, without using the Qdrant server, may also store your vectors on disk so they\u2019re persisted between runs.\n\n```\nqdrant  =  Qdrant . from_documents(\n\n    docs, embeddings, \n\n    path = \"/tmp/local_qdrant\" ,\n\n    collection_name = \"my_documents\" ,\n\n)\n\n```\n\n### On-premise server deployment\n\nNo matter if you choose to launch Qdrant locally with[ a Docker container ](https://qdrant.tech/documentation/guides/installation/), or\nselect a Kubernetes deployment with[ the official Helm chart ](https://github.com/qdrant/qdrant-helm), the way you\u2019re\ngoing to connect to such an instance will be identical. You\u2019ll need to provide a URL pointing to the service.\n\n```\nurl  =   \"<---qdrant url here --->\" \n\nqdrant  =  Qdrant . from_documents(\n\n    docs, \n\n    embeddings, \n\n    url, \n\n    prefer_grpc = True , \n\n    collection_name = \"my_documents\" ,\n\n)\n\n```\n\n## Next steps\n\nIf you\u2019d like to know more about running Qdrant in a LangChain-based application, please read our article[ Question Answering with LangChain and Qdrant without boilerplate ](https://qdrant.tech/articles/langchain-integration/). Some more information\nmight also be found in the[ LangChain documentation ](https://python.langchain.com/docs/integrations/vectorstores/qdrant).\n\n##### Table of contents\n\n- [ Local mode ](https://qdrant.tech/documentation/frameworks/langchain/#local-mode)\n    - [ In-memory ](https://qdrant.tech/documentation/frameworks/langchain/#in-memory)\n\n- [ On-disk storage ](https://qdrant.tech/documentation/frameworks/langchain/#on-disk-storage)\n\n- [ On-premise server deployment ](https://qdrant.tech/documentation/frameworks/langchain/#on-premise-server-deployment)\n- [ Next steps ](https://qdrant.tech/documentation/frameworks/langchain/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/langchain.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/llama-index/": "# LlamaIndex (GPT Index)\n\nLlamaIndex (formerly GPT Index) acts as an interface between your external data and Large Language Models. So you can bring your\nprivate data and augment LLMs with it. LlamaIndex simplifies data ingestion and indexing, integrating Qdrant as a vector index.\n\nInstalling LlamaIndex is straightforward if we use pip as a package manager. Qdrant is not installed by default, so we need to\ninstall it separately:\n\n`pip install llama-index qdrant-client\n`\n\nLlamaIndex requires providing an instance of `QdrantClient` , so it can interact with Qdrant server.\n\n```\nfrom   llama_index.vector_stores.qdrant   import  QdrantVectorStore\n\n\n\nimport   qdrant_client \n\n\n\nclient  =  qdrant_client . QdrantClient(\n\n     \"<qdrant-url>\" ,\n\n    api_key = \"<qdrant-api-key>\" ,  # For Qdrant Cloud, None for local instance \n\n)\n\n\n\nindex  =  QdrantVectorStore(client = client, collection_name = \"documents\" )\n\n```\n\nThe library[ comes with a notebook ](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/vector_stores/QdrantIndexDemo.ipynb)that shows an end-to-end example of how to use Qdrant within LlamaIndex.\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/docarray/": "# DocArray\n\nYou can use Qdrant natively in DocArray, where Qdrant serves as a high-performance document store to enable scalable vector search.\n\nDocArray is a library from Jina AI for nested, unstructured data in transit, including text, image, audio, video, 3D mesh, etc.\nIt allows deep-learning engineers to efficiently process, embed, search, recommend, store, and transfer the data with a Pythonic API.\n\nTo install DocArray with Qdrant support, please do\n\n`pip install  \"docarray[qdrant]\" \n`\n\nMore information can be found in[ DocArray\u2019s documentations ](https://docarray.jina.ai/advanced/document-store/qdrant/).\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/haystack/": "# Haystack\n\n[ Haystack ](https://haystack.deepset.ai/)serves as a comprehensive NLP framework, offering a modular methodology for constructing\ncutting-edge generative AI, QA, and semantic knowledge base search systems. A critical element in contemporary NLP systems is an\nefficient database for storing and retrieving extensive text data. Vector databases excel in this role, as they house vector\nrepresentations of text and implement effective methods for swift retrieval. Thus, we are happy to announce the integration\nwith Haystack - `QdrantDocumentStore` . This document store is unique, as it is maintained externally by the Qdrant team.\n\nThe new document store comes as a separate package and can be updated independently of Haystack:\n\n`pip install qdrant-haystack\n`\n\n `QdrantDocumentStore` supports[ all the configuration properties ](https://qdrant.tech/documentation/collections/#create-collection)available in\nthe Qdrant Python client. If you want to customize the default configuration of the collection used under the hood, you can\nprovide that settings when you create an instance of the `QdrantDocumentStore` . For example, if you\u2019d like to enable the\nScalar Quantization, you\u2019d make that in the following way:\n\n```\nfrom   qdrant_haystack.document_stores   import  QdrantDocumentStore\n\nfrom   qdrant_client.http   import  models\n\n\n\ndocument_store  =  QdrantDocumentStore(\n\n     \":memory:\" ,\n\n    index = \"Document\" ,\n\n    embedding_dim = 512 ,\n\n    recreate_index = True ,\n\n    quantization_config = models . ScalarQuantization(\n\n        scalar = models . ScalarQuantizationConfig(\n\n             type = models . ScalarType . INT8,\n\n            quantile = 0.99 ,\n\n            always_ram = True ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/txtai/": "# txtai\n\nQdrant might be also used as an embedding backend in[ txtai ](https://neuml.github.io/txtai/)semantic applications.\n\ntxtai simplifies building AI-powered semantic search applications using Transformers. It leverages the neural embeddings and their\nproperties to encode high-dimensional data in a lower-dimensional space and allows to find similar objects based on their embeddings\u2019\nproximity.\n\nQdrant is not built-in txtai backend and requires installing an additional dependency:\n\n`pip install qdrant-txtai\n`\n\nThe examples and some more information might be found in[ qdrant-txtai repository ](https://github.com/qdrant/qdrant-txtai).\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/cheshire-cat/": "# Cheshire Cat\n\n[ Cheshire Cat ](https://cheshirecat.ai/)is an open-source framework that allows you to develop intelligent agents on top of many Large Language Models (LLM). You can develop your custom AI architecture to assist you in a wide range of tasks.\n\nImage: [ Cheshire cat ](https://qdrant.tech/documentation/frameworks/cheshire-cat/cat.jpg)\n\nImage: [ Cheshire cat ](https://qdrant.tech/documentation/frameworks/cheshire-cat/cat.jpg)\n\n## Cheshire Cat and Qdrant\n\nCheshire Cat uses Qdrant as the default[ Vector Memory ](https://cheshire-cat-ai.github.io/docs/conceptual/memory/vector_memory/)for ingesting and retrieving documents.\n\n`# Decide host and port for your Cat. Default will be localhost:1865\nCORE_HOST=localhost\nCORE_PORT=1865\n\n# Qdrant server\n# QDRANT_HOST=localhost\n# QDRANT_PORT=6333`\n\nCheshire Cat takes great advantage of the following features of Qdrant:\n\n- [ Collection Aliases ](../../concepts/collections/#collection-aliases)to manage the change from one embedder to another.\n- [ Quantization ](../../guides/quantization/)to obtain a good balance between speed, memory usage and quality of the results.\n- [ Snapshots ](../../concepts/snapshots/)to not miss any information.\n- [ Community ](https://discord.com/invite/tdtYvXjC4h)\n\n\nImage: [ RAG Pipeline ](https://qdrant.tech/documentation/frameworks/cheshire-cat/stregatto.jpg)\n\nImage: [ RAG Pipeline ](https://qdrant.tech/documentation/frameworks/cheshire-cat/stregatto.jpg)\n\n## How to use the Cheshire Cat\n\n### Requirements\n\nTo run the Cheshire Cat, you need to have[ Docker ](https://docs.docker.com/engine/install/)and[ docker-compose ](https://docs.docker.com/compose/install/)already installed on your system.\n\n`docker run --rm -it -p 1865:80 ghcr.io/cheshire-cat-ai/core:latest\n`\n\n- Chat with the Cheshire Cat on[ localhost:1865/admin ](http://localhost:1865/admin).\n- You can also interact via REST API and try out the endpoints on[ localhost:1865/docs ](http://localhost:1865/docs)\n\n\nCheck the[ instructions on github ](https://github.com/cheshire-cat-ai/core/blob/main/README.md)for a more comprehensive quick start.\n\n### First configuration of the LLM\n\n- Open the Admin Portal in your browser at[ localhost:1865/admin ](http://localhost:1865/admin).\n- Configure the LLM in the `Settings` tab.\n- If you don\u2019t explicitly choose it using `Settings` tab, the Embedder follows the LLM.\n\n\n## Next steps\n\nFor more information, refer to the Cheshire Cat[ documentation ](https://cheshire-cat-ai.github.io/docs/)and[ blog ](https://cheshirecat.ai/blog/).\n\n- [ Getting started ](https://cheshirecat.ai/hello-world/)\n- [ How the Cat works ](https://cheshirecat.ai/how-the-cat-works/)\n- [ Write Your First Plugin ](https://cheshirecat.ai/write-your-first-plugin/)\n- [ Cheshire Cat\u2019s use of Qdrant - Vector Space ](https://cheshirecat.ai/dont-get-lost-in-vector-space/)\n- [ Cheshire Cat\u2019s use of Qdrant - Aliases ](https://cheshirecat.ai/the-drunken-cat-effect/)\n- [ Discord Community ](https://discord.com/invite/bHX5sNFCYU)\n\n\n##### Table of contents\n\n- [ Cheshire Cat and Qdrant ](https://qdrant.tech/documentation/frameworks/cheshire-cat/#cheshire-cat-and-qdrant)\n- [ How to use the Cheshire Cat ](https://qdrant.tech/documentation/frameworks/cheshire-cat/#how-to-use-the-cheshire-cat)\n    - [ Requirements ](https://qdrant.tech/documentation/frameworks/cheshire-cat/#requirements)\n\n- [ First configuration of the LLM ](https://qdrant.tech/documentation/frameworks/cheshire-cat/#first-configuration-of-the-llm)\n- [ Next steps ](https://qdrant.tech/documentation/frameworks/cheshire-cat/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/cheshire-cat.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/fifty-one/": "# FiftyOne\n\n[ FiftyOne ](https://voxel51.com/)is an open-source toolkit designed to enhance computer vision workflows by optimizing dataset quality\nand providing valuable insights about your models. FiftyOne 0.20, which includes a native integration with Qdrant, supporting workflows\nlike[ image similarity search ](https://docs.voxel51.com/user_guide/brain.html#image-similarity)and[ text search ](https://docs.voxel51.com/user_guide/brain.html#text-similarity).\n\nQdrant helps FiftyOne to find the most similar images in the dataset using vector embeddings.\n\nFiftyOne is available as a Python package that might be installed in the following way:\n\n`pip install fiftyone\n`\n\nPlease check out the documentation of FiftyOne on[ Qdrant integration ](https://docs.voxel51.com/integrations/qdrant.html).\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/airbyte/": "# Airbyte\n\n[ Airbyte ](https://airbyte.com/)is an open-source data integration platform that helps you replicate your data\nbetween different systems. It has a[ growing list of connectors ](https://docs.airbyte.io/integrations)that can\nbe used to ingest data from multiple sources. Building data pipelines is also crucial for managing the data in\nQdrant, and Airbyte is a great tool for this purpose.\n\nAirbyte may take care of the data ingestion from a selected source, while Qdrant will help you to build a search\nengine on top of it. There are three supported modes of how the data can be ingested into Qdrant:\n\n- **Full Refresh Sync**\n- **Incremental - Append Sync**\n- **Incremental - Append + Deduped**\n\n\nYou can read more about these modes in the[ Airbyte documentation ](https://docs.airbyte.io/integrations/destinations/qdrant).\n\n## Prerequisites\n\nBefore you start, make sure you have the following:\n\n1. Airbyte instance, either[ Open Source ](https://airbyte.com/solutions/airbyte-open-source),[ Self-Managed ](https://airbyte.com/solutions/airbyte-enterprise), or[ Cloud ](https://airbyte.com/solutions/airbyte-cloud).\n2. Running instance of Qdrant. It has to be accessible by URL from the machine where Airbyte is running.\nYou can follow the[ installation guide ](https://qdrant.tech/documentation/guides/installation/)to set up Qdrant.\n\n\n## Setting up Qdrant as a destination\n\nOnce you have a running instance of Airbyte, you can set up Qdrant as a destination directly in the UI.\nAirbyte\u2019s Qdrant destination is connected with a single collection in Qdrant.\n\nImage: [ Airbyte Qdrant destination ](https://qdrant.tech/documentation/frameworks/airbyte/qdrant-destination.png)\n\nImage: [ Airbyte Qdrant destination ](https://qdrant.tech/documentation/frameworks/airbyte/qdrant-destination.png)\n\n### Text processing\n\nAirbyte has some built-in mechanisms to transform your texts into embeddings. You can choose how you want to\nchunk your fields into pieces before calculating the embeddings, but also which fields should be used to\ncreate the point payload.\n\nImage: [ Processing settings ](https://qdrant.tech/documentation/frameworks/airbyte/processing.png)\n\nImage: [ Processing settings ](https://qdrant.tech/documentation/frameworks/airbyte/processing.png)\n\n### Embeddings\n\nYou can choose the model that will be used to calculate the embeddings. Currently, Airbyte supports multiple\nmodels, including OpenAI and Cohere.\n\nImage: [ Embeddings settings ](https://qdrant.tech/documentation/frameworks/airbyte/embedding.png)\n\nImage: [ Embeddings settings ](https://qdrant.tech/documentation/frameworks/airbyte/embedding.png)\n\nUsing some precomputed embeddings from your data source is also possible. In this case, you can pass the field\nname containing the embeddings and their dimensionality.\n\nImage: [ Precomputed embeddings settings ](https://qdrant.tech/documentation/frameworks/airbyte/precomputed-embedding.png)\n\nImage: [ Precomputed embeddings settings ](https://qdrant.tech/documentation/frameworks/airbyte/precomputed-embedding.png)\n\n### Qdrant connection details\n\nFinally, we can configure the target Qdrant instance and collection. In case you use the built-in authentication\nmechanism, here is where you can pass the token.\n\nImage: [ Qdrant connection details ](https://qdrant.tech/documentation/frameworks/airbyte/qdrant-config.png)\n\nImage: [ Qdrant connection details ](https://qdrant.tech/documentation/frameworks/airbyte/qdrant-config.png)\n\nOnce you confirm creating the destination, Airbyte will test if a specified Qdrant cluster is accessible and\nmight be used as a destination.\n\n## Setting up connection\n\nAirbyte combines sources and destinations into a single entity called a connection. Once you have a destination\nconfigured and a source, you can create a connection between them. It doesn\u2019t matter what source you use, as\nlong as Airbyte supports it. The process is pretty straightforward, but depends on the source you use.\n\nImage: [ Airbyte connection ](https://qdrant.tech/documentation/frameworks/airbyte/connection.png)\n\nImage: [ Airbyte connection ](https://qdrant.tech/documentation/frameworks/airbyte/connection.png)\n\nMore information about creating connections can be found in the[ Airbyte documentation ](https://docs.airbyte.com/understanding-airbyte/connections/).\n\n##### Table of contents\n\n- [ Prerequisites ](https://qdrant.tech/documentation/frameworks/airbyte/#prerequisites)\n- [ Setting up Qdrant as a destination ](https://qdrant.tech/documentation/frameworks/airbyte/#setting-up-qdrant-as-a-destination)\n    - [ Text processing ](https://qdrant.tech/documentation/frameworks/airbyte/#text-processing)\n\n- [ Embeddings ](https://qdrant.tech/documentation/frameworks/airbyte/#embeddings)\n\n- [ Qdrant connection details ](https://qdrant.tech/documentation/frameworks/airbyte/#qdrant-connection-details)\n- [ Setting up connection ](https://qdrant.tech/documentation/frameworks/airbyte/#setting-up-connection)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/airbyte.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/mindsdb/": "# MindsDB\n\n[ MindsDB ](https://mindsdb.com)is an AI automation platform for building AI/ML powered features and applications. It works by connecting any source of data with any AI/ML model or framework and automating how real-time data flows between them.\n\nWith the MindsDB-Qdrant integration, you can now select Qdrant as a database to load into and retrieve from with semantic search and filtering.\n\n **MindsDB allows you to easily** :\n\n- Connect to any store of data or end-user application.\n- Pass data to an AI model from any store of data or end-user application.\n- Plug the output of an AI model into any store of data or end-user application.\n- Fully automate these workflows to build AI-powered features and applications\n\n\n## Usage\n\nTo get started with Qdrant and MindsDB, the following syntax can be used.\n\n```\nCREATE   DATABASE   qdrant_test \n\nWITH   ENGINE   =   \"qdrant\" , \n\nPARAMETERS   =   { \n\n     \"location\" :   \":memory:\" , \n\n     \"collection_config\" :   { \n\n         \"size\" :   386 , \n\n         \"distance\" :   \"Cosine\" \n\n     } \n\n} \n\n```\n\nThe available arguments for instantiating Qdrant can be found[ here ](https://github.com/mindsdb/mindsdb/blob/23a509cb26bacae9cc22475497b8644e3f3e23c3/mindsdb/integrations/handlers/qdrant_handler/qdrant_handler.py#L408-L468).\n\n## Creating a new table\n\n- Qdrant options for creating a collection can be specified as `collection_config` in the `CREATE DATABASE` parameters.\n- By default, UUIDs are set as collection IDs. You can provide your own IDs under the `id` column.\n\n\n```\nCREATE   TABLE   qdrant_test.test_table   ( \n\n    SELECT   embeddings, '{\"source\": \"bbc\"}'   as   metadata   FROM   mysql_demo_db.test_embeddings \n\n); \n\n```\n\n## Querying the database\n\n#### Perform a full retrieval using the following syntax.\n\n`SELECT   *   FROM   qdrant_test.test_table \n`\n\nBy default, the `LIMIT` is set to 10 and the `OFFSET` is set to 0.\n\n#### Perform a similarity search using your embeddings\n\n```\nSELECT   *   FROM   qdrant_test.test_table \n\nWHERE   search_vector   =   ( select   embeddings   from   mysql_demo_db.test_embeddings   limit   1 ) \n\n```\n\n#### Perform a search using filters\n\n```\nSELECT   *   FROM   qdrant_test.test_table \n\nWHERE   ` metadata. source `   =   'bbc' ; \n\n```\n\n#### Delete entries using IDs\n\n```\nDELETE   FROM   qtest.test_table_6 \n\nWHERE   id   =   2 \n\n```\n\n#### Delete entries using filters\n\n```\nDELETE   *   FROM   qdrant_test.test_table \n\nWHERE   ` metadata. source `   =   'bbc' ; \n\n```\n\n#### Drop a table\n\n`  DROP   TABLE   qdrant_test.test_table; \n`\n\n## Next steps\n\nYou can find more information pertaining to MindsDB and its datasources[ here ](https://docs.mindsdb.com/).\n\n##### Table of contents\n\n- [ Usage ](https://qdrant.tech/documentation/frameworks/mindsdb/#usage)\n- [ Creating a new table ](https://qdrant.tech/documentation/frameworks/mindsdb/#creating-a-new-table)\n- [ Querying the database ](https://qdrant.tech/documentation/frameworks/mindsdb/#querying-the-database)\n    -\n\n- \n- [ Next steps ](https://qdrant.tech/documentation/frameworks/mindsdb/#next-steps)\n\n\n\n- \n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/mindsdb.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/autogen/": "# Microsoft Autogen\n\n[ AutoGen ](https://github.com/microsoft/autogen)is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks. AutoGen agents are customizable, conversable, and seamlessly allow human participation. They can operate in various modes that employ combinations of LLMs, human inputs, and tools.\n\n- Multi-agent conversations: AutoGen agents can communicate with each other to solve tasks. This allows for more complex and sophisticated applications than would be possible with a single LLM.\n- Customization: AutoGen agents can be customized to meet the specific needs of an application. This includes the ability to choose the LLMs to use, the types of human input to allow, and the tools to employ.\n- Human participation: AutoGen seamlessly allows human participation. This means that humans can provide input and feedback to the agents as needed.\n\n\nWith the Autogen-Qdrant integration, you can use the `QdrantRetrieveUserProxyAgent` from autogen to build retrieval augmented generation(RAG) services with ease.\n\n## Installation\n\n`pip install  \"pyautogen[retrievechat]\"   \"qdrant_client[fastembed]\" \n`\n\n## Usage\n\nA demo application that generates code based on context w/o human feedback\n\n#### Set your API Endpoint\n\nThe config_list_from_json function loads a list of configurations from an environment variable or a JSON file.\n\n```\nfrom   autogen   import  config_list_from_json\n\nfrom   autogen.agentchat.contrib.retrieve_assistant_agent   import  RetrieveAssistantAgent\n\nfrom   autogen.agentchat.contrib.qdrant_retrieve_user_proxy_agent   import  QdrantRetrieveUserProxyAgent\n\nfrom   qdrant_client   import  QdrantClient\n\n\n\nconfig_list  =  config_list_from_json(\n\n    env_or_file = \"OAI_CONFIG_LIST\" ,\n\n    file_location = \".\" \n\n)\n\n```\n\nIt first looks for the environment variable \u201cOAI_CONFIG_LIST\u201d which needs to be a valid JSON string. If that variable is not found, it then looks for a JSON file named \u201cOAI_CONFIG_LIST\u201d. The file structure sample can be found[ here ](https://github.com/microsoft/autogen/blob/main/OAI_CONFIG_LIST_sample).\n\n#### Construct agents for RetrieveChat\n\nWe start by initializing the RetrieveAssistantAgent and QdrantRetrieveUserProxyAgent. The system message needs to be set to \u201cYou are a helpful assistant.\u201d for RetrieveAssistantAgent. The detailed instructions are given in the user message.\n\n```\n# Print the generation steps \n\nautogen . ChatCompletion . start_logging()\n\n\n\n# 1. create a RetrieveAssistantAgent instance named \"assistant\" \n\nassistant  =  RetrieveAssistantAgent(\n\n    name = \"assistant\" ,\n\n    system_message = \"You are a helpful assistant.\" ,\n\n    llm_config = {\n\n         \"request_timeout\" :  600 ,\n\n         \"seed\" :  42 ,\n\n         \"config_list\" : config_list,\n\n    },\n\n)\n\n\n\n# 2. create a QdrantRetrieveUserProxyAgent instance named \"qdrantagent\" \n\n# By default, the human_input_mode is \"ALWAYS\", i.e. the agent will ask for human input at every step. \n\n# `docs_path` is the path to the docs directory. \n\n# `task` indicates the kind of task we're working on. \n\n# `chunk_token_size` is the chunk token size for the retrieve chat. \n\n# We use an in-memory QdrantClient instance here. Not recommended for production. \n\n\n\nragproxyagent  =  QdrantRetrieveUserProxyAgent(\n\n    name = \"qdrantagent\" ,\n\n    human_input_mode = \"NEVER\" ,\n\n    max_consecutive_auto_reply = 10 ,\n\n    retrieve_config = {\n\n         \"task\" :  \"code\" ,\n\n         \"docs_path\" :  \"./path/to/docs\" ,\n\n         \"chunk_token_size\" :  2000 ,\n\n         \"model\" : config_list[ 0 ][ \"model\" ],\n\n         \"client\" : QdrantClient( \":memory:\" ),\n\n         \"embedding_model\" :  \"BAAI/bge-small-en-v1.5\" ,\n\n    },\n\n)\n\n```\n\n#### Run the retriever service\n\n```\n# Always reset the assistant before starting a new conversation. \n\nassistant . reset()\n\n\n\n# We use the ragproxyagent to generate a prompt to be sent to the assistant as the initial message. \n\n# The assistant receives the message and generates a response. The response will be sent back to the ragproxyagent for processing. \n\n# The conversation continues until the termination condition is met, in RetrieveChat, the termination condition when no human-in-loop is no code block detected. \n\n\n\n# The query used below is for demonstration. It should usually be related to the docs made available to the agent \n\ncode_problem  =   \"How can I use FLAML to perform a classification task?\" \n\nragproxyagent . initiate_chat(assistant, problem = code_problem)\n\n```\n\n## Next steps\n\nCheck out more Autogen[ examples ](https://microsoft.github.io/autogen/docs/Examples). You can find detailed documentation about AutoGen[ here ](https://microsoft.github.io/autogen/).\n\n##### Table of contents\n\n- [ Installation ](https://qdrant.tech/documentation/frameworks/autogen/#installation)\n- [ Usage ](https://qdrant.tech/documentation/frameworks/autogen/#usage)\n    -\n\n- \n- [ Next steps ](https://qdrant.tech/documentation/frameworks/autogen/#next-steps)\n\n\n\n- \n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/autogen.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/dlt/": "# DLT(Data Load Tool)\n\n[ DLT ](https://dlthub.com/)is an open-source library that you can add to your Python scripts to load data from various and often messy data sources into well-structured, live datasets.\n\nWith the DLT-Qdrant integration, you can now select Qdrant as a DLT destination to load data into.\n\n **DLT Enables** \n\n- Automated maintenance - with schema inference, alerts and short declarative code, maintenance becomes simple.\n- Run it where Python runs - on Airflow, serverless functions, notebooks. Scales on micro and large infrastructure alike.\n- User-friendly, declarative interface that removes knowledge obstacles for beginners while empowering senior professionals.\n\n\n## Usage\n\nTo get started, install `dlt` with the `qdrant` extra.\n\n`pip install  \"dlt[qdrant]\" \n`\n\nConfigure the destination in the DLT secrets file. The file is located at `~/.dlt/secrets.toml` by default. Add the following section to the secrets file.\n\n```\n[destination.qdrant.credentials]\n\nlocation =  \"https://your-qdrant-url\" \n\napi_key =  \"your-qdrant-api-key\" \n\n```\n\nThe location will default to `http://localhost:6333` and `api_key` is not defined - which are the defaults for a local Qdrant instance.\nFind more information about DLT configurations[ here ](https://dlthub.com/docs/general-usage/credentials).\n\nDefine the source of the data.\n\n```\nimport   dlt \n\nfrom   dlt.destinations.qdrant   import  qdrant_adapter\n\n\n\nmovies  =  [\n\n    {\n\n         \"title\" :  \"Blade Runner\" ,\n\n         \"year\" :  1982 ,\n\n         \"description\" :  \"The film is about a dystopian vision of the future that combines noir elements with sci-fi imagery.\" \n\n    },\n\n    {\n\n         \"title\" :  \"Ghost in the Shell\" ,\n\n         \"year\" :  1995 ,\n\n         \"description\" :  \"The film is about a cyborg policewoman and her partner who set out to find the main culprit behind brain hacking, the Puppet Master.\" \n\n    },\n\n    {\n\n         \"title\" :  \"The Matrix\" ,\n\n         \"year\" :  1999 ,\n\n         \"description\" :  \"The movie is set in the 22nd century and tells the story of a computer hacker who joins an underground group fighting the powerful computers that rule the earth.\" \n\n    }\n\n]\n\n```\n\nDefine the pipeline.\n\n```\npipeline  =  dlt . pipeline(\n\n    pipeline_name = \"movies\" ,\n\n    destination = \"qdrant\" ,\n\n    dataset_name = \"movies_dataset\" ,\n\n)\n\n```\n\nRun the pipeline.\n\n```\ninfo  =  pipeline . run(\n\n    qdrant_adapter(\n\n        movies,\n\n        embed = [ \"title\" ,  \"description\" ]\n\n    )\n\n)\n\n```\n\nThe data is now loaded into Qdrant.\n\nTo use vector search after the data has been loaded, you must specify which fields Qdrant needs to generate embeddings for. You do that by wrapping the data (or[ DLT resource ](https://dlthub.com/docs/general-usage/resource)) with the `qdrant_adapter` function.\n\n## Write disposition\n\nA DLT[ write disposition ](https://dlthub.com/docs/dlt-ecosystem/destinations/qdrant/#write-disposition)defines how the data should be written to the destination. All write dispositions are supported by the Qdrant destination.\n\n## DLT Sync\n\nQdrant destination supports syncing of the[ DLT state ](https://dlthub.com/docs/general-usage/state#syncing-state-with-destination).\n\n## Next steps\n\n- The comprehensive Qdrant DLT destination documentation can be found[ here ](https://dlthub.com/docs/dlt-ecosystem/destinations/qdrant/).\n\n\n##### Table of contents\n\n- [ Usage ](https://qdrant.tech/documentation/frameworks/dlt/#usage)\n- [ Write disposition ](https://qdrant.tech/documentation/frameworks/dlt/#write-disposition)\n- [ DLT Sync ](https://qdrant.tech/documentation/frameworks/dlt/#dlt-sync)\n- [ Next steps ](https://qdrant.tech/documentation/frameworks/dlt/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/dlt.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/spark/": "# Apache Spark\n\n[ Spark ](https://spark.apache.org/)is a leading distributed computing framework that empowers you to work with massive datasets efficiently. When it comes to leveraging the power of Spark for your data processing needs, the[ Qdrant-Spark Connector ](https://github.com/qdrant/qdrant-spark)is to be considered. This connector enables Qdrant to serve as a storage destination in Spark, offering a seamless bridge between the two.\n\n## Installation\n\nYou can set up the Qdrant-Spark Connector in a few different ways, depending on your preferences and requirements.\n\n### GitHub Releases\n\nThe simplest way to get started is by downloading pre-packaged JAR file releases from the[ Qdrant-Spark GitHub releases page ](https://github.com/qdrant/qdrant-spark/releases). These JAR files come with all the necessary dependencies to get you going.\n\n### Building from Source\n\nIf you prefer to build the JAR from source, you\u2019ll need[ JDK 17 ](https://www.oracle.com/java/technologies/javase/jdk17-archive-downloads.html)and[ Maven ](https://maven.apache.org/)installed on your system. Once you have the prerequisites in place, navigate to the project\u2019s root directory and run the following command:\n\n`mvn package -P assembly\n`\n\nThis command will compile the source code and generate a fat JAR, which will be stored in the `target` directory by default.\n\n### Maven Central\n\nFor Java and Scala projects, you can also obtain the Qdrant-Spark Connector from[ Maven Central ](https://central.sonatype.com/artifact/io.qdrant/spark).\n\n```\n<dependency> \n\n     <groupId> io.qdrant </groupId> \n\n     <artifactId> spark </artifactId> \n\n     <version> 1.6 </version> \n\n</dependency> \n\n```\n\n## Getting Started\n\nAfter successfully installing the Qdrant-Spark Connector, you can start integrating Qdrant with your Spark applications. Below, we\u2019ll walk through the basic steps of creating a Spark session with Qdrant support and loading data into Qdrant.\n\n### Creating a single-node Spark session with Qdrant Support\n\nTo begin, import the necessary libraries and create a Spark session with Qdrant support. Here\u2019s how:\n\n```\nfrom   pyspark.sql   import  SparkSession\n\n\n\nspark  =  SparkSession . builder . config(\n\n         \"spark.jars\" ,\n\n         \"spark-1.0-assembly.jar\" ,   # Specify the downloaded JAR file \n\n    )\n\n     . master( \"local[*]\" )\n\n     . appName( \"qdrant\" )\n\n     . getOrCreate()\n\n```\n\n```\nimport   org.apache.spark.sql.SparkSession \n\n\n\nval  spark  =   SparkSession . builder\n\n   . config ( \"spark.jars\" ,   \"spark-1.0-assembly.jar\" )   // Specify the downloaded JAR file\n\n   . master ( \"local[*]\" ) \n\n   . appName ( \"qdrant\" ) \n\n   . getOrCreate () \n\n```\n\n```\nimport   org.apache.spark.sql.SparkSession ; \n\n\n\npublic   class   QdrantSparkJavaExample   { \n\n     public   static   void   main ( String []  args )   { \n\n        SparkSession spark  =  SparkSession . builder () \n\n                 . config ( \"spark.jars\" ,   \"spark-1.0-assembly.jar\" )   // Specify the downloaded JAR file\n\n                 . master ( \"local[*]\" ) \n\n                 . appName ( \"qdrant\" ) \n\n                 . getOrCreate (); \n\n         ... \n\n     } \n\n} \n\n```\n\n### Loading Data into Qdrant\n\nHere\u2019s how you can use the Qdrant-Spark Connector to upsert data:\n\n```\n< YourDataFrame > \n\n     . write\n\n     . format( \"io.qdrant.spark.Qdrant\" )\n\n     . option( \"qdrant_url\" ,  < QDRANT_URL > )   # REST URL of the Qdrant instance \n\n     . option( \"collection_name\" ,  < QDRANT_COLLECTION_NAME > )   # Name of the collection to write data into \n\n     . option( \"embedding_field\" ,  < EMBEDDING_FIELD_NAME > )   # Name of the field holding the embeddings \n\n     . option( \"schema\" ,  < YourDataFrame >. schema . json())   # JSON string of the dataframe schema \n\n     . mode( \"append\" )\n\n     . save()\n\n```\n\n```\n< YourDataFrame > \n\n     . write\n\n     . format ( \"io.qdrant.spark.Qdrant\" ) \n\n     . option ( \"qdrant_url\" ,   QDRANT_URL )   // REST URL of the Qdrant instance\n\n     . option ( \"collection_name\" ,   QDRANT_COLLECTION_NAME )   // Name of the collection to write data into\n\n     . option ( \"embedding_field\" ,   EMBEDDING_FIELD_NAME )   // Name of the field holding the embeddings\n\n     . option ( \"schema\" ,   < YourDataFrame >. schema . json ())   // JSON string of the dataframe schema\n\n     . mode ( \"append\" ) \n\n     . save () \n\n```\n\n```\n< YourDataFrame > \n\n     . write () \n\n     . format ( \"io.qdrant.spark.Qdrant\" ) \n\n     . option ( \"qdrant_url\" ,  QDRANT_URL )   // REST URL of the Qdrant instance\n\n     . option ( \"collection_name\" ,  QDRANT_COLLECTION_NAME )   // Name of the collection to write data into\n\n     . option ( \"embedding_field\" ,  EMBEDDING_FIELD_NAME )   // Name of the field holding the embeddings\n\n     . option ( \"schema\" ,   < YourDataFrame >. schema (). json ())   // JSON string of the dataframe schema\n\n     . mode ( \"append\" ) \n\n     . save (); \n\n```\n\n## Datatype Support\n\nQdrant supports all the Spark data types, and the appropriate data types are mapped based on the provided schema.\n\n## Options and Spark Types\n\nThe Qdrant-Spark Connector provides a range of options to fine-tune your data integration process. Here\u2019s a quick reference:\n\n| Option | Description | DataType | Required |\n|---|---|---|---|\n|  `qdrant_url`  | REST URL of the Qdrant instance |  `StringType`  | \u2705 |\n|  `collection_name`  | Name of the collection to write data into |  `StringType`  | \u2705 |\n|  `embedding_field`  | Name of the field holding the embeddings |  `ArrayType(FloatType)`  | \u2705 |\n|  `schema`  | JSON string of the dataframe schema |  `StringType`  | \u2705 |\n|  `mode`  | Write mode of the dataframe |  `StringType`  | \u2705 |\n|  `id_field`  | Name of the field holding the point IDs. Default: A random UUID is generated |  `StringType`  | \u274c |\n|  `batch_size`  | Max size of the upload batch. Default: 100 |  `IntType`  | \u274c |\n|  `retries`  | Number of upload retries. Default: 3 |  `IntType`  | \u274c |\n|  `api_key`  | Qdrant API key for authenticated requests. Default: null |  `StringType`  | \u274c |\n\n\nFor more information, be sure to check out the[ Qdrant-Spark GitHub repository ](https://github.com/qdrant/qdrant-spark). The Apache Spark guide is available[ here ](https://spark.apache.org/docs/latest/quick-start.html). Happy data processing!\n\n##### Table of contents\n\n- [ Installation ](https://qdrant.tech/documentation/frameworks/spark/#installation)\n    - [ GitHub Releases ](https://qdrant.tech/documentation/frameworks/spark/#github-releases)\n\n- [ Building from Source ](https://qdrant.tech/documentation/frameworks/spark/#building-from-source)\n\n- [ Maven Central ](https://qdrant.tech/documentation/frameworks/spark/#maven-central)\n- [ Getting Started ](https://qdrant.tech/documentation/frameworks/spark/#getting-started)\n    - [ Creating a single-node Spark session with Qdrant Support ](https://qdrant.tech/documentation/frameworks/spark/#creating-a-single-node-spark-session-with-qdrant-support)\n\n- [ Loading Data into Qdrant ](https://qdrant.tech/documentation/frameworks/spark/#loading-data-into-qdrant)\n- [ Datatype Support ](https://qdrant.tech/documentation/frameworks/spark/#datatype-support)\n- [ Options and Spark Types ](https://qdrant.tech/documentation/frameworks/spark/#options-and-spark-types)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/spark.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/dspy/": "# Stanford DSPy\n\n[ DSPy ](https://github.com/stanfordnlp/dspy)is the framework for solving advanced tasks with language models (LMs) and retrieval models (RMs). It unifies techniques for prompting and fine-tuning LMs \u2014 and approaches for reasoning, self-improvement, and augmentation with retrieval and tools.\n\n- Provides composable and declarative modules for instructing LMs in a familiar Pythonic syntax.\n- Introduces an automatic compiler that teaches LMs how to conduct the declarative steps in your program.\n\n\nProvides composable and declarative modules for instructing LMs in a familiar Pythonic syntax.\n\nIntroduces an automatic compiler that teaches LMs how to conduct the declarative steps in your program.\n\nQdrant can be used as a retrieval mechanism in the DSPy flow.\n\n## Installation\n\nFor the Qdrant retrieval integration, include `dspy-ai` with the `qdrant` extra:\n\n`pip install dspy-ai [ qdrant ] \n`\n\n## Usage\n\nWe can configure `DSPy` settings to use the Qdrant retriever model like so:\n\n```\nimport   dspy \n\nfrom   dspy.retrieve.qdrant_rm   import  QdrantRM\n\n\n\nfrom   qdrant_client   import  QdrantClient\n\n\n\nturbo  =  dspy . OpenAI(model = \"gpt-3.5-turbo\" )\n\nqdrant_client  =  QdrantClient()   # Defaults to a local instance at http://localhost:6333/ \n\nqdrant_retriever_model  =  QdrantRM( \"collection-name\" , qdrant_client, k = 3 )\n\n\n\ndspy . settings . configure(lm = turbo, rm = qdrant_retriever_model)\n\n```\n\nUsing the retriever is pretty simple. The `dspy.Retrieve(k)` module will search for the top-k passages that match a given query.\n\n```\nretrieve  =  dspy . Retrieve(k = 3 )\n\nquestion  =   \"Some question about my data\" \n\ntopK_passages  =  retrieve(question) . passages\n\n\n\nprint ( f \"Top  { retrieve . k }  passages for question:  { question }   \\n \" ,  \" \\n \" )\n\n\n\nfor  idx, passage  in   enumerate (topK_passages):\n\n     print ( f \" { idx + 1 } ]\" , passage,  \" \\n \" )\n\n```\n\nWith Qdrant configured as the retriever for contexts, you can set up a DSPy module like so:\n\n```\nclass   RAG (dspy . Module):\n\n     def  __init__(self, num_passages = 3 ):\n\n         super () . __init__()\n\n\n\n        self . retrieve  =  dspy . Retrieve(k = num_passages)\n\n         ... \n\n\n\n     def   forward (self, question):\n\n        context  =  self . retrieve(question) . passages\n\n         ... \n\n```\n\nWith the generic RAG blueprint now in place, you can add the many interactions offered by DSPy with context retrieval powered by Qdrant.\n\n## Next steps\n\nFind DSPy usage docs and examples[ here ](https://github.com/stanfordnlp/dspy#4-documentation--tutorials).\n\n##### Table of contents\n\n- [ Installation ](https://qdrant.tech/documentation/frameworks/dspy/#installation)\n- [ Usage ](https://qdrant.tech/documentation/frameworks/dspy/#usage)\n- [ Next steps ](https://qdrant.tech/documentation/frameworks/dspy/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/dspy.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/privategpt/": "# PrivateGPT\n\n[ PrivateGPT ](https://docs.privategpt.dev/)is a production-ready AI project that allows you to inquire about your documents using Large Language Models (LLMs) with offline support.\n\nPrivateGPT uses Qdrant as the default vectorstore for ingesting and retrieving documents.\n\n## Configuration\n\nQdrant settings can be configured by setting values to the qdrant property in the `settings.yaml` file. By default, Qdrant tries to connect to an instance at http://localhost:3000.\n\nExample:\n\n```\nqdrant : \n\n     url :   \"https://xyz-example.eu-central.aws.cloud.qdrant.io:6333\" \n\n     api_key :   \"<your-api-key>\" \n\n```\n\nThe available[ configuration options ](https://docs.privategpt.dev/manual/storage/vector-stores#qdrant-configuration)are:\n\n| Field | Description |\n|---|---|\n| location | If `:memory:` - use in-memory Qdrant instance.\nIf `str` - use it as a `url` parameter. |\n| url | Either host or str of `Optional[scheme], host, Optional[port], Optional[prefix]` .\nEg. `http://localhost:6333`  |\n| port | Port of the REST API interface. Default: `6333`  |\n| grpc_port | Port of the gRPC interface. Default: `6334`  |\n| prefer_grpc | If `true` - use gRPC interface whenever possible in custom methods. |\n| https | If `true` - use HTTPS(SSL) protocol. |\n| api_key | API key for authentication in Qdrant Cloud. |\n| prefix | If set, add `prefix` to the REST URL path.\nExample: `service/v1` will result in `http://localhost:6333/service/v1/{qdrant-endpoint}` for REST API. |\n| timeout | Timeout for REST and gRPC API requests.\nDefault: 5.0 seconds for REST and unlimited for gRPC |\n| host | Host name of Qdrant service. If url and host are not set, defaults to \u2019localhost'. |\n| path | Persistence path for QdrantLocal. Eg. `local_data/private_gpt/qdrant`  |\n| force_disable_check_same_thread | Force disable check_same_thread for QdrantLocal sqlite connection. |\n\n\n## Next steps\n\nFind the PrivateGPT docs[ here ](https://docs.privategpt.dev/).\n\n##### Table of contents\n\n- [ Configuration ](https://qdrant.tech/documentation/frameworks/privategpt/#configuration)\n- [ Next steps ](https://qdrant.tech/documentation/frameworks/privategpt/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/privategpt.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/fondant/": "# ML6 Fondant\n\n[ Fondant ](https://fondant.ai/en/stable/)is an open-source framework that aims to simplify and speed up large-scale data processing by making containerized components reusable across pipelines and execution environments.\n\nFondant features a Qdrant component image to load textual data and embeddings into a the database.\n\n## Usage\n\n **A data load pipeline for RAG using Qdrant** .\n\n```\nfrom   fondant.pipeline   import  ComponentOp, Pipeline\n\n\n\npipeline  =  Pipeline(\n\n    pipeline_name = \"ingestion-pipeline\" ,\n\n    pipeline_description = \"Pipeline to prepare and process  \\\n\n    data for building a RAG solution\" ,\n\n    base_path = \"./data-dir\" ,\n\n)\n\n\n\n# An example data source component \n\nload_from_source  =  ComponentOp(\n\n    component_dir = \"path/to/data-source-component\" ,\n\n    arguments = {\n\n         \"n_rows_to_load\" :  10 ,\n\n         # Custom arguments for the component \n\n    },\n\n)\n\n\n\nchunk_text_op  =  ComponentOp . from_registry(\n\n    name = \"chunk_text\" ,\n\n    arguments = {\n\n         \"chunk_size\" :  512 ,\n\n         \"chunk_overlap\" :  32 ,\n\n    },\n\n)\n\n\n\nembed_text_op  =  ComponentOp . from_registry(\n\n    name = \"embed_text\" ,\n\n    arguments = {\n\n         \"model_provider\" :  \"huggingface\" ,\n\n         \"model\" :  \"all-MiniLM-L6-v2\" ,\n\n    },\n\n)\n\n\n\n# Getting the Qdrant component from the Fondant registry \n\nindex_qdrant_op  =  ComponentOp . from_registry(\n\n    name = \"index_qdrant\" ,\n\n    arguments = {\n\n         \"url\" :  \"http:localhost:6333\" ,\n\n         \"collection_name\" :  \"some-collection-name\" ,\n\n    },\n\n)\n\n\n\n# Construct your pipeline \n\npipeline . add_op(load_from_source)\n\npipeline . add_op(chunk_text_op, dependencies = load_from_source)\n\npipeline . add_op(embed_text_op, dependencies = chunk_text_op)\n\npipeline . add_op(index_qdrant_op, dependencies = embed_text_op)\n\n```\n\n## Next steps\n\nFind the FondantAI docs[ here ](https://fondant.ai/en/stable/).\n\n##### Table of contents\n\n- [ Usage ](https://qdrant.tech/documentation/frameworks/fondant/#usage)\n- [ Next steps ](https://qdrant.tech/documentation/frameworks/fondant/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/fondant.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/frameworks/make/": "# Make.com\n\n[ Make ](https://www.make.com/)is a platform for anyone to design, build, and automate anything\u2014from tasks and workflows to apps and systems without code.\n\nFind the comprehensive list of available Make apps[ here ](https://www.make.com/en/integrations).\n\nQdrant is available as an[ app ](https://www.make.com/en/integrations/qdrant)within Make to add to your scenarios.\n\nImage: [ Qdrant Make hero ](https://qdrant.tech/documentation/integrations/make/hero-page.png)\n\nImage: [ Qdrant Make hero ](https://qdrant.tech/documentation/integrations/make/hero-page.png)\n\n## Prerequisites\n\nBefore you start, make sure you have the following:\n\n1. A Qdrant instance to connect to. You can get free cloud instance[ cloud.qdrant.io ](https://cloud.qdrant.io/).\n2. An account at Make.com. You can register yourself[ here ](https://www.make.com/en/register).\n\n\n## Setting up a connection\n\nNavigate to your scenario on the Make dashboard and select a Qdrant app module to start a connection.Image: [ Qdrant Make connection ](https://qdrant.tech/documentation/integrations/make/connection.png)\n\nImage: [ Qdrant Make connection ](https://qdrant.tech/documentation/integrations/make/connection.png)\n\nYou can now establish a connection to Qdrant using your[ instance credentials ](https://qdrant.tech/documentation/cloud/authentication/).\n\nImage: [ Qdrant Make form ](https://qdrant.tech/documentation/integrations/make/connection-form.png)\n\nImage: [ Qdrant Make form ](https://qdrant.tech/documentation/integrations/make/connection-form.png)\n\n## Modules\n\nModules represent actions that Make performs with an app.\n\nThe Qdrant Make app enables you to trigger the following app modules.Image: [ Qdrant Make modules ](https://qdrant.tech/documentation/integrations/make/modules.png)\n\nImage: [ Qdrant Make modules ](https://qdrant.tech/documentation/integrations/make/modules.png)\n\nThe modules support mapping to connect the data retrieved by one module to another module to perform the desired action. You can read more about the data processing options available for the modules in the[ Make reference ](https://www.make.com/en/help/modules).\n\n## Next steps\n\n- Find a list of Make workflow templates to connect with Qdrant[ here ](https://www.make.com/en/templates).\n- Make scenario reference docs can be found[ here ](https://www.make.com/en/help/scenarios).\n\n\nFind a list of Make workflow templates to connect with Qdrant[ here ](https://www.make.com/en/templates).\n\nMake scenario reference docs can be found[ here ](https://www.make.com/en/help/scenarios).\n\n##### Table of contents\n\n- [ Prerequisites ](https://qdrant.tech/documentation/frameworks/make/#prerequisites)\n- [ Setting up a connection ](https://qdrant.tech/documentation/frameworks/make/#setting-up-a-connection)\n- [ Modules ](https://qdrant.tech/documentation/frameworks/make/#modules)\n- [ Next steps ](https://qdrant.tech/documentation/frameworks/make/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/frameworks/make.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/community-links/": "# Community Contributions\n\nThough we do not officially maintain this content, we still feel that is is valuable and thank our dedicated contributors.\n\n| Link | Description | Stack |\n|---|---|---|\n| [ Pinecone to Qdrant Migration ](https://github.com/NirantK/qdrant_tools) | Complete python toolset that supports migration between two products. | Qdrant, Pinecone |\n| [ LlamaIndex Support for Qdrant ](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/QdrantIndexDemo.html) | Documentation on common integrations with LlamaIndex. | Qdrant, LlamaIndex |\n| [ Geo.Rocks Semantic Search Tutorial ](https://geo.rocks/post/qdrant-transformers-js-semantic-search/) | Create a fully working semantic search stack with a built in search API and a minimal stack. | Qdrant, HuggingFace, SentenceTransformers, transformers.js |\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/search-beginners": "# Semantic Search for Beginners\n\n| Time: 5 - 15 min | Level: Beginner |  |  |\n|---|---|---|---|\n\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/AASiqmtKo54)\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/AASiqmtKo54)\n\n## Overview\n\nIf you are new to vector databases, this tutorial is for you. In 5 minutes you will build a semantic search engine for science fiction books. After you set it up, you will ask the engine about an impending alien threat. Your creation will recommend books as preparation for a potential space attack.\n\nBefore you begin, you need to have a[ recent version of Python ](https://www.python.org/downloads/)installed. If you don\u2019t know how to run this code in a virtual environment, follow Python documentation for[ Creating Virtual Environments ](https://docs.python.org/3/tutorial/venv.html#creating-virtual-environments)first.\n\nThis tutorial assumes you\u2019re in the bash shell. Use the Python documentation to activate a virtual environment, with commands such as:\n\n`source  tutorial-env/bin/activate\n`\n\n## 1. Installation\n\nYou need to process your data so that the search engine can work with it. The[ Sentence Transformers ](https://www.sbert.net/)framework gives you access to common Large Language Models that turn raw data into embeddings.\n\n`pip install -U sentence-transformers\n`\n\nOnce encoded, this data needs to be kept somewhere. Qdrant lets you store data as embeddings. You can also use Qdrant to run search queries against this data. This means that you can ask the engine to give you relevant answers that go way beyond keyword matching.\n\n`pip install qdrant-client\n`\n\n### Import the models\n\nOnce the two main frameworks are defined, you need to specify the exact models this engine will use. Before you do, activate the Python prompt ( `>>>` ) with the `python` command.\n\n```\nfrom   qdrant_client   import  models, QdrantClient\n\nfrom   sentence_transformers   import  SentenceTransformer\n\n```\n\nThe[ Sentence Transformers ](https://www.sbert.net/)framework contains many embedding models. However,[ all-MiniLM-L6-v2 ](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)is the fastest encoder for this tutorial.\n\n`encoder  =  SentenceTransformer( \"all-MiniLM-L6-v2\" )\n`\n\n## 2. Add the dataset\n\n[ all-MiniLM-L6-v2 ](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)will encode the data you provide. Here you will list all the science fiction books in your library. Each book has metadata, a name, author, publication year and a short description.\n\n```\ndocuments  =  [\n\n    {\n\n         \"name\" :  \"The Time Machine\" ,\n\n         \"description\" :  \"A man travels through time and witnesses the evolution of humanity.\" ,\n\n         \"author\" :  \"H.G. Wells\" ,\n\n         \"year\" :  1895 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Ender's Game\" ,\n\n         \"description\" :  \"A young boy is trained to become a military leader in a war against an alien race.\" ,\n\n         \"author\" :  \"Orson Scott Card\" ,\n\n         \"year\" :  1985 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Brave New World\" ,\n\n         \"description\" :  \"A dystopian society where people are genetically engineered and conditioned to conform to a strict social hierarchy.\" ,\n\n         \"author\" :  \"Aldous Huxley\" ,\n\n         \"year\" :  1932 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Hitchhiker's Guide to the Galaxy\" ,\n\n         \"description\" :  \"A comedic science fiction series following the misadventures of an unwitting human and his alien friend.\" ,\n\n         \"author\" :  \"Douglas Adams\" ,\n\n         \"year\" :  1979 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Dune\" ,\n\n         \"description\" :  \"A desert planet is the site of political intrigue and power struggles.\" ,\n\n         \"author\" :  \"Frank Herbert\" ,\n\n         \"year\" :  1965 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Foundation\" ,\n\n         \"description\" :  \"A mathematician develops a science to predict the future of humanity and works to save civilization from collapse.\" ,\n\n         \"author\" :  \"Isaac Asimov\" ,\n\n         \"year\" :  1951 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Snow Crash\" ,\n\n         \"description\" :  \"A futuristic world where the internet has evolved into a virtual reality metaverse.\" ,\n\n         \"author\" :  \"Neal Stephenson\" ,\n\n         \"year\" :  1992 ,\n\n    },\n\n    {\n\n         \"name\" :  \"Neuromancer\" ,\n\n         \"description\" :  \"A hacker is hired to pull off a near-impossible hack and gets pulled into a web of intrigue.\" ,\n\n         \"author\" :  \"William Gibson\" ,\n\n         \"year\" :  1984 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The War of the Worlds\" ,\n\n         \"description\" :  \"A Martian invasion of Earth throws humanity into chaos.\" ,\n\n         \"author\" :  \"H.G. Wells\" ,\n\n         \"year\" :  1898 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Hunger Games\" ,\n\n         \"description\" :  \"A dystopian society where teenagers are forced to fight to the death in a televised spectacle.\" ,\n\n         \"author\" :  \"Suzanne Collins\" ,\n\n         \"year\" :  2008 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Andromeda Strain\" ,\n\n         \"description\" :  \"A deadly virus from outer space threatens to wipe out humanity.\" ,\n\n         \"author\" :  \"Michael Crichton\" ,\n\n         \"year\" :  1969 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Left Hand of Darkness\" ,\n\n         \"description\" :  \"A human ambassador is sent to a planet where the inhabitants are genderless and can change gender at will.\" ,\n\n         \"author\" :  \"Ursula K. Le Guin\" ,\n\n         \"year\" :  1969 ,\n\n    },\n\n    {\n\n         \"name\" :  \"The Three-Body Problem\" ,\n\n         \"description\" :  \"Humans encounter an alien civilization that lives in a dying system.\" ,\n\n         \"author\" :  \"Liu Cixin\" ,\n\n         \"year\" :  2008 ,\n\n    },\n\n]\n\n```\n\n## 3. Define storage location\n\nYou need to tell Qdrant where to store embeddings. This is a basic demo, so your local computer will use its memory as temporary storage.\n\n`qdrant  =  QdrantClient( \":memory:\" )\n`\n\n## 4. Create a collection\n\nAll data in Qdrant is organized by collections. In this case, you are storing books, so we are calling it `my_books` .\n\n```\nqdrant . recreate_collection(\n\n    collection_name = \"my_books\" ,\n\n    vectors_config = models . VectorParams(\n\n        size = encoder . get_sentence_embedding_dimension(),   # Vector size is defined by used model \n\n        distance = models . Distance . COSINE,\n\n    ),\n\n)\n\n```\n\n- Use `recreate_collection` if you are experimenting and running the script several times. This function will first try to remove an existing collection with the same name.\n- The `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. 384 is the encoder output dimensionality. You can also use model.get_sentence_embedding_dimension() to get the dimensionality of the model you are using.\n- The `distance` parameter lets you specify the function used to measure the distance between two points.\n\n\nUse `recreate_collection` if you are experimenting and running the script several times. This function will first try to remove an existing collection with the same name.\n\nThe `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. 384 is the encoder output dimensionality. You can also use model.get_sentence_embedding_dimension() to get the dimensionality of the model you are using.\n\nThe `distance` parameter lets you specify the function used to measure the distance between two points.\n\n## 5. Upload data to collection\n\nTell the database to upload `documents` to the `my_books` collection. This will give each record an id and a payload. The payload is just the metadata from the dataset.\n\n```\nqdrant . upload_records(\n\n    collection_name = \"my_books\" ,\n\n    records = [\n\n        models . Record(\n\n             id = idx, vector = encoder . encode(doc[ \"description\" ]) . tolist(), payload = doc\n\n        )\n\n         for  idx, doc  in   enumerate (documents)\n\n    ],\n\n)\n\n```\n\n## 6. Ask the engine a question\n\nNow that the data is stored in Qdrant, you can ask it questions and receive semantically relevant results.\n\n```\nhits  =  qdrant . search(\n\n    collection_name = \"my_books\" ,\n\n    query_vector = encoder . encode( \"alien invasion\" ) . tolist(),\n\n    limit = 3 ,\n\n)\n\nfor  hit  in  hits:\n\n     print (hit . payload,  \"score:\" , hit . score)\n\n```\n\n **Response:** \n\nThe search engine shows three of the most likely responses that have to do with the alien invasion. Each of the responses is assigned a score to show how close the response is to the original inquiry.\n\n```\n{'name': 'The War of the Worlds', 'description': 'A Martian invasion of Earth throws humanity into chaos.', 'author': 'H.G. Wells', 'year': 1898} score: 0.570093257022374\n\n{'name': \"The Hitchhiker's Guide to the Galaxy\", 'description': 'A comedic science fiction series following the misadventures of an unwitting human and his alien friend.', 'author': 'Douglas Adams', 'year': 1979} score: 0.5040468703143637\n\n{'name': 'The Three-Body Problem', 'description': 'Humans encounter an alien civilization that lives in a dying system.', 'author': 'Liu Cixin', 'year': 2008} score: 0.45902943411768216\n\n```\n\n### Narrow down the query\n\nHow about the most recent book from the early 2000s?\n\n```\nhits  =  qdrant . search(\n\n    collection_name = \"my_books\" ,\n\n    query_vector = encoder . encode( \"alien invasion\" ) . tolist(),\n\n    query_filter = models . Filter(\n\n        must = [models . FieldCondition(key = \"year\" ,  range = models . Range(gte = 2000 ))]\n\n    ),\n\n    limit = 1 ,\n\n)\n\nfor  hit  in  hits:\n\n     print (hit . payload,  \"score:\" , hit . score)\n\n```\n\n **Response:** \n\nThe query has been narrowed down to one result from 2008.\n\n`{'name': 'The Three-Body Problem', 'description': 'Humans encounter an alien civilization that lives in a dying system.', 'author': 'Liu Cixin', 'year': 2008} score: 0.45902943411768216\n`\n\n## Next Steps\n\nCongratulations, you have just created your very first search engine! Trust us, the rest of Qdrant is not that complicated, either. For your next tutorial you should try building an actual[ Neural Search Service with a complete API and a dataset ](../../tutorials/neural-search/).\n\n## Return to the bash shell\n\nTo return to the bash prompt:\n\n1. Press Ctrl+D to exit the Python prompt ( `>>>` ).\n2. Enter the `deactivate` command to deactivate the virtual environment.\n\n\n##### Table of contents\n\n- [ Overview ](https://qdrant.tech/documentation/tutorials/search-beginners/#overview)\n- [ 1. Installation ](https://qdrant.tech/documentation/tutorials/search-beginners/#1-installation)\n    - [ Import the models ](https://qdrant.tech/documentation/tutorials/search-beginners/#import-the-models)\n- [ 2. Add the dataset ](https://qdrant.tech/documentation/tutorials/search-beginners/#2-add-the-dataset)\n- [ 3. Define storage location ](https://qdrant.tech/documentation/tutorials/search-beginners/#3-define-storage-location)\n- [ 4. Create a collection ](https://qdrant.tech/documentation/tutorials/search-beginners/#4-create-a-collection)\n- [ 5. Upload data to collection ](https://qdrant.tech/documentation/tutorials/search-beginners/#5-upload-data-to-collection)\n- [ 6. Ask the engine a question ](https://qdrant.tech/documentation/tutorials/search-beginners/#6--ask-the-engine-a-question)\n    - [ Narrow down the query ](https://qdrant.tech/documentation/tutorials/search-beginners/#narrow-down-the-query)\n- [ Next Steps ](https://qdrant.tech/documentation/tutorials/search-beginners/#next-steps)\n- [ Return to the bash shell ](https://qdrant.tech/documentation/tutorials/search-beginners/#return-to-the-bash-shell)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/search-beginners.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/quick_start/#clients": "# Quickstart\n\nIn this short example, you will use the Python Client to create a Collection, load data into it and run a basic search query.\n\n## Download and run\n\nFirst, download the latest Qdrant image from Dockerhub:\n\n`docker pull qdrant/qdrant\n`\n\nThen, run the service:\n\n```\ndocker run -p 6333:6333 -p 6334:6334  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage:z  \\\n\n    qdrant/qdrant\n\n```\n\nUnder the default configuration all data will be stored in the `./qdrant_storage` directory. This will also be the only directory that both the Container and the host machine can both see.\n\nQdrant is now accessible:\n\n- REST API:[ localhost:6333 ](http://localhost:6333)\n- Web UI:[ localhost:6333/dashboard ](http://localhost:6333/dashboard)\n- GRPC API:[ localhost:6334 ](http://localhost:6334)\n\n\n## Initialize the client\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\n// The Rust client uses Qdrant's GRPC interface\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n```\n\n## Create a collection\n\nYou will be storing all of your vector data in a Qdrant collection. Let\u2019s call it `test_collection` . This collection will be using a dot product distance metric to compare vectors.\n\n```\nfrom   qdrant_client.http.models   import  Distance, VectorParams\n\n\n\nclient . create_collection(\n\n    collection_name = \"test_collection\" ,\n\n    vectors_config = VectorParams(size = 4 , distance = Distance . DOT),\n\n)\n\n```\n\n```\nawait  client.createCollection( \"test_collection\" , {\n\n  vectors :  { size:  4 , distance :   \"Dot\"  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{vectors_config::Config,   VectorParams,   VectorsConfig}; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  4 , \n\n                 distance:  Distance ::Dot.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n## Add vectors\n\nLet\u2019s now add a few vectors with a payload. Payloads are other data you want to associate with the vector:\n\n```\nfrom   qdrant_client.http.models   import  PointStruct\n\n\n\noperation_info  =  client . upsert(\n\n    collection_name = \"test_collection\" ,\n\n    wait = True ,\n\n    points = [\n\n        PointStruct( id = 1 , vector = [ 0.05 ,  0.61 ,  0.76 ,  0.74 ], payload = { \"city\" :  \"Berlin\" }),\n\n        PointStruct( id = 2 , vector = [ 0.19 ,  0.81 ,  0.75 ,  0.11 ], payload = { \"city\" :  \"London\" }),\n\n        PointStruct( id = 3 , vector = [ 0.36 ,  0.55 ,  0.47 ,  0.94 ], payload = { \"city\" :  \"Moscow\" }),\n\n        PointStruct( id = 4 , vector = [ 0.18 ,  0.01 ,  0.85 ,  0.80 ], payload = { \"city\" :  \"New York\" }),\n\n        PointStruct( id = 5 , vector = [ 0.24 ,  0.18 ,  0.22 ,  0.44 ], payload = { \"city\" :  \"Beijing\" }),\n\n        PointStruct( id = 6 , vector = [ 0.35 ,  0.08 ,  0.11 ,  0.44 ], payload = { \"city\" :  \"Mumbai\" }),\n\n    ],\n\n)\n\n\n\nprint (operation_info)\n\n```\n\n```\nconst  operationInfo  =   await  client.upsert( \"test_collection\" , {\n\n  wait:  true ,\n\n  points :  [\n\n    { id:  1 , vector :  [ 0.05 ,  0.61 ,  0.76 ,  0.74 ], payload :  { city :   \"Berlin\"  } },\n\n    { id:  2 , vector :  [ 0.19 ,  0.81 ,  0.75 ,  0.11 ], payload :  { city :   \"London\"  } },\n\n    { id:  3 , vector :  [ 0.36 ,  0.55 ,  0.47 ,  0.94 ], payload :  { city :   \"Moscow\"  } },\n\n    { id:  4 , vector :  [ 0.18 ,  0.01 ,  0.85 ,  0.80 ], payload :  { city :   \"New York\"  } },\n\n    { id:  5 , vector :  [ 0.24 ,  0.18 ,  0.22 ,  0.44 ], payload :  { city :   \"Beijing\"  } },\n\n    { id:  6 , vector :  [ 0.35 ,  0.08 ,  0.11 ,  0.44 ], payload :  { city :   \"Mumbai\"  } },\n\n  ],\n\n});\n\n\n\nconsole.debug(operationInfo);\n\n```\n\n```\nuse   qdrant_client::qdrant::PointStruct; \n\nuse   serde_json::json; \n\n\n\nlet   points   =   vec![ \n\n     PointStruct::new( \n\n         1 , \n\n         vec![ 0.05 ,   0.61 ,   0.76 ,   0.74 ], \n\n         json ! ( \n\n             { \"city\" :  \"Berlin\" } \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n     PointStruct::new( \n\n         2 , \n\n         vec![ 0.19 ,   0.81 ,   0.75 ,   0.11 ], \n\n         json ! ( \n\n             { \"city\" :  \"London\" } \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n     // ..truncated\n\n]; \n\nlet   operation_info   =   client \n\n     .upsert_points_blocking( \"test_collection\" .to_string(),   None ,   points,   None ) \n\n     . await ? ; \n\n\n\ndbg!(operation_info); \n\n```\n\n **Response:** \n\n`operation_id = 0  status =< UpdateStatus . COMPLETED:  'completed' > \n`\n\n`{ operation_id:  0 , status :   'completed'  }\n`\n\n```\nPointsOperationResponse   { \n\n     result:  Some (UpdateResult   { \n\n         operation_id:  0 , \n\n         status:  Completed , \n\n     }), \n\n     time:  0.006347708 , \n\n} \n\n```\n\n## Run a query\n\nLet\u2019s ask a basic question - Which of our stored vectors are most similar to the query vector `[0.2, 0.1, 0.9, 0.7]` ?\n\n```\nsearch_result  =  client . search(\n\n    collection_name = \"test_collection\" , query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ], limit = 3 \n\n)\n\n\n\nprint (search_result)\n\n```\n\n```\nlet  searchResult  =   await  client.search( \"test_collection\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  limit:  3 ,\n\n});\n\n\n\nconsole.debug(searchResult);\n\n```\n\n```\nuse   qdrant_client::qdrant::SearchPoints; \n\n\n\nlet   search_result   =   client \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         limit:  3 , \n\n         with_payload:  Some ( true .into()), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n\n\ndbg!(search_result); \n\n```\n\n **Response:** \n\n```\nScoredPoint( id = 4 , version = 0 , score = 1.362 , payload = { \"city\" :  \"New York\" }, vector = None ),\n\nScoredPoint( id = 1 , version = 0 , score = 1.273 , payload = { \"city\" :  \"Berlin\" }, vector = None ),\n\nScoredPoint( id = 3 , version = 0 , score = 1.208 , payload = { \"city\" :  \"Moscow\" }, vector = None )\n\n```\n\n```\n[\n\n  {\n\n    id:  4 ,\n\n    version:  0 ,\n\n    score:  1.362 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n  {\n\n    id:  1 ,\n\n    version:  0 ,\n\n    score:  1.273 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n  {\n\n    id:  3 ,\n\n    version:  0 ,\n\n    score:  1.208 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n];\n\n```\n\n```\nSearchResponse   { \n\n     result: [ \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 4 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.362 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 1 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.273 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 3 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.208 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n     ], \n\n     time:  0.003635125 , \n\n} \n\n```\n\nThe results are returned in decreasing similarity order. Note that payload and vector data is missing in these results by default.\nSee[ payload and vector in the result ](../concepts/search#payload-and-vector-in-the-result)on how to enable it.\n\n## Add a filter\n\nWe can narrow down the results further by filtering by payload. Let\u2019s find the closest results that include \u201cLondon\u201d.\n\n```\nfrom   qdrant_client.http.models   import  Filter, FieldCondition, MatchValue\n\n\n\nsearch_result  =  client . search(\n\n    collection_name = \"test_collection\" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    query_filter = Filter(\n\n        must = [FieldCondition(key = \"city\" , match = MatchValue(value = \"London\" ))]\n\n    ),\n\n    with_payload = True ,\n\n    limit = 3 ,\n\n)\n\n\n\nprint (search_result)\n\n```\n\n```\nsearchResult  =   await  client.search( \"test_collection\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  filter :  {\n\n    must :  [{ key :   \"city\" , match :  { value :   \"London\"  } }],\n\n  },\n\n  with_payload:  true ,\n\n  limit:  3 ,\n\n});\n\n\n\nconsole.debug(searchResult);\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   SearchPoints}; \n\n\n\nlet   search_result   =   client \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         filter:  Some (Filter::all([Condition::matches( \n\n             \"city\" , \n\n             \"London\" .to_string(), \n\n         )])), \n\n         limit:  2 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n\n\ndbg!(search_result); \n\n```\n\n **Response:** \n\n`ScoredPoint( id = 2 , version = 0 , score = 0.871 , payload = { \"city\" :  \"London\" }, vector = None )\n`\n\n```\n[\n\n  {\n\n    id:  2 ,\n\n    version:  0 ,\n\n    score:  0.871 ,\n\n    payload :  { city :   \"London\"  },\n\n    vector:  null ,\n\n  },\n\n];\n\n```\n\n```\nSearchResponse   { \n\n     result: [ \n\n         ScoredPoint   { \n\n             id:  Some ( \n\n                 PointId   { \n\n                     point_id_options:  Some ( \n\n                         Num( \n\n                             2 , \n\n                         ), \n\n                     ), \n\n                 }, \n\n             ), \n\n             payload: { \n\n                 \"city\" :  Value   { \n\n                     kind:  Some ( \n\n                         StringValue( \n\n                             \"London\" , \n\n                         ), \n\n                     ), \n\n                 }, \n\n             }, \n\n             score:  0.871 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n     ], \n\n     time:  0.004001083 , \n\n} \n\n```\n\nYou have just conducted vector search. You loaded vectors into a database and queried the database with a vector of your own. Qdrant found the closest results and presented you with a similarity score.\n\n## Next steps\n\nNow you know how Qdrant works. Getting started with[ Qdrant Cloud ](../cloud/quickstart-cloud/)is just as easy.[ Create an account ](https://qdrant.to/cloud)and use our SaaS completely free. We will take care of infrastructure maintenance and software updates.\n\nTo move onto some more complex examples of vector search, read our[ Tutorials ](../tutorials/)and create your own app with the help of our[ Examples ](../examples/).\n\n **Note:** There is another way of running Qdrant locally. If you are a Python developer, we recommend that you try Local Mode in[ Qdrant Client ](https://github.com/qdrant/qdrant-client), as it only takes a few moments to get setup.\n\n##### Table of contents\n\n- [ Download and run ](https://qdrant.tech/documentation/quick_start/#clients/#download-and-run)\n- [ Initialize the client ](https://qdrant.tech/documentation/quick_start/#clients/#initialize-the-client)\n- [ Create a collection ](https://qdrant.tech/documentation/quick_start/#clients/#create-a-collection)\n- [ Add vectors ](https://qdrant.tech/documentation/quick_start/#clients/#add-vectors)\n- [ Run a query ](https://qdrant.tech/documentation/quick_start/#clients/#run-a-query)\n- [ Add a filter ](https://qdrant.tech/documentation/quick_start/#clients/#add-a-filter)\n- [ Next steps ](https://qdrant.tech/documentation/quick_start/#clients/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/quick-start.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/cloud/authentication": "# Authentication\n\nThis page shows you how to use the Qdrant Cloud Console to create a custom API key for a cluster. You will learn how to connect to your cluster using the new API key.\n\n## Create API keys\n\nThe API key is only shown once after creation. If you lose it, you will need to create a new one.\nHowever, we recommend rotating the keys from time to time. To create additional API keys do the following.\n\n1. Go to the[ Cloud Dashboard ](https://qdrant.to/cloud).\n2. Select **Access Management** to display available API keys.\n3. Click **Create** and choose a cluster name from the dropdown menu.\n\n\n **Note:** You can create a key that provides access to multiple clusters. Select desired clusters in the dropdown box.\n\n1. Click **OK** and retrieve your API key.\n\n\n## Authenticate via SDK\n\nNow that you have created your first cluster and key, you might want to access Qdrant Cloud from within your application.\nOur official Qdrant clients for Python, TypeScript, Go, Rust, and .NET all support the API key parameter.\n\n```\ncurl  \\\n\n  -X GET https://xyz-example.eu-central.aws.cloud.qdrant.io:6333  \\\n\n  --header  'api-key: <provide-your-own-key>' \n\n\n\n# Alternatively, you can use the `Authorization` header with the `Bearer` prefix \n\ncurl  \\\n\n  -X GET https://xyz-example.eu-central.aws.cloud.qdrant.io:6333  \\\n\n  --header  'Authorization: Bearer <provide-your-own-key>' \n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nqdrant_client  =  QdrantClient(\n\n     \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n    api_key = \"<paste-your-api-key-here>\" ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({\n\n  host :   \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n  apiKey :   \"<paste-your-api-key-here>\" ,\n\n});\n\n```\n\n```\nusing   Qdrant.Client ;\n\n\n\nvar  client =  new  QdrantClient(\n\n   \"xyz-example.eu-central.aws.cloud.qdrant.io\" ,\n\n  https:  true ,\n\n  apiKey:  \"<paste-your-api-key-here>\" \n\n);\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"xyz-example.eu-central.aws.cloud.qdrant.io:6334\" ) \n\n     .with_api_key( \"<paste-your-api-key-here>\" ) \n\n     .build() \n\n     .unwrap(); \n\n```\n\n##### Table of contents\n\n- [ Create API keys ](https://qdrant.tech/documentation/cloud/authentication/#create-api-keys)\n- [ Authenticate via SDK ](https://qdrant.tech/documentation/cloud/authentication/#authenticate-via-sdk)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/cloud/authentication.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/neural-search-fastembed": "# Create a Neural Search Service with Fastembed\n\n| Time: 20 min | Level: Beginner | Output: GitHub |  |\n|---|---|---|---|\n\n\nThis tutorial shows you how to build and deploy your own neural search service to look through descriptions of companies from[ startups-list.com ](https://www.startups-list.com/)and pick the most similar ones to your query.\nThe website contains the company names, descriptions, locations, and a picture for each entry.\n\nAlternatively, you can use datasources such as[ Crunchbase ](https://www.crunchbase.com/), but that would require obtaining an API key from them.\n\nOur neural search service will use[ Fastembed ](https://github.com/qdrant/fastembed)package to generate embeddings of text descriptions and[ FastAPI ](https://fastapi.tiangolo.com/)to serve the search API.\nFastembed natively integrates with Qdrant client, so you can easily upload the data into Qdrant and perform search queries.\n\n## Workflow\n\nTo create a neural search service, you will need to transform your raw data and then create a search function to manipulate it.\nFirst, you will 1) download and prepare a sample dataset using a modified version of the BERT ML model. Then, you will 2) load the data into Qdrant, 3) create a neural search API and 4) serve it using FastAPI.\n\nImage: [ Neural Search Workflow ](https://qdrant.tech/docs/workflow-neural-search.png)\n\nImage: [ Neural Search Workflow ](https://qdrant.tech/docs/workflow-neural-search.png)\n\n **Note** : The code for this tutorial can be found here:[ Step 2: Full Code for Neural Search ](https://github.com/qdrant/qdrant_demo/).\n\n## Prerequisites\n\nTo complete this tutorial, you will need:\n\n- Docker - The easiest way to use Qdrant is to run a pre-built Docker image.\n- [ Raw parsed data ](https://storage.googleapis.com/generall-shared-data/startups_demo.json)from startups-list.com.\n- Python version >=3.8\n\n\n## Prepare sample dataset\n\nTo conduct a neural search on startup descriptions, you must first encode the description data into vectors.\nFastembed integration into qdrant client combines encoding and uploading into a single step.\n\nIt also takes care of batching and parallelization, so you don\u2019t have to worry about it.\n\nLet\u2019s start by downloading the data and installing the necessary packages.\n\n1. First you need to download the dataset.\n\n\n`wget https://storage.googleapis.com/generall-shared-data/startups_demo.json\n`\n\n## Run Qdrant in Docker\n\nNext, you need to manage all of your data using a vector engine. Qdrant lets you store, update or delete created vectors. Most importantly, it lets you search for the nearest vectors via a convenient API.\n\n **Note:** Before you begin, create a project directory and a virtual python environment in it.\n\n1. Download the Qdrant image from DockerHub.\n\n\n`docker pull qdrant/qdrant\n`\n\n1. Start Qdrant inside of Docker.\n\n\n```\ndocker run -p 6333:6333  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage  \\\n\n    qdrant/qdrant\n\n```\n\nYou should see output like this\n\n```\n...\n\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting 12 workers\n\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting \"actix-web-service-0.0.0.0:6333\" service on 0.0.0.0:6333\n\n```\n\nTest the service by going to[ http://localhost:6333/ ](http://localhost:6333/). You should see the Qdrant version info in your browser.\n\nAll data uploaded to Qdrant is saved inside the `./qdrant_storage` directory and will be persisted even if you recreate the container.\n\n## Upload data to Qdrant\n\n1. Install the official Python client to best interact with Qdrant.\n\n\n`pip install qdrant-client [ fastembed ] \n`\n\nNote, that you need to install the `fastembed` extra to enable Fastembed integration.\nAt this point, you should have startup records in the `startups_demo.json` file and Qdrant running on a local machine.\n\nNow you need to write a script to upload all startup data and vectors into the search engine.\n\n1. Create a client object for Qdrant.\n\n\n```\n# Import client library \n\nfrom   qdrant_client   import  QdrantClient\n\n\n\nqdrant_client  =  QdrantClient( \"http://localhost:6333\" )\n\n```\n\n1. Select model to encode your data.\n\n\nYou will be using a pre-trained model called `sentence-transformers/all-MiniLM-L6-v2` .\n\n`qdrant_client . set_model( \"sentence-transformers/all-MiniLM-L6-v2\" )\n`\n\n1. Related vectors need to be added to a collection. Create a new collection for your startup vectors.\n\n\n```\nqdrant_client . recreate_collection(\n\n    collection_name = \"startups\" ,\n\n    vectors_config = qdrant_client . get_fastembed_vector_params(),\n\n)\n\n```\n\nNote, that we use `get_fastembed_vector_params` to get the vector size and distance function from the model.\nThis method automatically generates configuration, compatible with the model you are using.\nWithout fastembed integration, you would need to specify the vector size and distance function manually. Read more about it[ here ](https://qdrant.tech/documentation/tutorials/neural-search).\n\nAdditionally, you can specify extended configuration for our vectors, like `quantization_config` or `hnsw_config` .\n\n1. Read data from the file.\n\n\n```\npayload_path  =  os . path . join(DATA_DIR,  \"startups_demo.json\" )\n\nmetadata  =  []\n\ndocuments  =  []\n\n\n\nwith   open (payload_path)  as  fd:\n\n     for  line  in  fd:\n\n        obj  =  json . loads(line)\n\n        documents . append(obj . pop( \"description\" ))\n\n        metadata . append(obj)\n\n```\n\nIn this block of code, we read data we read data from `startups_demo.json` file and split it into 2 lists: `documents` and `metadata` .\nDocuments are the raw text descriptions of startups. Metadata is the payload associated with each startup, such as the name, location, and picture.\nWe will use `documents` to encode the data into vectors.\n\n1. Encode and upload data.\n\n\n```\nclient . add(\n\n    collection_name = \"startups\" ,\n\n    documents = documents,\n\n    metadata = metadata,\n\n    parallel = 0 ,   # Use all available CPU cores to encode data \n\n)\n\n```\n\nThe `add` method will encode all documents and upload them to Qdrant.\nThis is one of two fastembed-specific methods, that combines encoding and uploading into a single step.\n\nThe `parallel` parameter controls the number of CPU cores used to encode data.\n\nAdditionally, you can specify ids for each document, if you want to use them later to update or delete documents.\nIf you don\u2019t specify ids, they will be generated automatically and returned as a result of the `add` method.\n\nYou can monitor the progress of the encoding by passing tqdm progress bar to the `add` method.\n\n```\nfrom   tqdm   import  tqdm\n\n\n\nclient . add(\n\n    collection_name = \"startups\" ,\n\n    documents = documents,\n\n    metadata = metadata,\n\n    ids = tqdm( range ( len (documents))),\n\n)\n\n```\n\n **Note** : See the full code for this step[ here ](https://github.com/qdrant/qdrant_demo/blob/master/qdrant_demo/init_collection_startups.py).\n\n## Build the search API\n\nNow that all the preparations are complete, let\u2019s start building a neural search class.\n\nIn order to process incoming requests, neural search will need 2 things: 1) a model to convert the query into a vector and 2) the Qdrant client to perform search queries.\nFastembed integration into qdrant client combines encoding and uploading into a single method call.\n\n1. Create a file named `neural_searcher.py` and specify the following.\n\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\n\n\nclass   NeuralSearcher :\n\n     def  __init__(self, collection_name):\n\n        self . collection_name  =  collection_name\n\n         # initialize Qdrant client \n\n        self . qdrant_client  =  QdrantClient( \"http://localhost:6333\" )\n\n        self . qdrant_client . set_model( \"sentence-transformers/all-MiniLM-L6-v2\" )\n\n```\n\n1. Write the search function.\n\n\n```\ndef   search (self, text:  str ):\n\n        search_result  =  self . qdrant_client . query(\n\n            collection_name = self . collection_name,\n\n            query_text = text,\n\n            query_filter = None ,   # If you don't want any filters for now \n\n            limit = 5    # 5 the most closest results is enough \n\n        )\n\n         # `search_result` contains found vector ids with similarity scores along with the stored payload \n\n         # In this function you are interested in payload only \n\n        metadata  =  [hit . metadata  for  hit  in  search_result]\n\n         return  metadata\n\n```\n\n1. Add search filters.\n\n\nWith Qdrant it is also feasible to add some conditions to the search.\nFor example, if you wanted to search for startups in a certain city, the search query could look like this:\n\n```\nfrom   qdrant_client.models   import  Filter\n\n\n\n     ... \n\n\n\n    city_of_interest  =   \"Berlin\" \n\n\n\n     # Define a filter for cities \n\n    city_filter  =  Filter( ** {\n\n         \"must\" : [{\n\n             \"key\" :  \"city\" ,  # Store city information in a field of the same name  \n\n             \"match\" : {  # This condition checks if payload field has the requested value \n\n                 \"value\" :  \"city_of_interest\" \n\n            }\n\n        }]\n\n    })\n\n\n\n    search_result  =  self . qdrant_client . query(\n\n        collection_name = self . collection_name,\n\n        query_text = text,\n\n        query_filter = city_filter,\n\n        limit = 5 \n\n    )\n\n     ... \n\n```\n\nYou have now created a class for neural search queries. Now wrap it up into a service.\n\n## Deploy the search with FastAPI\n\nTo build the service you will use the FastAPI framework.\n\n1. Install FastAPI.\n\n\nTo install it, use the command\n\n`pip install fastapi uvicorn\n`\n\n1. Implement the service.\n\n\nCreate a file named `service.py` and specify the following.\n\nThe service will have only one API endpoint and will look like this:\n\n```\nfrom   fastapi   import  FastAPI\n\n\n\n# The file where NeuralSearcher is stored \n\nfrom   neural_searcher   import  NeuralSearcher\n\n\n\napp  =  FastAPI()\n\n\n\n# Create a neural searcher instance \n\nneural_searcher  =  NeuralSearcher(collection_name = 'startups' )\n\n\n\n@app . get( \"/api/search\" )\n\ndef   search_startup (q:  str ):\n\n     return  {\n\n         \"result\" : neural_searcher . search(text = q)\n\n    }\n\n\n\n\n\nif  __name__  ==   \"__main__\" :\n\n     import   uvicorn \n\n    uvicorn . run(app, host = \"0.0.0.0\" , port = 8000 )\n\n```\n\n1. Run the service.\n\n\n`python service.py\n`\n\n1. Open your browser at[ http://localhost:8000/docs ](http://localhost:8000/docs).\n\n\nYou should be able to see a debug interface for your service.\n\nImage: [ FastAPI Swagger interface ](https://qdrant.tech/docs/fastapi_neural_search.png)\n\nImage: [ FastAPI Swagger interface ](https://qdrant.tech/docs/fastapi_neural_search.png)\n\nFeel free to play around with it, make queries regarding the companies in our corpus, and check out the results.\n\n## Next steps\n\nThe code from this tutorial has been used to develop a[ live online demo ](https://qdrant.to/semantic-search-demo).\nYou can try it to get an intuition for cases when the neural search is useful.\nThe demo contains a switch that selects between neural and full-text searches.\nYou can turn the neural search on and off to compare your result with a regular full-text search.\n\n **Note** : The code for this tutorial can be found here:[ Full Code for Neural Search ](https://github.com/qdrant/qdrant_demo/).\n\nJoin our[ Discord community ](https://qdrant.to/discord), where we talk about vector search and similarity learning, publish other examples of neural networks and neural search applications.\n\n##### Table of contents\n\n- [ Workflow ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#workflow)\n- [ Prerequisites ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#prerequisites)\n- [ Prepare sample dataset ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#prepare-sample-dataset)\n- [ Run Qdrant in Docker ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#run-qdrant-in-docker)\n- [ Upload data to Qdrant ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#upload-data-to-qdrant)\n- [ Build the search API ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#build-the-search-api)\n- [ Deploy the search with FastAPI ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#deploy-the-search-with-fastapi)\n- [ Next steps ](https://qdrant.tech/documentation/tutorials/neural-search-fastembed/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/neural-search-fastembed.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/tutorials/neural-search": "# Create a Simple Neural Search Service\n\n| Time: 30 min | Level: Beginner | Output: GitHub |  |\n|---|---|---|---|\n\n\nImage: [ Open In Colab ](https://colab.research.google.com/assets/colab-badge.svg)\n\nThis tutorial shows you how to build and deploy your own neural search service to look through descriptions of companies from[ startups-list.com ](https://www.startups-list.com/)and pick the most similar ones to your query. The website contains the company names, descriptions, locations, and a picture for each entry.\n\nA neural search service uses artificial neural networks to improve the accuracy and relevance of search results. Besides offering simple keyword results, this system can retrieve results by meaning. It can understand and interpret complex search queries and provide more contextually relevant output, effectively enhancing the user\u2019s search experience.\n\n## Workflow\n\nTo create a neural search service, you will need to transform your raw data and then create a search function to manipulate it. First, you will 1) download and prepare a sample dataset using a modified version of the BERT ML model. Then, you will 2) load the data into Qdrant, 3) create a neural search API and 4) serve it using FastAPI.\n\nImage: [ Neural Search Workflow ](https://qdrant.tech/docs/workflow-neural-search.png)\n\nImage: [ Neural Search Workflow ](https://qdrant.tech/docs/workflow-neural-search.png)\n\n **Note** : The code for this tutorial can be found here: |[ Step 1: Data Preparation Process ](https://colab.research.google.com/drive/1kPktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing)|[ Step 2: Full Code for Neural Search ](https://github.com/qdrant/qdrant_demo/tree/sentense-transformers). |\n\n## Prerequisites\n\nTo complete this tutorial, you will need:\n\n- Docker - The easiest way to use Qdrant is to run a pre-built Docker image.\n- [ Raw parsed data ](https://storage.googleapis.com/generall-shared-data/startups_demo.json)from startups-list.com.\n- Python version >=3.8\n\n\n## Prepare sample dataset\n\nTo conduct a neural search on startup descriptions, you must first encode the description data into vectors. To process text, you can use a pre-trained models like[ BERT ](https://en.wikipedia.org/wiki/BERT_(language_model))or sentence transformers. The[ sentence-transformers ](https://github.com/UKPLab/sentence-transformers)library lets you conveniently download and use many pre-trained models, such as DistilBERT, MPNet, etc.\n\n1. First you need to download the dataset.\n\n\n`wget https://storage.googleapis.com/generall-shared-data/startups_demo.json\n`\n\n1. Install the SentenceTransformer library as well as other relevant packages.\n\n\n`pip install sentence-transformers numpy pandas tqdm\n`\n\n1. Import all relevant models.\n\n\n```\nfrom   sentence_transformers   import  SentenceTransformer\n\nimport   numpy   as   np \n\nimport   json \n\nimport   pandas   as   pd \n\nfrom   tqdm.notebook   import  tqdm\n\n```\n\nYou will be using a pre-trained model called `all-MiniLM-L6-v2` .\nThis is a performance-optimized sentence embedding model and you can read more about it and other available models[ here ](https://www.sbert.net/docs/pretrained_models.html).\n\n1. Download and create a pre-trained sentence encoder.\n\n\n```\nmodel  =  SentenceTransformer(\n\n     \"all-MiniLM-L6-v2\" , device = \"cuda\" \n\n)   # or device=\"cpu\" if you don't have a GPU \n\n```\n\n1. Read the raw data file.\n\n\n`df  =  pd . read_json( \"./startups_demo.json\" , lines = True )\n`\n\n1. Encode all startup descriptions to create an embedding vector for each. Internally, the `encode` function will split the input into batches, which will significantly speed up the process.\n\n\n```\nvectors  =  model . encode(\n\n    [row . alt  +   \". \"   +  row . description  for  row  in  df . itertuples()],\n\n    show_progress_bar = True ,\n\n)\n\n```\n\nAll of the descriptions are now converted into vectors. There are 40474 vectors of 384 dimensions. The output layer of the model has this dimension\n\n```\nvectors . shape\n\n# > (40474, 384) \n\n```\n\n1. Download the saved vectors into a new file named `startup_vectors.npy`\n\n\n`np . save( \"startup_vectors.npy\" , vectors, allow_pickle = False )\n`\n\n## Run Qdrant in Docker\n\nNext, you need to manage all of your data using a vector engine. Qdrant lets you store, update or delete created vectors. Most importantly, it lets you search for the nearest vectors via a convenient API.\n\n **Note:** Before you begin, create a project directory and a virtual python environment in it.\n\n1. Download the Qdrant image from DockerHub.\n\n\n`docker pull qdrant/qdrant\n`\n\n1. Start Qdrant inside of Docker.\n\n\n```\ndocker run -p 6333:6333  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage  \\\n\n    qdrant/qdrant\n\n```\n\nYou should see output like this\n\n```\n...\n\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting 12 workers\n\n[2021-02-05T00:08:51Z INFO  actix_server::builder] Starting \"actix-web-service-0.0.0.0:6333\" service on 0.0.0.0:6333\n\n```\n\nTest the service by going to[ http://localhost:6333/ ](http://localhost:6333/). You should see the Qdrant version info in your browser.\n\nAll data uploaded to Qdrant is saved inside the `./qdrant_storage` directory and will be persisted even if you recreate the container.\n\n## Upload data to Qdrant\n\n1. Install the official Python client to best interact with Qdrant.\n\n\n`pip install qdrant-client\n`\n\nAt this point, you should have startup records in the `startups_demo.json` file, encoded vectors in `startup_vectors.npy` and Qdrant running on a local machine.\n\nNow you need to write a script to upload all startup data and vectors into the search engine.\n\n1. Create a client object for Qdrant.\n\n\n```\n# Import client library \n\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.models   import  VectorParams, Distance\n\n\n\nqdrant_client  =  QdrantClient( \"http://localhost:6333\" )\n\n```\n\n1. Related vectors need to be added to a collection. Create a new collection for your startup vectors.\n\n\n```\nqdrant_client . recreate_collection(\n\n    collection_name = \"startups\" ,\n\n    vectors_config = VectorParams(size = 384 , distance = Distance . COSINE),\n\n)\n\n```\n\n- Use `recreate_collection` if you are experimenting and running the script several times. This function will first try to remove an existing collection with the same name.\n- The `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. `384` is the encoder output dimensionality. You can also use `model.get_sentence_embedding_dimension()` to get the dimensionality of the model you are using.\n- The `distance` parameter lets you specify the function used to measure the distance between two points.\n\n\nUse `recreate_collection` if you are experimenting and running the script several times. This function will first try to remove an existing collection with the same name.\n\nThe `vector_size` parameter defines the size of the vectors for a specific collection. If their size is different, it is impossible to calculate the distance between them. `384` is the encoder output dimensionality. You can also use `model.get_sentence_embedding_dimension()` to get the dimensionality of the model you are using.\n\nThe `distance` parameter lets you specify the function used to measure the distance between two points.\n\n1. Create an iterator over the startup data and vectors.\n\n\nThe Qdrant client library defines a special function that allows you to load datasets into the service.\nHowever, since there may be too much data to fit a single computer memory, the function takes an iterator over the data as input.\n\n```\nfd  =   open ( \"./startups_demo.json\" )\n\n\n\n# payload is now an iterator over startup data \n\npayload  =   map (json . loads, fd)\n\n\n\n# Load all vectors into memory, numpy array works as iterable for itself. \n\n# Other option would be to use Mmap, if you don't want to load all data into RAM \n\nvectors  =  np . load( \"./startup_vectors.npy\" )\n\n```\n\n1. Upload the data\n\n\n```\nqdrant_client . upload_collection(\n\n    collection_name = \"startups\" ,\n\n    vectors = vectors,\n\n    payload = payload,\n\n    ids = None ,   # Vector ids will be assigned automatically \n\n    batch_size = 256 ,   # How many vectors will be uploaded in a single request? \n\n)\n\n```\n\nVectors are now uploaded to Qdrant.\n\n## Build the search API\n\nNow that all the preparations are complete, let\u2019s start building a neural search class.\n\nIn order to process incoming requests, neural search will need 2 things: 1) a model to convert the query into a vector and 2) the Qdrant client to perform search queries.\n\n1. Create a file named `neural_searcher.py` and specify the following.\n\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   sentence_transformers   import  SentenceTransformer\n\n\n\n\n\nclass   NeuralSearcher :\n\n     def  __init__(self, collection_name):\n\n        self . collection_name  =  collection_name\n\n         # Initialize encoder model \n\n        self . model  =  SentenceTransformer( \"all-MiniLM-L6-v2\" , device = \"cpu\" )\n\n         # initialize Qdrant client \n\n        self . qdrant_client  =  QdrantClient( \"http://localhost:6333\" )\n\n```\n\n1. Write the search function.\n\n\n```\ndef   search (self, text:  str ):\n\n         # Convert text query into vector \n\n        vector  =  self . model . encode(text) . tolist()\n\n\n\n         # Use `vector` for search for closest vectors in the collection \n\n        search_result  =  self . qdrant_client . search(\n\n            collection_name = self . collection_name,\n\n            query_vector = vector,\n\n            query_filter = None ,   # If you don't want any filters for now \n\n            limit = 5    # 5 the most closest results is enough \n\n        )\n\n         # `search_result` contains found vector ids with similarity scores along with the stored payload \n\n         # In this function you are interested in payload only \n\n        payloads  =  [hit . payload  for  hit  in  search_result]\n\n         return  payloads\n\n```\n\n1. Add search filters.\n\n\nWith Qdrant it is also feasible to add some conditions to the search.\nFor example, if you wanted to search for startups in a certain city, the search query could look like this:\n\n```\nfrom   qdrant_client.models   import  Filter\n\n\n\n     ... \n\n\n\n    city_of_interest  =   \"Berlin\" \n\n\n\n     # Define a filter for cities \n\n    city_filter  =  Filter( ** {\n\n         \"must\" : [{\n\n             \"key\" :  \"city\" ,  # Store city information in a field of the same name  \n\n             \"match\" : {  # This condition checks if payload field has the requested value \n\n                 \"value\" : city_of_interest\n\n            }\n\n        }]\n\n    })\n\n\n\n    search_result  =  self . qdrant_client . search(\n\n        collection_name = self . collection_name,\n\n        query_vector = vector,\n\n        query_filter = city_filter,\n\n        limit = 5 \n\n    )\n\n     ... \n\n```\n\nYou have now created a class for neural search queries. Now wrap it up into a service.\n\n## Deploy the search with FastAPI\n\nTo build the service you will use the FastAPI framework.\n\n1. Install FastAPI.\n\n\nTo install it, use the command\n\n`pip install fastapi uvicorn\n`\n\n1. Implement the service.\n\n\nCreate a file named `service.py` and specify the following.\n\nThe service will have only one API endpoint and will look like this:\n\n```\nfrom   fastapi   import  FastAPI\n\n\n\n# The file where NeuralSearcher is stored \n\nfrom   neural_searcher   import  NeuralSearcher\n\n\n\napp  =  FastAPI()\n\n\n\n# Create a neural searcher instance \n\nneural_searcher  =  NeuralSearcher(collection_name = 'startups' )\n\n\n\n@app . get( \"/api/search\" )\n\ndef   search_startup (q:  str ):\n\n     return  {\n\n         \"result\" : neural_searcher . search(text = q)\n\n    }\n\n\n\n\n\nif  __name__  ==   \"__main__\" :\n\n     import   uvicorn \n\n    uvicorn . run(app, host = \"0.0.0.0\" , port = 8000 )\n\n```\n\n1. Run the service.\n\n\n`python service.py\n`\n\n1. Open your browser at[ http://localhost:8000/docs ](http://localhost:8000/docs).\n\n\nYou should be able to see a debug interface for your service.\n\nImage: [ FastAPI Swagger interface ](https://qdrant.tech/docs/fastapi_neural_search.png)\n\nImage: [ FastAPI Swagger interface ](https://qdrant.tech/docs/fastapi_neural_search.png)\n\nFeel free to play around with it, make queries regarding the companies in our corpus, and check out the results.\n\n## Next steps\n\nThe code from this tutorial has been used to develop a[ live online demo ](https://qdrant.to/semantic-search-demo).\nYou can try it to get an intuition for cases when the neural search is useful.\nThe demo contains a switch that selects between neural and full-text searches.\nYou can turn the neural search on and off to compare your result with a regular full-text search.\n\n **Note** : The code for this tutorial can be found here: |[ Step 1: Data Preparation Process ](https://colab.research.google.com/drive/1kPktoudAP8Tu8n8l-iVMOQhVmHkWV_L9?usp=sharing)|[ Step 2: Full Code for Neural Search ](https://github.com/qdrant/qdrant_demo/tree/sentense-transformers). |\n\nJoin our[ Discord community ](https://qdrant.to/discord), where we talk about vector search and similarity learning, publish other examples of neural networks and neural search applications.\n\n##### Table of contents\n\n- [ Workflow ](https://qdrant.tech/documentation/tutorials/neural-search/#workflow)\n- [ Prerequisites ](https://qdrant.tech/documentation/tutorials/neural-search/#prerequisites)\n- [ Prepare sample dataset ](https://qdrant.tech/documentation/tutorials/neural-search/#prepare-sample-dataset)\n- [ Run Qdrant in Docker ](https://qdrant.tech/documentation/tutorials/neural-search/#run-qdrant-in-docker)\n- [ Upload data to Qdrant ](https://qdrant.tech/documentation/tutorials/neural-search/#upload-data-to-qdrant)\n- [ Build the search API ](https://qdrant.tech/documentation/tutorials/neural-search/#build-the-search-api)\n- [ Deploy the search with FastAPI ](https://qdrant.tech/documentation/tutorials/neural-search/#deploy-the-search-with-fastapi)\n- [ Next steps ](https://qdrant.tech/documentation/tutorials/neural-search/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/tutorials/neural-search.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/quick_start/#installation": "# Quickstart\n\nIn this short example, you will use the Python Client to create a Collection, load data into it and run a basic search query.\n\n## Download and run\n\nFirst, download the latest Qdrant image from Dockerhub:\n\n`docker pull qdrant/qdrant\n`\n\nThen, run the service:\n\n```\ndocker run -p 6333:6333 -p 6334:6334  \\\n\n    -v  $( pwd ) /qdrant_storage:/qdrant/storage:z  \\\n\n    qdrant/qdrant\n\n```\n\nUnder the default configuration all data will be stored in the `./qdrant_storage` directory. This will also be the only directory that both the Container and the host machine can both see.\n\nQdrant is now accessible:\n\n- REST API:[ localhost:6333 ](http://localhost:6333)\n- Web UI:[ localhost:6333/dashboard ](http://localhost:6333/dashboard)\n- GRPC API:[ localhost:6334 ](http://localhost:6334)\n\n\n## Initialize the client\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\n// The Rust client uses Qdrant's GRPC interface\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n```\n\n## Create a collection\n\nYou will be storing all of your vector data in a Qdrant collection. Let\u2019s call it `test_collection` . This collection will be using a dot product distance metric to compare vectors.\n\n```\nfrom   qdrant_client.http.models   import  Distance, VectorParams\n\n\n\nclient . create_collection(\n\n    collection_name = \"test_collection\" ,\n\n    vectors_config = VectorParams(size = 4 , distance = Distance . DOT),\n\n)\n\n```\n\n```\nawait  client.createCollection( \"test_collection\" , {\n\n  vectors :  { size:  4 , distance :   \"Dot\"  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::{vectors_config::Config,   VectorParams,   VectorsConfig}; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  4 , \n\n                 distance:  Distance ::Dot.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n## Add vectors\n\nLet\u2019s now add a few vectors with a payload. Payloads are other data you want to associate with the vector:\n\n```\nfrom   qdrant_client.http.models   import  PointStruct\n\n\n\noperation_info  =  client . upsert(\n\n    collection_name = \"test_collection\" ,\n\n    wait = True ,\n\n    points = [\n\n        PointStruct( id = 1 , vector = [ 0.05 ,  0.61 ,  0.76 ,  0.74 ], payload = { \"city\" :  \"Berlin\" }),\n\n        PointStruct( id = 2 , vector = [ 0.19 ,  0.81 ,  0.75 ,  0.11 ], payload = { \"city\" :  \"London\" }),\n\n        PointStruct( id = 3 , vector = [ 0.36 ,  0.55 ,  0.47 ,  0.94 ], payload = { \"city\" :  \"Moscow\" }),\n\n        PointStruct( id = 4 , vector = [ 0.18 ,  0.01 ,  0.85 ,  0.80 ], payload = { \"city\" :  \"New York\" }),\n\n        PointStruct( id = 5 , vector = [ 0.24 ,  0.18 ,  0.22 ,  0.44 ], payload = { \"city\" :  \"Beijing\" }),\n\n        PointStruct( id = 6 , vector = [ 0.35 ,  0.08 ,  0.11 ,  0.44 ], payload = { \"city\" :  \"Mumbai\" }),\n\n    ],\n\n)\n\n\n\nprint (operation_info)\n\n```\n\n```\nconst  operationInfo  =   await  client.upsert( \"test_collection\" , {\n\n  wait:  true ,\n\n  points :  [\n\n    { id:  1 , vector :  [ 0.05 ,  0.61 ,  0.76 ,  0.74 ], payload :  { city :   \"Berlin\"  } },\n\n    { id:  2 , vector :  [ 0.19 ,  0.81 ,  0.75 ,  0.11 ], payload :  { city :   \"London\"  } },\n\n    { id:  3 , vector :  [ 0.36 ,  0.55 ,  0.47 ,  0.94 ], payload :  { city :   \"Moscow\"  } },\n\n    { id:  4 , vector :  [ 0.18 ,  0.01 ,  0.85 ,  0.80 ], payload :  { city :   \"New York\"  } },\n\n    { id:  5 , vector :  [ 0.24 ,  0.18 ,  0.22 ,  0.44 ], payload :  { city :   \"Beijing\"  } },\n\n    { id:  6 , vector :  [ 0.35 ,  0.08 ,  0.11 ,  0.44 ], payload :  { city :   \"Mumbai\"  } },\n\n  ],\n\n});\n\n\n\nconsole.debug(operationInfo);\n\n```\n\n```\nuse   qdrant_client::qdrant::PointStruct; \n\nuse   serde_json::json; \n\n\n\nlet   points   =   vec![ \n\n     PointStruct::new( \n\n         1 , \n\n         vec![ 0.05 ,   0.61 ,   0.76 ,   0.74 ], \n\n         json ! ( \n\n             { \"city\" :  \"Berlin\" } \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n     PointStruct::new( \n\n         2 , \n\n         vec![ 0.19 ,   0.81 ,   0.75 ,   0.11 ], \n\n         json ! ( \n\n             { \"city\" :  \"London\" } \n\n         ) \n\n         .try_into() \n\n         .unwrap(), \n\n     ), \n\n     // ..truncated\n\n]; \n\nlet   operation_info   =   client \n\n     .upsert_points_blocking( \"test_collection\" .to_string(),   None ,   points,   None ) \n\n     . await ? ; \n\n\n\ndbg!(operation_info); \n\n```\n\n **Response:** \n\n`operation_id = 0  status =< UpdateStatus . COMPLETED:  'completed' > \n`\n\n`{ operation_id:  0 , status :   'completed'  }\n`\n\n```\nPointsOperationResponse   { \n\n     result:  Some (UpdateResult   { \n\n         operation_id:  0 , \n\n         status:  Completed , \n\n     }), \n\n     time:  0.006347708 , \n\n} \n\n```\n\n## Run a query\n\nLet\u2019s ask a basic question - Which of our stored vectors are most similar to the query vector `[0.2, 0.1, 0.9, 0.7]` ?\n\n```\nsearch_result  =  client . search(\n\n    collection_name = \"test_collection\" , query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ], limit = 3 \n\n)\n\n\n\nprint (search_result)\n\n```\n\n```\nlet  searchResult  =   await  client.search( \"test_collection\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  limit:  3 ,\n\n});\n\n\n\nconsole.debug(searchResult);\n\n```\n\n```\nuse   qdrant_client::qdrant::SearchPoints; \n\n\n\nlet   search_result   =   client \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         limit:  3 , \n\n         with_payload:  Some ( true .into()), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n\n\ndbg!(search_result); \n\n```\n\n **Response:** \n\n```\nScoredPoint( id = 4 , version = 0 , score = 1.362 , payload = { \"city\" :  \"New York\" }, vector = None ),\n\nScoredPoint( id = 1 , version = 0 , score = 1.273 , payload = { \"city\" :  \"Berlin\" }, vector = None ),\n\nScoredPoint( id = 3 , version = 0 , score = 1.208 , payload = { \"city\" :  \"Moscow\" }, vector = None )\n\n```\n\n```\n[\n\n  {\n\n    id:  4 ,\n\n    version:  0 ,\n\n    score:  1.362 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n  {\n\n    id:  1 ,\n\n    version:  0 ,\n\n    score:  1.273 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n  {\n\n    id:  3 ,\n\n    version:  0 ,\n\n    score:  1.208 ,\n\n    payload:  null ,\n\n    vector:  null ,\n\n  },\n\n];\n\n```\n\n```\nSearchResponse   { \n\n     result: [ \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 4 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.362 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 1 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.273 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n         ScoredPoint   { \n\n             id:  Some (PointId   { \n\n                 point_id_options:  Some (Num( 3 )), \n\n             }), \n\n             payload: {}, \n\n             score:  1.208 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n     ], \n\n     time:  0.003635125 , \n\n} \n\n```\n\nThe results are returned in decreasing similarity order. Note that payload and vector data is missing in these results by default.\nSee[ payload and vector in the result ](../concepts/search#payload-and-vector-in-the-result)on how to enable it.\n\n## Add a filter\n\nWe can narrow down the results further by filtering by payload. Let\u2019s find the closest results that include \u201cLondon\u201d.\n\n```\nfrom   qdrant_client.http.models   import  Filter, FieldCondition, MatchValue\n\n\n\nsearch_result  =  client . search(\n\n    collection_name = \"test_collection\" ,\n\n    query_vector = [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n    query_filter = Filter(\n\n        must = [FieldCondition(key = \"city\" , match = MatchValue(value = \"London\" ))]\n\n    ),\n\n    with_payload = True ,\n\n    limit = 3 ,\n\n)\n\n\n\nprint (search_result)\n\n```\n\n```\nsearchResult  =   await  client.search( \"test_collection\" , {\n\n  vector :  [ 0.2 ,  0.1 ,  0.9 ,  0.7 ],\n\n  filter :  {\n\n    must :  [{ key :   \"city\" , match :  { value :   \"London\"  } }],\n\n  },\n\n  with_payload:  true ,\n\n  limit:  3 ,\n\n});\n\n\n\nconsole.debug(searchResult);\n\n```\n\n```\nuse   qdrant_client::qdrant::{Condition,   Filter,   SearchPoints}; \n\n\n\nlet   search_result   =   client \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"test_collection\" .to_string(), \n\n         vector:  vec ! [ 0.2 ,   0.1 ,   0.9 ,   0.7 ], \n\n         filter:  Some (Filter::all([Condition::matches( \n\n             \"city\" , \n\n             \"London\" .to_string(), \n\n         )])), \n\n         limit:  2 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n\n\ndbg!(search_result); \n\n```\n\n **Response:** \n\n`ScoredPoint( id = 2 , version = 0 , score = 0.871 , payload = { \"city\" :  \"London\" }, vector = None )\n`\n\n```\n[\n\n  {\n\n    id:  2 ,\n\n    version:  0 ,\n\n    score:  0.871 ,\n\n    payload :  { city :   \"London\"  },\n\n    vector:  null ,\n\n  },\n\n];\n\n```\n\n```\nSearchResponse   { \n\n     result: [ \n\n         ScoredPoint   { \n\n             id:  Some ( \n\n                 PointId   { \n\n                     point_id_options:  Some ( \n\n                         Num( \n\n                             2 , \n\n                         ), \n\n                     ), \n\n                 }, \n\n             ), \n\n             payload: { \n\n                 \"city\" :  Value   { \n\n                     kind:  Some ( \n\n                         StringValue( \n\n                             \"London\" , \n\n                         ), \n\n                     ), \n\n                 }, \n\n             }, \n\n             score:  0.871 , \n\n             version:  0 , \n\n             vectors:  None , \n\n         }, \n\n     ], \n\n     time:  0.004001083 , \n\n} \n\n```\n\nYou have just conducted vector search. You loaded vectors into a database and queried the database with a vector of your own. Qdrant found the closest results and presented you with a similarity score.\n\n## Next steps\n\nNow you know how Qdrant works. Getting started with[ Qdrant Cloud ](../cloud/quickstart-cloud/)is just as easy.[ Create an account ](https://qdrant.to/cloud)and use our SaaS completely free. We will take care of infrastructure maintenance and software updates.\n\nTo move onto some more complex examples of vector search, read our[ Tutorials ](../tutorials/)and create your own app with the help of our[ Examples ](../examples/).\n\n **Note:** There is another way of running Qdrant locally. If you are a Python developer, we recommend that you try Local Mode in[ Qdrant Client ](https://github.com/qdrant/qdrant-client), as it only takes a few moments to get setup.\n\n##### Table of contents\n\n- [ Download and run ](https://qdrant.tech/documentation/quick_start/#installation/#download-and-run)\n- [ Initialize the client ](https://qdrant.tech/documentation/quick_start/#installation/#initialize-the-client)\n- [ Create a collection ](https://qdrant.tech/documentation/quick_start/#installation/#create-a-collection)\n- [ Add vectors ](https://qdrant.tech/documentation/quick_start/#installation/#add-vectors)\n- [ Run a query ](https://qdrant.tech/documentation/quick_start/#installation/#run-a-query)\n- [ Add a filter ](https://qdrant.tech/documentation/quick_start/#installation/#add-a-filter)\n- [ Next steps ](https://qdrant.tech/documentation/quick_start/#installation/#next-steps)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/quick-start.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/integrations/llama-index/": "# LlamaIndex (GPT Index)\n\nLlamaIndex (formerly GPT Index) acts as an interface between your external data and Large Language Models. So you can bring your\nprivate data and augment LLMs with it. LlamaIndex simplifies data ingestion and indexing, integrating Qdrant as a vector index.\n\nInstalling LlamaIndex is straightforward if we use pip as a package manager. Qdrant is not installed by default, so we need to\ninstall it separately:\n\n`pip install llama-index qdrant-client\n`\n\nLlamaIndex requires providing an instance of `QdrantClient` , so it can interact with Qdrant server.\n\n```\nfrom   llama_index.vector_stores.qdrant   import  QdrantVectorStore\n\n\n\nimport   qdrant_client \n\n\n\nclient  =  qdrant_client . QdrantClient(\n\n     \"<qdrant-url>\" ,\n\n    api_key = \"<qdrant-api-key>\" ,  # For Qdrant Cloud, None for local instance \n\n)\n\n\n\nindex  =  QdrantVectorStore(client = client, collection_name = \"documents\" )\n\n```\n\nThe library[ comes with a notebook ](https://github.com/jerryjliu/llama_index/blob/main/docs/examples/vector_stores/QdrantIndexDemo.ipynb)that shows an end-to-end example of how to use Qdrant within LlamaIndex.\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/concepts/indexing/#payload-index": "# Indexing\n\nA key feature of Qdrant is the effective combination of vector and traditional indexes. It is essential to have this because for vector search to work effectively with filters, having vector index only is not enough. In simpler terms, a vector index speeds up vector search, and payload indexes speed up filtering.\n\nThe indexes in the segments exist independently, but the parameters of the indexes themselves are configured for the whole collection.\n\nNot all segments automatically have indexes.\nTheir necessity is determined by the[ optimizer ](../optimizer)settings and depends, as a rule, on the number of stored points.\n\n## Payload Index\n\nPayload index in Qdrant is similar to the index in conventional document-oriented databases.\nThis index is built for a specific field and type, and is used for quick point requests by the corresponding filtering condition.\n\nThe index is also used to accurately estimate the filter cardinality, which helps the[ query planning ](../search#query-planning)choose a search strategy.\n\nCreating an index requires additional computational resources and memory, so choosing fields to be indexed is essential. Qdrant does not make this choice but grants it to the user.\n\nTo mark a field as indexable, you can use the following:\n\n```\nPUT /collections/{collection_name}/index\n\n{\n\n    \"field_name\": \"name_of_the_field_to_index\",\n\n    \"field_schema\": \"keyword\"\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient(host = \"localhost\" , port = 6333 )\n\n\n\nclient . create_payload_index(\n\n    collection_name = \" {collection_name} \" ,\n\n    field_name = \"name_of_the_field_to_index\" ,\n\n    field_schema = \"keyword\" ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createPayloadIndex( \"{collection_name}\" , {\n\n  field_name :   \"name_of_the_field_to_index\" ,\n\n  field_schema :   \"keyword\" ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::FieldType}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_field_index( \n\n         \"{collection_name}\" , \n\n         \"name_of_the_field_to_index\" , \n\n         FieldType::Keyword, \n\n         None , \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nAvailable field types are:\n\n- `keyword` - for[ keyword ](../payload/#keyword)payload, affects[ Match ](../filtering/#match)filtering conditions.\n- `integer` - for[ integer ](../payload/#integer)payload, affects[ Match ](../filtering/#match)and[ Range ](../filtering/#range)filtering conditions.\n- `float` - for[ float ](../payload/#float)payload, affects[ Range ](../filtering/#range)filtering conditions.\n- `bool` - for[ bool ](../payload/#bool)payload, affects[ Match ](../filtering/#match)filtering conditions (available as of 1.4.0).\n- `geo` - for[ geo ](../payload/#geo)payload, affects[ Geo Bounding Box ](../filtering/#geo-bounding-box)and[ Geo Radius ](../filtering/#geo-radius)filtering conditions.\n- `text` - a special kind of index, available for[ keyword ](../payload/#keyword)/ string payloads, affects[ Full Text search ](../filtering/#full-text-match)filtering conditions.\n\n\nPayload index may occupy some additional memory, so it is recommended to only use index for those fields that are used in filtering conditions.\nIf you need to filter by many fields and the memory limits does not allow to index all of them, it is recommended to choose the field that limits the search result the most.\nAs a rule, the more different values a payload value has, the more efficiently the index will be used.\n\n### Full-text index\n\n *Available as of v0.10.0* \n\nQdrant supports full-text search for string payload.\nFull-text index allows you to filter points by the presence of a word or a phrase in the payload field.\n\nFull-text index configuration is a bit more complex than other indexes, as you can specify the tokenization parameters.\nTokenization is the process of splitting a string into tokens, which are then indexed in the inverted index.\n\nTo create a full-text index, you can use the following:\n\n```\nPUT /collections/{collection_name}/index\n\n{\n\n    \"field_name\": \"name_of_the_field_to_index\",\n\n    \"field_schema\": {\n\n        \"type\": \"text\",\n\n        \"tokenizer\": \"word\",\n\n        \"min_token_len\": 2,\n\n        \"max_token_len\": 20,\n\n        \"lowercase\": true\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient(host = \"localhost\" , port = 6333 )\n\n\n\nclient . create_payload_index(\n\n    collection_name = \" {collection_name} \" ,\n\n    field_name = \"name_of_the_field_to_index\" ,\n\n    field_schema = models . TextIndexParams(\n\n         type = \"text\" ,\n\n        tokenizer = models . TokenizerType . WORD,\n\n        min_token_len = 2 ,\n\n        max_token_len = 15 ,\n\n        lowercase = True ,\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient, Schemas }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createPayloadIndex( \"{collection_name}\" , {\n\n  field_name :   \"name_of_the_field_to_index\" ,\n\n  field_schema :  {\n\n     type :   \"text\" ,\n\n    tokenizer :   \"word\" ,\n\n    min_token_len:  2 ,\n\n    max_token_len:  15 ,\n\n    lowercase:  true ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         payload_index_params::IndexParams,   FieldType,   PayloadIndexParams,   TextIndexParams, \n\n         TokenizerType, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_field_index( \n\n         \"{collection_name}\" , \n\n         \"name_of_the_field_to_index\" , \n\n         FieldType::Text, \n\n         Some ( & PayloadIndexParams   { \n\n             index_params:  Some (IndexParams::TextIndexParams(TextIndexParams   { \n\n                 tokenizer:  TokenizerType ::Word   as   i32 , \n\n                 min_token_len:  Some ( 2 ), \n\n                 max_token_len:  Some ( 10 ), \n\n                 lowercase:  Some ( true ), \n\n             })), \n\n         }), \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nAvailable tokenizers are:\n\n- `word` - splits the string into words, separated by spaces, punctuation marks, and special characters.\n- `whitespace` - splits the string into words, separated by spaces.\n- `prefix` - splits the string into words, separated by spaces, punctuation marks, and special characters, and then creates a prefix index for each word. For example: `hello` will be indexed as `h` , `he` , `hel` , `hell` , `hello` .\n- `multilingual` - special type of tokenizer based on[ charabia ](https://github.com/meilisearch/charabia)package. It allows proper tokenization and lemmatization for multiple languages, including those with non-latin alphabets and non-space delimiters. See[ charabia documentation ](https://github.com/meilisearch/charabia)for full list of supported languages supported normalization options. In the default build configuration, qdrant does not include support for all languages, due to the increasing size of the resulting binary. Chinese, Japanese and Korean languages are not enabled by default, but can be enabled by building qdrant from source with `--features multiling-chinese,multiling-japanese,multiling-korean` flags.\n\n\nSee[ Full Text match ](../filtering/#full-text-match)for examples of querying with full-text index.\n\n## Vector Index\n\nA vector index is a data structure built on vectors through a specific mathematical model.\nThrough the vector index, we can efficiently query several vectors similar to the target vector.\n\nQdrant currently only uses HNSW as a dense vector index.\n\n[ HNSW ](https://arxiv.org/abs/1603.09320)(Hierarchical Navigable Small World Graph) is a graph-based indexing algorithm. It builds a multi-layer navigation structure for an image according to certain rules. In this structure, the upper layers are more sparse and the distances between nodes are farther. The lower layers are denser and the distances between nodes are closer. The search starts from the uppermost layer, finds the node closest to the target in this layer, and then enters the next layer to begin another search. After multiple iterations, it can quickly approach the target position.\n\nIn order to improve performance, HNSW limits the maximum degree of nodes on each layer of the graph to `m` . In addition, you can use `ef_construct` (when building index) or `ef` (when searching targets) to specify a search range.\n\nThe corresponding parameters could be configured in the configuration file:\n\n```\nstorage : \n\n   # Default parameters of HNSW Index. Could be overridden for each collection or named vector individually \n\n   hnsw_index : \n\n     # Number of edges per node in the index graph. \n\n     # Larger the value - more accurate the search, more space required. \n\n     m :   16 \n\n     # Number of neighbours to consider during the index building. \n\n     # Larger the value - more accurate the search, more time required to build index. \n\n     ef_construct :   100 \n\n     # Minimal size (in KiloBytes) of vectors for additional payload-based indexing. \n\n     # If payload chunk is smaller than `full_scan_threshold_kb` additional indexing won't be used - \n\n     # in this case full-scan search should be preferred by query planner and additional indexing is not required. \n\n     # Note: 1Kb = 1 vector of size 256 \n\n     full_scan_threshold :   10000 \n\n```\n\nAnd so in the process of creating a[ collection ](../collections). The `ef` parameter is configured during[ the search ](../search)and by default is equal to `ef_construct` .\n\nHNSW is chosen for several reasons.\nFirst, HNSW is well-compatible with the modification that allows Qdrant to use filters during a search.\nSecond, it is one of the most accurate and fastest algorithms, according to[ public benchmarks ](https://github.com/erikbern/ann-benchmarks).\n\n *Available as of v1.1.1* \n\nThe HNSW parameters can also be configured on a collection and named vector\nlevel by setting[ hnsw_config ](../indexing/#vector-index)to fine-tune search\nperformance.\n\n## Sparse Vector Index\n\n *Available as of v1.7.0* \n\n### Key Features of Sparse Vector Index\n\n- **Support for Sparse Vectors:** Qdrant supports sparse vectors, characterized by a high proportion of zeroes.\n- **Efficient Indexing:** Utilizes an inverted index structure to store vectors for each non-zero dimension, optimizing memory and search speed.\n\n\n### Search Mechanism\n\n- **Index Usage:** The index identifies vectors with non-zero values in query dimensions during a search.\n- **Scoring Method:** Vectors are scored using the dot product.\n\n\n### Optimizations\n\n- **Reducing Vectors to Score:** Implementations are in place to minimize the number of vectors scored, especially for dimensions with numerous vectors.\n\n\n### Filtering and Configuration\n\n- **Filtering Support:** Similar to dense vectors, supports filtering by payload fields.\n- **full_scan_threshold  Configuration:** Allows control over when to switch search from the payload index to minimize scoring vectors.\n- **Threshold for Sparse Vectors:** Specifies the threshold in terms of the number of matching vectors found by the query planner.\n\n\n`full_scan_threshold`\n\n### Index Storage and Management\n\n- **Memory-Based Index:** The index resides in memory for appendable segments, ensuring fast search and update operations.\n- **Handling Immutable Segments:** For immutable segments, the sparse index can either stay in memory or be mapped to disk with the `on_disk` flag.\n\n\n **Example Configuration:** To enable on-disk storage for immutable segments and full scan for queries inspecting less than 5000 vectors:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"sparse_vectors\": {\n\n        \"text\": {\n\n            \"index\": {\n\n                \"on_disk\": true,\n\n                \"full_scan_threshold\": 5000\n\n            }\n\n         },\n\n    }\n\n}\n\n```\n\n## Filtrable Index\n\nSeparately, payload index and vector index cannot solve the problem of search using the filter completely.\n\nIn the case of weak filters, you can use the HNSW index as it is. In the case of stringent filters, you can use the payload index and complete rescore.\nHowever, for cases in the middle, this approach does not work well.\n\nOn the one hand, we cannot apply a full scan on too many vectors. On the other hand, the HNSW graph starts to fall apart when using too strict filters.\n\nImage: [ HNSW fail ](https://qdrant.tech/docs/precision_by_m.png)\n\nImage: [ HNSW fail ](https://qdrant.tech/docs/precision_by_m.png)\n\nImage: [ hnsw graph ](https://qdrant.tech/docs/graph.gif)\n\nImage: [ hnsw graph ](https://qdrant.tech/docs/graph.gif)\n\nYou can find more information on why this happens in our[ blog post ](https://blog.vasnetsov.com/posts/categorical-hnsw/).\nQdrant solves this problem by extending the HNSW graph with additional edges based on the stored payload values.\n\nExtra edges allow you to efficiently search for nearby vectors using the HNSW index and apply filters as you search in the graph.\n\nThis approach minimizes the overhead on condition checks since you only need to calculate the conditions for a small fraction of the points involved in the search.\n\n##### Table of contents\n\n- [ Payload Index ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#payload-index)\n    - [ Full-text index ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#full-text-index)\n- [ Vector Index ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#vector-index)\n- [ Sparse Vector Index ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#sparse-vector-index)\n    - [ Key Features of Sparse Vector Index ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#key-features-of-sparse-vector-index)\n\n- [ Search Mechanism ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#search-mechanism)\n\n- [ Optimizations ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#optimizations)\n\n- [ Filtering and Configuration ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#filtering-and-configuration)\n\n- [ Index Storage and Management ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#index-storage-and-management)\n- [ Filtrable Index ](https://qdrant.tech/documentation/concepts/indexing/#payload-index/#filtrable-index)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/indexing.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/guides/multiple-partitions/#calibrate-performance": "# Configure Multitenancy\n\n **How many collections should you create?** In most cases, you should only use a single collection with payload-based partitioning. This approach is called multitenancy. It is efficient for most of users, but it requires additional configuration. This document will show you how to set it up.\n\n **When should you create multiple collections?** When you have a limited number of users and you need isolation. This approach is flexible, but it may be more costly, since creating numerous collections may result in resource overhead. Also, you need to ensure that they do not affect each other in any way, including performance-wise.\n\n## Partition by payload\n\nWhen an instance is shared between multiple users, you may need to partition vectors by user. This is done so that each user can only access their own vectors and can\u2019t see the vectors of other users.\n\n1. Add a `group_id` field to each vector in the collection.\n\n\n```\nPUT /collections/{collection_name}/points\n\n{\n\n    \"points\": [\n\n        {\n\n            \"id\": 1,\n\n            \"payload\": {\"group_id\": \"user_1\"},\n\n            \"vector\": [0.9, 0.1, 0.1]\n\n        },\n\n        {\n\n            \"id\": 2,\n\n            \"payload\": {\"group_id\": \"user_1\"},\n\n            \"vector\": [0.1, 0.9, 0.1]\n\n        },\n\n        {\n\n            \"id\": 3,\n\n            \"payload\": {\"group_id\": \"user_2\"},\n\n            \"vector\": [0.1, 0.1, 0.9]\n\n        },\n\n    ]\n\n}\n\n```\n\n```\nclient . upsert(\n\n    collection_name = \" {collection_name} \" ,\n\n    points = [\n\n        models . PointStruct(\n\n             id = 1 ,\n\n            payload = { \"group_id\" :  \"user_1\" },\n\n            vector = [ 0.9 ,  0.1 ,  0.1 ],\n\n        ),\n\n        models . PointStruct(\n\n             id = 2 ,\n\n            payload = { \"group_id\" :  \"user_1\" },\n\n            vector = [ 0.1 ,  0.9 ,  0.1 ],\n\n        ),\n\n        models . PointStruct(\n\n             id = 3 ,\n\n            payload = { \"group_id\" :  \"user_2\" },\n\n            vector = [ 0.1 ,  0.1 ,  0.9 ],\n\n        ),\n\n    ],\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.upsert( \"{collection_name}\" , {\n\n  points :  [\n\n    {\n\n      id:  1 ,\n\n      payload :  { group_id :   \"user_1\"  },\n\n      vector :  [ 0.9 ,  0.1 ,  0.1 ],\n\n    },\n\n    {\n\n      id:  2 ,\n\n      payload :  { group_id :   \"user_1\"  },\n\n      vector :  [ 0.1 ,  0.9 ,  0.1 ],\n\n    },\n\n    {\n\n      id:  3 ,\n\n      payload :  { group_id :   \"user_2\"  },\n\n      vector :  [ 0.1 ,  0.1 ,  0.9 ],\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::PointStruct}; \n\nuse   serde_json::json; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .upsert_points_blocking( \n\n         \"{collection_name}\" .to_string(), \n\n         None , \n\n         vec![ \n\n             PointStruct::new( \n\n                 1 , \n\n                 vec![ 0.9 ,   0.1 ,   0.1 ], \n\n                 json ! ( \n\n                     { \"group_id\" :  \"user_1\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n             PointStruct::new( \n\n                 2 , \n\n                 vec![ 0.1 ,   0.9 ,   0.1 ], \n\n                 json ! ( \n\n                     { \"group_id\" :  \"user_1\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n             PointStruct::new( \n\n                 3 , \n\n                 vec![ 0.1 ,   0.1 ,   0.9 ], \n\n                 json ! ( \n\n                     { \"group_id\" :  \"user_2\" } \n\n                 ) \n\n                 .try_into() \n\n                 .unwrap(), \n\n             ), \n\n         ], \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n1. Use a filter along with `group_id` to filter vectors for each user.\n\n\n```\nPOST /collections/{collection_name}/points/search\n\n{\n\n    \"filter\": {\n\n        \"must\": [\n\n            {\n\n                \"key\": \"group_id\",\n\n                \"match\": {\n\n                    \"value\": \"user_1\"\n\n                }\n\n            }\n\n        ]\n\n    },\n\n    \"vector\": [0.1, 0.1, 0.9],\n\n    \"limit\": 10\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . search(\n\n    collection_name = \" {collection_name} \" ,\n\n    query_filter = models . Filter(\n\n        must = [\n\n            models . FieldCondition(\n\n                key = \"group_id\" ,\n\n                match = models . MatchValue(\n\n                    value = \"user_1\" ,\n\n                ),\n\n            )\n\n        ]\n\n    ),\n\n    query_vector = [ 0.1 ,  0.1 ,  0.9 ],\n\n    limit = 10 ,\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.search( \"{collection_name}\" , {\n\n  filter :  {\n\n    must :  [{ key :   \"group_id\" , match :  { value :   \"user_1\"  } }],\n\n  },\n\n  vector :  [ 0.1 ,  0.1 ,  0.9 ],\n\n  limit:  10 ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{Condition,   Filter,   SearchPoints}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .search_points( & SearchPoints   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         filter:  Some (Filter::must([Condition::matches( \n\n             \"group_id\" , \n\n             \"user_1\" .to_string(), \n\n         )])), \n\n         vector:  vec ! [ 0.1 ,   0.1 ,   0.9 ], \n\n         limit:  10 , \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n## Calibrate performance\n\nThe speed of indexation may become a bottleneck in this case, as each user\u2019s vector will be indexed into the same collection. To avoid this bottleneck, consider *bypassing the construction of a global vector index* for the entire collection and building it only for individual groups instead.\n\nBy adopting this strategy, Qdrant will index vectors for each user independently, significantly accelerating the process.\n\nTo implement this approach, you should:\n\n1. Set `payload_m` in the HNSW configuration to a non-zero value, such as 16.\n2. Set `m` in hnsw config to 0. This will disable building global index for the whole collection.\n\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 768,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"hnsw_config\": {\n\n        \"payload_m\": 16,\n\n        \"m\": 0\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient, models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 768 , distance = models . Distance . COSINE),\n\n    hnsw_config = models . HnswConfigDiff(\n\n        payload_m = 16 ,\n\n        m = 0 ,\n\n    ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    size:  768 ,\n\n    distance :   \"Cosine\" ,\n\n  },\n\n  hnsw_config :  {\n\n    payload_m:  16 ,\n\n    m:  0 ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   HnswConfigDiff,   VectorParams, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  768 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         hnsw_config:  Some (HnswConfigDiff   { \n\n             payload_m:  Some ( 16 ), \n\n             m:  Some ( 0 ), \n\n             .. Default ::default() \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n1. Create keyword payload index for `group_id` field.\n\n\n```\nPUT /collections/{collection_name}/index\n\n{\n\n    \"field_name\": \"group_id\",\n\n    \"field_schema\": \"keyword\"\n\n}\n\n```\n\n```\nclient . create_payload_index(\n\n    collection_name = \" {collection_name} \" ,\n\n    field_name = \"group_id\" ,\n\n    field_schema = models . PayloadSchemaType . KEYWORD,\n\n)\n\n```\n\n```\nclient.createPayloadIndex( \"{collection_name}\" , {\n\n  field_name :   \"group_id\" ,\n\n  field_schema :   \"keyword\" ,\n\n});\n\n```\n\n```\nuse   qdrant_client::{client::QdrantClient,   qdrant::FieldType}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_field_index( \n\n         \"{collection_name}\" , \n\n         \"group_id\" , \n\n         FieldType::Keyword, \n\n         None , \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\n## Limitations\n\nOne downside to this approach is that global requests (without the `group_id` filter) will be slower since they will necessitate scanning all groups to identify the nearest neighbors.\n\n##### Table of contents\n\n- [ Partition by payload ](https://qdrant.tech/documentation/guides/multiple-partitions/#calibrate-performance/#partition-by-payload)\n- [ Calibrate performance ](https://qdrant.tech/documentation/guides/multiple-partitions/#calibrate-performance/#calibrate-performance)\n- [ Limitations ](https://qdrant.tech/documentation/guides/multiple-partitions/#calibrate-performance/#limitations)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/guides/multiple-partitions.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings.", "https://qdrant.tech/documentation/collections/#create-collection": "# Collections\n\nA collection is a named set of points (vectors with a payload) among which you can search. The vector of each point within the same collection must have the same dimensionality and be compared by a single metric.[ Named vectors ](https://qdrant.tech/documentation/collections/#create-collection/#collection-with-multiple-vectors)can be used to have multiple vectors in a single point, each of which can have their own dimensionality and metric requirements.\n\nDistance metrics are used to measure similarities among vectors.\nThe choice of metric depends on the way vectors obtaining and, in particular, on the method of neural network encoder training.\n\nQdrant supports these most popular types of metrics:\n\n- Dot product: `Dot` -[ [wiki] ](https://en.wikipedia.org/wiki/Dot_product)\n- Cosine similarity: `Cosine` -[ [wiki] ](https://en.wikipedia.org/wiki/Cosine_similarity)\n- Euclidean distance: `Euclid` -[ [wiki] ](https://en.wikipedia.org/wiki/Euclidean_distance)\n- Manhattan distance: `Manhattan` -[ [wiki] ](https://en.wikipedia.org/wiki/Taxicab_geometry)\n\n\nIn addition to metrics and vector size, each collection uses its own set of parameters that controls collection optimization, index construction, and vacuum.\nThese settings can be changed at any time by a corresponding request.\n\n## Setting up multitenancy\n\n **How many collections should you create?** In most cases, you should only use a single collection with payload-based partitioning. This approach is called[ multitenancy ](https://en.wikipedia.org/wiki/Multitenancy). It is efficient for most of users, but it requires additional configuration.[ Learn how to set it up ](../../tutorials/multiple-partitions/)\n\n **When should you create multiple collections?** When you have a limited number of users and you need isolation. This approach is flexible, but it may be more costly, since creating numerous collections may result in resource overhead. Also, you need to ensure that they do not affect each other in any way, including performance-wise.\n\n## Create a collection\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 300,\n\n      \"distance\": \"Cosine\"\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 100 , distance = models . Distance . COSINE),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  { size:  100 , distance :   \"Cosine\"  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorsConfig}, \n\n}; \n\n\n\n//The Rust client uses Qdrant's GRPC interface\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  100 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nIn addition to the required options, you can also specify custom values for the following collection options:\n\n- `hnsw_config` - see[ indexing ](../indexing/#vector-index)for details.\n- `wal_config` - Write-Ahead-Log related configuration. See more details about[ WAL ](../storage/#versioning)\n- `optimizers_config` - see[ optimizer ](../optimizer)for details.\n- `shard_number` - which defines how many shards the collection should have. See[ distributed deployment ](../../guides/distributed_deployment#sharding)section for details.\n- `on_disk_payload` - defines where to store payload data. If `true` - payload will be stored on disk only. Might be useful for limiting the RAM usage in case of large payload.\n- `quantization_config` - see[ quantization ](../../guides/quantization/#setting-up-quantization-in-qdrant)for details.\n\n\nDefault parameters for the optional collection parameters are defined in[ configuration file ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml).\n\nSee[ schema definitions ](https://qdrant.github.io/qdrant/redoc/index.html#operation/create_collection)and a[ configuration file ](https://github.com/qdrant/qdrant/blob/master/config/config.yaml)for more information about collection and vector parameters.\n\n *Available as of v1.2.0* \n\nVectors all live in RAM for very quick access. The `on_disk` parameter can be\nset in the vector configuration. If true, all vectors will live on disk. This\nwill enable the use of[ memmaps ](../../concepts/storage/#configuring-memmap-storage),\nwhich is suitable for ingesting a large amount of data.\n\n### Create collection from another collection\n\n *Available as of v1.0.0* \n\nIt is possible to initialize a collection from another existing collection.\n\nThis might be useful for experimenting quickly with different configurations for the same data set.\n\nMake sure the vectors have the same size and distance function when setting up the vectors configuration in the new collection.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n      \"size\": 100,\n\n      \"distance\": \"Cosine\"\n\n    },\n\n    \"init_from\": {\n\n       \"collection\": \"{from_collection_name}\"\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = models . VectorParams(size = 100 , distance = models . Distance . COSINE),\n\n    init_from = models . InitFrom(collection = \" {from_collection_name} \" ),\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  { size:  100 , distance :   \"Cosine\"  },\n\n  init_from :  { collection :   \"{from_collection_name}\"  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorsConfig}, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::Params(VectorParams   { \n\n                 size:  100 , \n\n                 distance:  Distance ::Cosine.into(), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n         init_from_collection:  Some ( \"{from_collection_name}\" .to_string()), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\n### Collection with multiple vectors\n\n *Available as of v0.10.0* \n\nIt is possible to have multiple vectors per record.\nThis feature allows for multiple vector storages per collection.\nTo distinguish vectors in one record, they should have a unique name defined when creating the collection.\nEach named vector in this mode has its distance and size:\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"image\": {\n\n            \"size\": 4,\n\n            \"distance\": \"Dot\"\n\n        },\n\n        \"text\": {\n\n            \"size\": 8,\n\n            \"distance\": \"Cosine\"\n\n        }\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = {\n\n         \"image\" : models . VectorParams(size = 4 , distance = models . Distance . DOT),\n\n         \"text\" : models . VectorParams(size = 8 , distance = models . Distance . COSINE),\n\n    },\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    image :  { size:  4 , distance :   \"Dot\"  },\n\n    text :  { size:  8 , distance :   \"Cosine\"  },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   VectorParams,   VectorParamsMap, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         vectors_config:  Some (VectorsConfig   { \n\n             config:  Some (Config::ParamsMap(VectorParamsMap   { \n\n                 map: [ \n\n                     ( \n\n                         \"image\" .to_string(), \n\n                         VectorParams   { \n\n                             size:  4 , \n\n                             distance:  Distance ::Dot.into(), \n\n                             .. Default ::default() \n\n                         }, \n\n                     ), \n\n                     ( \n\n                         \"text\" .to_string(), \n\n                         VectorParams   { \n\n                             size:  8 , \n\n                             distance:  Distance ::Cosine.into(), \n\n                             .. Default ::default() \n\n                         }, \n\n                     ), \n\n                 ] \n\n                 .into(), \n\n             })), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nFor rare use cases, it is possible to create a collection without any vector storage.\n\n *Available as of v1.1.1* \n\nFor each named vector you can optionally specify[ hnsw_config ](../indexing/#vector-index)or[ quantization_config ](../../guides/quantization/#setting-up-quantization-in-qdrant)to\ndeviate from the collection configuration. This can be useful to fine-tune\nsearch performance on a vector level.\n\n *Available as of v1.2.0* \n\nVectors all live in RAM for very quick access. On a per-vector basis you can set `on_disk` to true to store all vectors on disk at all times. This will enable\nthe use of[ memmaps ](../../concepts/storage/#configuring-memmap-storage),\nwhich is suitable for ingesting a large amount of data.\n\n### Collection with sparse vectors\n\n *Available as of v1.7.0* \n\nQdrant supports sparse vectors as a first-class citizen.\n\nSparse vectors are useful for text search, where each word is represented as a separate dimension.\n\nCollections can contain sparse vectors as additional[ named vectors ](https://qdrant.tech/documentation/collections/#create-collection/#collection-with-multiple-vectors)along side regular dense vectors in a single point.\n\nUnlike dense vectors, sparse vectors must be named.\nAnd additionally, sparse vectors and dense vectors must have different names within a collection.\n\n```\nPUT /collections/{collection_name}\n\n{\n\n    \"sparse_vectors\": {\n\n        \"text\": { },\n\n    }\n\n}\n\n```\n\n```\nfrom   qdrant_client   import  QdrantClient\n\nfrom   qdrant_client.http   import  models\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . create_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    sparse_vectors_config = {\n\n         \"text\" : models . SparseVectorParams(),\n\n    },\n\n)\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.createCollection( \"{collection_name}\" , {\n\n  sparse_vectors :  {\n\n    text :  { },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::{ \n\n     client::QdrantClient, \n\n     qdrant::{ \n\n         vectors_config::Config,   CreateCollection,   Distance,   SparseVectorParams,   VectorParamsMap, \n\n         VectorsConfig, \n\n     }, \n\n}; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient \n\n     .create_collection( & CreateCollection   { \n\n         collection_name:  \"{collection_name}\" .to_string(), \n\n         sparse_vectors_config:  Some (SparseVectorsConfig   { \n\n             map: [ \n\n                     ( \n\n                         \"text\" .to_string(), \n\n                         SparseVectorParams   {}, \n\n                     ), \n\n                 ] \n\n                 .into(), \n\n             }), \n\n         }), \n\n         .. Default ::default() \n\n     }) \n\n     . await ? ; \n\n```\n\nOutside of a unique name, there are no required configuration parameters for sparse vectors.\n\nThe distance function for sparse vectors is always `Dot` and does not need to be specified.\n\nHowever, there are optional parameters to tune the underlying[ sparse vector index ](../indexing/#sparse-vector-index).\n\n### Delete collection\n\n`DELETE /collections/{collection_name}\n`\n\n`client . delete_collection(collection_name = \" {collection_name} \" )\n`\n\n`client.deleteCollection( \"{collection_name}\" );\n`\n\n`client.delete_collection( \"{collection_name}\" ). await ? ; \n`\n\n### Update collection parameters\n\nDynamic parameter updates may be helpful, for example, for more efficient initial loading of vectors.\nFor example, you can disable indexing during the upload process, and enable it immediately after the upload is finished.\nAs a result, you will not waste extra computation resources on rebuilding the index.\n\nThe following command enables indexing for segments that have more than 10000 kB of vectors stored:\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"optimizers_config\": {\n\n        \"indexing_threshold\": 10000\n\n    }\n\n}\n\n```\n\n```\nclient . update_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    optimizer_config = models . OptimizersConfigDiff(indexing_threshold = 10000 ),\n\n)\n\n```\n\n```\nclient.updateCollection( \"{collection_name}\" , {\n\n  optimizers_config :  {\n\n    indexing_threshold:  10000 ,\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::qdrant::OptimizersConfigDiff; \n\n\n\nclient \n\n     .update_collection( \n\n         \"{collection_name}\" , \n\n         & OptimizersConfigDiff   { \n\n             indexing_threshold:  Some ( 10000 ), \n\n             .. Default ::default() \n\n         }, \n\n         None , \n\n         None , \n\n         None , \n\n         None , \n\n         None , \n\n     ) \n\n     . await ? ; \n\n```\n\nThe following parameters can be updated:\n\n- `optimizers_config` - see[ optimizer ](../optimizer/)for details.\n- `hnsw_config` - see[ indexing ](../indexing/#vector-index)for details.\n- `quantization_config` - see[ quantization ](../../guides/quantization/#setting-up-quantization-in-qdrant)for details.\n- `vectors` - vector-specific configuration, including individual `hnsw_config` , `quantization_config` and `on_disk` settings.\n- `params` - other collection parameters, including `write_consistency_factor` and `on_disk_payload` .\n\n\nFull API specification is available in[ schema definitions ](https://qdrant.github.io/qdrant/redoc/index.html#tag/collections/operation/update_collection).\n\nCalls to this endpoint may be blocking as it waits for existing optimizers to\nfinish. We recommended against using this in a production database as it may\nintroduce huge overhead due to the rebuilding of the index.\n\n#### Update vector parameters\n\n *Available as of v1.4.0* \n\n`\"\"`\n\nQdrant 1.4 adds support for updating more collection parameters at runtime. HNSW\nindex, quantization and disk configurations can now be changed without\nrecreating a collection. Segments (with index and quantized data) will\nautomatically be rebuilt in the background to match updated parameters.\n\nTo put vector data on disk for a collection that **does not have** named vectors,\nuse `\"\"` as name:\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"\": {\n\n            \"on_disk\": true\n\n        }\n\n    },\n\n}\n\n```\n\nTo put vector data on disk for a collection that **does have** named vectors:\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"my_vector\": {\n\n            \"on_disk\": true\n\n        }\n\n    },\n\n}\n\n```\n\nIn the following example the HNSW index and quantization parameters are updated,\nboth for the whole collection, and for `my_vector` specifically:\n\n```\nPATCH /collections/{collection_name}\n\n{\n\n    \"vectors\": {\n\n        \"my_vector\": {\n\n            \"hnsw_config\": {\n\n                \"m\": 32,\n\n                \"ef_construct\": 123\n\n            },\n\n            \"quantization_config\": {\n\n                \"product\": {\n\n                    \"compression\": \"x32\",\n\n                    \"always_ram\": true\n\n                }\n\n            },\n\n            \"on_disk\": true\n\n        }\n\n    },\n\n    \"hnsw_config\": {\n\n        \"ef_construct\": 123\n\n    },\n\n    \"quantization_config\": {\n\n        \"scalar\": {\n\n            \"type\": \"int8\",\n\n            \"quantile\": 0.8,\n\n            \"always_ram\": false\n\n        }\n\n    }\n\n}\n\n```\n\n```\nclient . update_collection(\n\n    collection_name = \" {collection_name} \" ,\n\n    vectors_config = {\n\n         \"my_vector\" : models . VectorParamsDiff(\n\n            hnsw_config = models . HnswConfigDiff(\n\n                m = 32 ,\n\n                ef_construct = 123 ,\n\n            ),\n\n            quantization_config = models . ProductQuantization(\n\n                product = models . ProductQuantizationConfig(\n\n                    compression = models . CompressionRatio . X32,\n\n                    always_ram = True ,\n\n                ),\n\n            ),\n\n            on_disk = True ,\n\n        ),\n\n    },\n\n    hnsw_config = models . HnswConfigDiff(\n\n        ef_construct = 123 ,\n\n    ),\n\n    quantization_config = models . ScalarQuantization(\n\n        scalar = models . ScalarQuantizationConfig(\n\n             type = models . ScalarType . INT8,\n\n            quantile = 0.8 ,\n\n            always_ram = False ,\n\n        ),\n\n    ),\n\n)\n\n```\n\n```\nclient.updateCollection( \"{collection_name}\" , {\n\n  vectors :  {\n\n    my_vector :  {\n\n      hnsw_config :  {\n\n        m:  32 ,\n\n        ef_construct:  123 ,\n\n      },\n\n      quantization_config :  {\n\n        product :  {\n\n          compression :   \"x32\" ,\n\n          always_ram:  true ,\n\n        },\n\n      },\n\n      on_disk:  true ,\n\n    },\n\n  },\n\n  hnsw_config :  {\n\n    ef_construct:  123 ,\n\n  },\n\n  quantization_config :  {\n\n    scalar :  {\n\n       type :   \"int8\" ,\n\n      quantile:  0.8 ,\n\n      always_ram:  true ,\n\n    },\n\n  },\n\n});\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\nuse   qdrant_client::qdrant::{ \n\n     quantization_config_diff::Quantization,   vectors_config_diff::Config,   HnswConfigDiff, \n\n     QuantizationConfigDiff,   QuantizationType,   ScalarQuantization,   VectorParamsDiff, \n\n     VectorsConfigDiff, \n\n}; \n\n\n\nclient \n\n     .update_collection( \n\n         \"{collection_name}\" , \n\n         None , \n\n         None , \n\n         None , \n\n         Some ( & HnswConfigDiff   { \n\n             ef_construct:  Some ( 123 ), \n\n             .. Default ::default() \n\n         }), \n\n         Some ( & VectorsConfigDiff   { \n\n             config:  Some (Config::ParamsMap( \n\n                 qdrant_client::qdrant::VectorParamsDiffMap   { \n\n                     map:  HashMap ::from([( \n\n                         ( \"my_vector\" .into()), \n\n                         VectorParamsDiff   { \n\n                             hnsw_config:  Some (HnswConfigDiff   { \n\n                                 m:  Some ( 32 ), \n\n                                 ef_construct:  Some ( 123 ), \n\n                                 .. Default ::default() \n\n                             }), \n\n                             .. Default ::default() \n\n                         }, \n\n                     )]), \n\n                 }, \n\n             )), \n\n         }), \n\n         Some ( & QuantizationConfigDiff   { \n\n             quantization:  Some (Quantization::Scalar(ScalarQuantization   { \n\n                 r#type:  QuantizationType ::Int8   as   i32 , \n\n                 quantile:  Some ( 0.8 ), \n\n                 always_ram:  Some ( true ), \n\n                 .. Default ::default() \n\n             })), \n\n         }), \n\n     ) \n\n     . await ? ; \n\n```\n\n## Collection info\n\nQdrant allows determining the configuration parameters of an existing collection to better understand how the points are\ndistributed and indexed.\n\n```\nGET /collections/{collection_name}\n\n{\n\n    \"result\": {\n\n        \"status\": \"green\",\n\n        \"optimizer_status\": \"ok\",\n\n        \"vectors_count\": 1068786,\n\n        \"indexed_vectors_count\": 1024232,\n\n        \"points_count\": 1068786,\n\n        \"segments_count\": 31,\n\n        \"config\": {\n\n            \"params\": {\n\n                \"vectors\": {\n\n                    \"size\": 384,\n\n                    \"distance\": \"Cosine\"\n\n                },\n\n                \"shard_number\": 1,\n\n                \"replication_factor\": 1,\n\n                \"write_consistency_factor\": 1,\n\n                \"on_disk_payload\": false\n\n            },\n\n            \"hnsw_config\": {\n\n                \"m\": 16,\n\n                \"ef_construct\": 100,\n\n                \"full_scan_threshold\": 10000,\n\n                \"max_indexing_threads\": 0\n\n            },\n\n            \"optimizer_config\": {\n\n                \"deleted_threshold\": 0.2,\n\n                \"vacuum_min_vector_number\": 1000,\n\n                \"default_segment_number\": 0,\n\n                \"max_segment_size\": null,\n\n                \"memmap_threshold\": null,\n\n                \"indexing_threshold\": 20000,\n\n                \"flush_interval_sec\": 5,\n\n                \"max_optimization_threads\": 1\n\n            },\n\n            \"wal_config\": {\n\n                \"wal_capacity_mb\": 32,\n\n                \"wal_segments_ahead\": 0\n\n            }\n\n        },\n\n        \"payload_schema\": {}\n\n    },\n\n    \"status\": \"ok\",\n\n    \"time\": 0.00010143\n\n}\n\n```\n\n`client . get_collection(collection_name = \" {collection_name} \" )\n`\n\n`client.getCollection( \"{collection_name}\" );\n`\n\n`client.collection_info( \"{collection_name}\" ). await ? ; \n`\n\nIf you insert the vectors into the collection, the `status` field may become `yellow` whilst it is optimizing. It will become `green` once all the points are\nsuccessfully processed.\n\nThe following color statuses are possible:\n\n- \ud83d\udfe2 `green` : collection is ready\n- \ud83d\udfe1 `yellow` : collection is optimizing\n- \ud83d\udd34 `red` : an error occurred which the engine could not recover from\n\n\n### Approximate point and vector counts\n\nYou may be interested in the count attributes:\n\n- `points_count` - total number of objects (vectors and their payloads) stored in the collection\n- `vectors_count` - total number of vectors in a collection, useful if you have multiple vectors per point\n- `indexed_vectors_count` - total number of vectors stored in the HNSW or sparse index. Qdrant does not store all the vectors in the index, but only if an index segment might be created for a given configuration.\n\n\nThe above counts are not exact, but should be considered approximate. Depending\non how you use Qdrant these may give very different numbers than what you may\nexpect. It\u2019s therefore important **not** to rely on them.\n\nMore specifically, these numbers represent the count of points and vectors in\nQdrant\u2019s internal storage. Internally, Qdrant may temporarily duplicate points\nas part of automatic optimizations. It may keep changed or deleted points for a\nbit. And it may delay indexing of new points. All of that is for optimization\nreasons.\n\nUpdates you do are therefore not directly reflected in these numbers. If you see\na wildly different count of points, it will likely resolve itself once a new\nround of automatic optimizations has completed.\n\nTo clarify: these numbers don\u2019t represent the exact amount of points or vectors\nyou have inserted, nor does it represent the exact number of distinguishable\npoints or vectors you can query. If you want to know exact counts, refer to the[ count API ](../points/#counting-points).\n\n *Note: these numbers may be removed in a future version of Qdrant.* \n\n### Indexing vectors in HNSW\n\nIn some cases, you might be surprised the value of `indexed_vectors_count` is lower than `vectors_count` . This is an intended behaviour and\ndepends on the[ optimizer configuration ](../optimizer). A new index segment is built if the size of non-indexed vectors is higher than the\nvalue of `indexing_threshold` (in kB). If your collection is very small or the dimensionality of the vectors is low, there might be no HNSW segment\ncreated and `indexed_vectors_count` might be equal to `0` .\n\nIt is possible to reduce the `indexing_threshold` for an existing collection by[ updating collection parameters ](https://qdrant.tech/documentation/collections/#create-collection/#update-collection-parameters).\n\n## Collection aliases\n\nIn a production environment, it is sometimes necessary to switch different versions of vectors seamlessly.\nFor example, when upgrading to a new version of the neural network.\n\nThere is no way to stop the service and rebuild the collection with new vectors in these situations.\nAliases are additional names for existing collections.\nAll queries to the collection can also be done identically, using an alias instead of the collection name.\n\nThus, it is possible to build a second collection in the background and then switch alias from the old to the new collection.\nSince all changes of aliases happen atomically, no concurrent requests will be affected during the switch.\n\n### Create alias\n\n```\nPOST /collections/aliases\n\n{\n\n    \"actions\": [\n\n        {\n\n            \"create_alias\": {\n\n                \"collection_name\": \"example_collection\",\n\n                \"alias_name\": \"production_collection\"\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . update_collection_aliases(\n\n    change_aliases_operations = [\n\n        models . CreateAliasOperation(\n\n            create_alias = models . CreateAlias(\n\n                collection_name = \"example_collection\" , alias_name = \"production_collection\" \n\n            )\n\n        )\n\n    ]\n\n)\n\n```\n\n```\nclient.updateCollectionAliases({\n\n  actions :  [\n\n    {\n\n      create_alias :  {\n\n        collection_name :   \"example_collection\" ,\n\n        alias_name :   \"production_collection\" ,\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n`client.create_alias( \"example_collection\" ,   \"production_collection\" ). await ? ; \n`\n\n### Remove alias\n\n```\nPOST /collections/aliases\n\n{\n\n    \"actions\": [\n\n        {\n\n            \"delete_alias\": {\n\n                \"alias_name\": \"production_collection\"\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . update_collection_aliases(\n\n    change_aliases_operations = [\n\n        models . DeleteAliasOperation(\n\n            delete_alias = models . DeleteAlias(alias_name = \"production_collection\" )\n\n        ),\n\n    ]\n\n)\n\n```\n\n```\nclient.updateCollectionAliases({\n\n  actions :  [\n\n    {\n\n      delete_alias :  {\n\n        alias_name :   \"production_collection\" ,\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n`client.delete_alias( \"production_collection\" ). await ? ; \n`\n\n### Switch collection\n\nMultiple alias actions are performed atomically.\nFor example, you can switch underlying collection with the following command:\n\n```\nPOST /collections/aliases\n\n{\n\n    \"actions\": [\n\n        {\n\n            \"delete_alias\": {\n\n                \"alias_name\": \"production_collection\"\n\n            }\n\n        },\n\n        {\n\n            \"create_alias\": {\n\n                \"collection_name\": \"example_collection\",\n\n                \"alias_name\": \"production_collection\"\n\n            }\n\n        }\n\n    ]\n\n}\n\n```\n\n```\nclient . update_collection_aliases(\n\n    change_aliases_operations = [\n\n        models . DeleteAliasOperation(\n\n            delete_alias = models . DeleteAlias(alias_name = \"production_collection\" )\n\n        ),\n\n        models . CreateAliasOperation(\n\n            create_alias = models . CreateAlias(\n\n                collection_name = \"example_collection\" , alias_name = \"production_collection\" \n\n            )\n\n        ),\n\n    ]\n\n)\n\n```\n\n```\nclient.updateCollectionAliases({\n\n  actions :  [\n\n    {\n\n      delete_alias :  {\n\n        alias_name :   \"production_collection\" ,\n\n      },\n\n    },\n\n    {\n\n      create_alias :  {\n\n        collection_name :   \"example_collection\" ,\n\n        alias_name :   \"production_collection\" ,\n\n      },\n\n    },\n\n  ],\n\n});\n\n```\n\n```\nclient.delete_alias( \"production_collection\" ). await ? ; \n\nclient.create_alias( \"example_collection\" ,   \"production_collection\" ). await ? ; \n\n```\n\n### List collection aliases\n\n`GET /collections/{collection_name}/aliases\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . get_collection_aliases(collection_name = \" {collection_name} \" )\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.getCollectionAliases( \"{collection_name}\" );\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.list_collection_aliases( \"{collection_name}\" ). await ? ; \n\n```\n\n### List all aliases\n\n`GET /aliases\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . get_aliases()\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.getAliases();\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.list_aliases(). await ? ; \n\n```\n\n### List all collections\n\n`GET /collections\n`\n\n```\nfrom   qdrant_client   import  QdrantClient\n\n\n\nclient  =  QdrantClient( \"localhost\" , port = 6333 )\n\n\n\nclient . get_collections()\n\n```\n\n```\nimport  { QdrantClient }  from   \"@qdrant/js-client-rest\" ;\n\n\n\nconst  client  =   new  QdrantClient({ host :   \"localhost\" , port:  6333  });\n\n\n\nclient.getCollections();\n\n```\n\n```\nuse   qdrant_client::client::QdrantClient; \n\n\n\nlet   client   =   QdrantClient::from_url( \"http://localhost:6334\" ).build() ? ; \n\n\n\nclient.list_collections(). await ? ; \n\n```\n\n##### Table of contents\n\n- [ Setting up multitenancy ](https://qdrant.tech/documentation/collections/#create-collection/#setting-up-multitenancy)\n- [ Create a collection ](https://qdrant.tech/documentation/collections/#create-collection/#create-a-collection)\n    - [ Create collection from another collection ](https://qdrant.tech/documentation/collections/#create-collection/#create-collection-from-another-collection)\n\n- [ Collection with multiple vectors ](https://qdrant.tech/documentation/collections/#create-collection/#collection-with-multiple-vectors)\n\n- [ Collection with sparse vectors ](https://qdrant.tech/documentation/collections/#create-collection/#collection-with-sparse-vectors)\n\n- [ Delete collection ](https://qdrant.tech/documentation/collections/#create-collection/#delete-collection)\n\n- [ Update collection parameters ](https://qdrant.tech/documentation/collections/#create-collection/#update-collection-parameters)\n- [ Collection info ](https://qdrant.tech/documentation/collections/#create-collection/#collection-info)\n    - [ Approximate point and vector counts ](https://qdrant.tech/documentation/collections/#create-collection/#approximate-point-and-vector-counts)\n\n- [ Indexing vectors in HNSW ](https://qdrant.tech/documentation/collections/#create-collection/#indexing-vectors-in-hnsw)\n- [ Collection aliases ](https://qdrant.tech/documentation/collections/#create-collection/#collection-aliases)\n    - [ Create alias ](https://qdrant.tech/documentation/collections/#create-collection/#create-alias)\n\n- [ Remove alias ](https://qdrant.tech/documentation/collections/#create-collection/#remove-alias)\n\n- [ Switch collection ](https://qdrant.tech/documentation/collections/#create-collection/#switch-collection)\n\n- [ List collection aliases ](https://qdrant.tech/documentation/collections/#create-collection/#list-collection-aliases)\n\n- [ List all aliases ](https://qdrant.tech/documentation/collections/#create-collection/#list-all-aliases)\n\n- [ List all collections ](https://qdrant.tech/documentation/collections/#create-collection/#list-all-collections)\n\n\n- [ \n Edit on GitHub\n ](https://github.com/qdrant/landing_page/tree/master/qdrant-landing/content/documentation/concepts/collections.md)\n- [ \n Create an Issue\n ](https://github.com/qdrant/landing_page/issues/new/choose)\n\n\n#### Product\n\n- [ \nUse cases\n ](https://qdrant.tech/use-cases/)\n- [ \nSolutions\n ](https://qdrant.tech/solutions/)\n- [ \nBenchmarks\n ](https://qdrant.tech/benchmarks/)\n- [ \nDemos\n ](https://qdrant.tech/demo/)\n- [ \nPricing\n ](https://qdrant.tech/pricing/)\n\n\n#### Community\n\n- [ \n\u00a0\nGithub\n ](https://github.com/qdrant/qdrant)\n- [ \n\u00a0\nDiscord\n ](https://qdrant.to/discord)\n- [ \n\u00a0\nTwitter\n ](https://qdrant.to/twitter)\n- [ \n\u00a0\nNewsletter\n ](https://qdrant.tech/subscribe/)\n- [ \n\u00a0\nContact us\n ](https://qdrant.to/contact-us)\n\n\n#### Company\n\n- [ \nJobs\n ](https://qdrant.join.com)\n- [ \nPrivacy Policy\n ](https://qdrant.tech/legal/privacy-policy/)\n- [ \nTerms\n ](https://qdrant.tech/legal/terms_and_conditions/)\n- [ \nImpressum\n ](https://qdrant.tech/legal/impressum/)\n- [ \nCredits\n ](https://qdrant.tech/legal/credits/)\n\n\n#### Latest Publications\n\n#### Combining the precision of exact keyword search with NN-based ranking\n\n#### Qdrant 1.7.0 brought a bunch of new features. Let's take a closer look at them!\n\n#### Qdrant 1.6 brings recommendations strategies and more flexibility to the Recommendation API.\n\n- [  ](https://github.com/qdrant/qdrant)\n- [  ](https://qdrant.to/linkedin)\n- [  ](https://qdrant.to/twitter)\n- [  ](https://qdrant.to/discord)\n- [  ](https://www.youtube.com/channel/UC6ftm8PwH1RU_LM1jwG0LQA)\n\n\n##### Thanks for using Qdrant!\n\nSubscribe to our e-mail newsletter if you want to be updated on new features and news regarding\nQdrant.\n\nLike what we are doing? Consider giving us a \u2b50[ on Github ](https://github.com/qdrant/qdrant).\n\nWe use cookies to learn more about you. At any time you can delete or block cookies through your browser settings."}