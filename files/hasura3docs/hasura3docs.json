{"https://hasura.io/docs/3.0/": "# Hasura DDN Documentation\n\nWelcome to Hasura DDN public alpha!\n\nWe're happy to have you with us and are excited to share what we've been working on.\n\nHasura Data Delivery Network (DDN) provides instant GraphQL APIs on various data sources. It's a new way for backend teams to provide data access from the edge in a reliable, performant and secure way.\n\nHasura brings you lightning-fast builds, a declarative metadata specification, and a set of developer tools to make you and your teams more productive than ever.\n\nThis documentation is a work in progress and we would love your feedback. If you have any suggestions or find any bugs, please use our handy feedback component on each page and reach out.\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/9V8IwOaozqE?enablejsapi=1&origin=https://hasura.io)\n\n### Popular Topics\n\n#### Basics\n\nHere, you can learn more about our core concepts; we'll cover all the basics so you're ready to start building.\n\n#### Get Started\n\nLearn how to get started with Hasura and deploy a GraphQL API on your data in minutes.\n\n#### GraphQL API\n\nWe provide an instant GraphQL API by generating your GraphQL schema for you based on your data.", "https://hasura.io/docs/3.0/index/": "# Hasura DDN Documentation\n\nWelcome to Hasura DDN public alpha!\n\nWe're happy to have you with us and are excited to share what we've been working on.\n\nHasura Data Delivery Network (DDN) provides instant GraphQL APIs on various data sources. It's a new way for backend teams to provide data access from the edge in a reliable, performant and secure way.\n\nHasura brings you lightning-fast builds, a declarative metadata specification, and a set of developer tools to make you and your teams more productive than ever.\n\nThis documentation is a work in progress and we would love your feedback. If you have any suggestions or find any bugs, please use our handy feedback component on each page and reach out.\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/9V8IwOaozqE?enablejsapi=1&origin=https://hasura.io)\n\n### Popular Topics\n\n#### Basics\n\nHere, you can learn more about our core concepts; we'll cover all the basics so you're ready to start building.\n\n#### Get Started\n\nLearn how to get started with Hasura and deploy a GraphQL API on your data in minutes.\n\n#### GraphQL API\n\nWe provide an instant GraphQL API by generating your GraphQL schema for you based on your data.", "https://hasura.io/docs/3.0/getting-started/overview/": "# Get Started with Hasura\n\nYou can quickly and easily get started with Hasura for free.\n\nYou can create a project, connect a data source, and have an API in minutes \u2014 all from your IDE.\n\n#### Quick Links\n\n- [ Get started with DDN. ](https://hasura.io/docs/3.0/getting-started/local-dev/)\n\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/MdVd7tbrNN8?enablejsapi=1&origin=https://hasura.io)\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/Basics/overview/": "# Basics\n\nHasura DDN is a GraphQL engine that connects to your databases & microservices and instantly gives you a production-ready GraphQL API. It utilizes the OpenDD Specification to provide a consistent and reliable API experience.\n\n#### Quick Links\n\n- [ Understand the core concepts of Hasura DDN. ](https://hasura.io/docs/3.0/basics/core-concepts/)\n- [ Familiarize yourself with why and how we build Hasura DDN. ](https://hasura.io/docs/3.0/basics/background/)\n\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/auth/overview/": "# Authentication\n\nHasura gives you the power to authenticate users how you want, integrating with many popular auth services or your own existing custom solution hosted elsewhere.\n\n\n#### Quick Links\n\n- [ Check out the AuthConfig metadata. ](https://hasura.io/docs/3.0/auth/authentication/)\n- [ Implement auth using JWT mode. ](https://hasura.io/docs/3.0/auth/authentication/jwt/)\n- [ Implement auth using webhook mode. ](https://hasura.io/docs/3.0/auth/authentication/webhook/)\n\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/KQ6MHzp6XzE?enablejsapi=1&origin=https://hasura.io)\n\nImage: [ Authentication and authorization with Hasura ](https://hasura.io/docs/3.0/assets/images/auth-high-level-overview-diagram-0e382368ed24f0a214f1363003958e5e.png)\n\n## Using Authentication\u200b\n\n### JWT Mode\n\nWith JWT Mode, Hasura can easily integrate with your existing authentication service and rapidly help you configure granular access to your data.\n\n### Webhook Mode\n\nWith webhook mode you can specify a URL for Hasura to call which will return user information in session variables.\n\n### Role Emulation\n\nHasura can be set up to emulate roles and process requests using the defined access-control rules for another role. This can be useful for testing without setting up authentication.\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/connectors/overview/": "# Hasura Native Data Connectors Overview\n\nNative Data Connectors are a way to connect your Hasura GraphQL Engine to external data sources.\n\nYou can use them to query and join data across multiple data sources. Built using the[ Native Data Connector Specification ](https://github.com/hasura/ndc-spec/), you can use the ones that are available out of the box, or build your own.\n\n#### Quick Links\n\n- [ Build (and share) your own connector! ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/)\n- [ Learn more about connectors. ](https://hasura.io/docs/3.0/connectors/introduction/)\n\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/C1TwiW6xJ-8?enablejsapi=1&origin=https://hasura.io)\n\n## Using connectors\u200b\n\n### Learn more about connectors\n\nCheck out a broad introduction to connectors and how to use them in your projects.\n\n### Use v3 connectors with v2 projects\n\nThere are a number of connectors that are available for Hasura GraphQL Engine v3.\n\n### Use the PostgreSQL connector\n\nLearn about the PostgreSQL connector for your next project.\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/data-domain-modeling/overview/": "# Data Domain Modeling\n\nHasura now uses the Open Data Domain Specification (OpenDD spec) as the foundation for constructing your data supergraph.\n\nThis specification serves as the definitive reference for your organization's data graph and APIs over it. It offers a declarative approach for defining your data models and configuring access-controlled APIs to access the data.\n\n#### Quick Links\n\n- [ Learn more about the OpenDD spec and how it can unlock your data. ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/)\n\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/jXiDgAjwfLs?enablejsapi=1&origin=https://hasura.io)\n\n### Learn OpenDD types\n\nLearn more about the OpenDD types available to you as you define your application's data layer.\n\n### Create models\n\nModels act as the building blocks for your application's data layer. Learn how to create them.\n\n### Define permissions\n\nPermissions give you a simple, declarative means of determining user roles with fine-grained access control.\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/graphql-api/overview/": "# GraphQL API\n\nWhen you add a new data connector to Hasura, depending on the source and the abilities of the connector, you'll be able to interact with your related and deeply nested data easily with the power of GraphQL.\n\nDocumentation for data connectors can be found either in the[ Connector Hub ](https://hasura.io/connectors)or in the repo of each connector itself. With the data connector documentation, you'll be able to find which of the GraphQL queries documented in this section are available to you.\n\nHasura supports only queries at this stage, with mutations and subscriptions coming soon\n\n#### Quick Links\n\n- [ Check out GraphQL queries. ](https://hasura.io/docs/3.0/graphql-api/queries/)\n- [ Visit the Connector Hub. ](https://hasura.io/connector)\n\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/edrjbjvvRow?enablejsapi=1&origin=https://hasura.io)\n\n## Using Queries\u200b\n\n### Filter query results\n\nLearn how to filter query results using `where` arguments.\n\n### Sort query results\n\nLearn how to sort query results using the `order_by` argument.\n\n### Make nested queries across types\n\nLearn how to make complex nested queries across different types in your GraphQL API.\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/ci-cd/overview/": "# Hasura DDN CI/CD\n\nHasura introduces a range of CI/CD features that significantly streamline the development, testing, and deployment of APIs. These features are designed to enhance the iteration process and reduce downtime during updates.\n\nYou'll enjoy sub-second CI/CD with builds and project shares, zero-downtime rollouts, rapid testing and deployments, and enhanced metadata version control.\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/o-MJmypRPro?enablejsapi=1&origin=https://hasura.io)\n\nImage: [ CI CD with Hasura ](https://hasura.io/docs/3.0/assets/images/CI_CD-6bc62c9b436693cb3c32e817828f9dcf.png)\n\n### Learn about projects\n\nProjects are hosted on Hasura DDN, our data delivery network.\n\n### See how builds work\n\nCreate builds to iteratively collaborate on your supergraph and test changes before applying them.\n\n### Use secrets to keep your details secure\n\nKeep your version-controlled metadata free of sensitive information using secrets.\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/cli/overview/": "# Hasura CLI\n\nHasura introduces a new CLI, that gives you complete control over your data layer.\n\nYou can create projects, apply builds, set secrets, and even tunnel to a secure local data source for development \u2014 all without leaving your favorite terminal.\n\n#### Quick Links\n\n- [ Learn how install the new CLI. ](https://hasura.io/docs/3.0/cli/installation/)\n- [ Check out the commands. ](https://hasura.io/docs/3.0/cli/commands/)\n\n\nEmbedded content: [ View content ](https://www.youtube.com/embed/o-MJmypRPro?enablejsapi=1&origin=https://hasura.io)\n\n### Install the CLI for macOS\n\nClick here to learn how to install the CLI.\n\n### Install the CLI for Linux\n\nClick here to learn how to install the CLI.\n\n### Install the CLI for Windows\n\nClick here to learn how to install the CLI.\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/observability/overview/": "# Observability\n\nOut of the box, Hasura DDN comes with a set of tools that help you monitor and debug your GraphQL API. With observability, you can check on the performance of your GraphQL API, debug errors, and get insights into your GraphQL API usage.\n\n#### Quick Links\n\n- [ Check out traces. ](https://hasura.io/docs/3.0/observability/traces/)\n\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/faq/": "# Hasura FAQ\n\n## What is the general architecture of Hasura DDN?\u200b\n\nHasura DDN is built on the major advancements made in Hasura Version 3:\n\n **Hasura Runtime Engine:** The Hasura Engine is responsible for processing and serving APIs based on provided\nmetadata. In DDN, the engine is serverless by default and there is a clear separation of build time and runtime\nconcerns which is analogous to compiled programming languages. Metadata can now be authored, edited and deployed\ndeclaratively without causing any downtime. The new engine can also serve production-grade APIs from the\nedge with extremely high performance since it accesses metadata on a per-request basis and benefits from vastly\nimproved startup times. Essentially the cold start problem has been removed in DDN leading to zero-downtime rollouts.\n\n **Open Data Domain Specification (OpenDD Spec):** At the heart of Hasura API development is the OpenDD\nspecification. It is a format which defines the structure of metadata used by the Hasura runtime engine. Think of the\nspecification as an API contract generator helping you to reason about your data domains and model your applications\nand APIs. It is a significant update to the existing Hasura metadata structure with fixed types such as `models` and `commands` . And by ensuring that it is API protocol agnostic it is easily extended to other API technologies\nbesides GraphQL such as gRPC and REST.[ Learn more ](https://hasura.io/docs/3.0/data-domain-modeling/overview/).\n\n **Native Data Connector (NDC) Specification:** The NDC specification describes how the API request will be executed and\nhow the engine will interact with the underlying data source and is a new data connectivity specification from Hasura.\nIn DDN, there is now no concept of \"native databases\" and access to all data sources including PostgreSQL will be\nbased on the native data connector specification. This helps in providing rich feature sets for *all* data sources as\ncompared to just a few select ones. Moreover, there is now a strong focus on enabling the community to build\ndata connector agents themselves. The specification and provided[ Rust ](https://github.com/hasura/ndc-hub#rust-sdk)and[ Typescript ](https://github.com/hasura/ndc-sdk-typescript)SDKs support building high-quality integrations for\nalmost any conceivable data source (both databases and APIs), offering features like native queries, push-down\ncapabilities, and connection pooling.[ Learn more ](https://hasura.io/docs/3.0/connectors/overview/).\n\n **Hasura Cloud:** The cloud layer in Hasura DDN, Hasura Cloud, introduces the Data Delivery Network (DDN) for global API\nperformance and availability. This layer also facilitates secure tunnels for local development using Hasura Secure\nConnect and also offers tools for managing projects, builds, environments, secrets, subgraph namespaces and essentially\nrepresents the control plane for Hasura DDN.\n\n **Hasura CLI:** The new Hasura CLI (Command-Line Interface), serves as a powerful tool for developers\nto interact with the Hasura platform. It allows users to initialize projects, manage metadata, create builds, and deploy\nproduction APIs both locally and in the cloud, easily.[ Learn More ](https://hasura.io/docs/3.0/cli/overview/)\n\n **Hasura Console:** The Hasura Console has been revamped to enable rapid onboarding, testing and troubleshooting. The\nconsole now provides rich visualizations, deep dive metrics into models, enhanced traces, the new GraphiQL API\nexplorer, new operational health dashboard and a refurbished data manager that scales seamlessly with heavy loads.[Learn More]([ https://console.hasura.io/ ](https://console.hasura.io/))\n\n **Builds:** Each metadata change in Hasura now results in an atomic build which is represented by an immutable artifact\nthat is loaded onto Hasura DDN instantly. Which means there is inherent version control and the ability to push\nmetadata changes instantly and without errors.[ Learn more ](https://hasura.io/docs/3.0/ci-cd/builds/)\n\n **Environments:** Environments introduce the concept of infrastructure sharing and management in Hasura. Each build is\nspecific to an environment and provides a unique testing API. Users will need to create build profiles for each\nenvironment. The idea is to give development teams total flexibility to iterate using dedicated resources without\naffecting production workloads.[ Learn more ](https://hasura.io/docs/3.0/ci-cd/environments/)\n\n **Subgraphs:** Subgraphs introduce a module system for metadata. They allow multi-team organizations working on a\nHasura project to segment access to different metadata objects. A project's metadata is the amalgamation of metadata\nobjects from all its subgraphs, and each subgraph can be accessed and updated independently. It also helps in\navoiding conflicts when there are, for example, tables with the same names in different data sources.[ Learn more ](https://hasura.io/docs/3.0/ci-cd/subgraphs/)\n\n## What will be the benefit for me, the developer? (Why would I want to use or switch to DDN?)\u200b\n\n- Significant improvements to metadata authoring and management.\n    - No more cold start problem and instant changes to metadata. Deploy multiple times in an hour. Deploy with\nlightning speed and sub-second CI/CD.\n\n- No dependency on upstream services which means zero-downtime deployments.\n\n- Code driven workflows with advanced code generation tooling.\n\n- A single spec to define your whole API across diverse data sources.\n\n- Declarative metadata authoring with full control on API schema generation.\n\n- No metadata database - one less thing to manage in production.\n- Connect to any data with Native Data Connectors (NDCs).\n- Compose all your data sources, APIs and information into a single, powerful, inter-related supergraph.\n- Work better with your team with improved version control and collaboration features.\n- Unparalleled performance at any scale with optimized query execution and caching mechanisms.\n- Serverless runtime for improved efficiency and reduced latency.\n- Access a global edge network for low-latency, high-performance APIs with the Data Delivery Network (DDN).\n- Bring the programming language of your choice such as Typescript to compose business logic\n- Perform advanced mutations and workflows within the request response lifecycle.\n\n\n## What CI/CD features does Hasura DDN offer?\u200b\n\n **Instant CI/CD:** Hasura brings instant CI/CD capabilities, enabling developers to test and validate changes\nrapidly.\n\n **CLI-Controlled Deployments:** The Hasura Command-Line Interface (CLI) plays a central role in controlling and managing\ndeployments. It allows developers to manage projects, create builds and promote them to production. This CLI-centric\napproach simplifies the deployment process.[ Learn more ](https://hasura.io/docs/3.0/cli/overview/)\n\n **Builds and Project Shares:** With Hasura, metadata states are represented as builds. Once a build is thoroughly tested\nand validated, it can be applied to a project as the live API and made available to API consumers globally. This\nseparation of build and production steps ensure a smoother transition from development to production.\n\n **Extremely Fast Builds:** Hasura also introduces cloud innovations that allow metadata builds to be created instantly,\nregardless of the number of models. This means that deploying even a large number of models is a swift and seamless\nprocess and developers can rapidly test multiple deployments within a day.\n\n **Zero Downtime Rollouts:** With Hasura, going to production is facilitated without restarts and with zero downtime.\nThis ensures that your API remains available to users while updates are being applied.\n\n **Metadata Version Control:** Hasura includes in-product metadata version control. Each build is associated with a\nunique build ID, making it easier to track and manage different versions of your metadata. This enhances transparency\nand auditability during the deployment process.\n\n **Environments:** With environments you can design workflows that best mimic your software development lifecycle. Using\nenvironments enabled you to plan and manage infrastructure within your teams effectively.\n\n### What can be automated?\u200b\n\nSince metadata authoring is mostly code driven using the new LSP and the CLI, many metadata related changes can\nbe automated using a version management and CI/CD tool of your choice.\n\n## How does Hasura DDN connect to data sources?\u200b\n\nNative Data Connectors (NDC) are a framework introduced in Hasura DDN that enables developers to build custom data\nconnector agents. These agents facilitate the integration between Hasura and external data sources, allowing Hasura to\nseamlessly interact with a wide range of databases, services, and APIs. NDCs can be built for almost any conceivable\nsource of data and are the only way to connect to data sources in Hasura DDN.\n\nNative Data Connectors can either be self-hosted or hosted by Hasura.[ Learn more ](https://hasura.io/docs/3.0/connectors/overview/)\n\n## Is Hasura DDN open source?\u200b\n\nThe[ Hasura DDN engine ](https://github.com/hasura/v3-engine)and all[ Hasura data connectors ](https://hasura.io/connectors)are open-source.\n\n## What is the pricing structure for DDN?\u200b\n\nDDN is completely free for 90 days for all Alpha users. Stay tuned for additional pricing information.\n\n## What is the timeline for Hasura DDN? (When is v3 coming out?)\u200b\n\nHasura DDN Alpha is now publicly available, and we will continue to add features and listen to feedback from our\ncommunity. We are expecting the Beta release in few months, followed by General Availability within the first\nhalf of 2024. For the most up-to-date information on the timeline, we recommend referring to our[ official announcements and releases ](https://hasura.io/community/).\n\n## What does Alpha release mean?\u200b\n\nThis is the first public version of Hasura Data Delivery Network with a limited functionality set and some known issues.\nThis is to engage with the community at the earliest while continuing to work to make the platform stable and\nfunctionality complete. As such, there may be some breaking changes introduced in the Alpha version. Also, customer support\nwill be limited during this phase and most communication from Hasurans will happen via direct conversation with the\nteam via Discord channels, user groups, and community calls.\n\n## What is the recommended approach to metadata authoring?\u200b\n\nThe recommended approach is to start via the CLI and the CLI init command. This will create local directory and file\nscaffolding for you after which you can author metadata using our VS Code extension. The console is intended to be a\nquick getting started tool and for visualization and monitoring.\n\nWe expect most metadata management will happen via the code driven tools that we have in DDN. We are investing in\nextensive code generation capabilities via the LSP and users will still get to enjoy the quick authoring experiences\nof v2 such as that of permission building, outside the console.\n\n## Authoring metadata looks hard, how can I get started?\u200b\n\nThe Hasura LSP (Language Server Protocol)[ plugin for VSCode ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)and other editors will help you\nget started with authoring. It includes autocomplete, validations, code actions and go-to-definition features.\n\n## Will DDN be self-hosted?\u200b\n\nDDN Alpha and Beta will not be available as self-hosted options. We are evaluating plans to meet the deployment\nneeds of our users as we move towards general availability.\n\n### Why don\u2019t you have a container I can download?\u200b\n\nHasura DDN leverages a range of cloud services to offer comprehensive features and advanced innovations. We are\ncommitted to delivering optimum value to our users with the benefits offered by a cloud-first approach\n\n### Do I need a container to develop locally?\u200b\n\nNo. Our enhanced metadata authoring capabilities allow you to work via the Hasura VS Code plugin and CLI and test and\nvisualize your API endpoints via deployments in the Hasura DDN console.\n\nWe strongly believe that this is a more enhanced experience than building locally and then migrating ton your\nproduction endpoints.\n\n## I\u2019m operating in a given cloud provider region. How can I have Hasura run in the same region?\u200b\n\nHasura DDN is strategically deployed in 10 regions worldwide. (We plan to increase coverage drastically as we move\ncloser to Beta and beyond) Depending on the origin of a request, we automatically activate an instance of Hasura in the\nnearest region. This process is completed in under 10 milliseconds, ensuring consistently optimal performance,\nclosest to your users.\n\n## Will Hasura DDN be compatible with Hasura v1/v2?\u200b\n\nThe default generated GraphQL schema (ie: the API your consumers use) of Hasura DDN is compatible with v2 schemas\nand will not change. However, Hasura DDN uses a completely new metadata structure and hence will require migration\ntools to move metadata from v1/v2 metadata.\n\n## Will Hasura v2 be supported after Hasura DDN is released?\u200b\n\nWe will still support, maintain and improve Hasura v2 as per our[ version support policy ](https://hasura.io/docs/latest/policies/versioning/)and will be providing migration tools to\nmove Hasura v2 deployments to DDN in the near future.\n\n## What is the difference between how Hasura v2 and DDN metadata is handled?\u200b\n\nIn practical terms, the Hasura v2 metadata system was designed to draw extra information directly from the data source,\nspecifically details such as columns and fields.\n\nThis meant that whenever the Hasura GraphQL Engine was initialized, it had to probe or \"introspect\" the data source's\nschema to create a GraphQL schema. This introduced delays at start-up especially if the data source was large or if\nthere were network issues.\n\nOpenDD metadata operates differently as it is inherently self-contained and exists independent of any data source. This\nleads to instant startup and deploy times and ensures consistency as the system is no longer polling an underlying\ndata source for schema information which may have changed.\n\nThe OpenDD metadata has full coverage, and details like fields and their respective types are predefined and embedded\nwithin metadata. This design choice removes the need for the system to check the data source schema every time during\nstartup to shape a GraphQL schema. Instead, this introspection or probing of the data source's structure is now carried\nout during the metadata creation, or build phase. This leads to massively improved startup times and ensures that the\nmetadata is consistent and self-contained.\n\n## Will Hasura continue supporting existing plans, specifically, the Cloud Free and Professional plans?\u200b\n\nYes. We are committed to maintaining & supporting the Free and Professional plans to ensure there is no disruption\nto our users.\n\n## I heard DDN is built in Rust. Why Rust over Haskell?\u200b\n\nWe have a lot of love for Haskell. It's a beautiful language that we have been using for the Hasura engine since the\nbeginning, and will still be using it on Hasura v2. Without going into the weeds in a FAQ, we wanted to benefit from\nRust's performance, ecosystem and community for DDN. Rust is a modern, high-performance, and memory-safe language. It is\nalso gaining much traction in the cloud-native space, and we are excited to be using it for the significant parts of the\nHasura DDN codebase. If you are a Rust developer and want to do cool stuff, please check out our careers page.\n\n## How do I migrate from v1/v2 to DDN? (What would be the experience of bringing graphQL APIs in v3?)\u200b\n\nWe will provide a low-code migration tool for you to quickly port over to DDN in the coming months.\n\n### If currently running a v2.x will it be moved automatically to v3?\u200b\n\nNo, it will not. The v2 cloud projects will remain untouched and there will be no change of business. Moving to DDN\nwill be an opt-in process. Having said that, we strongly encourage upgrading to DDN early when features you require\nare available. Our teams are available to make the migration process as smooth as possible.\n\n### Can we request to lock ourselves to 2.x?\u200b\n\nThe migration is an opt-in process, so you do not need to request to have yourselves locked to a particular version.\nIf however, you see no upgrade path even in the next two years, please give us a heads-up and we will work out\noptions with you.\n\n### What is the migration path for the v2 Remote Schemas feature in v3?\u200b\n\nThe way to utilize remote schemas in DDN has changed from v2. However, we will make sure that the developer\nexperience is the same or better than it is in v2 and will provide migration guidance for this use-case in the\ncoming months.\n\n### Will Event and Scheduled Triggers be supported in Hasura DDN?\u200b\n\nYes they will be but the developer experience will change. We are still in the design phase for this and will provide\nmore details in the coming months.\n\n### Will Actions be supported in Hasura DDN?\u200b\n\nIf you mean business logic and API integration then yes but there is no concept of 'Actions' in Hasura DDN. In\nHasura DDN Alpha you can now use Typescript directly for 'Action-like' functionality. What is better is that now you\ncan host your Action webhooks/functions on Hasura itself. Moreover, we will be scaling support to most other popular\nlanguages such as Java, GoLang, Rust, Python and more.\n\n### Will Remote Schemas (external GraphQL APIs) be supported in Hasura DDN?\u200b\n\nYes, but there will not be a tab in Console or metadata object represented for Remote Schemas. All external GraphQL\nAPIs, previously known as Remote Schemas, will be utilized via Native Data Connectors. We will provide generic\nconnectors or connector SDKs so that you can bring in external GraphQL APIs in the low-code manner you are used to\nin v2.\n\n### Will mutations be supported in Hasura DDN?\u200b\n\nYes, of course, but the developer experience of configuring mutations will change.\n\n### What are the main changes to the Hasura Console?\u200b\n\nThere has been a complete redesign of the Hasura Console with new panels for visualization and operational health.\nWe have totally revamped the GraphiQL and Data Manager tabs and have implemented all new settings panel for\nenvironments, secrets, subgraphs and collaborators.\n\nMoreover, there is no longer the concept of an admin secret in Hasura DDN. In fact, we will auto generate a Personal\nAccess Token (PAT) which will provide the previous admin secret functionality.\n\n### Will v3 have a data manager in the console?\u200b\n\nYes. A better version which can scale with large datasets and be used for many types of databases and not only\nPostgreSQL.\n\n### What about database migrations?\u200b\n\nDatabase migrations are deprecated. We will provide a generated SQL that you can use in an ORM tool of your choice. We\nare open to any feedback on this product strategy. Do let us know about your pain point, and we can recommend a\nsolution that works best for you.\n\n## Is a Hasura DDN API faster than a Hasura v2 API?\u200b\n\nYes. Hasura DDN includes significant performance improvements compared to its predecessors. The optimizations\nimplemented in Hasura DDN aim to provide faster response times and improved scalability, ensuring a smooth and efficient\nexperience for your applications and users. We will be releasing detailed performance benchmarks in the coming months.\n\n### What did you think of this doc?\n\n- [ What is the general architecture of Hasura DDN? ](https://hasura.io/docs/3.0/faq/#what-is-the-general-architecture-of-hasura-ddn)\n- [ What will be the benefit for me, the developer? (Why would I want to use or switch to DDN?) ](https://hasura.io/docs/3.0/faq/#what-will-be-the-benefit-for-me-the-developer-why-would-i-want-to-use-or-switch-to-ddn)\n- [ What CI/CD features does Hasura DDN offer? ](https://hasura.io/docs/3.0/faq/#what-cicd-features-does-hasura-ddn-offer)\n    - [ What can be automated? ](https://hasura.io/docs/3.0/faq/#what-can-be-automated)\n- [ How does Hasura DDN connect to data sources? ](https://hasura.io/docs/3.0/faq/#how-does-hasura-ddn-connect-to-data-sources)\n- [ Is Hasura DDN open source? ](https://hasura.io/docs/3.0/faq/#is-hasura-ddn-open-source)\n- [ What is the pricing structure for DDN? ](https://hasura.io/docs/3.0/faq/#what-is-the-pricing-structure-for-ddn)\n- [ What is the timeline for Hasura DDN? (When is v3 coming out?) ](https://hasura.io/docs/3.0/faq/#what-is-the-timeline-for-hasura-ddn-when-is-v3-coming-out)\n- [ What does Alpha release mean? ](https://hasura.io/docs/3.0/faq/#what-does-alpha-release-mean)\n- [ What is the recommended approach to metadata authoring? ](https://hasura.io/docs/3.0/faq/#what-is-the-recommended-approach-to-metadata-authoring)\n- [ Authoring metadata looks hard, how can I get started? ](https://hasura.io/docs/3.0/faq/#authoring-metadata-looks-hard-how-can-i-get-started)\n- [ Will DDN be self-hosted? ](https://hasura.io/docs/3.0/faq/#will-ddn-be-self-hosted)\n    - [ Why don\u2019t you have a container I can download? ](https://hasura.io/docs/3.0/faq/#why-dont-you-have-a-container-i-can-download)\n\n- [ Do I need a container to develop locally? ](https://hasura.io/docs/3.0/faq/#do-i-need-a-container-to-develop-locally)\n- [ I\u2019m operating in a given cloud provider region. How can I have Hasura run in the same region? ](https://hasura.io/docs/3.0/faq/#im-operating-in-a-given-cloud-provider-region-how-can-i-have-hasura-run-in-the-same-region)\n- [ Will Hasura DDN be compatible with Hasura v1/v2? ](https://hasura.io/docs/3.0/faq/#will-hasura-ddn-be-compatible-with-hasura-v1v2)\n- [ Will Hasura v2 be supported after Hasura DDN is released? ](https://hasura.io/docs/3.0/faq/#will-hasura-v2-be-supported-after-hasura-ddn-is-released)\n- [ What is the difference between how Hasura v2 and DDN metadata is handled? ](https://hasura.io/docs/3.0/faq/#what-is-the-difference-between-how-hasura-v2-and-ddn-metadata-is-handled)\n- [ Will Hasura continue supporting existing plans, specifically, the Cloud Free and Professional plans? ](https://hasura.io/docs/3.0/faq/#will-hasura-continue-supporting-existing-plans-specifically-the-cloud-free-and-professional-plans)\n- [ I heard DDN is built in Rust. Why Rust over Haskell? ](https://hasura.io/docs/3.0/faq/#i-heard-ddn-is-built-in-rust-why-rust-over-haskell)\n- [ How do I migrate from v1/v2 to DDN? (What would be the experience of bringing graphQL APIs in v3?) ](https://hasura.io/docs/3.0/faq/#how-do-i-migrate-from-v1v2-to-ddn-what-would-be-the-experience-of-bringing-graphql-apis-in-v3)\n    - [ If currently running a v2.x will it be moved automatically to v3? ](https://hasura.io/docs/3.0/faq/#if-currently-running-a-v2x-will-it-be-moved-automatically-to-v3)\n\n- [ Can we request to lock ourselves to 2.x? ](https://hasura.io/docs/3.0/faq/#can-we-request-to-lock-ourselves-to-2x)\n\n- [ What is the migration path for the v2 Remote Schemas feature in v3? ](https://hasura.io/docs/3.0/faq/#what-is-the-migration-path-for-the-v2-remote-schemas-feature-in-v3)\n\n- [ Will Event and Scheduled Triggers be supported in Hasura DDN? ](https://hasura.io/docs/3.0/faq/#will-event-and-scheduled-triggers-be-supported-in-hasura-ddn)\n\n- [ Will Actions be supported in Hasura DDN? ](https://hasura.io/docs/3.0/faq/#will-actions-be-supported-in-hasura-ddn)\n\n- [ Will Remote Schemas (external GraphQL APIs) be supported in Hasura DDN? ](https://hasura.io/docs/3.0/faq/#will-remote-schemas-external-graphql-apis-be-supported-in-hasura-ddn)\n\n- [ Will mutations be supported in Hasura DDN? ](https://hasura.io/docs/3.0/faq/#will-mutations-be-supported-in-hasura-ddn)\n\n- [ What are the main changes to the Hasura Console? ](https://hasura.io/docs/3.0/faq/#what-are-the-main-changes-to-the-hasura-console)\n\n- [ Will v3 have a data manager in the console? ](https://hasura.io/docs/3.0/faq/#will-v3-have-a-data-manager-in-the-console)\n\n- [ What about database migrations? ](https://hasura.io/docs/3.0/faq/#what-about-database-migrations)\n- [ Is a Hasura DDN API faster than a Hasura v2 API? ](https://hasura.io/docs/3.0/faq/#is-a-hasura-ddn-api-faster-than-a-hasura-v2-api)\n", "https://hasura.io/docs/3.0/glossary/": "# Hasura DDN Glossary\n\n## Data Delivery Network (DDN)\u200b\n\nHasura DDN is a globally distributed and always-available cloud for APIs and data connectivity which enables\nblazingly-fast and secure delivery of real-time data over GraphQL or REST APIs. It is powered by innovations in Hasura\nversion 3 including a serverless runtime and the new OpenDD metadata specification.\n\n## Serverless Runtime System\u200b\n\nThe new runtime engine in Hasura DDN which accesses metadata on a per-request basis, enabling improved isolation and\nscalability. The serverless runtime also eliminates shared state and cold start issues for enhanced performance.\n\n## Metadata Authoring\u200b\n\nThe process of defining and creating metadata files using the OpenDD and Native Data Connector specifications in Hasura\nDDN. It involves specifying data types, models, commands, data source and API configurations. Learn[ more ](https://hasura.io/docs/3.0/data-domain-modeling/overview/).\n\n## Open Data Domain Specification (OpenDD Spec)\u200b\n\nA standardized specification that defines the metadata structure for APIs in Hasura DDN. The OpenDD spec includes typed\nmetadata objects such as types, models, commands, data sources, functions and API configurations. Learn[ more ](https://hasura.io/docs/3.0/data-domain-modeling/overview/).\n\n## Data Sources\u200b\n\nAny external data source, database, or service that can be connected to Hasura DDN using a Data Connector agent. Every\ndata source must have connector URL and schema.[ Learn more ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/).\n\n## Native Data Connector Specification (NDC Spec)\u200b\n\nA standardized specification that allows you to extend the functionality of the Hasura server by providing web services\nwhich can resolve new sources of data that defines the metadata structure for APIs in Hasura DDN. All data backends in\nHasura DDN conform to this backend and use types defined by this specification such as collections, functions and\nprocedures. Learn[ more ](https://hasura.github.io/ndc-spec/).\n\n## Native Data Connector Agents\u200b\n\nData connector agents that integrate Hasura with various external data sources and services and are based on the native\ndata connector specification. Native data connectors can be either official Hasura connectors, verified by Hasura or a\nnon-verified connector.[ Learn more ](https://hasura.io/docs/3.0/connectors/overview/).\n\n## Push-Down Capabilities\u200b\n\nThe ability in Hasura DDN to delegate certain query operations including Authorization to the underlying data source.\nThis can improve query optimization and performance and is the reason why data connectors in Hasura DDN are called\n'native'.\n\n## Connector Hub\u200b\n\nRefers to the public site where all Native Data Connectors for Hasura DDN are listed. Users can discover connectors, get\nmore information about their specific features and find documentation on how to use each connector with Hasura DDN.[ Learn more ](https://hasura.io/connectors/).\n\n## Model\u200b\n\nAn OpenDD metadata object that is fundamental to API design in Hasura DDN. The model is the entity that has a direct\nmapping to the underlying native data connector schema object or collection.\n\nA model includes reference to the data type and includes configuration details related to API configuration, arguments\nand global ids.\n\nIt supports select, insert, update and delete operations. Within the select operation the different query operations\ninclude filtering, aggregating, paginating and limiting.[ Learn more ](https://hasura.io/docs/3.0/data-domain-modeling/models/).\n\n## Command\u200b\n\nThe Hasura entity that helps encapsulate business logic and represents an action that can be performed which returns\nback some type of result. It directly maps to the native data connector object's functions and procedures.[ Learn more ](https://hasura.io/docs/3.0/data-domain-modeling/commands/).\n\n## Relationships\u200b\n\nAn OpenDD metadata object in Hasura DDN that defines the relationship between two models or between a model and a\ncommand. This facilitates data interconnection.[ Learn more ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/).\n\n## Permissions\u200b\n\nAn OpenDD metadata object in Hasura DDN that defines the access control or authorization rules on models and commands.[ Learn more ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/).\n\n## Global ID\u200b\n\nRefers to the Relay global ID that encodes the type and ID of an object in a single string. In Hasura this is defined\nper model and enables fetching any object directly, regardless of what kind of object it is. A result of this is that\nyou get the node root field in the GraphQL API schema to use with a Relay client.[ Learn more ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/).\n\n## Collection\u200b\n\nA collection is a native data connector spec object that maps one-to-one with the underlying data source object.\nTracking a collection results in the creation of a model OpenDD object in Hasura metadata.\n\nIt can be queried or mutated and contains name, arguments and object types.[ Learn more ](https://hasura.github.io/ndc-spec/specification/schema/collections.html).\n\n## Function\u200b\n\nA function is a native data connector specification object and is a special type of collection. It only returns a\nsingle row and a single column, can contain arguments and cannot be mutated.\n\nTracking a function results in the creation of a `Command` OpenDD object in Hasura metadata.[ Learn more ](https://hasura.github.io/ndc-spec/specification/schema/functions.html).\n\n## Procedure\u200b\n\nA procedure is a native data connector specification object, and it defines an action that the data connector\nimplements. Each procedure has arguments and a return type.\n\nTracking a procedure results in the creation of a `Command` OpenDD object in Hasura metadata.[ Learn more ](https://hasura.github.io/ndc-spec/specification/schema/procedures.html).\n\n## Builds\u200b\n\nEach metadata change in Hasura DDN represents an immutable build. Every build has a unique GraphQL Endpoint that can be\ntested independently. Builds are tied to projects and there is a one-to-many mapping between projects and builds.[ Learn more ](https://hasura.io/docs/3.0/ci-cd/overview/).\n\n## Subgraphs\u200b\n\nIn Hasura DDN, Subgraphs provide autonomy, separation and security to teams for working with project metadata and allow\nthem to organize and structure metadata as per team and business requirements. There can be multiple subgraphs in a\nproject.\n\nAll subgraphs contribute to one build at any given time, ie: one subgraph can be used create a build only when it does\nnot introduce a breaking change at the project level.[ Learn more ](https://hasura.io/docs/3.0/data-domain-modeling/overview/).\n\n## Hasura CLI (Command-Line Interface)\u200b\n\nA tool in Hasura DDN that enables developers to interact with Hasura from the command line. It supports various commands\nfor creating builds, deploying projects, creating tunnels and managing secrets.[ Learn more ](https://hasura.io/docs/3.0/cli/overview/).\n\n## LSP (language server protocol)\u200b\n\nThe Hasura Language Server Protocol (LSP) enables the integration of language features such as tracking data source\nobjects, validation of metadata, providing diagnostics at the time of authoring and helping autocomplete metadata.\n\nIt supports `.hml` files which are a Hasura variant of `.yaml` files. We have used the Hasura LSP to build our[ VSCode extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)which you can download to help\nyou write metadata. We have plans to provide extensions such as these for other text editors.\n\n## Hasura Secure Connect\u200b\n\nA feature in Hasura DDN that creates secure tunnels to connect with local resources, aiding local development while\nensuring data security. It requires a local daemon to be run via the CLI.\n\n## Hasura Console\u200b\n\nAn interface in Hasura DDN that provides tools for metadata visualizing, API testing and deployment, and team\ncollaboration. It offers tools to validate metadata before creating builds and metrics and traces to determine the usage\nand health of the API.\n\n## Secrets\u200b\n\nA secret is an object that contains small amounts of sensitive information such as database connection strings. It is\nbest practice to first create secrets using the Hasura CLI or Console and then use those secrets in the metadata.\n\n## Cloud PAT\u200b\n\nThis refers to a personal authentication token that Hasura Cloud creates automatically for you on every new project\ncreation. This ensures that your GraphQL API always has a security mechanism. The auto-generated PAT is included in the\nAPI header `cloud_pat` .\n\n### What did you think of this doc?\n\n- [ Data Delivery Network (DDN) ](https://hasura.io/docs/3.0/glossary/#data-delivery-network-ddn)\n- [ Serverless Runtime System ](https://hasura.io/docs/3.0/glossary/#serverless-runtime-system)\n- [ Metadata Authoring ](https://hasura.io/docs/3.0/glossary/#metadata-authoring)\n- [ Open Data Domain Specification (OpenDD Spec) ](https://hasura.io/docs/3.0/glossary/#open-data-domain-specification-opendd-spec)\n- [ Data Sources ](https://hasura.io/docs/3.0/glossary/#data-sources)\n- [ Native Data Connector Specification (NDC Spec) ](https://hasura.io/docs/3.0/glossary/#native-data-connector-specification-ndc-spec)\n- [ Native Data Connector Agents ](https://hasura.io/docs/3.0/glossary/#native-data-connector-agents)\n- [ Push-Down Capabilities ](https://hasura.io/docs/3.0/glossary/#push-down-capabilities)\n- [ Connector Hub ](https://hasura.io/docs/3.0/glossary/#connector-hub)\n- [ Model ](https://hasura.io/docs/3.0/glossary/#model)\n- [ Command ](https://hasura.io/docs/3.0/glossary/#command)\n- [ Relationships ](https://hasura.io/docs/3.0/glossary/#relationships)\n- [ Permissions ](https://hasura.io/docs/3.0/glossary/#permissions)\n- [ Global ID ](https://hasura.io/docs/3.0/glossary/#global-id)\n- [ Collection ](https://hasura.io/docs/3.0/glossary/#collection)\n- [ Function ](https://hasura.io/docs/3.0/glossary/#function)\n- [ Procedure ](https://hasura.io/docs/3.0/glossary/#procedure)\n- [ Builds ](https://hasura.io/docs/3.0/glossary/#builds)\n- [ Subgraphs ](https://hasura.io/docs/3.0/glossary/#subgraphs)\n- [ Hasura CLI (Command-Line Interface) ](https://hasura.io/docs/3.0/glossary/#hasura-cli-command-line-interface)\n- [ LSP (language server protocol) ](https://hasura.io/docs/3.0/glossary/#lsp-language-server-protocol)\n- [ Hasura Secure Connect ](https://hasura.io/docs/3.0/glossary/#hasura-secure-connect)\n- [ Hasura Console ](https://hasura.io/docs/3.0/glossary/#hasura-console)\n- [ Secrets ](https://hasura.io/docs/3.0/glossary/#secrets)\n- [ Cloud PAT ](https://hasura.io/docs/3.0/glossary/#cloud-pat)\n", "https://hasura.io/docs/3.0/basics/overview/": "# Basics\n\nHasura DDN is a GraphQL engine that connects to your databases & microservices and instantly gives you a production-ready GraphQL API. It utilizes the OpenDD Specification to provide a consistent and reliable API experience.\n\n#### Quick Links\n\n- [ Understand the core concepts of Hasura DDN. ](https://hasura.io/docs/3.0/basics/core-concepts/)\n- [ Familiarize yourself with why and how we build Hasura DDN. ](https://hasura.io/docs/3.0/basics/background/)\n\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/getting-started/local-dev/": "# Get Started with DDN\n\n## Introduction\u200b\n\nIn this guide, we'll walk you through the steps to create a new Hasura project, connect a database, execute your first\nquery, create lightning-fast production builds, and incorporate business logic using TypeScript \u2014 all with VS Code and\nthe **new Hasura CLI** . Throughout this guide, you'll be introduced to new Hasura concepts, like builds, our new\nmetadata structure, and more.\n\nGet an instant API!\n\nYou can create a project via[ the Console ](https://console.hasura.io)\u2014 our web-based GUI \u2014 to spin up an API by just\nproviding a database url. However, we recommended you follow the guide on this page to set up your project via the CLI,\nwhich will allow you to easily iterate on your project.\n\n## Step 1: Prerequisites\u200b\n\n1. Install the[ new Hasura CLI ](https://hasura.io/docs/3.0/cli/installation/)\n2. Install the[ Hasura VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)\n3. Have a PostgreSQL database\n\n\nYou can connect a local PostgreSQL database to Hasura DDN using the new[ Hasura CLI ](https://hasura.io/docs/3.0/cli/overview/). If you don't\nhave a PostgreSQL database and prefer to connect to a cloud provider, check out our friends at[ Neon ](https://neon.tech).\n\nDon't want to set up a database?\n\nWe've provisioned a read-only database for you to use for this guide if you'd like. You can use the following connection\nstring in Step 3:\n\n`postgresql://read_only_user:readonlyuser@35.236.11.122:5432/v3-docs-sample-app`\n\nI don't use VS Code\n\nGood news! LSP support is coming soon to other editors. In the meantime, give[ VS Code ](https://code.visualstudio.com/download)a try \u2014 it's a great editor!\n\n## Step 2: Log into Hasura\u200b\n\nAfter our prerequisites are taken care of, log into Hasura Cloud with the CLI:\n\n`hasura3 login`\n\nThis will open up a browser window and initiate an OAuth2 login flow. If the browser window doesn't open automatically,\nuse the link shown in the terminal output to launch the flow.\n\nNew CLI?!\n\nYep! If you can't tell already, we've completely rewritten the CLI from the ground up. You can learn more about the new\ncommands by running:\n\n`hasura3 --help`\n\n## Step 3: Create a new project\u200b\n\nTo create a new project, use the following command, passing the directory where you want to create the project as an\nargument. This command will create the configuration files and directory structure by default. It will also prompt you\nto create a new Hasura DDN project in the cloud too.\n\n```\nhasura3 init --dir  < PROJECT_DIRECTORY >\ncd   < PROJECT_DIRECTORY >\n```\n\nThe CLI will prompt you with the following:\n\n```\nUse the arrow keys to navigate: \u2193 \u2191 \u2192 \u2190\nPlease choose how you would like to initialise Hasura DDN?\n  Create a new project         |          ( Start building on a new DDN project )\n    Empty project\n```\n\nChoose `Create a new project` and the CLI will respond with the following:\n\n```\nCreating a new project\nCreating hasura.yaml  .. .\nCreating build-profile  .. .\nCreating metadata.hml  .. .\nProject  < PROJECT_NAME >  is created at  < DIR >\n```\n\nWhat's a project?\n\nEach project on Hasura DDN can have a corresponding local project that can be used for development. This local project\ncontains the following structure by default:\n\n```\n\u251c\u2500\u2500 build-profile.yaml\n\u251c\u2500\u2500 hasura.yaml\n\u251c\u2500\u2500 subgraphs\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 default\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 commands\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 dataconnectors\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 models\n\u2514\u2500\u2500 supergraph\n    \u251c\u2500\u2500 auth-config.hml\n    \u2514\u2500\u2500 compatibility-config.hml\n```\n\nWe'll dive into how to use these files as we continue through this guide. However, if you'd like more information on the\nnew project structure, see our page on[ project configuration ](https://hasura.io/docs/3.0/ci-cd/config/).\n\n## Step 4: Connect a data source\u200b\n\nThe next step is to add a data source to the project so that we can build APIs on that source. With Hasura DDN, a source\nis added through a Data Connector. We will use the[ Postgres Data Connector ](https://hasura.io/connectors/postgres).\n\n`hasura3 metadata add-hub-connector pg_db --dir  .  --subgraph default --id hasura/postgres --url  \"postgresql://read_only_user:readonlyuser@35.236.11.122:5432/v3-docs-sample-app\"`\n\nThis will also create a `.env` in the root of your project with the connection string you provided. This allows you to\nuse `.gitignore` to ignore the `.env` file and keep your connection string safe when committing your project to version\ncontrol.\n\nWe're passing a few flags to this command:\n\n- `--dir .` tells the CLI to use the current directory as the project directory.\n- `--subgraph default` tells the CLI to add the data source to the default[ subgraph ](https://hasura.io/docs/3.0/ci-cd/subgraphs/).\n- `--id hasura/postgres` tells the CLI to use the `hasura/postgres` connector from the[ connector hub ](https://hasura.io/connectors).\n\n\nDon't want to use our DB?\n\nIf you don't want to use our demo Postgres database, or you have a local database you want to try out with Hasura,\nreplace the url with your connection string.\n\nFor example, you can use a generic postgres connection string: `postgresql://<USERNAME>:<PASSWORD>@<HOST>:<PORT>/<DATABASE_NAME>` . This works with local databases, too \u2014 you can\ncreate a[ Secure Connect tunnel ](https://hasura.io/docs/3.0/ci-cd/tunnels/).\n\n## Step 5: Start watch mode\u200b\n\nNow that we have added a data source and scaffolded our metadata, let's start Hasura's watch mode so that when we make\nchanges, our GraphQL API will update automatically:\n\n`hasura3  watch  --dir  .`\n\nThe CLI will respond with the following warning to ensure you don't accidentally apply a build to your production\nenvironment:\n\n```\nThis command will create new builds in the selected environment \"default\" and change the current applied build.\nWe recommend using a test environment so that there is no disruption to existing work.\nDo you want to continue?\n```\n\nThis command will take over the current terminal tab and watch for changes to the folder. This will keep creating and\napplying new **builds** \u2014 that represent a new version of the GraphQL API \u2014 as you make changes. If you'd like to learn\nmore about watch mode and what flags you can pass, check out the[ CLI docs on watch mode ](https://hasura.io/docs/3.0/cli/commands/watch/).\n\nIf you are using a local Postgres database, this command also creates a tunnel to your local machine to make the\ndatabase available to Hasura DDN.\n\nWatch mode is for development only\n\nYou should not use watch mode in production. This leads to security vulnerabilities and performance issues.\n\nWhat's a build?\n\nThis is the first concept we've introduced in this guide. Builds are a new concept in Hasura that allow you to quickly\niterate and prototype on your project's metadata. A build is an immutable, fully-functioning GraphQL API that represents\na milestone in your development cycle.\n\nIt may be helpful to think of builds as git commits. Since each is deployed on Hasura DDN, it can be shared with other\nusers.\n\nEach build is completely independent. One project can have multiple builds, out of which, one is applied to production.\nThis workflow allows for easier rollbacks on production, and greater collaboration during development.\n\n## Step 6: Launch VS Code and track tables\u200b\n\nMake sure the[ Hasura VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)is\ninstalled and that you have logged in.\n\nLaunch VS Code in the project directory:\n\n`code  < PROJECT_DIRECTORY >`\n\nTo log in, open the command palette (Ctrl+Shift+P or Cmd+Shift+P) and type `Hasura: Login` . This will open a browser\nwindow and initiate a login flow. If the browser window doesn't open automatically, use the link shown in the\nnotification from VS Code to launch the flow.\n\nOpen the new `hml` file that was created at `subgraphs/default/dataconnectors/pg_db/pg_db.hml` . You'll see that Hasura\nautomatically introspected your data source and created your schema for you. From here, you can immediately track all\ntables, views, relationships, and quickly scaffold out your metadata by using the Hasura VS Code extension.\n\nBring up the command palette, type `hasura track all` , and choose the option from the dropdown. Then, select your data\nsource's name (e.g., `pg_db` ) from the dropdown.\n\nYour metadata files will be populated with everything you need to get started! \ud83c\udf89\n\nImage: [ VSCode data connector ](https://hasura.io/docs/3.0/assets/images/0.0.1_vscode-track-table-b3838e2adf2662239ee5f2054552bb2f.png)\n\nA lot happened under the hood. Let's break it down:\n\n- Within the `subgraphs/default/dataconnectors/pg_db` directory, a new `pg_types.hml` file was generated.\n    - This file contains all of the types that were introspected from your data source and that your API will use.\n- Within the `models` subdirectory, new named files for each of your models were created.\n    - These files contain the metadata for each model, including their fields, permissions, relationships, and more.\n\n\nWhat are models?\n\nModels are a new way to represent your data in Hasura.\n\nModels in the[ OpenDD Spec ](https://hasura.io/docs/3.0/data-domain-modeling/overview/)refer to a collection of objects (such as rows in a\nrelational database, or documents in a NoSQL database) of a given OpenDD Spec[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/).\nModels are backed by a data source and can support CRUD operations. You can learn more about models[ here ](https://hasura.io/docs/3.0/data-domain-modeling/models/).\n\nIdeally, you'll want to separate out each model into its own file. However, for the sake of this guide, we've kept them\nall in one file.\n\n## Step 7: Run your first query\u200b\n\nHead to the terminal where `hasura3 watch` is running. A new build was automatically generated when you imported models;\nyou can visit this using the link in the terminal output.\n\n```\n+---------------+------------------------------------------------------------+\n| Build ID      | <BUILD_ID>                                                 |\n+---------------+------------------------------------------------------------+\n| Build Version | <BUILD_VERSION>                                            |\n+---------------+------------------------------------------------------------+\n| Build URL     | https://<PROJECT_NAME_AND_BUILD_ID>.ddn.hasura.app/graphql |\n+---------------+------------------------------------------------------------+\n| Project Id    | <PROJECT_ID>                                               |\n+---------------+------------------------------------------------------------+\n| Console Url   | https://console.hasura.io/project/<PROJECT_NAME>/graphql   |\n+---------------+------------------------------------------------------------+\n| FQDN          | <PROJECT_NAME_AND_BUILD_ID_STUB>.ddn.hasura.app            |\n+---------------+------------------------------------------------------------+\n| Environment   | default                                                    |\n+---------------+------------------------------------------------------------+\n```\n\nWe're using the docs sample app's schema for this guide's visuals, but you can use the GraphiQL Explorer to create your\nquery or write it manually:\n\nImage: [ Execute a query ](https://hasura.io/docs/3.0/assets/images/0.0.1_console-execute-query-on-build-859fb8dd4c06c6f70a219ad293d06b76.png)\n\n```\nquery   OrdersQuery   {\n   orders   {\n     id\n     status\n     delivery_date\n     user   {\n       id\n       name\n       email\n     }\n     product   {\n       id\n       name\n     }\n   }\n}\n```\n\n## Step 8: Incorporate custom business logic\u200b\n\nWith DDN, Hasura introduces a new way of writing custom business logic using the the TypeScript connector. This exposes\nfunctions or procedures that can be added to Hasura metadata as a[ command ](https://hasura.io/docs/3.0/data-domain-modeling/commands/), which\ncan be made available over the GraphQL API as a query or a mutation.\n\nFirst, we'll kill the `hasura watch` session by pressing `Ctrl + C` in the terminal. Then, we can create a new\nTypeScript connector using the following command in the project's root:\n\n`hasura3 metadata add-hub-connector ts_logic --dir  .  --subgraph default --id hasura/ts-deno --url http://localhost:8100`\n\nThis command will create all necessary files required by the `ts-deno` connector, including the DataConnector metadata\nand TypeScript functions.\n\nNow that we added a new connector, head to the tab where `hasura3 watch` was running and restart the command. Deno's\nrequired to run the TypeScript connector locally, so you'll need to install it if you haven't already:\n\n```\n# install deno\ncurl  -fsSL https://deno.land/x/install/install.sh  |   sh\n# start hasura watch\nhasura3  watch\n```\n\nThis command will now start the connector locally using `deno` and then creates a tunnel from Hasura Cloud to your local\nmachine so that it is reachable.\n\nThere will be a new file called `index.ts` in this directory. This file will contain a simple hello world function:\n\n```\n// subgraphs/default/dataconnectors/ts_logic/index.ts\nexport   function   hello ( ) :   string   {\n   return   \"hello world\" ;\n}\n```\n\n## Step 9: Track the function as a procedure\u200b\n\nSwitch to VS Code and open `subgraphs/default/dataconnectors/ts_logic/ts_logic.hml` . The procedure `helloWorld` will be\nunderlined with a code action to track the function as a command in the subgraph. This will create a command metadata\nobject which will expose this function as a mutation. Just like before, your types will be generated for you.\n\nImage: [ Track a function in VSCode ](https://hasura.io/docs/3.0/assets/images/0.0.1_track-ts-27a9cdab928f5b7a14faed965ea9be34.png)\n\n## Step 10: Execute the function using GraphiQL\u200b\n\nA new build has been generated for you. You can run the following mutation in the GraphiQL Explorer to execute the\nfunction:\n\n```\nmutation   tsFunctionQuery   {\n   hello\n}\n```\n\nImage: [ Track a function in VSCode ](https://hasura.io/docs/3.0/assets/images/0.0.1_ts-mutation-1456889263c8dc355b606bc765f3547a.png)\n\nSince Deno and Hasura are watching for changes, you can modify the function and it will automatically update the API and\nbe available on DDN \ud83c\udf89\n\n## Step 11: Apply a build to production\u200b\n\nAs we've been developing our API, Hasura generated new builds for us in the background. We can see these builds by\nrunning the following command:\n\n`hasura3 build list`\n\n```\n+---------------+-------------+------------+--------------------------------------------+--------------------------------+--------------------------------+\n| BUILD VERSION | ENVIRONMENT | IS APPLIED |                 BUILD URL                  |          DESCRIPTION           |           CREATED AT           |\n+---------------+-------------+------------+--------------------------------------------+--------------------------------+--------------------------------+\n| dea725b352    | default     | true       | native-calf-5513-dea725b352.ddn.hasura.app | Watch build Thu, 30 Nov 2023   | Thu, 30 Nov 2023 15:35:00      |\n|               |             |            |                                            | 09:34:58 CST                   | +0000                          |\n+---------------+-------------+------------+--------------------------------------------+--------------------------------+--------------------------------+\n```\n\nWatch mode also **automatically** applies the newest build to the environment it's watching. This is one reason why\nwatch mode is incredibly powerful during development.\n\nIf you're not using watch mode, you can apply a build \u2014 which means it will serve as the API for the current\nenvironment's build \u2014 using the following command:\n\n`hasura3 build apply --version  < BUILD_VERSION >`\n\n## What's next?\u200b\n\n### Iterate on your metadata\u200b\n\nWe've just demonstrated how to quickly get set up and running with Hasura. Now that you've got a project up and running,\nyou can iterate on your metadata and build out your API. Head back to your IDE, make some modifications, create a new\nbuild, and see what happens \ud83c\udf89\n\nLearn more about structuring your data supergraph by checking out our[ Data Domain Modeling ](https://hasura.io/docs/3.0/data-domain-modeling/overview/)section.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/getting-started/local-dev/#introduction)\n- [ Step 1: Prerequisites ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-1-prerequisites)\n- [ Step 2: Log into Hasura ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-2-log-into-hasura)\n- [ Step 3: Create a new project ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-3-create-a-new-project)\n- [ Step 4: Connect a data source ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-4-connect-a-data-source)\n- [ Step 5: Start watch mode ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-5-start-watch-mode)\n- [ Step 6: Launch VS Code and track tables ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-6-launch-vs-code-and-track-tables)\n- [ Step 7: Run your first query ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-7-run-your-first-query)\n- [ Step 8: Incorporate custom business logic ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-8-incorporate-custom-business-logic)\n- [ Step 9: Track the function as a procedure ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-9-track-the-function-as-a-procedure)\n- [ Step 10: Execute the function using GraphiQL ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-10-execute-the-function-using-graphiql)\n- [ Step 11: Apply a build to production ](https://hasura.io/docs/3.0/getting-started/local-dev/#step-11-apply-a-build-to-production)\n- [ What's next? ](https://hasura.io/docs/3.0/getting-started/local-dev/#whats-next)\n", "https://hasura.io/docs/3.0/basics/alpha-release/": "# The Alpha Release\n\n## What is the Alpha release?\u200b\n\nThe Alpha release is the first public rollout of the Hasura Data Delivery Network geared towards a limited use-case set.\n\nThis is an opportunity for our engaged community to have early access to DDN and explore this significant update to the\nplatform. We encourage our users to be true design partners providing feedback and suggestions as we take the platform\ntowards general availability. We invite community members to let us know their thoughts and questions[ here ](https://discord.com/channels/407792526867693568/1164275846538874900)and engage with our product and engineering\nteams. To enable frictionless evaluation DDN, Alpha is completely free for 90 days for all Alpha users. We are rapidly\nevolving the platform and will keep you updated with the progress.\n\nPlease note that there could be some breaking changes introduced in the Alpha version, however we will make sure not to\nintroduce any drastic changes. In most instances, it would require you to create new builds without the need for\nrefactoring the entire metadata. We will give you advance notice before any such changes are rolled out in production.\nAlso, customer support will be limited during this phase and most of the communication wil happen via direct\nconversation with the Hasura team via discord channels, user groups, emails, and community calls.\n\n## What is available to use in the Alpha release?\u200b\n\nThe Alpha release offers an initial look into the power of Hasura DDN:\n\n### API Authoring\u200b\n\n- **VS Code Extension:** [ A VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)for\nHasura DDN that provides a rich editing experience for OpenDD metadata.\n- **LSP:** Language Server Protocol - a parser and validator for the OpenDD Specification that powers the VS Code\nextension.\n- **Hasura Console:** [ A UI ](https://console.hasura.io)for creating projects, viewing metadata, relationships and\nrunning API queries.\n\n\n### GraphQL API Features\u200b\n\n- **Queries:** Other GraphQL operations coming soon.\n- [ Mutations: via Commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)([ CQRS pattern ](https://learn.microsoft.com/en-us/azure/architecture/patterns/cqrs)). True database inserts, updates,\nand deletes via the respective data connectors are coming soon.\n- [ Permissions: ](https://hasura.io/docs/3.0/auth/authorization/index/)An OpenDD metadata object in Hasura DDN that defines the access\ncontrol or authorization rules on models and commands.\n- [ Relationships: ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/)An OpenDD metadata object in Hasura DDN that defines the\nrelationship between two models or between a model and a command. This facilitates data interconnection\n- [ Relay: ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/)The Relay global ID enables fetching any object directly, regardless\nof what kind of object it is.\n\n\n### CI/CD\u200b\n\n- [ Hasura3 CLI: ](https://hasura.io/docs/3.0/cli/overview/)A revamped Command-Line Interface for improved developer interactions.\n- **Secure Connect:** A feature in Hasura DDN that creates secure tunnels to connect with local resources, aiding local\ndevelopment while ensuring data security. It requires a local daemon to be run via the CLI.\n- [ Builds: ](https://hasura.io/docs/3.0/ci-cd/builds/)Each metadata change in Hasura DDN represents an immutable build. Every build has a\nunique GraphQL Endpoint that can be tested independently.\n- [ Projects: ](https://hasura.io/docs/3.0/ci-cd/projects/)Builds are tied to projects and there is a one-to-many mapping between projects\nand builds\n- [ Collaborators: ](https://hasura.io/docs/3.0/ci-cd/collaborators/)A way to work together in Cloud projects.\n- [ Subgraphs: ](https://hasura.io/docs/3.0/ci-cd/subgraphs/)A system to modularize metadata for better team collaboration.\n- [ Secrets: ](https://hasura.io/docs/3.0/ci-cd/secrets/)a means of storing sensitive information as key-value pairs that you don't want\nexposed in your metadata.\n\n\n### Business Logic with Typescript\u200b\n\n[ Typescript with Deno ](https://github.com/hasura/ndc-typescript-deno).\n\n### Native Data Connectors and SDKs\u200b\n\n- **Native Data Connector SDKs:** [ Rust ](https://github.com/hasura/ndc-hub#rust-sdk)and[ Typescript ](https://github.com/hasura/ndc-sdk-typescript)\n- **Official Connectors:** [ Postgres ](https://github.com/hasura/ndc-postgres),[ Clickhouse ](https://github.com/hasura/ndc-clickhouse),[ Sendgrid ](https://github.com/hasura/ndc-sendgrid),\n\n\n **Native Data Connector SDKs:** [ Rust ](https://github.com/hasura/ndc-hub#rust-sdk)and[ Typescript ](https://github.com/hasura/ndc-sdk-typescript)\n\n **Official Connectors:** [ Postgres ](https://github.com/hasura/ndc-postgres),[ Clickhouse ](https://github.com/hasura/ndc-clickhouse),[ Sendgrid ](https://github.com/hasura/ndc-sendgrid),\n\n## What are the known limitations of the Alpha release?\u200b\n\nBeing the first glimpse into Hasura DDN, the Alpha release comes with some limitations:\n\n- **Mutations, Event Triggers and Subscriptions:** Coming soon! Mutations and event triggers can be performed via[ Commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)in the alpha release though. Please do check commands and Typescript\nConnector out for business logic, mutations and event triggers.\n- **Compatibility:** While the default GraphQL schema is compatible with Hasura v2, some advanced v2 features might not\nbe supported.\n- **Migration Tools:** Complete migration tools from Hasura v2 to DDN are in development.\n- **Data Connectors:** Not all previously supported data sources have connectors yet; however, the[ NDC SDKs ](https://hasura.io/docs/3.0/basics/alpha-release/#sdks-and-connectors)will soon bridge this gap.\n\n\nCheck out the[ FAQ section ](https://hasura.io/docs/3.0/faq/)for more information on the major changes from v2.\n\n## What is the timeline for upcoming releases?\u200b\n\nThe specific timeline for Hasura DDN Beta and General Availability will vary based on feature development and\nimprovements. We're dedicated to delivering robust and trustworthy releases on a periodic basis with detailed changelog\non the new capabilities. For the most current updates, always refer to our official announcements and release notes.\n\nThank you for being a part of this exciting journey with Hasura DDN. Your participation drives our innovation, and\ntogether, we'll reshape the future of modern application development.\n\n## Moving to a supergraph architecture\u200b\n\n- Before Hasura DDN\n- After Hasura DDN\n\n\n### Before Hasura DDN\u200b\n\nBusinesses, while modernizing, face challenges in delivering digital experiences quickly and cost-effectively. Product\ndevelopment teams are often bottle-necked, waiting on backend teams for secure and efficient data access. This results\nin manually implementing custom APIs, microservice sprawl, orchestrating security policies, wasting time and stifling\ninnovation.\n\nImage: [ Hasura DDN basics before diagram ](https://hasura.io/docs/3.0/assets/images/hasura-ddn-basics-before-diagram-9649df015481d611759ac1020403fcd5.png)\n\n### After Hasura DDN\u200b\n\nIn moving to a supergraph architecture with Hasura, organizations can significantly minimize the complexity of their\ndata infrastructure. By connecting directly to data sources via Hasura DDN and native data connectors (NDCs), the\nrequirement for hand-crafted APIs and microservices is vastly reduced and collaboration is enhanced with backend teams\ncontributing independently.\n\nData can be securely exposed and interconnected, allowing for the creation of a single, unified data graph, able to be\ndeployed for wide-ranging requirements from client apps to public APIs on globally distributed infrastructure for\nminimal latency, scalability, and unwavering reliability.\n\nImage: [ Hasura DDN basics after diagram ](https://hasura.io/docs/3.0/assets/images/hasura-ddn-basics-after-diagram-15e580dcf6aee734d9bb16a41d503b98.png)\n\n### What did you think of this doc?\n\n- [ What is the Alpha release? ](https://hasura.io/docs/3.0/basics/alpha-release/#what-is-the-alpha-release)\n- [ What is available to use in the Alpha release? ](https://hasura.io/docs/3.0/basics/alpha-release/#what-is-available-to-use-in-the-alpha-release)\n    - [ API Authoring ](https://hasura.io/docs/3.0/basics/alpha-release/#api-authoring)\n\n- [ GraphQL API Features ](https://hasura.io/docs/3.0/basics/alpha-release/#graphql-api-features)\n\n- [ CI/CD ](https://hasura.io/docs/3.0/basics/alpha-release/#cicd)\n\n- [ Business Logic with Typescript ](https://hasura.io/docs/3.0/basics/alpha-release/#business-logic-with-typescript)\n\n- [ Native Data Connectors and SDKs ](https://hasura.io/docs/3.0/basics/alpha-release/#sdks-and-connectors)\n- [ What are the known limitations of the Alpha release? ](https://hasura.io/docs/3.0/basics/alpha-release/#what-are-the-known-limitations-of-the-alpha-release)\n- [ What is the timeline for upcoming releases? ](https://hasura.io/docs/3.0/basics/alpha-release/#what-is-the-timeline-for-upcoming-releases)\n- [ Moving to a supergraph architecture ](https://hasura.io/docs/3.0/basics/alpha-release/#moving-to-a-supergraph-architecture)\n    - [ Before Hasura DDN ](https://hasura.io/docs/3.0/basics/alpha-release/#before-hasura-ddn)\n\n- [ After Hasura DDN ](https://hasura.io/docs/3.0/basics/alpha-release/#after-hasura-ddn)\n", "https://hasura.io/docs/3.0/basics/background/": "# Background\n\n## Why are we building Hasura DDN?\u200b\n\nWith the rapid evolution of digital experiences, businesses are constantly seeking solutions to build next-generation\napplications efficiently and cost-effectively. However, a common bottleneck is the inability to swiftly provide secure\nand efficient access to necessary data.\n\nHasura DDN addresses this challenge, by utilizing the **data supergraph** architecture and development methodology in a way which unlocks improved team and developer productivity.\n\n### Meeting the growing needs of our developer community\u200b\n\nIn conversations with developers focused on building APIs and microservices, we've identified key challenges within the\ncommunity. Hasura DDN is designed to address these challenges, simplifying the workflow for software developers and\narchitects globally.\n\n#### For API Authors\u200b\n\nDevelopers involved in API authoring value:\n\n- **Feature-rich Domain Modeling** : Easily model complex data domains with flexibility.\n- **Composability Across Diverse Data Domains** : Seamlessly integrate various data sources.\n- **Developer Experience (DX)** : Access tools that accelerate building and iterating processes.\n- **Programming Language Flexibility** : Choose the programming language that best fits your project needs.\n\n\n#### For API Maintainers\u200b\n\nTeams managing API maintenance focus on:\n\n- **Performance and Operational Efficiency** : Scale and optimize performance with minimal operational overhead.\n- **Seamless Rollouts and Stability** : Implement changes and updates confidently, ensuring no downtime and avoiding\nbreaking changes.\n- **Federated CI/CD for Team Independence** : Facilitate independent functioning of teams with a robust CI/CD pipeline.\n- **Edge and Distributed Topology** : Deploy APIs efficiently, enhancing global scalability and user proximity.\n- **Rapid Onboarding and Data Domain Discovery** : Enable quick onboarding for developers and easy discovery of data\ndomains and their possible interrelations.\n\n\n#### For API Consumers\u200b\n\nConsumers of APIs prioritize:\n\n- **Reliability** : To have a reliable API that is documented and typed.\n- **Consistency** : To have a consistent API to fetch data from, irrespective of the data source.\n- **Discoverability** : To discover what data is available to them via their API and to try out that API with ease.\n\n\n## What is the Hasura Data Delivery Network (DDN)?\u200b\n\nHasura DDN is a paradigm shift in data API creation and management and how we think about data domains in response to\nthe evolved requirements of our users. Based on the new Open Data Domain Specification (OpenDD spec) and Native Data\nConnector Specifications (NDC spec), Hasura DDN facilitates the rapid declarative scaffolding and deployment of an API\nlayer that can be configured to connect to virtually any data source. With Hasura DDN, we are introducing a new approach\nto microservices development that is designed to provide, both in developer workflow and final product: a faster, more\npowerful, agile, and scalable solution for building modern applications.\n\nFor more details please refer to the[ FAQ section in the docs ](https://hasura.io/docs/3.0/faq/).\n\n### What did you think of this doc?\n\n- [ Why are we building Hasura DDN? ](https://hasura.io/docs/3.0/basics/background/#why-are-we-building-hasura-ddn)\n    - [ Meeting the growing needs of our developer community ](https://hasura.io/docs/3.0/basics/background/#meeting-the-growing-needs-of-our-developer-community)\n- [ What is the Hasura Data Delivery Network (DDN)? ](https://hasura.io/docs/3.0/basics/background/#what-is-the-hasura-data-delivery-network-ddn)\n", "https://hasura.io/docs/3.0/basics/core-concepts/": "# Core Concepts\n\nThe sprawl of microservices and APIs which any given product needs to connect to in order to function has led to a new\nset of challenges for developers and architects.\n\nIn the modern era of building applications, the data layer is becoming increasingly complex; it's no longer just a\ndatabase, but a collection of databases, services, and APIs.\n\nHasura DDN introduces the concept of a **data supergraph** to help you manage this complexity.\n\n## The state of the data layer\u200b\n\nImagine the following sets of teams within a hypothetical company:\n\n- **Product Management Team** : Responsible for the relational database storing product information. This team focuses on\ncataloging products, managing inventory, and ensuring product details are accurate and up-to-date by use of a **relational PostgreSQL database** .\n- **User Experience Team** : Manages a **MongoDB document database** and related APIs for storing user information. Their\nfocus is on maintaining user profiles, preferences, and ensuring privacy and security of user data.\n- **Search Optimization Team** : Handles the **integration of an Algolia search service** for products and partner\nstores. They work on optimizing search algorithms, ensuring relevant search results, and improving the overall search\nexperience for users.\n- **Finance and Transactions Team** : Oversees the **Stripe payment service and underlying relational database** for\nprocessing payments. This includes managing transaction security, payment gateway integrations, and ensuring smooth\nfinancial transactions.\n- **Logistics and Shipping Team** : Responsible for the **ShipStation shipping service, fulfilling orders, and the\nunderlying relational database that supports this process** . Their primary focus is on logistics, order tracking, and\nensuring timely delivery of products.\n- **Data Science and Recommendations Team** : Manages the **Weaviate vector database** for storing user recommendations.\nThey work on personalization algorithms, user behavior analysis, and providing tailored product recommendations to\nenhance user experience.\n\n\n **Product Management Team** : Responsible for the relational database storing product information. This team focuses on\ncataloging products, managing inventory, and ensuring product details are accurate and up-to-date by use of a **relational PostgreSQL database** .\n\n **User Experience Team** : Manages a **MongoDB document database** and related APIs for storing user information. Their\nfocus is on maintaining user profiles, preferences, and ensuring privacy and security of user data.\n\n **Search Optimization Team** : Handles the **integration of an Algolia search service** for products and partner\nstores. They work on optimizing search algorithms, ensuring relevant search results, and improving the overall search\nexperience for users.\n\n **Finance and Transactions Team** : Oversees the **Stripe payment service and underlying relational database** for\nprocessing payments. This includes managing transaction security, payment gateway integrations, and ensuring smooth\nfinancial transactions.\n\n **Logistics and Shipping Team** : Responsible for the **ShipStation shipping service, fulfilling orders, and the\nunderlying relational database that supports this process** . Their primary focus is on logistics, order tracking, and\nensuring timely delivery of products.\n\n **Data Science and Recommendations Team** : Manages the **Weaviate vector database** for storing user recommendations.\nThey work on personalization algorithms, user behavior analysis, and providing tailored product recommendations to\nenhance user experience.\n\nThe diversity of teams within this hypothetical company, each with their unique focus and specialized data services,\nepitomizes the common challenge in modern data management and API development. These teams all operate with distinct\nAPIs, schemas, and methodologies. This fragmentation not only complicates the process of developing applications but\nalso necessitates the involvement of skilled data architects and engineers to efficiently integrate and maintain these\nvaried data sources.\n\n## Subgraphs\u200b\n\nIn our e-commerce application example, each service above represents what we term a **subgraph** .\n\nA subgraph is much more than just a single data source; it is all the metadata needed to act as a self-contained entity\nthat can be independently authored, owned, maintained, and deployed by an individual team, to then be an **interconnected part of a unified API** .\n\nFor API authors, this means the ability to build out an API \u2014 composed of different sources \u2014 in a simple, declarative\nway. You can utilize unique access-control rules, authentication mechanisms, and custom business logic within your\nsubgraphs to create a secure and robust API.\n\nEach subgraph in our example is a modular component of the data supergraph. These components securely work together to\novercome the traditional barriers posed by isolated data sources, facilitating a more fluid and interconnected data\nlayer. This integrated approach simplifies application development across diverse data systems, enabling faster\niteration and more efficient maintenance by engineering teams.\n\n### How do I build a subgraph?\u200b\n\nSubgraphs are composed of related data sources \u2014 be that as traditional databases, or as custom business logic \u2014 and are\nconnected to your data layer using **data connectors** . Hasura DDN utilizes a number of data\nconnectors that work with popular databases, services, and APIs out-of-the-box; you can also build your own. **These\nsubgraphs can even include your own custom business logic as TypeScript functions that return or mutate data directly\nvia your GraphQL API.** This saves you the time and effort of building and maintaining your own APIs to manage data\nsources and existing microservices.\n\nAfter connecting your data source, you can then author your metadata using the[ Hasura CLI ](https://hasura.io/docs/3.0/cli/overview/)and our[ LSP-enabled VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura). This metadata is\nthen deployed to your Hasura DDN instance, where it is used to build your subgraph and eventually serve your GraphQL\nAPI.\n\n## Supergraph\u200b\n\nA **data supergraph** is the framework that brings together all of your subgraphs into one secure API. This\norchestration allows for the creation of applications that span multiple data sources, services, third-party APIs,\nbusiness logic and \u2014 most importantly \u2014 teams, seamlessly bridging their complexities into a single layer.\n\nFor those responsible for maintaining the data layer, this means you now have a single, holistic API to manage, rather\nthan multiple disparate data sources and connections. This enables you to create CI/CD pipelines, monitor performance\nusing industry-standard observability tools, and manage access control in a more streamlined and efficient manner.\n\nFor your consumers, this means they have a single endpoint to access all the data they need, thereby reducing the\ncomplexity of their applications. This also allows them to focus on building the best possible user experience, rather\nthan wrangling the underlying data layer.\n\n### How do I build a supergraph?\u200b\n\nThis happens automatically.\n\nAs you add subgraphs to your Hasura project, Hasura DDN automatically builds a supergraph of all your data sources. You\nhave the freedom and flexibility to define relationships \u2014 including fine-grained access control \u2014 across this\nsupergraph, connecting data sources together and making them available in ways that make sense for your application.\n\n## Next steps\u200b\n\nCheck out our[ getting started guide ](https://hasura.io/docs/3.0/getting-started/local-dev/)to learn how to build your first data supergraph.\n\n### What did you think of this doc?\n\n- [ The state of the data layer ](https://hasura.io/docs/3.0/basics/core-concepts/#the-state-of-the-data-layer)\n- [ Subgraphs ](https://hasura.io/docs/3.0/basics/core-concepts/#subgraphs)\n    - [ How do I build a subgraph? ](https://hasura.io/docs/3.0/basics/core-concepts/#how-do-i-build-a-subgraph)\n- [ Supergraph ](https://hasura.io/docs/3.0/basics/core-concepts/#supergraph)\n    - [ How do I build a supergraph? ](https://hasura.io/docs/3.0/basics/core-concepts/#how-do-i-build-a-supergraph)\n- [ Next steps ](https://hasura.io/docs/3.0/basics/core-concepts/#next-steps)\n", "https://hasura.io/docs/3.0/auth/authentication/": "# Hasura Authentication\n\n## Introduction\u200b\n\n **Authentication verifies the identity of a user.** \n\nHasura GraphQL Engine utilizes \"session variables\", with specific user, role, organization and any other information you\nmay need to determine the data access rights of the user.\n\nWith these session variables you are able to define permission rules on your data domain to provide fine-grained access\ncontrol to resources.\n\nActual authentication is handled outside of Hasura i.e. the responsibility for generating session variables is delegated\nto your (new or existing) authentication service in order to provide you with the greatest flexibility and range of\noptions for your authentication needs.\n\nHasura's authentication can be configured via JSON web tokens (JWT) or a webhook service and can be integrated with any\nother provider you choose (e.g.[ Auth0 ](https://auth0.com/),[ Firebase Auth ](https://firebase.google.com/products/auth),[ AWS Cognito ](https://aws.amazon.com/cognito/), a custom solution, etc.) in order to verify the user and set session\nvariables that then control access to data.\n\nThis document details the `AuthConfig` metadata object used to set up authentication for incoming requests in Hasura.\n\n## Auth Config\u200b\n\nOnly a single `AuthConfig` object can be defined in the metadata. It has the following structure:\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `allowRoleEmulationBy`  | String | false | Name of the role which allows role emulation. Read more about role emulation[ here ](https://hasura.io/docs/3.0/auth/authentication/role-emulation/). |\n|  `webhook`  | Object | false | Configuration of the authentication webhook. |\n|  `jwt`  | Object | false | Configuration of the JWT secret. |\n\n\nYou must select one of the supported authentication modes\n\nIn the object, only one of the supported authentication modes ( `jwt` or `webhook` ) is expected.\n\n## JWT authentication\u200b\n\n### Example\u200b\n\n```\nkind :  AuthConfig\nversion :  v1\ndefinition :\n   jwt :\n     key :\n       fixed :\n         algorithm :  HS256\n         key :\n           value :  token\n     tokenLocation :\n       type :  BearerAuthorization\n     claimsConfig :\n       namespace :\n         claimsFormat :  Json\n         location :   \"/https:~1~1hasura.io~1jwt~1claims\"\n```\n\nFor a full description of JWT mode[ see here ](https://hasura.io/docs/3.0/auth/authentication/jwt/).\n\n## Webhook authentication\u200b\n\n### Example\u200b\n\n```\n---\nkind :  AuthConfig\nversion :  v1\ndefinition :\n   allowRoleEmulationBy :  admin\n   webhook :\n     url :  http : //auth.yourservice.com/validate - request\n     method :  Get\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `url`  | URL | true | URL of the authentication webhook. |\n|  `method`  | String | false | HTTP method to use while making the request to the authentication webhook. Only `Get` and `Post` methods are supported. |\n\n\nFor a full description of webhook mode[ see here ](https://hasura.io/docs/3.0/auth/authentication/webhook/).\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/auth/authentication/#introduction)\n- [ Auth Config ](https://hasura.io/docs/3.0/auth/authentication/#auth-config)\n- [ JWT authentication ](https://hasura.io/docs/3.0/auth/authentication/#jwt-auth-config)\n    - [ Example ](https://hasura.io/docs/3.0/auth/authentication/#example)\n- [ Webhook authentication ](https://hasura.io/docs/3.0/auth/authentication/#webhook-auth-config)\n    - [ Example ](https://hasura.io/docs/3.0/auth/authentication/#example-1)\n", "https://hasura.io/docs/3.0/auth/authorization/index/": "# Hasura Authorization\n\n## Introduction\u200b\n\n **Authorization determines what a verified user can access.** \n\nThe OpenDD Spec lets you define permissions (also known as access control or authorization rules) on[ output types ](https://hasura.io/docs/3.0/data-domain-modeling/types/),[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/), and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)in your data domain.\n\nThere are three forms of permissions in the OpenDD Spec:\n\n- [ Type Permissions ](https://hasura.io/docs/3.0/auth/authorization/index/#type-permissions): Define which fields within a `ScalarType` or `ObjectType` can\nbe accessed by a particular role.\n- [ Model Permissions ](https://hasura.io/docs/3.0/auth/authorization/index/#model-permissions): Define which rows within a[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/)can be accessed by a specific role.\n- [ Command Permissions ](https://hasura.io/docs/3.0/auth/authorization/index/#command-permissions): Define which[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)can be\nexecuted by a given role.\n\n\nA role comes into existence when it is defined in one of these three ways.\n\nEvery request to Hasura should carry the necessary session variables or roles from your authentication service. The\npresence and values of these roles determine which permissions apply to the request. There is no longer the concept\nof a built-in, default, super-user `admin` role in Hasura DDN. You can however set up[ role emulation ](https://hasura.io/docs/3.0/auth/authentication/role-emulation/)in order to test your permissions with another role.\n\nHasura's roles and permissions via the OpenDD Spec are implemented at the Hasura Engine layer. They have no direct\nrelationship to any data source users and roles.\n\n## Type Permissions\u200b\n\nWith the OpenDD Spec, you can specify which fields of a `ScalarType` or `ObjectType` are accessible to specific roles.\n\n### Example\u200b\n\nTo define permissions on an output type `product` for `admin` and `customer` roles:\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  product\n   permissions :\n     -   role :  admin\n       output :\n         allowedFields :\n           -  id\n           -  name\n           -  price\n           -  manufacturer_id\n     -   role :  customer\n       output :\n         allowedFields :\n           -  id\n           -  name\n           -  price\n```\n\nNo access for undefined roles\n\nIf a role doesn't have any permissions defined for a type, it won't have access to it.\n\n## Model Permissions\u200b\n\nYou can control which rows or objects within a model a role can access. The syntax for this filter check, known as a `FieldComparison`  `ModelPredicate` , is available in the[ OpenDD Spec ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate).\n\n### Example\u200b\n\nThe following defines permissions for the `Users` model:\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  Users\n   permissions :\n   -   role :  admin\n     select :\n       filter :\n   -   role :  customer\n     select :\n     filter :\n       fieldComparison :\n         field :  id\n         operator :  _eq\n         value :\n           sessionVariable :  x - hasura - user - id\n```\n\nIn the above example, the `admin` role has no restrictions on the `Users` model. The `customer` role can only access the\nrow where the `id` field matches the `x-hasura-user-id` session variable ie: themselves.\n\n## Command Permissions\u200b\n\nCommand permissions determine which roles can execute specific commands by defining one boolean value of `allowExecution` for each role.\n\n### Example\u200b\n\nFor a command named `send_abandoned_cart_email` , the permissions might look like:\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  send_abandoned_cart_email\n   permissions :\n   -   role :  admin\n     allowExecution :   true\n   -   role :  customer\n     allowExecution :   false\n```\n\nIn the above example the `admin` role can execute the `send_abandoned_cart_email` command, but the `customer` role\ncannot.\n\nNo access for undefined roles\n\nIf a role doesn't have any permissions defined for a command, it won't have the ability to execute that command.\n\n## Testing Permissions\u200b\n\nYou can test permissions directly in the Hasura Console's API interface:\n\n1. Define the desired permissions for a particular type, model, or command in your metadata.\n2. Make a request through the Hasura DDN Console GraphiQL API interface and send the session variables as request\nheaders (e.g., a role you've defined permissions for).\n3. Check the returned data to ensure it adheres to your permission configurations.\n\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/auth/authorization/index/#introduction)\n- [ Type Permissions ](https://hasura.io/docs/3.0/auth/authorization/index/#type-permissions)\n    - [ Example ](https://hasura.io/docs/3.0/auth/authorization/index/#example)\n- [ Model Permissions ](https://hasura.io/docs/3.0/auth/authorization/index/#model-permissions)\n    - [ Example ](https://hasura.io/docs/3.0/auth/authorization/index/#example-1)\n- [ Command Permissions ](https://hasura.io/docs/3.0/auth/authorization/index/#command-permissions)\n    - [ Example ](https://hasura.io/docs/3.0/auth/authorization/index/#example-2)\n- [ Testing Permissions ](https://hasura.io/docs/3.0/auth/authorization/index/#testing-permissions)\n", "https://hasura.io/docs/3.0/auth/authentication/jwt/": "# Authentication Using JWTs\n\n## Introduction\u200b\n\nThis page details how to configure Hasura Engine to use JWT mode in order to authenticate incoming requests.\n\nThis process requires that your auth service returns a JWT to the client, which it passes to Hasura GraphQL\nEngine in an: `Authorization: Bearer <JWT>` header of the request.\n\nHasura then verifies and decodes the JWT to extract `x-hasura-*` session variable claim values. The `x-hasura-role` session variable is required, and you will also most likely utilize the user id and any other information which you\nneed to determine access to your data.\n\nImage: [ Authentication using JWT ](https://hasura.io/docs/3.0/assets/images/auth-jwt-overview-diagram-afcb2de929684d64f9784dc42b9f5ddd.png)\n\n## JWT authentication\u200b\n\nYou can enable JWT mode by configuring your metadata appropriately:\n\n### Example\u200b\n\n```\nkey :\n   fixed :\n     algorithm :  HS256\n     key :\n       value :  token\ntokenLocation :\n   type :  BearerAuthorization\nclaimsConfig :\n   namespace :\n     claimsFormat :  Json\n     location :   \"/https:~1~1hasura.io~1jwt~1claims\"\n```\n\n### All jwt configuration fields\u200b\n\n```\nkey :\n   # either `fixed` or `jwkFromUrl` is expected.\n   fixed :\n     algorithm :  required - algorithm - to - be - used - to - decode - the - JWT\n     key :  required - key - as - string\n   jwkFromUrl :  required - JWK - url\nclaimsConfig :\n   # either `namespace` or `locations` is expected.\n   namespace :\n     location :  optional - json - pointer - to - the - claims - default - https : //hasura.io/jwt/claims\n     claimsFormat :  optional - claims - format - default - Json\n   locations :\n     # Object with keys as session variables and values as object\n     x-hasura-role :\n       # either `literal` or `path` is expected.\n       literal :  required - string\n       path :\n         path :  required - json - pointer - to - the - claim\n         default :  optional - default\ntokenLocation :  required - object - to - indicate - cookie - or - authorization - header - or - custom - header\naudience :   \"<optional-string-or-list-of-strings-to-verify-audience>\"\nissuer :   \"<optional-string-to-verify-issuer>\"\nallowedSkew :   \"<optional-number-of-seconds-in-integer>\"\n```\n\n### Metadata structure\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `key`  | [ JWT key ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-key) | true | JWT key type to configure the JWT authentication. |\n|  `claimsConfig`  | [ Claims Config ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-claims-config) | true | Configuration of the Hasura claims within the JWT. |\n|  `tokenLocation`  | [ Object ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-token-location-values) | true | Declares the request header or the cookie (with cookie name) from which to read the JWT. Default: `{\"type\": \"tokenLocationValues\"}` . |\n|  `audience`  | String | false | When set, verifies the `aud` claims in the JWT to be equal to this value. |\n|  `issuer`  | String | false | When set, verifies the `iss` claim in the JWT claim equal to this value. |\n|  `allowedSkew`  | Int | false | Optional field to provide some leeway (to account for clock skews) while comparing the JWT expiry time. This field expects an integer value which will be the number of seconds of the skew value. |\n\n\n#### JWT key\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fixed`  | [ Fixed key ](https://hasura.io/docs/3.0/auth/authentication/jwt/#fixed-jwt-key) | false | Fixed JWT mode, when the `algorithm` and the `key` fields are known and aren't expected to change during runtime. |\n|  `jwkFromUrl`  | URL | false | JWK URL from which the graphql-engine will determine the `algorithm` and `key` fields from dynamically. |\n\n\nNote\n\nEither, the `fixed` or the `jwkFromUrl` is expected.\n\n##### Fixed JWT key\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `algorithm`  | String | false | Algorithm used to decode the JWT. Possible values are: `HS256` , `HS384` , `HS512` , `ES256` , `ES384` , `RS256` , `RS384` , `RS512` , `PS256` , `PS384` , `PS512` and `EdDSA` . |\n|  `key`  | String | false | Key to decode the JWT. |\n\n\n#### JWT claims config\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `namespace`  | [ Namespace ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-claims-namespace) | false | Used when all of the Hasura claims are present in a single object within the decoded JWT. |\n|  `claimsMap`  | [ Claims Map ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-claimsmap) | false | Can be used when Hasura claims are not all present in the single object, but individual claims are either provided a default value or a JSON pointer within the decoded JWT. |\n\n\nNote\n\nEither, the `namespace` or the `claimsMap` is expected. If neither is present, then the default `namespace` value is used.\n\n##### JWT claims namespace\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `path`  | [ JSON Pointer ](https://www.rfc-editor.org/rfc/rfc6901) | true | JSON pointer to the Hasura claims object.  Default: \"https:~1~1hasura.io~1jwt~1claims\" (JSON Pointer for `https://hasura. io/jwt/claims` ). |\n|  `format`  | String | false | Format of the Hasura claims object. Possible values ( `Json` , `StringifiedJson` ). Default value: `Json` . |\n\n\n##### JWT claims map\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `x-hasura-allowed-roles`  | [ Claims Map Object ([String]) ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-claims-map-object) | true | JSON pointer to the Hasura claims object. |\n|  `x-hasura-default-role`  | [ Claims Map Object (String) ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-claims-map-object) | true | JSON pointer to the Hasura claims object. |\n| Custom claim* | [ Claims Map Object (String) ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-claims-map-object) | false | JSON pointer to the custom Hasura claim. |\n\n\nNote\n\nAny number of Custom claims can be added to the claims map.\n\n###### JWT claims map object <T>\u200b\n\n`<T>`\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `literal`  |  `<T>`  | false | Literal value of the Hasura claim. |\n|  `path`  | [ JSON claims map path object ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-claims-map-path-object) | false | Get claim value using a JSON pointer to the Hasura claim with a fallback default value, if the value is not present at the JSON pointer. |\n\n\n###### JWT claims map path object <T>\u200b\n\n`<T>`\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `path`  | [ JSON Pointer ](https://www.rfc-editor.org/rfc/rfc6901) | false | JSON pointer to the Hasura claim. |\n|  `default`  |  `<T>`  | false | Default value of the Hasura claim, if there is no value present at the `path` . |\n\n\nNote\n\nFor `x-hasura-allowed-roles` , `<T>` will be `[String]` and for `x-hasura-default-role` or any other custom claims, `<T>` will be a `String` .\n\n#### JWT token location values\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `BearerAuthorization`  | String | false | JWT is provided in the `Authorization` header in the format of `Bearer <JWT>`  |\n|  `Header`  | Object | false | Name of the header which will contain the JWT. A JSON object with the name of the custom header is expected like: `{ \"Header\": \"<custom-header-name>\" }`  |\n|  `Cookie`  | Object | false | JWT is provided in the `Cookie` header. A JSON object with the name of the cookie is expected like: `{ \"Cookie\": \"<custom-cookie-name>\" }`  |\n\n\n### Example Decoded Payload\u200b\n\n```\n{\n   \"sub\" :   \"1234567890\" ,\n   \"name\" :   \"John Doe\" ,\n   \"admin\" :   true ,\n   \"iat\" :   1516239022 ,\n   \"https://hasura.io/jwt/claims\" :   {\n     \"x-hasura-default-role\" :   \"user\" ,\n     \"x-hasura-allowed-roles\" :   [ \"user\" ,   \"admin\" ] ,\n     \"x-hasura-user-id\" :   \"123\" ,\n     \"x-hasura-org-id\" :   \"456\" ,\n     \"x-hasura-custom\" :   \"custom-value\"\n   }\n}\n```\n\n### Example Encoded JWT\u200b\n\n```\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWUsImlhdCI6MTUxNjI\nzOTAyMiwiaHR0cHM6Ly9oYXN1cmEuaW8vand0L2NsYWltcyI6eyJ4LWhhc3VyYS1kZWZhdWx0LXJvbGUiOiJ1c2VyIiwieC1oYXN1cmEtYWxsb3dlZC1yb2x\nlcyI6WyJ1c2VyIiwiYWRtaW4iXSwieC1oYXN1cmEtdXNlci1pZCI6IjEyMyIsIngtaGFzdXJhLW9yZy1pZCI6IjQ1NiIsIngtaGFzdXJhLWN1c3RvbSI6ImN\n1c3RvbS12YWx1ZSJ9fQ.07mlUOhH3Oigz_Yyil8EC579Ht6PbZ1yr8fYJfhQ4NE\n```\n\n **Note:**  `x-hasura-default-role` and `x-hasura-allowed-roles` are mandatory, while the rest of the claims are optional.\n\n[ See here for the JWT debugger ](https://jwt.io/#debugger-io?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWUsImlhdCI6MTUxNjIzOTAyMiwiaHR0cHM6Ly9oYXN1cmEuaW8vand0L2NsYWltcyI6eyJ4LWhhc3VyYS1kZWZhdWx0LXJvbGUiOiJ1c2VyIiwieC1oYXN1cmEtYWxsb3dlZC1yb2xlcyI6WyJ1c2VyIiwiYWRtaW4iXSwieC1oYXN1cmEtdXNlci1pZCI6IjEyMyIsIngtaGFzdXJhLW9yZy1pZCI6IjQ1NiIsIngtaGFzdXJhLWN1c3RvbSI6ImN1c3RvbS12YWx1ZSJ9fQ.07mlUOhH3Oigz_Yyil8EC579Ht6PbZ1yr8fYJfhQ4NE)of this example JWT token. The signature secret is `ultra-secret-very-secret-super-secret-key` .\n\n### Hasura JWT format\u200b\n\nThe `x-hasura-role` value can be sent as a plain **header** in the request to indicate the role which should be used.\n\nWhen your auth server generates the JWT, the custom claims in the JWT **must contain the following** in a custom\nclaims namespace:\n\n1. A `x-hasura-allowed-roles` field. A list of allowed roles for the user i.e. acceptable values of the optional `x-hasura-role`  *header* .[ See more ](https://hasura.io/docs/3.0/auth/authentication/jwt/#x-hasura-allowed-roles)\n2. A `x-hasura-default-role` field. The role that will be used when the optional `x-hasura-role`  *header* is **not\npassed** .[ See more ](https://hasura.io/docs/3.0/auth/authentication/jwt/#x-hasura-default-role)\n3. Add any other optional `x-hasura-*` claim fields (required as per your defined permissions) to the custom\nnamespace.[ See more ](https://hasura.io/docs/3.0/auth/authentication/jwt/#x-hasura-)\n\n\nThe JWT should be sent to Hasura Engine in an: `Authorization: Bearer <JWT>` header. Eg:\n\n```\nPOST   /v1/graphql   HTTP/1.1\nAuthorization :   Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWI...\nX-Hasura-Role :   editor\n...\n```\n\nTo summarize, `x-hasura-allowed-roles` session variable contains a list of all the roles that the user can assume\nand the `x-hasura-role` header tells the Hasura Engine which role to use for the request, and if that is missing\nthen the `x-hasura-default-role` session variable will be used.\n\nThis setup makes it more convenient for a JWT to only need to be issued once with a list of allowed roles for the\nuser, and then allow the client to decide which of those roles to actually use for a request. This prevents the user\nneeding to log in again or unnecessary JWT re-issuance.\n\nIf, for example, your app will not need to switch user roles and the user only needs one role, for instance: `user` ,\nyou can just issue a JWT with `x-hasura-default-role` set to `user` and `x-hasura-allowed-roles` set to `[\"user\"]` and not send the `x-hasura-role` header in the request.\n\nThis setup is designed so that there is one authoritative way to construct your JWT token for the Hasura Engine which\ncan cover a wide range of use cases.\n\n### Hasura JWT Claim Description\u200b\n\n#### x-hasura-allowed-roles\u200b\n\nThe `x-hasura-allowed-roles` list can contain all the roles which a particular user can assume, eg: `[ \"user\", \"manager\", \"owner\" ]` . Usually, these will have varying degrees of access to your data as specified in\nPermissions and by specifying this list it lets the Hasura Engine know that this user\ncan assume any of them.\n\n#### x-hasura-default-role\u200b\n\nThe `x-hasura-default-role` will be the role that the user falls back to when no `x-hasura-role` value is\nspecified in the header of the request. Usually, this will be the role with the least privileges and can be\noverridden by the `x-hasura-role` header when making a request.\n\n#### x-hasura-*\u200b\n\nThe JWT can have other user-defined `x-hasura-*` fields and their values can only be strings (they will be converted to\nthe right type automatically). You can use these `x-hasura-*` values in your permission rules.\n\nThe JWT will normally also contain standard ( `sub` , `iat` etc.) and custom ( `name` , `admin` etc.) claims\n\n### JWT Notes\u200b\n\n- JWT claim fields eg: `x-hasura-default-role` are case-insensitive.\n- Hasura GraphQL Engine only has access to headers and JWT claims which are prefixed with `x-hasura-` .\n- Hasura GraphQL Engine only has access to JWT claims in the `https://hasura.io/jwt/claims` or[ custom defined ](https://hasura.io/docs/3.0/auth/authentication/jwt/#claims-namespace-path)namespace.\n- All `x-hasura-*` values should be of type `String` , they will be converted to the right type automatically.\n\n\n## Hasura JWT configuration options\u200b\n\n### type\u200b\n\nThis specifies the cryptographic signing algorithm which is used to sign the JWTs. Valid values are : `HS256` , `HS384` , `HS512` , `RS256` , `RS384` , `RS512` , `Ed25519` , `ES256` , `ES384` , `ES512` . (see[ https://jwt.io ](https://jwt.io/)).\n\n `HS*` is for HMAC-SHA based algorithms. `RS*` is for RSA based signing. `Ed*` is for Edwards-curve Digital Signature\nalgorithms. `ES*` is for Elliptic-curve Digital Signature algorithms. For example, if your auth server is using\nHMAC-SHA256 for signing the JWTs, then use `HS256` . If it is using RSA with SHA-512, then use `RS512` . If it is using an\nEdDSA instance of Edwards25519, then use `Ed25519` . If it is using an ES instance of ECDSA with 256-bit curve, then use `ES256` .\n\nThis is an optional field. This is required only if you are using the `key` property in the config.\n\n### key\u200b\n\n- In the case of a symmetric key (i.e. a HMAC-based key), just the key as is. (e.g. -\"abcdef...\"). The key must be long\nenough for the chosen algorithm, (e.g. for HS256 it must be at least 32 characters long).\n- In the case of an asymmetric key (RSA, EdDSA, ECDSA etc.), only the **public** key, in a PEM-encoded string or as an\nX509 certificate.\n\n\nThis is an optional field. You can also provide a URL to fetch JWKs from using the `jwkUrl` field.\n\n### jwkUrl\u200b\n\nAn URL where a provider publishes their JWKs (JSON Web Keys - which are used for signing the JWTs). The URL **must** publish the JWKs in the standard format as described[ here ](https://tools.ietf.org/html/rfc7517).\n\nThis is optional as you have the alternative of also providing the key (certificate, PEM-encoded public key) as a\nstring - in the[ key ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-json-key)field along with the[ type ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-json-type).\n\n### claimsNamespacePath\u200b\n\nThis is an optional field. You can specify the key name, inside which the Hasura specific claims will be present, e.g. `https://mydomain.com/claims` . The default value is `https://hasura.io/jwt/claims` .\n\n##### Configure claimsNamespacePath\u200b\n\n`claimsNamespacePath`\n\nAn optional JSON path value to the Hasura claims present in the JWT token. Example values are `/hasura/claims` or `/` (i.e. root of the payload).\n\nThe JWT token should be in the following format if the `claimsNamespacePath` is set to `/hasura/claims` :\n\n```\n{\n   \"sub\" :   \"1234567890\" ,\n   \"name\" :   \"John Doe\" ,\n   \"admin\" :   true ,\n   \"iat\" :   1516239022 ,\n   \"hasura\" :   {\n     \"claims\" :   {\n       \"x-hasura-allowed-roles\" :   [ \"editor\" ,   \"user\" ,   \"mod\" ] ,\n       \"x-hasura-default-role\" :   \"user\" ,\n       \"x-hasura-user-id\" :   \"1234567890\" ,\n       \"x-hasura-org-id\" :   \"123\" ,\n       \"x-hasura-custom\" :   \"custom-value\"\n     }\n   }\n}\n```\n\nClaims namespace values\n\nWhen the `claimsNamespacePath` is not set, the default value is `https:~1~1hasura.io~1jwt~1claims` (JSON pointer\nfor claims namespace).\n\n### claimsFormat\u200b\n\nThis is an optional field, with only the following possible values allowed: `json` , `stringifiedJson` .\n\nThe default is `json` .\n\nThis is to indicate whether the Hasura-specific claims are a regular JSON object or a stringified JSON.\n\nThis is required because providers like AWS Cognito only allow strings in the JWT claims.[ See #1176 ](https://github.com/hasura/graphql-engine/issues/1176).\n\nExample:\n\nIf `claimsFormat` is `json` then the JWT claims should look like:\n\n```\n{\n   \"sub\" :   \"1234567890\" ,\n   \"name\" :   \"John Doe\" ,\n   \"admin\" :   true ,\n   \"iat\" :   1516239022 ,\n   \"https://hasura.io/jwt/claims\" :   {\n     \"x-hasura-allowed-roles\" :   [ \"editor\" ,   \"user\" ,   \"mod\" ] ,\n     \"x-hasura-default-role\" :   \"user\" ,\n     \"x-hasura-user-id\" :   \"1234567890\" ,\n     \"x-hasura-org-id\" :   \"123\" ,\n     \"x-hasura-custom\" :   \"custom-value\"\n   }\n}\n```\n\nIf `claimsFormat` is `stringified_json` then the JWT claims should look like:\n\n```\n{\n   \"sub\" :   \"1234567890\" ,\n   \"name\" :   \"John Doe\" ,\n   \"admin\" :   true ,\n   \"iat\" :   1516239022 ,\n   \"https://hasura.io/jwt/claims\" :   \"{\\\"x-hasura-allowed-roles\\\":[\\\"editor\\\",\\\"user\\\",\\\"mod\\\"],\\\"x-hasura-default-role\\\":\\\"user\\\",\\\"x-hasura-user-id\\\":\\\"1234567890\\\",\\\"x-hasura-org-id\\\":\\\"123\\\",\\\"x-hasura-custom\\\":\\\"custom-value\\\"}\"\n}\n```\n\n### claimsMap\u200b\n\nThis is an optional field. Certain providers might not allow adding custom claims. In such a case, you can map Hasura\nsession variables with existing JWT claims using `claimsMap` . The `claimsMap` is a JSON object where keys are session\nvariables and values can be a JSON pointer (with a default value option, when the key specified by the JSON pointer doesn't\nexist) or a literal value.\n\nThe literal values should be of type `String` , except for the `x-hasura-allowed-roles` claim which expects a string\narray.\n\nThe value of a claim referred by a JSON path must be a string. To use the JSON path value, the path needs to be given\nin a JSON object with `path` as the key and the JSON pointer as the value:\n\n```\n{\n   \"path\" :   \"/user/all_roles\"\n}\n```\n\n```\n{\n   \"path\" :   \"/roles/default\" ,\n   \"default\" :   \"user\"\n}\n```\n\nClaims map precedence\n\nIf `claimsMap` is provided in the JWT config, `claimsNamespacePath` and `claimsFormat` will be\nignored.\n\n **Example: JWT config with JSON path values** \n\n```\n{\n   \"sub\" :   \"1234567890\" ,\n   \"name\" :   \"John Doe\" ,\n   \"admin\" :   true ,\n   \"iat\" :   1516239022 ,\n   \"user\" :   {\n     \"id\" :   \"ujdh739kd\"\n   } ,\n   \"hasura\" :   {\n     \"all_roles\" :   [ \"user\" ,   \"editor\" ]\n   }\n}\n```\n\nThe mapping for `x-hasura-allowed-roles` , `x-hasura-default-role` and `x-hasura-user-id` session variables can be\nspecified in the `claimsMap` configuration as follows:\n\n```\n{\n   \"type\" :   \"RS512\" ,\n   \"key\" :   \"-----BEGIN PUBLIC KEY-----\\nMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDdlatRjRjogo3WojgGHFHYLugd\\nUWAY9iR3fy4arWNA1KoS8kVw33cJibXr8bvwUAUparCwlvdbH6dvEOfou0/gCFQs\\nHUfQrSDv+MuSUMAe8jzKE4qW+jK+xQU9a03GUnKHkkle+Q0pX/g6jXZ7r1/xAK5D\\no2kQ+X5xK9cipRgEKwIDAQAB\\n-----END PUBLIC KEY-----\\n\" ,\n   \"claimsMap\" :   {\n     \"x-hasura-allowed-roles\" :   {   \"path\" :   \"/hasura/all_roles\"   } ,\n     \"x-hasura-default-role\" :   {   \"path\" :   \"/hasura/all_roles[0]\"   } ,\n     \"x-hasura-user-id\" :   {   \"path\" :   \"/user/id\"   }\n   }\n}\n```\n\n **Example: JWT config with JSON path values and default values** \n\n```\n{\n   \"sub\" :   \"1234567890\" ,\n   \"name\" :   \"John Doe\" ,\n   \"admin\" :   true ,\n   \"iat\" :   1516239022 ,\n   \"hasura\" :   {\n     \"all_roles\" :   [ \"user\" ,   \"editor\" ]\n   }\n}\n```\n\n```\n{\n   \"type\" :   \"RS512\" ,\n   \"key\" :   \"-----BEGIN PUBLIC KEY-----\\nMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDdlatRjRjogo3WojgGHFHYLugd\\nUWAY9iR3fy4arWNA1KoS8kVw33cJibXr8bvwUAUparCwlvdbH6dvEOfou0/gCFQs\\nHUfQrSDv+MuSUMAe8jzKE4qW+jK+xQU9a03GUnKHkkle+Q0pX/g6jXZ7r1/xAK5D\\no2kQ+X5xK9cipRgEKwIDAQAB\\n-----END PUBLIC KEY-----\\n\" ,\n   \"claimsMap\" :   {\n     \"x-hasura-allowed-roles\" :   {   \"path\" :   \"/hasura/all_roles\"   } ,\n     \"x-hasura-default-role\" :   {   \"path\" :   \"/hasura/all_roles[0]\"   } ,\n     \"x-hasura-user-id\" :   {   \"path\" :   \"/user/id\" ,   \"default\" :   \"ujdh739kd\"   }\n   }\n}\n```\n\nIn the above case, since the `/user/id` doesn't exist in the JWT token, the default value of the `x-hasura-user-id` i.e\n\"ujdh739kd\" will be used\n\n **Example: JWT config containing literal values** \n\n```\n{\n   \"sub\" :   \"1234567890\" ,\n   \"name\" :   \"John Doe\" ,\n   \"admin\" :   true ,\n   \"iat\" :   1516239022 ,\n   \"user\" :   {\n     \"id\" :   \"ujdh739kd\"\n   }\n}\n```\n\nThe corresponding JWT config should be:\n\n```\n{\n   \"type\" :   \"RS512\" ,\n   \"key\" :   \"-----BEGIN PUBLIC KEY-----\\nMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDdlatRjRjogo3WojgGHFHYLugd\\nUWAY9iR3fy4arWNA1KoS8kVw33cJibXr8bvwUAUparCwlvdbH6dvEOfou0/gCFQs\\nHUfQrSDv+MuSUMAe8jzKE4qW+jK+xQU9a03GUnKHkkle+Q0pX/g6jXZ7r1/xAK5D\\no2kQ+X5xK9cipRgEKwIDAQAB\\n-----END PUBLIC KEY-----\\n\" ,\n   \"claimsMap\" :   {\n     \"x-hasura-allowed-roles\" :   [ \"user\" ,   \"editor\" ] ,\n     \"x-hasura-default-role\" :   \"user\" ,\n     \"x-hasura-user-id\" :   {   \"path\" :   \"/user/id\"   }\n   }\n}\n```\n\nIn the above example, the `x-hasura-allowed-roles` and `x-hasura-default-role` values are set in the JWT config and the\nvalue of the `x-hasura-user-id` is a JSON path to the value in the JWT token.\n\n### audience\u200b\n\nThis is an optional field. Certain providers might set a claim which indicates the intended audience for the JWT. This\ncan be checked by setting this field.\n\nWhen this field is set, during the verification process of the JWT, the `aud` claim in the JWT will be checked to\nsee whether it is equal to the `audience` field given in the configuration. If they are not equal then the JWT will\nbe rejected.\n\nSee the[ RFC ](https://tools.ietf.org/html/rfc7519#section-4.1.3)for more details.\n\nThis field can be a string, or a list of strings.\n\nExamples:\n\n```\n{\n   \"jwkUrl\" :   \"https://......\" ,\n   \"audience\" :   \"myapp-1234\"\n}\n```\n\nor\n\n```\n{\n   \"jwkUrl\" :   \"https://......\" ,\n   \"audience\" :   [ \"myapp-1234\" ,   \"myapp-6789\" ]\n}\n```\n\nAudience Security Vulnerability\n\nCertain JWT providers share JWKs between multiple tenants. They use the `aud` claim of the JWT to specify the intended\naudience. Setting the `audience` field in the Hasura JWT configuration will make sure that the `aud` claim\nfrom the JWT is also checked during verification. Not doing this check will allow JWTs issued for other tenants to be\nvalid as well.\n\nIn these cases, you **MUST** set the `audience` field to the appropriate value. Failing to do so is a **major security\nvulnerability** .\n\n### issuer\u200b\n\nThis is an optional field. It takes a string value.\n\nWhen this field is set, during the verification process of the JWT, the `iss` claim in the JWT will be checked to\nsee whether it is equal to the `issuer` field given in the configuration. If they are not equal then the JWT will be\nrejected.\n\nSee[ RFC ](https://tools.ietf.org/html/rfc7519#section-4.1.1)for more details.\n\nExamples:\n\n```\n{\n   \"jwkUrl\" :   \"https://......\" ,\n   \"issuer\" :   \"https://my-auth-server.com\"\n}\n```\n\n#### Issuer notes\u200b\n\n- Certain providers require you to verify the `iss` claim on the JWT. To do that you can set this field to the\nappropriate value.\n- A JWT configuration without an issuer will match any issuer field present in an incoming JWT.\n- An incoming JWT without an issuer specified will match a configuration even if it specifies an issuer.\n\n\n### allowedSkew\u200b\n\n `allowedSkew` is an optional field to provide some leeway (to account for clock skews) while comparing the JWT expiry\ntime. This field expects an integer value which will be the number of seconds of the skew value.\n\n### header\u200b\n\nThis is an optional field, which indicates which request header to read the JWT from. This field is a stringified JSON\nobject.\n\nThe following are the possible values:\n\n- `{\"type\": \"Authorization\"}`\n- `{\"type\": \"Cookie\", \"name\": \"cookie_name\" }`\n- `{\"type\": \"CustomHeader\", \"name\": \"header_name\" }`\n\n\nDefault is `{\"type\": \"Authorization\"}` .\n\nIn the default mode, Hasura expects an `Authorization` header with a `Bearer` token.\n\nIn the cookie mode, Hasura will try to parse the cookie header with the given cookie name. The value of the cookie\nshould be the exact JWT.\n\nIn the custom header mode, Hasura expects a `header_name` header with the exact JWT token value.\n\nExample:\n\nIf `header` is `{\"type\": \"Authorization\"}` then JWT header should look like:\n\n`Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWI...`\n\nIf `header` is `{\"type\": \"Cookie\", \"name\": \"cookie_name\" }` then JWT header should look like:\n\n`Cookie: cookie_name=eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWI...`\n\nIf `header` is `{\"type\": \"CustomHeader\", \"name\": \"header_name\" }` then JWT header should look like:\n\n`header_name: eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWI...`\n\n## Hasura JWT Config Examples\u200b\n\n#### HMAC-SHA based\u200b\n\nYour auth server is using HMAC-SHA algorithms to sign JWTs, and is using a 256-bit key. In this case, the JWT config\nwill look like:\n\n```\n{\n   \"type\" :   \"HS256\" ,\n   \"key\" :   \"3EK6FD+o0+c7tzBNVfjpMkNDi2yARAAKzQlk8O2IKoxQu4nF7EdAh8s3TwpHwrdWT6R\"\n}\n```\n\nThe `key` is the actual shared secret, which is used by Hasura and the external auth server.\n\n#### RSA based\u200b\n\nIf your auth server is using the RSA algorithm to sign JWTs, and is using a 512-bit key, the JWT config only needs to\nhave the public key.\n\n **Example 1** : public key in PEM format (not OpenSSH format):\n\n```\n{\n   \"type\" :   \"RS512\" ,\n   \"key\" :   \"-----BEGIN PUBLIC KEY-----\\nMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDdlatRjRjogo3WojgGHFHYLugd\\nUWAY9iR3fy4arWNA1KoS8kVw33cJibXr8bvwUAUparCwlvdbH6dvEOfou0/gCFQs\\nHUfQrSDv+MuSUMAe8jzKE4qW+jK+xQU9a03GUnKHkkle+Q0pX/g6jXZ7r1/xAK5D\\no2kQ+X5xK9cipRgEKwIDAQAB\\n-----END PUBLIC KEY-----\\n\"\n}\n```\n\n **Example 2** : public key as X509 certificate:\n\n```\n{\n   \"type\" :   \"RS512\" ,\n   \"key\" :   \"-----BEGIN CERTIFICATE-----\\nMIIDHDCCAgSgAwIBAgIINw9gva8BPPIwDQYJKoZIhvcNAQEFBQAwMTEvMC0GA1UE\\nAxMmc2VjdXJldG9rZW4uc3lzdGVtLmdzZXJ2aWNlYWNjb3VudC5jb20wHhcNMTgQt7dIsMTIU9k1SUrFviZOGnmHWtIAw\\nmtYBcM9I0f9/ka45JIRp5Y1NKpAMFSShs7Wv0m1JS1kXQHdJsPSmjmDKcwnBe3R/\\nTU3foRRywR/3AJRM15FNjTqvUm7TeaW16LkkRoECAwEAAaM4MDYwDAYDVR0TAQH/\\nBAIwADAOBgNVHQ8BAf8EBAMCB4AwFgYDVR0lAQH/BAwwCgYIKwYBBQUHAwIwDQYJ\\nKoZIhvcNAQEFBQADggEBADfY2DEmc2gb8/pqMNWHYq/nTYfJPpK4VA9A0lFTNeoq\\nzmnbGwhKj24X+Nw8trsvkrKxHvCI1alDgBaCyzjGGvgOrh8X0wLtymp1yj6PWwee\\nR2ZPdUaB62TCzO0iRv7W6o39ey+mU/FyYRtxF0ecxG2a0KNsIyFkciXUAeC5UVDo\\nBNp678/SDDx9Ltuxc6h56a/hpBGf9Yzhr0RvYy3DmjBs6eopiGFmjnOKNxQrZ5t2\\n339JWR+yiGEAtoHqk/fINMf1An6Rung1xYowrm4guhCIVi5unAvQ89fq0I6mzPg6\\nLhTpeP0o+mVYrBmtYVpDpv0e71cfYowSJCCkod/9YbY=\\n-----END CERTIFICATE-----\"\n}\n```\n\n **Example 3** : public key published as JWKs:\n\n```\n{\n   \"jwkUrl\" :   \"https://www.googleapis.com/service_accounts/v1/jwk/securetoken@system.gserviceaccount.com\"\n}\n```\n\n#### EdDSA based\u200b\n\nIf your auth server is using EdDSA to sign JWTs, and is using the Ed25519 variant key, the JWT config only needs to have\nthe public key.\n\n **Example 1** : public key in PEM format (not OpenSSH format):\n\n```\n{\n   \"type\" :   \"Ed25519\" ,\n   \"key\" :   \"-----BEGIN PUBLIC KEY-----\\nMCowBQYDK2VwAyEAG9I+toAAJicilbPt36tiC4wi7E1Dp9rMmfnwdKyVXi0=\\n-----END PUBLIC KEY-----\"\n}\n```\n\n **Example 2** : public key as X509 certificate:\n\n```\n{\n   \"type\" : \"Ed25519\" ,\n   \"key\" :   \"-----BEGIN CERTIFICATE REQUEST-----\\nMIIBAzCBtgIBADAnMQswCQYDVQQGEwJERTEYMBYGA1UEAwwPd3d3LmV4YW1wbGUu\\nY29tMCowBQYDK2VwAyEA/9DV/InajW02Q0tC/tyr9mCSbSnNP1txICXVJrTGKDSg\\nXDBaBgkqhkiG9w0BCQ4xTTBLMAsGA1UdDwQEAwIEMDATBgNVHSUEDDAKBggrBgEF\\nBQcDATAnBgNVHREEIDAegg93d3cuZXhhbXBsZS5jb22CC2V4YW1wbGUuY29tMAUG\\nAytlcANBAKbTqnTyPcf4ZkVuq2tC108pBGY19VgyoI+PP2wD2KaRz4QAO7Bjd+7S\\nljyJoN83UDdtdtgb7aFgb611gx9W4go=\\n-----END CERTIFICATE REQUEST-----\"\n}\n```\n\n#### EC based\u200b\n\nIf your auth server is using ECDSA to sign JWTs, and is using the ES variant with a 256-bit key, the JWT config only\nneeds to have the public key.\n\n **Example 1** : public key in PEM format (not OpenSSH format):\n\n```\n{\n   \"type\" :   \"ES256\" ,\n   \"key\" :   \"-----BEGIN PUBLIC KEY-----\\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEEVs/o5+uQbTjL3chynL4wXgUg2R9\\nq9UU8I5mEovUf86QZ7kOBIjJwqnzD1omageEHWwHdBO6B+dFabmdT9POxg==\\n-----END PUBLIC KEY-----\"\n}\n```\n\n **Example 2** : public key as X509 certificate:\n\n```\n{\n   \"type\" :   \"ES256\" ,\n   \"key\" :   \"-----BEGIN CERTIFICATE-----\\nMIIBbjCCARWgAwIBAgIUGn02F6Y6s88dDGmIfwiNxWxDjhswCgYIKoZIzj0EAwIw\\nDTELMAkGA1UEBhMCSU4wHhcNMjMwNTI0MTAzNTI4WhcNMjgwNTIyMTAzNTI4WjAN\\nMQswCQYDVQQGEwJJTjBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IABBFbP6OfrkG0\\n4y93Icpy+MF4FINkfavVFPCOZhKL1H/OkGe5DgSIycKp8w9aJmoHhB1sB3QTugfn\\nRWm5nU/TzsajUzBRMB0GA1UdDgQWBBSaqFjzps1qG+x2DPISjaXTWsTOdDAfBgNV\\nHSMEGDAWgBSaqFjzps1qG+x2DPISjaXTWsTOdDAPBgNVHRMBAf8EBTADAQH/MAoG\\nCCqGSM49BAMCA0cAMEQCIBDHHWa/uLAVdGFEk82auTmw995+MsRwv52VXLw2Z+ji\\nAiAXzOWIcGN8p25uhUN/7v9gEcADGIS4yUiv8gsn/Jk2ow==\\n-----END CERTIFICATE-----\"\n}\n```\n\n **Example 3** : public key published as JWKs:\n\n```\n{\n   \"jwkUrl\" :   \"https://www.gstatic.com/iap/verify/public_key-jwk\"\n}\n```\n\n## Security considerations\u200b\n\n### Setting audience check\u200b\n\nCertain JWT providers share JWKs between multiple tenants (like Firebase). They use the `aud` claim of JWT to specify\nthe intended tenant for the JWT. Setting the `audience` field in the Hasura JWT configuration will make sure that the `aud` claim from the JWT is also checked during verification. Not doing this check will allow JWTs issued for other\ntenants to be valid as well.\n\nIn these cases, you **MUST** set the `audience` field to appropriate value. **Failing to do so is a major security\nvulnerability** .\n\n## Popular providers and known issues\u200b\n\n### Firebase\u200b\n\nThis page of the Firebase[ docs ](https://firebase.google.com/docs/auth/admin/verify-id-tokens#verify_id_tokens_using_a_third-party_jwt_library)mentions that JWKs are published under:\n\n[ https://www.googleapis.com/robot/v1/metadata/x509/securetoken@system.gserviceaccount.com ](https://www.googleapis.com/robot/v1/metadata/x509/securetoken@system.gserviceaccount.com)\n\nBut that is a non-standard format. Firebase also publishes the same certificates as the proper JWK format under:\n\n[ https://www.googleapis.com/service_accounts/v1/jwk/securetoken@system.gserviceaccount.com ](https://www.googleapis.com/service_accounts/v1/jwk/securetoken@system.gserviceaccount.com)\n\nIf you are using Firebase and Hasura, use this config:\n\n```\n{\n   \"jwkUrl\" :   \"https://www.googleapis.com/service_accounts/v1/jwk/securetoken@system.gserviceaccount.com\" ,\n   \"audience\" :   \"<firebase-project-id>\" ,\n   \"issuer\" :   \"https://securetoken.google.com/<firebase-project-id>\"\n}\n```\n\n### Auth0\u200b\n\nRefer to the[ Auth0 JWT Integration tutorial ](https://hasura.io/learn/graphql/hasura-authentication/integrations/auth0/)for a detailed guide on integrating Auth0 with Hasura.\n\nAuth0 publishes their JWK under:\n\n `https://<your-auth0-domain>.auth0.com/.well-known/jwks.json` \n\nBut they have a[ bug where the certificate thumbprint does not match ](https://community.auth0.com/t/certificate-thumbprint-is-longer-than-20-bytes/7794/3).\nHence, currently this URL does not work with Hasura.\n\nCurrent workaround is - download the X590 certificate from:\n\n `https://<your-auth0-domain>.auth0.com/pem` \n\nAnd use it in the `key` field:\n\n```\n{\n   \"type\" : \"RS512\" ,\n   \"key\" :  \"-----BEGIN CERTIFICATE-----\nMIIDDTCAfWgAwIBAgIJhNlZ11IDrxbMA0GCSqSIb3DQEBCwUAMCQxIjAgBgNV\nBAMTGXlc3QtaGdlLWp3C5ldS5hdXRoMC5jb20HhcNMTgwNzMwMTM1MjM1WhcN\nMzIwND3MTM1MjM1WjAkSIwIAYDVQQDExl0ZXNLWhnZS1qd3QuZXUuYXV0aDAu\nY29tMIBIjANBgkqhkiGw0BAQEFAAOCAQ8AMIICgKCAQEA13CivdSkNzRnOnR5\nZNiReD+AgbL7BWjRiw3RwjxRp5PYzvAGuj94yR6LRh3QybYtsMFbSg5J7fNq6\nLd6yMpMrUu8CBOnYY456b/2jlf+Vp8vEQuKvPOOw8Ev6x7X3blcuXCELSwyL3\nAGHq9OP2RV6V6CIE863zzuYH5HDLzU35oMZqogJVRJM0+6besH6TnSTNiA7xi\nBAqFaiRNQRVi1CAUa0bkN1XRp4AFy7d63VldOsM+8QnCNHySdDr1XevVuq6DK\nLQyGexFy4niALgHV0Q7A+xP1c2G6rJomZmn4j1avnlBpU87E58JMrRHOCj+5m\nXj22/QDAQABo0IwQDAPgNVHRMBAf8EBTADAQHMB0GA1UdDgQWBBT6FvNkuUgu\ntk3OYQi4lo5aOgwazAOgNVHQ8BAf8EBAMCAoQDQYJKoZIhvcNAQELBQADggEB\nADCLj+L22pEKyqaIUlhUJh7DAiDSLafy0fw56CntzPhqiZVVRlhxeAKidkCLV\nr9IEbRuxUoXiQSezPqM //9xHegMp0f2VauVCFg7EpUanYwvqFqjy9LWgH+SBz\n4uroLSZ5g1EPsHtlArLChA90caTX4e7Z7Xlu8G2kHRJB5nC7ycdbMUvEWBMeI\ntn/pcbmZ3/vlgj4UTEnURe2UPmSJpxmPwXqBcvwdKHRMgFXhZxojWCi0z4ftf\nf8t8UJIcbEblnkYe7wzYy8tOXoMMHqGSisCdkp/866029rJsKbwd8rVIyKNC5\nfrGYaw+0cxO6/WvSir0eA=\n-----END CERTIFICATE-----\n\"\n}\n```\n\n### Clerk\u200b\n\nClerk integrates with Hasura GraphQL Engine using JWTs.\n\nClerk publishes their JWK under: `https://<YOUR_CLERK_FRONTEND_API>/.well-known/jwks.json` \n\nRefer to the[ Clerk authentication guide ](https://hasura.io/learn/graphql/hasura-authentication/integrations/clerk/)to\nset up authenticated requests to Hasura with Clerk.\n\n## Generate a JWT Config for Auth0 or Firebase\u200b\n\nThe JWT Config to be used in the metadata can be generated using:[ https://hasura.io/jwt-config ](https://hasura.io/jwt-config).\n\n **Currently, the UI supports generating config for Auth0 and Firebase** .\n\nThe config generated from this page can be directly pasted in yaml files and command line arguments as it takes care of\nescaping new lines.\n\nImage: [ Generating JWT config ](https://hasura.io/docs/3.0/assets/images/auth_jwt-config-generated-8d727462247674b10067bc14ca8f9838.png)\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/auth/authentication/jwt/#introduction)\n- [ JWT authentication ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-auth-config)\n    - [ Example ](https://hasura.io/docs/3.0/auth/authentication/jwt/#example)\n\n- [ All jwt configuration fields ](https://hasura.io/docs/3.0/auth/authentication/jwt/#all-jwt-configuration-fields)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/auth/authentication/jwt/#metadata-structure)\n\n- [ Example Decoded Payload ](https://hasura.io/docs/3.0/auth/authentication/jwt/#example-decoded-payload)\n\n- [ Example Encoded JWT ](https://hasura.io/docs/3.0/auth/authentication/jwt/#example-encoded-jwt)\n\n- [ Hasura JWT format ](https://hasura.io/docs/3.0/auth/authentication/jwt/#hasura-jwt-format)\n\n- [ Hasura JWT Claim Description ](https://hasura.io/docs/3.0/auth/authentication/jwt/#hasura-jwt-claim-description)\n\n- [ JWT Notes ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-notes)\n- [ Hasura JWT configuration options ](https://hasura.io/docs/3.0/auth/authentication/jwt/#hasura-jwt-configuration-options)\n    - [ type ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-json-type)\n\n- [ key ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-json-key)\n\n- [ jwkUrl ](https://hasura.io/docs/3.0/auth/authentication/jwt/#jwt-json-jwkUrl)\n\n- [ claimsNamespacePath ](https://hasura.io/docs/3.0/auth/authentication/jwt/#claims-namespace-path)\n\n- [ claimsFormat ](https://hasura.io/docs/3.0/auth/authentication/jwt/#claimsformat)\n\n- [ claimsMap ](https://hasura.io/docs/3.0/auth/authentication/jwt/#claimsmap)\n\n- [ audience ](https://hasura.io/docs/3.0/auth/authentication/jwt/#audience)\n\n- [ issuer ](https://hasura.io/docs/3.0/auth/authentication/jwt/#issuer)\n\n- [ allowedSkew ](https://hasura.io/docs/3.0/auth/authentication/jwt/#allowedskew)\n\n- [ header ](https://hasura.io/docs/3.0/auth/authentication/jwt/#header)\n- [ Hasura JWT Config Examples ](https://hasura.io/docs/3.0/auth/authentication/jwt/#hasura-jwt-config-examples)\n- [ Security considerations ](https://hasura.io/docs/3.0/auth/authentication/jwt/#security-considerations)\n    - [ Setting audience check ](https://hasura.io/docs/3.0/auth/authentication/jwt/#setting-audience-check)\n- [ Popular providers and known issues ](https://hasura.io/docs/3.0/auth/authentication/jwt/#popular-providers-and-known-issues)\n    - [ Firebase ](https://hasura.io/docs/3.0/auth/authentication/jwt/#firebase)\n\n- [ Auth0 ](https://hasura.io/docs/3.0/auth/authentication/jwt/#auth0-issues)\n\n- [ Clerk ](https://hasura.io/docs/3.0/auth/authentication/jwt/#clerk)\n- [ Generate a JWT Config for Auth0 or Firebase ](https://hasura.io/docs/3.0/auth/authentication/jwt/#generating-jwt-config)\n", "https://hasura.io/docs/3.0/auth/authentication/webhook/": "# Authentication Using a Webhook\n\n## Introduction\u200b\n\nYou can configure the Hasura Engine to use webhook mode in order to authenticate incoming requests.\n\nThis process of using webhook mode for authentication with Hasura requires specifying a URL - which Hasura calls with\nthe original request headers - that then returns a body containing the user information in session variables.\n\nImage: [ Authentication using webhooks ](https://hasura.io/docs/3.0/assets/images/auth-webhook-overview-diagram-2cb0cf5d72dc6ecebd9dc4610a15e99c.png)\n\nThe webhook service will use your request headers to determine the auth status of the user and return the user role and\nany other information as session variables in the response body.\n\n## Configuring webhook mode\u200b\n\nYou can configure Hasura to run in webhook mode by running the GraphQL Engine by adding an object endpoint to your\nmetadata.\n\n### Example\u200b\n\n```\n---\nkind :  AuthConfig\nversion :  v1\ndefinition :\n   allowRoleEmulationBy :  admin\n   webhook :\n     webhookUrl :  http : //auth.yourservice.com/validate - request\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `webhookUrl`  | URL | true | URL of the authentication webhook. |\n|  `mode`  | String | false | HTTP method to use while making the request to the authentication webhook. Only `Get` and `Post` methods are supported (default: `Get` ). |\n\n\nNote\n\nIf you are running Hasura using Docker, ensure that the Hasura Docker container can reach the webhook.\n\n## Spec for webhook requests\u200b\n\n### GET request Example\u200b\n\n```\nGET   https://<your-custom-webhook-url>/   HTTP/1.1\n<Header-Key>: <Header-Value>\n```\n\nIf you configure your webhook to use `Get` , then Hasura **will forward all client headers except** :\n\n- `Content-Length`\n- `Content-Type`\n- `Content-MD5`\n- `User-Agent`\n- `Host`\n- `Origin`\n- `Referer`\n- `Accept`\n- `Accept-Encoding`\n- `Accept-Language`\n- `Accept-Datetime`\n- `Cache-Control`\n- `Connection`\n- `DNT`\n\n\n#### POST request Example\u200b\n\n `Post` requests will receive **all the client headers** . Given a request like:\n\n```\nquery   UserQuery ( $a :   Int )   {\n   users ( where :   {   id :   {   _eq :   $a   }   } )   {\n     id\n   }\n}\n```\n\nwith variables `{\"a\": 1}` , the webhook will receive a request in the following form:\n\n```\nPOST   https://<your-custom-webhook>/   HTTP/1.1\nContent-Type :   application/json\n{\n   \"headers\" :   {\n     \"header-key1\" :   \"header-value1\" ,\n     \"header-key2\" :   \"header-value2\"\n   }\n}\n```\n\nInvalid requests\n\nIf an invalid JSON request is sent, then the request body is not forwarded to the webhook\n\n## Spec for webhook responses\u200b\n\n### Success\u200b\n\nTo allow the GraphQL request to go through, your webhook must return a `200` status code.\n\nYou will, at least, need to set the `x-hasura-role` session variable to let the Hasura Engine know which role to use for\nthis request. Unlike JWT auth mode, you do not have to pass `x-hasura-allowed-roles` or `x-hasura-default-role` session\nvariables. This is because the webhook is called for each request, allowing the auth service to easily switch the user\nrole if needed.\n\nIn the example below the `x-hasura-is-owner` and `x-hasura-custom` are examples of custom session variables which\nwill be available to your permission rules in Hasura Engine.\n\n```\nHTTP/1.1   200   OK\nContent-Type :   application/json\n{\n     \"x-hasura-user-id\" :   \"25\" ,\n     \"X-hasura-role\" :   \"user\" ,\n     \"X-hasura-is-owner\" :   \"true\" ,\n     \"X-hasura-custom\" :   \"custom value\"\n}\n```\n\nValue types\n\nAll values should be `String` . They will be converted to the right type automatically upon receipt.\n\nSet-Cookie headers\n\nIf `Set-Cookie` HTTP headers are set by the auth webhook, they are forwarded by Hasura Engine as response headers for\nboth GET/POST request methods.\n\n### Auth denial\u200b\n\nIf you want to deny the GraphQL request, return a `401 Unauthorized` exception.\n\n`HTTP/1.1   401   Unauthorized`\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/auth/authentication/webhook/#introduction)\n- [ Configuring webhook mode ](https://hasura.io/docs/3.0/auth/authentication/webhook/#configuring-webhook-mode)\n    - [ Example ](https://hasura.io/docs/3.0/auth/authentication/webhook/#example)\n- [ Spec for webhook requests ](https://hasura.io/docs/3.0/auth/authentication/webhook/#webhook-request)\n    - [ GET request Example ](https://hasura.io/docs/3.0/auth/authentication/webhook/#get-request-example)\n- [ Spec for webhook responses ](https://hasura.io/docs/3.0/auth/authentication/webhook/#webhook-response)\n    - [ Success ](https://hasura.io/docs/3.0/auth/authentication/webhook/#success)\n\n- [ Auth denial ](https://hasura.io/docs/3.0/auth/authentication/webhook/#auth-denial)\n", "https://hasura.io/docs/3.0/auth/authentication/role-emulation/": "# Role Emulation\n\n## Introduction\u200b\n\nYou can configure authentication to allow certain roles to emulate other roles. This can be useful during development\nto test access-control rules without setting up authentication.\n\nTo set up role emulation, the `AuthConfig` Hasura metadata object accepts a field called `allowRoleEmulationBy` .\n\nWhen `allowRoleEmulationBy` is set up, Hasura will check for the value of the `x-hasura-role` session variable\nwhich is returned in the webhook or JWT response to be equal to the value set in the `allowRoleEmulationBy` . If the\nvalues are equal, then role emulation will be enabled for that request.\n\nWhen role emulation is enabled for a request, the session variables, including the role, will be used from\nthe HTTP request headers instead of from the JWT or webhook.\n\n### Role emulation scenario setup\u200b\n\nIn the example below, we set up role emulation for the `user` role, allowing a `user` to emulate any other role:\n\n```\n---\nkind :  AuthConfig\nversion :  v1\ndefinition :\n   allowRoleEmulationBy :  user\n   webhook :\n     webhookUrl :  https : //myauth.service.com/validate - request\n```\n\nThen, the following GraphQL request is made:\n\n```\nPOST   /graphql   HTTP/2.0\nContent-Type :   application/json\nx-hasura-role :   author\nx-hasura-author-id :   2\n{\n   \"query\" :   \"query GetAuthor { author { id name } }\" ,\n   \"variables\" :   null ,\n   \"operationName\" :   \"GetAuthor\"\n}\n```\n\nThis request will be executed normally using the `author` role and access-control rules related to the `author` role\nwill be applied to the request, for example: returning only the `id` and `name` fields of the author with `id` 2.\n\n### Role emulation scenario 1\u200b\n\nNow, let's assume the authentication webhook responds with the following session variables for the request:\n\n```\n{\n   \"x-hasura-role\" :   \"user\"\n}\n```\n\nThen, because the `user` role is allowed to emulate other roles, (as per the `allowRoleEmulationBy: user` value in our\nAuthConfig) the GraphQL request will be executed as the `author` role, because the `x-hasura-role: author` value is set\nin the headers of the request, along with `x-hasura-author-id: 2` .\n\n### Role emulation scenario 2\u200b\n\nIf the authentication webhook response is as follows:\n\n```\n{\n   \"x-hasura-role\" :   \"user\" ,\n   \"x-hasura-author-id\" :   1\n}\n```\n\nThen even in this case, because the `user` role is making the request and is allowed to emulate other roles,\nthe GraphQL request will be executed as the `author` role, as that is the role stipulated in the request headers.\n\nThus, the value of the session variable `x-hasura-author-id` will be 2 and not 1.\n\n### Role emulation scenario 3\u200b\n\nTo illustrate an unsuccessful emulation scenario; if the webhook response were the following:\n\n```\n{\n   \"x-hasura-role\" :   \"author\" ,\n   \"x-hasura-author-id\" :   1\n}\n```\n\nThen, the GraphQL query will be executed as the `author` role and **only** the session variables from the authentication\nwebhook response will be considered.\n\nThis is because the author role is not allowed to emulate other roles via HTTP request headers. All session variables\nfor this role will be extracted from either a verified JWT or authentication webhook response.\n\nTherefore, in this case, the value of the session variable `x-hasura-author-id` will be 1 as returned by the\nauthentication webhook response and not 2 as specified in the request headers.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/auth/authentication/role-emulation/#introduction)\n    - [ Role emulation scenario setup ](https://hasura.io/docs/3.0/auth/authentication/role-emulation/#role-emulation-scenario-setup)\n\n- [ Role emulation scenario 1 ](https://hasura.io/docs/3.0/auth/authentication/role-emulation/#role-emulation-scenario-1)\n\n- [ Role emulation scenario 2 ](https://hasura.io/docs/3.0/auth/authentication/role-emulation/#role-emulation-scenario-2)\n\n- [ Role emulation scenario 3 ](https://hasura.io/docs/3.0/auth/authentication/role-emulation/#role-emulation-scenario-3)\n", "https://hasura.io/docs/3.0/connectors/introduction/": "# Introduction\n\n## What is a data connector?\u200b\n\nA data connector is an HTTP service that exposes a set of APIs that Hasura uses to communicate with the data source. The\ndata connector is responsible for interpreting work to be done on behalf of the Hasura Engine, using the native query\nlanguage of the data source.\n\nData connectors, which are built using the[ NDC Specification ](http://hasura.github.io/ndc-spec/)and closely integrated\nwith the[ OpenDD spec ](https://github.com/hasura/open-data-domain-specification), enable anyone to connect rich,\nhighly-native data sources.\n\nThe NDC Specification defines a set of APIs that a data connector must implement. These APIs, which accept and return\nJSON, are used by Hasura to communicate with the data connector agent. The NDC specification also defines a set of\nmetadata that the data connector agent must provide to Hasura. This metadata is used by Hasura to introspect the data\nconnector, generate the GraphQL schema, and execute operations against the data source.\n\nYou can[ build your own data connector ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/), or use one of the many connectors\navailable on the[ Connector Hub ](https://hasura.io/connectors).\n\n## Types of data connectors\u200b\n\nThere are two main types of connectors available for use in Hasura v3 projects: Integrated and HTTP connectors.\n\n### Integrated connectors\u200b\n\nIntegrated connectors are configured and deployed via your project metadata only and do not require any additional\nprocesses.\n\nAn example of an integrated connector is the[ Postgres Connector ](https://hasura.io/connectors/postgres).\n\n### HTTP connectors\u200b\n\nHTTP connectors are configured and deployed **independently** of your project metadata and only the URL of the deployed\nconnector is required in your metadata.\n\nWhile Hasura does not prescribe any process for deploying an HTTP connector it does provide the `connector` CLI plugin\nfor easily deploying connectors that use our SDKs. You can learn more in our[ connector deployment guide ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors).\n\nAn example of an HTTP connector is the[ SendGrid Connector ](https://hasura.io/connectors/sendgrid).\n\n## What data connectors are available?\u200b\n\nBrowse the[ Connector Hub ](https://hasura.io/connectors)for an up-to-date list of all available connectors.\n\n### What did you think of this doc?\n\n- [ What is a data connector? ](https://hasura.io/docs/3.0/connectors/introduction/#what-is-a-data-connector)\n- [ Types of data connectors ](https://hasura.io/docs/3.0/connectors/introduction/#types-of-data-connectors)\n    - [ Integrated connectors ](https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors)\n\n- [ HTTP connectors ](https://hasura.io/docs/3.0/connectors/introduction/#http-connectors)\n- [ What data connectors are available? ](https://hasura.io/docs/3.0/connectors/introduction/#what-data-connectors-are-available)\n", "https://hasura.io/docs/3.0/connectors/hub/": "# Connector Hub\n\nHasura maintains a directory of[ available and upcoming v3 Connectors ](https://hasura.io/connectors/). This provides a\nsearchable and browsable index of connector versions. Each connector listed also has a details page with deployment\ninstructions.\n\nThe following instructions will explain how to have a connector listed on the connector's directory.\n\n## Authoring your connector\u200b\n\nFollow the[ Build your own Connector ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/)guide for\ninstructions on how to write a connector.\n\n## Setting up a connector repository\u200b\n\nCurrently, a connector must be published as an open source repository on GitHub.\n\nThis should include the following:\n\n- A `README.md` documenting what the connector is, and how to use it.\n- A `Dockerfile` that builds and runs your connector in the context of the `connector` plugin.\n\n\nDockerfile Requirements\n\nIf your connector relies on the `--volume` feature from the connector plugin, then your Dockerfile must **COPY** the\nvolume from a placeholder file/directory. This should be done as late in the Dockerfile as possible if you wish to\noptimize for caching.\n\n(See:[ the NDC-Typescript-Deno Dockerfile ](https://github.com/hasura/ndc-typescript-deno/blob/main/Dockerfile))\n\n## Publishing your Connector on the Connector Hub\u200b\n\nAll connectors listed on the Connector Hub currently require an entry in the[ ndc-hub repository registry ](https://github.com/hasura/ndc-hub/tree/main/registry). See the[ SendGrid Connector ](https://github.com/hasura/ndc-hub/tree/main/registry/sendgrid)for an example.\n\nOnce your repository is set up and tested with the[ Connector CLI Plugin ](https://hasura.io/docs/latest/hasura-cli/connector-plugin/)you should open a pull request\nagainst the[ NDC-Hub repo ](https://github.com/hasura/ndc-hub)to add a directory representing your connector.\n\nIt should contain:\n\n- A `README.md` file\n    - This should be a condensed version of the `README.md` in your connector repository that acts as a quickstart guide\nfor Hasura users.\n- A `logo.png` file\n    - This will appear next to your connector in the Connector Hub directory.\n- A `metadata.json` file\n    - This is used for indexing your connector and listing its published versions.\n\n\n## Tagging your Connector Versions\u200b\n\nThe `\"source_code\"` key in the `metadata.json` lists published versions of your connector.\n\nWe recommend that you tag releases of your connector in your repository according to[ \"semver\" ](https://semver.org).\n\nYou should include the Git hash of the version you are tagging so that stealth updates cannot be released without\nreview.\n\n- `is_open_source` should be `true` , and\n- `is_verified` should be `false`\n\n\nFor example:\n\n```\n    \"source_code\":{\n        \"is_open_source\": true,\n        \"repository\":\"https://github.com/foo/bar/\",\n        \"version\":[\n            {\n                \"tag\": \"v0.2\",\n                \"hash\": \"c0b3f13893e24a41df084985908af7ced0265498\",\n                \"is_verified\": false\n            },\n            {\n                \"tag\":\"v0.1\",\n                \"hash\":\"8dc16c427e4e0136ebf0cfba1de3831c7939befb\",\n                \"is_verified\": false\n            }\n        ]\n    }\n```\n\nYou can update your connector with new tags and details at any time, however all PRs will be reviewed by Hasura for the\nimmediate future.\n\n## Verifying your Connector\u200b\n\nPlease mark `\"is_verified\": false` in your connector metadata on initial publication.\n\nIf you wish to have your connector verified then you can raise this in the pull request discussion, or[ open an issue ](https://github.com/hasura/ndc-hub/issues/new).\n\nMore information about partnering with Hasura to have a verified version of your connector listed will be available\nsoon.\n\n## Maintaining your Connector\u200b\n\nIf you wish to have your connector listed on the Connector Hub, you should commit to making a best-effort to maintain the\nconnector to ensure that it is up-to-date with respect to:\n\n- Hasura Compatibility\n- Relevant Security Updates\n\n\nThe updates should be released as new versions of your connector.\n\n### What did you think of this doc?\n\n- [ Authoring your connector ](https://hasura.io/docs/3.0/connectors/hub/#authoring-your-connector)\n- [ Setting up a connector repository ](https://hasura.io/docs/3.0/connectors/hub/#setting-up-a-connector-repository)\n- [ Publishing your Connector on the Connector Hub ](https://hasura.io/docs/3.0/connectors/hub/#publishing-your-connector-on-the-connector-hub)\n- [ Tagging your Connector Versions ](https://hasura.io/docs/3.0/connectors/hub/#tagging-your-connector-versions)\n- [ Verifying your Connector ](https://hasura.io/docs/3.0/connectors/hub/#verifying-your-connector)\n- [ Maintaining your Connector ](https://hasura.io/docs/3.0/connectors/hub/#maintaining-your-connector)\n", "https://hasura.io/docs/3.0/connectors/deployment/": "# Deploy a Data Connector\n\n## Integrated connectors\u200b\n\n[ Integrated connectors ](https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors)do not need to be deployed, and are\navailable for immediate use in any project. You can see a full list of integrated connectors on the[ Connector Hub ](https://hasura.io/connectors).\n\n## HTTP connectors\u200b\n\n### Deploy an HTTP connector via a cloud provider\u200b\n\n[ HTTP connectors ](https://hasura.io/docs/3.0/connectors/introduction/#http-connectors)can easily be deployed to a variety of cloud providers.\nSimply follow the deployment instructions of your chosen provider.\n\n### Deploy an HTTP connector via Hasura using the CLI\u200b\n\nYou can also deploy them to Hasura using our `connector` CLI plugin. You can see a full list of HTTP connectors on the[ Connector Hub ](https://hasura.io/connectors).\n\nOpen source repositories that are set up according to the connector convention can be used via the `connector` CLI\nplugin.\n\nCurious about an example?\n\nSee the[ SendGrid connector's repository ](https://github.com/hasura/ndc-sendgrid/tree/main#sendgrid-connector)to see\nhow the connector is set up.\n\nOnce you have the Hasura v3 CLI you can install the plugin as follows:\n\n`hasura3 plugin  install  connector`\n\nLimit access to your connector\n\nYou can set the `SERVICE_TOKEN_SECRET` environment variable to only allow requests from authorized clients. Set the\ntoken while deploying the connector and then create a secret on Hasura Cloud with the same value:\n\n`hasura3 secret  set  -k SERVICE_TOKEN_SECRET -v  < secret-value >`\n\nDeploy the connector to Hasura Cloud:\n\n```\nhasura3 connector create my-connector:v1 \\\n  --github-repo-url https://github.com/hasura/cool-connector/tree/v0.7 \\\n  --config-file conf.json \\\n  --env SERVICE_TOKEN_SECRET='MY-SECRET-TOKEN-XXX123'\n```\n\n### Add connecotr to Metadata\u200b\n\nGet the URL for the deployed connector and add a `kind: DataConnector` object to your metadata:\n\n```\nkind :  DataConnector\nversion :  v2\ndefinition :\n   name :  my_connector\n   url :\n     singleUrl :\n       value :  https : //my - connector - 9XXX7 - hyc5v23h6a - ue.a.run.app\n   headers :\n     Authorization :\n       stringValueFromSecret :  SERVICE_TOKEN_SECRET\n```\n\nBuild the new metadata:\n\n`hasura3 build create -d  \"add new connector\"`\n\n### What did you think of this doc?\n\n- [ Integrated connectors ](https://hasura.io/docs/3.0/connectors/deployment/#integrated-connectors)\n- [ HTTP connectors ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors)\n    - [ Deploy an HTTP connector via a cloud provider ](https://hasura.io/docs/3.0/connectors/deployment/#deploy-an-http-connector-via-a-cloud-provider)\n\n- [ Deploy an HTTP connector via Hasura using the CLI ](https://hasura.io/docs/3.0/connectors/deployment/#deploy-an-http-connector-via-hasura-using-the-cli)\n\n- [ Add connecotr to Metadata ](https://hasura.io/docs/3.0/connectors/deployment/#add-connecotr-to-metadata)\n", "https://hasura.io/docs/3.0/connectors/build-your-own-connector/": "# Build Your Own Connector\n\nYou can build your own connector using one of our SDKs. Currently, we have the following available:\n\n- [ Rust Data Connector SDK ](https://github.com/hasura/ndc-hub#rust-sdk)\n- [ TypeScript Data Connector SDK ](https://github.com/hasura/ndc-sdk-typescript)\n\n\nAlternatively, you can implement the NDC spec directly, or use the[ TypeScript connector ](https://github.com/hasura/ndc-typescript-deno)for simple functions and procedures.\n\n## Create a Connector tutorial\u200b\n\nIf you are interested in creating a connector, we have a series of video tutorials that walk you through the\nprocess. We have these available in a repo you can[ check out here ](https://github.com/hasura/ndc-learn/tree/main).\n\n## Examples\u200b\n\n### CSV Connector - Direct NDC Spec Implementation\u200b\n\nThe NDC Specification documentation can be found[ here ](https://hasura.github.io/ndc-spec/overview.html)and a guide,\nbased on developing a connector for CSVs, can be found[ here ](https://hasura.github.io/ndc-spec/tutorial/index.html).\nYou can use this guide as a reference to build your own connector.\n\nLimitations\n\nComplex input types in procedures are not supported yet.\n\n### Sendgrid Connector - Rust SDK\u200b\n\nAn example of implementing the Sendgrid API can be found[ on GitHub here ](https://github.com/hasura/ndc-sendgrid/).\n\nThe architecture can be summarized as follows:\n\n- The connector is designed to work via the[ hasura3 connector plugin ](https://hasura.io/docs/latest/hasura-cli/connector-plugin/)deployment method.\n- As with all connector-plugin connectors, the connector is built and run as defined in its[ Dockerfile ](https://github.com/hasura/ndc-sendgrid/blob/main/Dockerfile)\n    - The `Dockerfile` :\n        - Installs system dependencies\n\n- Builds the Rust Cargo project\n\n- Copies the release build\n\n- Starts the server reading the configuration from `/config.json`\n\n- The `Dockerfile` :\n    - Installs system dependencies\n- The connector is implemented using the[ Rust Data Connector SDK ](https://github.com/hasura/ndc-hub#rust-sdk)\n    - The[ main entrypoint ](https://github.com/hasura/ndc-sendgrid/blob/main/crates/ndc-sendgrid/src/main.rs)uses the\nSDK's `default_main` method invoked with our `SendGridConnector` implementation of the `Connector` trait.\n\n- The most important aspects of this implementation are\n    - Defining its `SendGridConfiguration` that includes its API Key.\n\n- Exposing its `/schema`\n\n- Providing a `/query` to list email templates\n\n- Providing a `/mutation` to send emails\n\n- The[ SendGrid API interactions ](https://github.com/hasura/ndc-sendgrid/blob/main/crates/ndc-sendgrid/src/sendgrid_api.rs)expose\n    - `invoke_list_function_templates` , and\n\n- `invoke_send_mail`\n\n- The most important aspects of this implementation are\n    - Defining its `SendGridConfiguration` that includes its API Key.\n\n- The[ SendGrid API interactions ](https://github.com/hasura/ndc-sendgrid/blob/main/crates/ndc-sendgrid/src/sendgrid_api.rs)expose\n    - `invoke_list_function_templates` , and\n- With all this in place the connector can be used by referencing[ the repository ](https://github.com/hasura/ndc-sendgrid)and running the following command:\n- The running connector can then:\n    - Be referenced in Hasura v3 metadata\n\n- Leveraged by the LSP\n\n- Targeted by the engine\n\n- Receive Translated GraphQL Queries\n\n\nThe connector is designed to work via the[ hasura3 connector plugin ](https://hasura.io/docs/latest/hasura-cli/connector-plugin/)deployment method.\n\nAs with all connector-plugin connectors, the connector is built and run as defined in its[ Dockerfile ](https://github.com/hasura/ndc-sendgrid/blob/main/Dockerfile)\n\nThe connector is implemented using the[ Rust Data Connector SDK ](https://github.com/hasura/ndc-hub#rust-sdk)\n\nWith all this in place the connector can be used by referencing[ the repository ](https://github.com/hasura/ndc-sendgrid)and running the following command:\n\n`hasura3 connector create sendgrid:v1 --github-repo-url https://github.com/hasura/ndc-sendgrid/tree/main --config-file config.json`\n\nThe running connector can then:\n\n### Sendgrid Connector - Typescript Connector\u200b\n\nThe[ TypeScript Connector ](https://github.com/hasura/ndc-typescript-deno/)provides a simple way to deploy TypeScript\nfunctions as data connectors. **There is no need to implement an API, use an SDK, or write a Dockerfile.** Simply\nprovide a Typescript function to the Typescript Connector, and it will be deployed and executed within the[ Deno ](https://deno.com/)runtime.\n\nAs an example, we can write a Sendgrid connector consisting of the following two files:\n\n `functions/sendgrid.ts` :\n\n```\nimport   {  sendSimpleMail ,  IResult  }   from   \"https://deno.land/x/sendgrid@0.0.3/mod.ts\" ;\nexport   async   function   send ( subject :   string ,  to :   string ,  from :   string ,  plain :   string ,  html :   string ) :   Promise < IResult >   {\n   const   API_KEY   =  Deno . env . get ( \"SENDGRID_API_KEY\" ) ;\n   if   ( ! API_KEY )   {\n     throw   new   Error ( \"Error: SENDGRID_API_KEY environment variable must be set.\" ) ;\n   }\n   const  response  =   await   sendSimpleMail (\n     {\n      subject ,\n      to :   [ {  email :  to  } ] ,\n      from :   {  email :  from  } ,\n      content :   [\n         {  type :   \"text/plain\" ,  value :  plain  } ,\n         {  type :   \"text/html\" ,  value :  html  } ,\n       ] ,\n     } ,\n     {\n      apiKey :   API_KEY ,\n     }\n   ) ;\n   return  response ;\n}\n```\n\n `config.json` :\n\n```\n{\n   \"typescript_source\" :   \"/functions/sendgrid.ts\"\n}\n```\n\nThe file `config.json` tells the Typescript Connector where to find our Typescript function. The file `functions/sendgrid.ts` contains the function itself.\n\nTo deploy the connector you can use the command:\n\n`hasura3 connector create sendgrid:deno:v1 --github-repo-url https://github.com/hasura/ndc-typescript-deno/tree/main --config-file config.json --volume ./functions:/functions --env  SENDGRID_API_KEY = 'YOUR_SENDGRID_API_KEY'`\n\nThe example code shown here can be found[ on GitHub ](https://github.com/hasura/ndc-sendgrid-deno).\n\n### What did you think of this doc?\n\n- [ Create a Connector tutorial ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/#create-a-connector-tutorial)\n- [ Examples ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/#examples)\n    - [ CSV Connector - Direct NDC Spec Implementation ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/#csv-connector---direct-ndc-spec-implementation)\n\n- [ Sendgrid Connector - Rust SDK ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/#sendgrid-connector---rust-sdk)\n\n- [ Sendgrid Connector - Typescript Connector ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/#sendgrid-connector---typescript-connector)\n", "https://hasura.io/docs/3.0/connectors/postgresql/": "# Native Data Connector for PostgreSQL\n\nThe Native Data Connector for PostgreSQL is our flagship connector, with rich support for all kinds of queries.\n\nFlavors of PostgreSQL\n\nThis connector works with most flavors of PostgreSQL \u2014 such as Yugabyte and Aurora \u2014 but has not been tested with all.\nIf you are looking for a connector for a specific flavor of PostgreSQL, you can search the[ Connector Hub ](https://hasura.io/connectors)or[ build your own ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/).\n\n## Configuration\u200b\n\nSubject to change\n\nDuring this active development phase, the configuration structure is subject to change.\n\nThe connector will create an empty configuration as follows:\n\n```\n---\nversion :   1\nconnectionUri :\n   uri :   \"\"\nmetadata :\n   tables :   { }\n   nativeQueries :   { }\n   aggregateFunctions :   { }\n   comparisonOperators :   { }\n```\n\nOnce you enter your connection string for a PostgreSQL database and refresh your data source using the[ Hasura VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura), the `\"tables\"` and `\"aggregate_functions\"` sections will be auto-populated based on the current state of the database.\n\nThese will always be regenerated from scratch.\n\n### PostgreSQL connection URI\u200b\n\nThe PostgreSQL database URL should follow the[ PostgreSQL connection URI form ](https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING), which looks\nlike this:\n\n`postgresql://[user[:password]@][host[:port]][/dbname][?param1=value2&param2=value2&...]`\n\nRemember to encode any ambiguous characters using standard URI encoding. For example, if you have an `@` in your\nusername, it will need to be written as `%40` .\n\n### Native Queries\u200b\n\nNative queries can be defined by adding them to the `\"nativeQueries\"` section. Each query is specified as SQL. The\nreturn structure of the query must be explicitly specified in the `\"columns\"` field.\n\nNative queries can take arguments using the `{{argument_name}}` syntax. Arguments must be specified along with their\ntype. The arguments are not interpolated, but provided to PostgreSQL as parameters, and therefore must be specific\nvalues, not arbitrary SQL.\n\nHere's an example which filters a table called `\"Artist\"` :\n\n```\n---\nversion :   1\nconnectionUri :\n   uri :  postgresql : //alice@database.host\nmetadata :\n   tables :   { }\n   nativeQueries :\n     artist_below_id :\n       sql :  SELECT * FROM public.\"Artist\" WHERE \"ArtistId\" <  { { id } }\n       columns :\n         ArtistId :\n           name :  ArtistId\n           type :  int4\n         Name :\n           name :  Name\n           type :  varchar\n       arguments :\n         id :\n           name :  id\n           type :  int4\n```\n\n## Scalar types\u200b\n\nSQL data types are mapped to GraphQL types. The current mappings are as follows:\n\n| SQL data type | GraphQL type |\n|---|---|\n|  `bool`  |  `Boolean`  |\n|  `int2`  |  `Int`  |\n|  `int4`  |  `Int`  |\n|  `int8`  |  `Int`  |\n|  `float4`  |  `Float`  |\n|  `float8`  |  `Float`  |\n|  `numeric`  |  `Float`  |\n|  `char`  |  `String`  |\n|  `varchar`  |  `String`  |\n|  `text`  |  `String`  |\n|  `uuid`  |  `String`  |\n|  `date`  |  `String`  |\n|  `time`  |  `String`  |\n|  `timestamp`  |  `String`  |\n|  `timestamptz`  |  `String`  |\n|  `timetz`  |  `String`  |\n\n\nOther SQL scalar types are unsupported, but may still work in certain situations.\n\nData type aliases\n\nNote that many of these SQL data types have aliases in PostgreSQL, which can be found in the[ PostgreSQL documentation\non data types ](https://www.postgresql.org/docs/current/datatype.html).\n\n## Nested types\u200b\n\nThe connector does not currently support nested data structures, such as `array` , `hstore` , `json` , or `jsonb` , though\nthey may still work in certain situations.\n\n## Queries\u200b\n\nThe connector supports all query operations; see the[ query documentation ](https://hasura.io/docs/3.0/graphql-api/queries/)for details.\n\n### Predicates\u200b\n\nThe `_is_null` operator checks whether a value is `NULL` .\n\nThe following binary operators are supported when filtering:\n\n| Name | GraphQL operator | PostgreSQL operator | GraphQL types |\n|---|---|---|---|\n| equals |  `_ eq`  |  `=`  | all |\n| not equals |  `_ neq`  |  `<>`  | all |\n| less than |  `_ lt`  |  `<`  | all |\n| less than or equal to |  `_ lte`  |  `<=`  | all |\n| greater than |  `_ gt`  |  `>`  | all |\n| greater than or equal to |  `_ gte`  |  `>=`  | all |\n| like |  `_ like`  |  `LIKE`  |  `String`  |\n| not like |  `_ nlike`  |  `NOT LIKE`  |  `String`  |\n| case-insensitive like |  `_ ilike`  |  `ILIKE`  |  `String`  |\n| not case-insensitive like |  `_ nilike`  |  `NOT ILIKE`  |  `String`  |\n| similar |  `_ similar`  |  `SIMILAR TO`  |  `String`  |\n| not similar |  `_ nsimilar`  |  `NOT SIMILAR TO`  |  `String`  |\n| regex |  `_ regex`  |  `~`  |  `String`  |\n| not regex |  `_ nregex`  |  `!~`  |  `String`  |\n| case-insensitive regex |  `_ iregex`  |  `~`  |  `String`  |\n| not case-insensitive regex |  `_ niregex`  |  `!~`  |  `String`  |\n\n\nThe `_not` , `_and` , and `_or` operators all work as usual.\n\n### What did you think of this doc?\n\n- [ Configuration ](https://hasura.io/docs/3.0/connectors/postgresql/#configuration)\n    - [ PostgreSQL connection URI ](https://hasura.io/docs/3.0/connectors/postgresql/#postgresql-connection-uri)\n\n- [ Native Queries ](https://hasura.io/docs/3.0/connectors/postgresql/#native-queries)\n- [ Scalar types ](https://hasura.io/docs/3.0/connectors/postgresql/#scalar-types)\n- [ Nested types ](https://hasura.io/docs/3.0/connectors/postgresql/#nested-types)\n- [ Queries ](https://hasura.io/docs/3.0/connectors/postgresql/#queries)\n    - [ Predicates ](https://hasura.io/docs/3.0/connectors/postgresql/#predicates)\n", "https://hasura.io/docs/3.0/connectors/typescript/": "# Custom Business Logic using the TypeScript Connector\n\nA connector can be inferred from a TypeScript file. This gives you the ability to write custom business logic in\nTypescript and have it run as a connector.\n\nYou can find all the information you need to configure, run, test, and deploy the Typescript connector on the[ Connector Hub ](https://hasura.io/connectors/typescript-deno).\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/connectors/v2-compatibility/": "# Using a v3 Connector in a v2 Project via the Proxy\n\n## Introduction\u200b\n\nThe[ Connector Hub ](https://hasura.io/connectors)is designed to act as the new gold-standard for data source compatibility\nand works seamlessly with Hasura v3 projects to integrate diverse datasets and interactions in your projects.\n\nWhile this is immensely useful in a v3 context, what does it mean for your existing v2 projects? Will they be able to\nuse the new connectors?\n\nThe integrated Connector Proxy addresses this question by providing an optional `/v2` endpoint. Any connector using the\nHasura Connector SDKs will be able to enable this endpoint and be instantly compatible with existing v2 projects without\nany further modification.\n\n## Usage and configuration\u200b\n\nWhen deploying your connector with the[ connector plugin ](https://hasura.io/docs/3.0/connectors/introduction/#the-connector-cli-plugin),\nsimply enable the `ENABLE_V2_COMPATIBILITY` mode via an environment variable:\n\n```\nhasura3 connector create my-connector:v1 \\\n  --github-repo-url https://github.com/hasura/cool-connector/tree/v0.7 \\\n  --config-file conf.json \\\n  --env ENABLE_V2_COMPATIBILITY=true\n```\n\nIf your connector has been configured with a `SERVICE_TOKEN_SECRET` , you will need your v2 project to configure the\nproxy data connector with a corresponding configuration option.\n\nFor example, if your connector was created like so:\n\n```\nhasura3 connector create my-connector:v1 \\\n  --github-repo-url https://github.com/hasura/cool-connector/tree/v0.7 \\\n  --config-file conf.json \\\n  --env ENABLE_V2_COMPATIBILITY=true\n  --env SERVICE_TOKEN_SECRET='MY-SECRET-TOKEN-XXX123'\n```\n\nThen your v2 project connector config would look like:\n\n```\n{\n  \"service_token_secret\": \"MY-SECRET-TOKEN-XXX123\"\n}\n```\n\n## Limitations\u200b\n\nThe primary limitation of the proxy is that the v3 architecture no longer allows for dynamic configuration of connectors\nand their configuration is set on creation.\n\nThis means that you will have to deploy a v3 connector per-usage scenario as per the v3 pattern.\n\nYou can then track entities as per a normal v2 project once the connector is available via the proxy endpoint.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/connectors/v2-compatibility/#introduction)\n- [ Usage and configuration ](https://hasura.io/docs/3.0/connectors/v2-compatibility/#usage-and-configuration)\n- [ Limitations ](https://hasura.io/docs/3.0/connectors/v2-compatibility/#limitations)\n", "https://hasura.io/docs/3.0/data-domain-modeling/introduction/": "# Introduction\n\nHasura v3 introduces the OpenDD specification for constructing a supergraph. The metadata for Hasura v3 is an extension of the OpenDD spec, and adds some Hasura-specific configuration on top of OpenDD.\n\nThe OpenDD metadata defines the data model for each subgraph, including the types of the data objects, models and commands used to interact with the data, and access control rules on this data.\nThis data model is then combined with Native Data Connector agents, which are services to communicate with the raw data sources (like a database) in order to server your API.\n\n## How is this different from Hasura v2 metadata?\u200b\n\n- Hasura V2 metadata was specifically designed for Hasura, whereas OpenDD is a general specification for modeling a data supergraph usable by anyone.\nThe bits of configuration in Hasura v3 metadata that are specific to Hasura reside outside of the OpenDD spec.\n- Functionally, the V2 metadata relied directly on the raw data source for information like columns and fields, whereas\nOpenDD metadata is independent of the data source. In OpenDD, all fields and types are explicitly defined within the\nmetadata itself which eliminates the necessity for data source schema introspection at startup to generate a\nGraphQL schema. Also, the v3 metadata is still semantically consistent even if the underlying data source has changed.\n- Compared to the v2 metadata, there is a lot more flexibility offered by OpenDD when configuring your GraphQL API.\n\n\n## The OpenDD spec\u200b\n\nThe OpenDD spec lets you define the following to configure your data graph:\n\n- Data Connectors - that will be used to access the raw sources of data.\n- Data types - using the OpenDD type system to give strong types to your data.\n- Models - collections of data objects that can be queried. These server as the interface for querying your data.\n- Commands - opaque functions or procedures that can be used to query or mutate data.\n- Relationships - creating edges in your graph from a data type to a model or a command.\n- Permissions - access control rules on your types / models / commands.\n\n\nIn this way, your data graph is decoupled from any underlying database, data source or other physical\nlayer of storage. This is powerful as it enables you to consistently deliver data with the same structure and authorization rules.\nThis consistency remains intact even when you make significant changes, such as transitioning from MySQL to PostgreSQL,\nadopting MongoDB for read operations and MySQL for write operations, altering your transactional email system, or\nswitching payment providers.\n\nA metadata object is the fundamental building block of OpenDD and Hasura V3 metadata.\nHasura v3 metadata is split into one supergraph configuration and any number of subgraph configurations.\n\n## Supergraph Configuration\u200b\n\nThe supergraph configuration is an array of one of the following metadata objects:\n\n```\nobjects :\n   -   kind :  CompatibilityConfig\n     # ... (other properties for CompatibilityConfig)\n   -   kind :  AuthConfig\n     # ... (other properties for AuthConfig)\n```\n\nMore details about these can be found[ here ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph).\n\n## Subgraph Configuration\u200b\n\nThere can be any number of subgraphs in your supergraph. Each subgraph has a name and a configuration consisting of an array of the following metadata objects:\n\n```\nname :  my_subgraph\nobjects :\n   -   kind :  HasuraHubDataConnector\n     # ... (other properties for HasuraHubDataConnector)\n   -   kind :  DataConnector\n     # ... (other properties for DataConnector)\n   -   kind :  ScalarType\n     # ... (other properties for ScalarType)\n   -   kind :  ObjectType\n     # ... (other properties for ObjectType)\n   -   kind :  DataConnectorScalarRepresentation\n     # ... (other properties for DataConnectorScalarRepresentation)\n   -   kind :  Model\n     # ... (other properties for Model)\n   -   kind :  Command\n     # ... (other properties for Command)\n   -   kind :  Relationship\n     # ... (other properties for Relationship)\n   -   kind :  TypePermissions\n     # ... (other properties for TypePermissions)\n   -   kind :  ModelPermissions\n     # ... (other properties for ModelPermissions)\n   -   kind :  CommandPermissions\n     # ... (other properties for CommandPermissions)\n```\n\n## Data Connectors\u200b\n\nThe[ data connector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/)will define where the data is coming from. It can be a database, a REST API,\na GraphQL API, etc. The data connector will use the[ Native Data Connector ](https://hasura.io/docs/3.0/connectors/overview/)protocol to\nconnect to the data source and fetch the data.\n\n### The DataConnector object\u200b\n\nThe[ DataConnector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/)object describes a physical data connector that is hosted at a URL that Hasura can talk to for serving queries.\nThese data connectors are self-deployed and managed outside of the Hasura metadata.\n\n### The HasuraHubDataConnector object\u200b\n\nThe[ HasuraHubDataConnector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector)object allows you to atomically configure and deploy a data connector available in the[ Connector Hub ](https://hasura.io/connectors/)directly from the metadata.\n\n## Types\u200b\n\n[ Types ](https://hasura.io/docs/3.0/data-domain-modeling/types/)are a fundamental building block of OpenDD metadata with every bit of data in OpenDD having a\ntype\n\n### The ObjectType object\u200b\n\nThe[ ObjectType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types)object allows you to create structured object types with fields.\n\n### The ScalarType object\u200b\n\nThe[ ScalarType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types)object allows you to create opaque types whose semantics are unknown to OpenDD.\n\n### The DataConnectorScalarRepresentation object\u200b\n\nThe[ DataConnectorScalarRepresentation ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation)object allows you to define how a\nscalar type from a data connector (eg: varchar from postgres) is represented in your data graph.\n\n## Models\u200b\n\n[ Models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)are the link between your data sources and the API Hasura generates. A model may be backed by a\ndatabase table, an ad-hoc SQL query, a pre-materialized view, a custom REST or GraphQL API server, etc.\n\n### The Model object\u200b\n\nThe[ Model ](https://hasura.io/docs/3.0/data-domain-modeling/models/)object represents a collection of data objects (like rows in a SQL table or documents in\ncollection in a NoSQL database) of a certain[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/). A Model object also defines how the model and its types\nor fields map to entities in the underlying data source. It also defines how it is represented in the GraphQL API.\n\n## Commands\u200b\n\n[ Commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)are the other way of accessing data within the OpenDD spec. Commands are functions /\nprocedures whose implementations are unknown to OpenDD except for their input arguments and output type.\n\n### The Command object\u200b\n\nThe[ Command ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)object defines the name of the command, the arguments to the command and the output type\nof the command. It also defines any mappings of arguments / types from OpenDD to their corresponding NDC versions.\n\n## Relationships\u200b\n\n[ Relationships ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/)allow you extend[ object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/)with related[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)which then allows you to query nested or linked information.\n\n### The Relationship object\u200b\n\nThe[ Relationship ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/)object defines a relationship between a source[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)and a\ntarget[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/).\n\n## Permissions\u200b\n\nThe OpenDD Spec lets you define[ permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/), (also known as access control or authorization rules)\non[ types ](https://hasura.io/docs/3.0/data-domain-modeling/types/),[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/).\n\n### The TypePermissions object\u200b\n\n[ TypePermissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions)define which fields are allowed to be accessed by a\nrole.\n\n### The ModelPermissions object\u200b\n\n[ ModelPermissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions)define which objects or rows within the model are\nallowed to be accessed by a role.\n\n### The CommandPermissions object\u200b\n\n[ CommandPermissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions)define which commands are allowed to be executed by a\nrole.\n\n## Automatic metadata generation\u200b\n\nThe new Hasura DDN tooling of Console and the[ VS Code Extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)have built-in capabilities to\nautogenerate the OpenDD spec metadata from your existing data via the GUI console or CLI terminal commands.\nAlternatively, you can also author metadata manually.\n\n### What did you think of this doc?\n\n- [ How is this different from Hasura v2 metadata? ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#how-is-this-different-from-hasura-v2-metadata)\n- [ The OpenDD spec ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-opendd-spec)\n- [ Supergraph Configuration ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#supergraph-configuration)\n- [ Subgraph Configuration ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#subgraph-configuration)\n- [ Data Connectors ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#data-connectors)\n    - [ The DataConnector object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-dataconnector-object)\n\n- [ The HasuraHubDataConnector object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#hasura-hub-data-connector)\n- [ Types ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#types)\n    - [ The ObjectType object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-objecttype-object)\n\n- [ The ScalarType object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-scalartype-object)\n\n- [ The DataConnectorScalarRepresentation object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-dataconnectorscalarrepresentation-object)\n- [ Models ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#models)\n    - [ The Model object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-model-object)\n- [ Commands ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#commands)\n    - [ The Command object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-command-object)\n- [ Relationships ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#relationships)\n    - [ The Relationship object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-relationship-object)\n- [ Permissions ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#permissions)\n    - [ The TypePermissions object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-typepermissions-object)\n\n- [ The ModelPermissions object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-modelpermissions-object)\n\n- [ The CommandPermissions object ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#the-commandpermissions-object)\n- [ Automatic metadata generation ](https://hasura.io/docs/3.0/data-domain-modeling/introduction/#automatic-metadata-generation)\n", "https://hasura.io/docs/3.0/data-domain-modeling/types/": "# OpenDD Types\n\n## Introduction\u200b\n\nIn the OpenDD spec in Hasura, types serve as the fundamental elements that define the structure of your data.\n\nBeing able to define types in your data domain is beneficial because it provides you with the flexibility to define them\nseparately from the types in your data connector.\n\nThe specification employs a concrete type system that includes both primitive types and user-defined types. All\nsubsequent layers, such as models, commands, and relationships are defined in terms of these types.\n\nThe types can be one of the following:\n\n| OpenDD Type | Description |\n|---|---|\n| Primitive | These are the basic types `ID` , `Int` , `Float` , `Boolean` , or `String`  |\n| Custom | These are user-defined types, such as[ ScalarType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types)or[ ObjectType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types) |\n| Type References | When specifying the types of a field or an argument, you can mark them as required `!` or repeated `[]` . |\n\n\nThe spec also allows you to map existing data connector scalars to types in your data domain.\n\nYou can also define custom types by either aliasing existing types (such as primitives or custom), or you can define a\ntype with fields. In turn, the fields themselves can be a primitive or another custom type.\n\nType references are types of fields and arguments that refer to other primitive or custom types and which can be marked\nas nullable, required or repeated (in the case of arrays).\n\n[ Scalar type representation ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation)helps in mapping data connector scalars to any of the OpenDD\ntypes.\n\n## Primitive types and type references\u200b\n\nPrimitive types supported by the OpenDD spec are `ID` , `Int` , `Float` , `Boolean` and `String` .\n\nType references in OpenDD follow[ GraphQL type\nsyntax ](https://spec.graphql.org/June2018/#sec-Combining-List-and-Non-Null). Fields and arguments are nullable by\ndefault. To represent non-nullability, specify a `!` after the type name. Similarly, array fields and arguments are\nwrapped in `[]` .\n\n### Examples\u200b\n\nIf the field is nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory\n```\n\nIf the field is non-nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory !\n```\n\nIf the field is a nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ]\n```\n\nIf the field is a nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ]\n```\n\nIf the field is a non-nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ] !\n```\n\nIf the field is a non-nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ] !\n```\n\n## Scalar types\u200b\n\nIn the OpenDD spec, you can create opaque types whose semantics are unknown to OpenDD by defining an object with `kind:\nScalarType` and `version: v1` . These show up as scalars in your GraphQL schema. The object `definition` should include `name` and an optional `graphql` field.\n\n### Metadata structure\u200b\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   graphql :  <ScalarTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `graphql`  | [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalartypegraphqlconfig) | false | Configuration for using this scalar type in the GraphQL API. |\n\n\n#### ScalarTypeGraphQLConfig\u200b\n\n `ScalarTypeGraphQLConfig` is an object that defines the configuration for using this scalar type in the GraphQL API.\nAll scalar types are represented as custom[ GraphQL scalars ](https://graphql.org/learn/schema/#scalar-types)in the resulting GraphQL API.\nThis object has a field `typeName` that corresponds to the GraphQL type name to use for this scalar type.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\nBelow, we define an `Email` type that is represented as a primitive `String` type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  Email\n   graphql :\n     typeName :  EmailScalar\n```\n\nBelow, we define an `OpaqueDate` type that is represented as a custom object type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  OpaqueDate\n```\n\n## Object types\u200b\n\nIn the OpenDD spec, completely new types can be created by defining an object with `kind: ObjectType` and `version: v1` .\nYou need to also define a name and the fields for this type.\n\n### Metadata structure\u200b\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   fields :\n     -   name :  field1\n       type :  <TypeReference >\n     -   name :  field2\n       type :  <TypeReference >\n   globalIdFields :\n     -  field1\n   graphql :  <ObjectTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `fields`  | [ [Field] ](https://hasura.io/docs/3.0/data-domain-modeling/types/#field) | true | List of fields. |\n|  `globalIdFields`  |  `[String]`  | false | Names of the fields that will form the Global ID associated with the object type. |\n|  `graphql`  | [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#objecttypegraphqlconfig) | false | Configuration for using this object type in the GraphQL API. |\n\n\n#### Field\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the field. |\n|  `type`  |  `String`  | true | Type reference of the field. |\n\n\n#### ObjectTypeGraphQLConfig\u200b\n\n `ObjectTypeGraphQLConfig` is config that defines the configuration for using this object type in the GraphQL API.\nWhen used in an output context, a[ GraphQL object type ](https://graphql.org/learn/schema/#object-types-and-fields)is generated for each OpenDD object. `ObjectTypeGraphQLConfig` has a field `typeName` that corresponds to the GraphQL type name to use for this OpenDD object type.\nThe fields of this generated GraphQL object type will have the same names as the OpenDD field names. The generated GraphQL field types\nwill also pick the nullability and repeated characteristics based on the OpenDD type reference for the field.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Below, we define an `author` type that has three fields: `author_id` , `first_name` , and `last_name` . Each field is\nrepresented as a primitive `Int` or `String` type. The `author_id` field is non-nullable whereas `first_name` and `last_name` fields are nullable.\nWhen used in the GraphQL API in an output context, this will result in a GraphQL object type called `Author` .\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n```\n\n1. Extending the `author` type to also have a Global ID field\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n   globalIdFields :\n     -  author_id\n```\n\nNow, the `Author` GraphQL type will have an auto-generated `id` field that is a globally\nunique ID across your data domain, which will be based on the `author_id` field of `artist` .\nThe `node` query root field of the Relay API can then be used to retrieve this global ID,\ngiven there is a model whose `objectType` is `artist` and it is set as the `globalIdSource` .\n\n## Scalar type representation for data connectors\u200b\n\nA scalar type from a data connector can be represented as an OpenDD type by defining an object with `kind: DataConnectorScalarRepresentation` and `version: v1` . To define a scalar type representation, you need to\nhave a data connector name, a data connector scalar type, a type representation and an optional graphql field.\n\nMap scalars for user in your GraphQL API\n\nIt is necessary to map **any** available scalar from a data connector that is used in the GraphQL API.\n\n### Metadata structure\u200b\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  <DataSourceName >\n   dataConnectorScalarType :  <ScalarTypeName >\n   representation :  <TypeName >\n   graphql :  <DataConnectorScalarGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnectorName`  |  `String`  | true | Name of the data connector. |\n|  `dataConnectorScalarType`  |  `String`  | true | Name of the scalar type from the data connector. |\n|  `representation`  |  `String`  | true | Representation of the scalar type in GraphQL schema. |\n|  `graphql`  | [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#dcscalargraphqlconfig) | false | Configuration for using this data connector scalar type in the GraphQL API. |\n\n\n#### DCScalarGraphQLConfig\u200b\n\n `DCScalarGraphQLConfig` is an object that defines the configuration for using this data connector scalar type in the\nGraphQL API. This object has a field `comparisonExpressionTypeName` that corresponds to the GraphQL type name to use for\nthe comparison expression input type that is generated for this data connector scalar type. This comparison expression type\nwill contain the comparison operators for this scalar as defined by the data connector.\n\n```\ngraphql :\n   comparisonExpressionTypeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Mapping a `text` scalar type from the `my_source` connector to a primitive `String` type and giving its GraphQL comparison expression a type name.\n\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  my_source\n   dataConnectorScalarType :  text\n   representation :  String\n   graphql :\n     comparisonExpressionTypeName :  text_comparison_exp\n```\n\n1. Mapping a PostgreSQL scalar `geography` to a custom object type.\n\n\n```\n-   kind :  ObjectType\n   version :  v1\n   definition :\n     name :  Geography\n     fields :\n       -   name :  type\n         type :  String\n       -   name :  coordinates\n         type :   [ Float ]\n-   kind :  DataConnectorScalarRepresentation\n   version :  v1\n   definition :\n     dataConnectorName :  pg_source\n     dataConnectorScalarType :  geography\n     representation :  Geography\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/types/#introduction)\n- [ Primitive types and type references ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#examples)\n- [ Scalar types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#metadata-structure)\n        - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalartypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#examples-1)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#metadata-structure)\n    - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalartypegraphqlconfig)\n- [ Object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#metadata-structure-1)\n        - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#field)\n\n- [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#objecttypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#metadata-structure-1)\n    - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#field)\n- [ Scalar type representation for data connectors ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#metadata-structure-2)\n        - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#dcscalargraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#metadata-structure-2)\n    - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#dcscalargraphqlconfig)\n", "https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/": "# OpenDD Data Connectors\n\n## Introduction\u200b\n\nA data connector is a way to specify where your data comes from and how it can be used. It can connect to various types\nof data sources, like SQL databases, NoSQL databases, REST APIs, GraphQL APIs, files, and more.\n\nYou can declare a data connector and use it in your[ model's ](https://hasura.io/docs/3.0/data-domain-modeling/models/)configuration\nby[ referencing it with the source ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source)property, which connects that model to\nthe respective data connector.\n\nIn the Open Data Domain Specification (OpenDD spec), you can connect to data sources through a `DataConnector` or a `HasuraHubDataConnector` .\n\n## DataConnector\u200b\n\nTo create a data connector object, you will need to define an object with `kind: DataConnector` and `version: v1` .\nThe object `definition` should include four fields: `name` , `url` , `headers` and `schema` .\n\n```\nkind :  DataConnector\nversion :  v2\ndefinition :\n   name :  <DataConnectorName >\n   url :  <DataConnectorURL >\n   headers :  <DataConnectorHeaders >\n   schema :  <SchemaResponse >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the Data Connector. |\n|  `url`  | [ DataConnectorURL ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#dataconnectorurl) | true | URL to access the data connector. |\n|  `headers`  | [ DataConnectorHeaders ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#dataconnectorheaders) | true | Request headers to pass on to the data connector. |\n|  `schema`  | [ SchemaResponse ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#schemaresponse) | true | The schema response from the data connector. This includes `scalar_ types` , `object_ type` , `collections` , `functions` and `procedures` . |\n\n\n### DataConnectorURL\u200b\n\n `DataConnectorURL` is an object that either defines a single URL for the data connector or separate read/write URLs\nfor the data connector. For example, it can take either of the following\n\n```\nurl :\n   singleUrl :  <URL as Secret >\n```\n\n```\nurl :\n   read :  <URL as Secret >\n   write :  <URL as Secret >\n```\n\nThe[ secret syntax ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret)should be used for URLs.\n\nRead/Write URLs are used to access the appropriate data connector based on the GraphQL operation type. For example, if\nthe operation type is `Query` or `Subscription` , then the `read` URL will be used to access the data connector.\nSimilarly, for a `Mutation` operation, the `write` URL will be used.\n\n### DataConnectorHeaders\u200b\n\n `DataConnectorHeaders` is an object that defines the headers to be forwarded to the data connector when making requests.\nThe keys of this object are header names and the values are the header values in the[ secret syntax ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret).\nE.g., if a bearer authorization token needs to be forwarded, the headers field would be:\n\n```\nheaders :\n   Authorization :\n     value :  Bearer <token >\n```\n\nor if the header is coming from a secret:\n\n```\nheaders:\n  Authorization:\n    stringValueFromSecret: <secret name>\n```\n\n### SchemaResponse\u200b\n\n `SchemaResponse` is an object that defines the types, schema, functions, etc. of the data connector. This is usually\nprovided by the `/schema` endpoint of the data connector. It contains the following fields:\n\n```\nschema :\n   scalar_types :  <ScalarTypes >\n   object_types :  <ObjectTypes >\n   collections :  <Collections >\n   functions :  <Functions >\n   procedures :  <Procedures >\n```\n\nThe structure and detailed documentation of these fields can be found[ here ](https://hasura.github.io/ndc-spec/specification/schema/index.html).\n\n### Example\u200b\n\nIn this example, we'll create a data connector for the Chinook data set. The Chinook data set is a sample database that\nrepresents a digital media store, including tables for artists, albums, tracks, and more. Each object we reference above\nis present in the complete example below:\n\n```\nkind :  DataConnector\nversion :  v2\ndefinition :\n   name :  my_data_connector\n   url :\n     singleUrl :\n       value :  http : //localhost : 8080\n   schema :\n     scalar_types :\n       String :\n         aggregate_functions :   { }\n         comparison_operators :\n           like :\n             argument_type :\n               type :  named\n               name :  String\n         update_operators :   { }\n       Int :\n         aggregate_functions :\n           min :\n             result_type :\n               type :  nullable\n               underlying_type :\n                 type :  named\n                 name :  Int\n           max :\n             result_type :\n               type :  nullable\n               underlying_type :\n                 type :  named\n                 name :  Int\n         comparison_operators :   { }\n         update_operators :   { }\n     object_types :\n       Artist :\n         description :  An artist\n         fields :\n           ArtistId :\n             description :  The artist's primary key\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n           Name :\n             description :  The artist's name\n             arguments :   { }\n             type :\n               type :  named\n               name :  String\n       Album :\n         description :  An album\n         fields :\n           AlbumId :\n             description :  The album's primary key\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n           Title :\n             description :  The album's title\n             arguments :   { }\n             type :\n               type :  named\n               name :  String\n           ArtistId :\n             description :  The album's artist ID\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n       Track :\n         description :  A track\n         fields :\n           TrackId :\n             description :  The track's primary key\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n           Name :\n             description :  The track's name\n             arguments :   { }\n             type :\n               type :  named\n               name :  String\n           AlbumId :\n             description :  The track's album ID\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n       artist_below_id :\n         description :  An artist\n         fields :\n           ArtistId :\n             description :  The artist's primary key\n             arguments :\n               id :\n                 description :  The cyling id\n                 type :\n                   type :  named\n                   name :  Int\n             type :\n               type :  named\n               name :  Int\n           Name :\n             description :  The artist's name\n             arguments :   { }\n             type :\n               type :  named\n               name :  String\n     collections :\n       -   name :  Artist\n         description :  A collection of artists\n         arguments :   { }\n         type :  Artist\n         deletable :   false\n         uniqueness_constraints :\n           ArtistById :\n             unique_columns :\n               -  ArtistId\n         foreign_keys :   { }\n       -   name :  Album\n         description :  A collection of albums\n         arguments :   { }\n         type :  Album\n         deletable :   false\n         uniqueness_constraints :\n           AlbumById :\n             unique_columns :\n               -  AlbumId\n         foreign_keys :   { }\n       -   name :  Track\n         description :  A collection of tracks\n         arguments :   { }\n         type :  Track\n         deletable :   false\n         uniqueness_constraints :\n           TrackById :\n             unique_columns :\n               -  TrackId\n         foreign_keys :   { }\n       -   name :  artist_below_id\n         description :  A collection of artists below a certain id\n         arguments :\n           id :\n             description :  The ceiling id\n             type :\n               type :  named\n               name :  Int\n         type :  Artist\n         deletable :   false\n         uniqueness_constraints :   { }\n         foreign_keys :   { }\n     functions :   [ ]\n     procedures :   [ ]\n```\n\n## HasuraHubDataConnector\u200b\n\nInstead of deploying your own data connector, Hasura metadata also allows you to directly configure and use one of the standard data connectors from the[ Connector Hub ](https://hasura.io/connectors/).\n\n### Metadata Object\u200b\n\nTo configure a HasuraHubDataConnector, you will need to add the following metadata object:\n\n```\nkind :  HasuraHubDataConnector\nversion :  v1\ndefinition :\n   name :  <DataConnectorName >\n   connectorId :  <HasuraHubConnectorId >\n   connectorConfiguration :  <ConnectorConfigurations >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the Data Connector. |\n|  `connectorId`  |  `String`  | true | The Connector Hub ID of the connector to configure. Currently, only `hasura/postgres` is supported. |\n|  `connectorConfiguration`  | [[ ConnectorConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#connectorConfiguration)] | true | The configurations to deploy the connector, one for every region that the connector should be deployed in. |\n\n\n#### ConnectorConfiguration\u200b\n\nConnectorConfiguration defines the configuration to deploy a connector in a particular region.\nTypically, you want to deploy the connector in a region that's closest to your database. The NDC schemas for deployments across all regions must be identical.\n\nThe structure of ConnectorConfiguration is as follows:\n\n```\nregion :  <String >\nmode :  <ReadOnly / ReadWrite / WriteOnly >\nconfiguration :  <Connector specific configuration >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `region`  |  `String`  | true | Name of the cloud region. Eg: gcp-asia-south1 |\n|  `mode`  |  `String`  | true | Whether this connector should support reads only, writes only, or both. |\n|  `connectorConfiguration`  |  `Any`  | true | The configuration specific to the connector ID you chose from the Hub. |\n\n\n### Example\u200b\n\nIn this example we are configuring a postgres data connector using a postgres database URL in a single region.\n\n```\nkind :  HasuraHubDataConnector\nversion :  v1\ndefinition :\n   name :  foo\n   connectorId :  hasura/postgres\n   connectorConfiguration :\n     -   region :  gcp - asia - south1\n       mode :  ReadWrite\n       configuration :\n         version :   1\n         connectionUri :\n           uri :\n             value :  postgres : //username : password@database - host/database_name\n         metadata :  < ... >\n```\n\nAfter populating the URL, typically, the rest of configuration will be automatically authored through tooling (eg: Hasura VSCode extension).\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#introduction)\n- [ DataConnector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#dataconnector)\n    - [ DataConnectorURL ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#dataconnectorurl)\n\n- [ DataConnectorHeaders ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#dataconnectorheaders)\n\n- [ SchemaResponse ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#schemaresponse)\n\n- [ Example ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#example)\n- [ HasuraHubDataConnector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector)\n    - [ Metadata Object ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#metadata-object)\n        - [ ConnectorConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#connectorConfiguration)\n\n- [ Example ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#example-1)\n\n- [ Metadata Object ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#metadata-object)\n    - [ ConnectorConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#connectorConfiguration)\n", "https://hasura.io/docs/3.0/data-domain-modeling/models/": "# OpenDD Models\n\n## Introduction\u200b\n\nModels are the link between your data connectors and the API Hasura generates. A model may be backed by a database\ntable, an ad-hoc SQL query, a pre-materialized view, a custom REST or GraphQL API server, etc.\n\nOnce a model is declared it will then often be referenced by `Relationship` and/or `Permissions` objects.\n\n## Description\u200b\n\nTo create a model, you need to define an OpenDD object with `kind: Model` and `version: v1` . The object `definition` has the following fields:\n\n### Metadata structure\u200b\n\n```\nkind :  Model\nversion :  v1\ndefinition :\n   name :  <ModelName >\n   objectType :  <TypeName >\n   globalIDSource :  true  |  false\n   source :  <SourceConfiguration >\n   graphql :  <GraphQLConfiguration >\n   arguments :   [ ArgumentDefinition ]\n   filterableFields :   [ FilterableFields ]\n   orderableFields :   [ OrderableFields ]\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the model. |\n|  `objectType`  |  `String`  | true | [ Type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)of the objects in this model. |\n|  `globalIDSource`  |  `Boolean`  | true | If this model should be used as the[ Global ID ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/)source for its `objectType` . |\n|  `source`  | [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source) | false | Source configuration for the model. |\n|  `graphql`  | [ ModelGraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql) | false | GraphQL configuration for the model. |\n|  `arguments`  | [ [ArgumentDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition) | true | The argument definitions for the model. |\n|  `filterableFields`  | [ [FilterableFieldDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#filterablefielddefinition) | true | Filterable fields for the model. |\n|  `orderableFields`  | [ [OrderableFieldDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#orderablefielddefinition) | true | Orderable fields for the model. |\n\n\nFilterable/Orderable Fields support\n\nAt the moment, we don't support field level filterable/orderable customizations. So, you will have to provide an\nexhaustive list of the fields of your model in `filterableFields` and `orderableFields` .\n\n#### SourceConfiguration\u200b\n\nThe source configuration is an object that defines the data source for the model. It has the following fields:\n\n```\nsource :\n   dataConnectorName :  <DataConnectorName >\n   collection :  <CollectionName >\n   typeMapping :  <TypeMapping >\n```\n\n| source Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnector`  |  `String`  | true | Name of the source data connector backing this model. |\n|  `collection`  |  `String`  | true | Name of the collection in the source data connector backing this model. |\n|  `typeMapping`  | [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping) | true | Type mappings from OpenDD object types used within the model to the corresponding data connector types. |\n\n\n#### ModelGraphQLConfiguration\u200b\n\nModelGraphQLConfiguration is an object that defines how the model should be surfaced in the GraphQL API. It has the following fields:\n\n```\ngraphql :\n   selectUniques :  <SelectUniques >\n   selectMany :  <SelectMany >\n   filterExpressionType :  <FilterExpressionType >\n   orderByExpressionType :  <OrderByExpressionType >\n   argumentsInputType :  <ArgumentsInputType >\n```\n\n| graphql Field | Type | Required | Description |\n|---|---|---|---|\n|  `selectUniques`  | [ [SelectUniques] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#selectuniques) | true | Select uniques configuration for the model. |\n|  `selectMany`  | [ SelectMany ](https://hasura.io/docs/3.0/data-domain-modeling/models/#selectmany) | false | Select many configuration for the model. |\n|  `filterExpressionType`  |  `String`  | false | GraphQL type name to use for the filter input. |\n|  `orderByExpressionType`  |  `String`  | false | GraphQL type name to use for the order by input. |\n|  `argumentsInputType`  |  `String`  | false | GraphQL type name to use for the model arguments input. |\n\n\n##### SelectUniques\u200b\n\nSelect uniques is an array of objects that defines the unique identifiers for the model. For each select unique defined here,\na query root field is added to the GraphQL API. For each field defined in the `uniqueIdentifier` , an input argument is added\nto the query root field which can be supplied to retrieve the unique identified object from the model.\n\n```\nselectUniques :\n   queryRootField :  <QueryRootField >\n   uniqueIdentifier :  <UniqueIdentifier >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `queryRootField`  |  `String`  | true | Name of the query root field to use in the GraphQL API. |\n|  `uniqueIdentifier`  |  `Array`  | true | Set of fields which can uniquely identify a row/object in the model. |\n\n\n##### SelectMany\u200b\n\nSelect many configuration for a model adds a query root field to the GraphQl API that can be used to retrieve multiple objects from the model.\nThis field can accept the following arguments:\n\n- `args` , used for supplying the values for the model's arguments. This argument is generated only if the model has arguments and `argumentsInputType` is set in the ModelGraphQlConfiguration.\n- `where` , used for filtering the objects to retrieve. This argument is generated only if `filterExpressionType` is set in the ModelGraphQlConfiguration. The filter expression contains all the filterable fields and the `_and` / `_or` / `_not` logical operators.\n- `order_by` , used for sorting the retrieved objects. This argument is generated only if `orderByExpressionType` is set in the ModelGraphQlConfiguration. The order by expression contains all the orderable fields.\n- `limit` , used for limiting the number of retrieved objects.\n- `offset` , used for skipping the first `offset` objects when retrieving.\n\n\n```\nselectMany :\n   queryRootField :  <QueryRootField >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `queryRootField`  |  `String`  | true | Name of the query root field to use in the GraphQL API. |\n\n\n#### FilterableFieldDefinition\u200b\n\nThe filterable field definition is an object that lists the allowed operators for a given field.\n\n```\nfilterableFields :\n   -   fieldName :  <String >\n     operators :\n       enableAll :   true\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | Name of the field. |\n|  `operators`  |  `Object`  | true | Allowed operators (at the moment, we only support `enableAll: true` ) |\n\n\n#### OrderableFieldDefinition\u200b\n\nOrderable field definition is an object that lists down the allowed order by directions for a given field.\n\n```\norderableFields :\n   -   fieldName :  <String >\n     orderByDirections :\n       enableAll :   true\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | Name of the field. |\n|  `orderByDirections`  |  `Object`  | true | Allowed order by directions (at the moment, we only support `enableAll: true` ) |\n\n\n## Examples\u200b\n\nIn this example, we're creating a model called `Authors` backed by a database table called `authors` in the `db` data\nsource:\n\n```\nkind :  Model\nversion :  v1\ndefinition :\n   name :  Authors\n   objectType :  author\n   globalIdSource :   true\n   source :\n     dataConnectorName :  db\n     collection :  authors\n     typeMapping :\n       author :\n         fieldMapping :\n           author_id :\n             column :  id\n           first_name :\n             column :  first_name\n           last_name :\n             column :  last_name\n   graphql :\n     selectUniques :\n       -   queryRootField :  AuthorByID\n         uniqueIdentifier :\n           -  author_id\n     selectMany :\n       queryRootField :  AuthorMany\n     filterExpressionType :  Author_Where_Exp\n     orderByExpressionType :  Author_Order_By\n   arguments :   [ ]\n   filterableFields :\n     -   fieldName :  author_id\n       operators :\n         enableAll :   true\n     -   fieldName :  first_name\n       operators :\n         enableAll :   true\n     -   fieldName :  last_name\n       operators :\n         enableAll :   true\n   orderableFields :\n     -   fieldName :  author_id\n       orderByDirections :\n         enableAll :   true\n     -   fieldName :  first_name\n       orderByDirections :\n         enableAll :   true\n     -   fieldName :  last_name\n       orderByDirections :\n         enableAll :   true\n```\n\nAssuming the ObjectType was defined like[ this ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples), and the scalar types corresponding to the fields had\nappropriate comparison expressions defined, the resulting GraphQl API will be:\n\n```\ntype   Query   {\n   node ( id :   ID ! ) :   Node\n   AuthorByID ( author_id :   Int ! ) :   Author\n   AuthorMany ( where :   Author_Where_Exp ,   order_by   Author_Order_By ,   limit :   Int ,   offset :   Int ) :   Author\n}\ntype   Author   {\n   id :   ID !\n   author_id :   Int !\n   first_name :   String\n   last_name :   String\n}\ninput   Author_Where_Exp :   {\n   _and :   [ Author_Where_Exp ! ]\n   _or :   [ Author_Where_Exp ! ]\n   _not :   [ Author_Where_Exp ! ]\n   author_id :   int_comparison_exp\n   first_name :   text_comparison_exp\n   last_name :   text_comparison_exp\n}\ninput   Author_Order_By   {\n   author_id :   order_by\n   first_name :   order_by\n   last_name :   order_by\n}\nenum   order_by   {\n   Asc ,\n   Desc\n}\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/models/#introduction)\n- [ Description ](https://hasura.io/docs/3.0/data-domain-modeling/models/#description)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure)\n        - [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source)\n\n- [ ModelGraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql)\n\n- [ FilterableFieldDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/models/#filterablefielddefinition)\n\n- [ OrderableFieldDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/models/#orderablefielddefinition)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure)\n    - [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source)\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/models/#examples)\n", "https://hasura.io/docs/3.0/data-domain-modeling/commands/": "# OpenDD Commands\n\n## Introduction\u200b\n\nCommands are backed by **functions** or **procedures** declared in a `DataConnector` allowing you to execute business logic\ndirectly from your GraphQL API. You can use them to validate, process, or enrich some data, call another API, or log a\nuser in. As an example, with commands you can connect to a REST endpoint which can be your own custom server, a public\nAPI, or a serverless function.\n\nTo create a command, you need to define an OpenDD object with `kind: Command` and `version: v1` . The object `definition` has the following fields:\n\n### Metadata structure\u200b\n\n```\nkind :  Command\nversion :  v1\ndefinition :\n   name :  <String >\n   arguments :  <ArgumentDefinition >\n   outputType :  <String >\n   source :  <CommandSourceConfiguration >\n   graphql :  <GraphQLConfiguration >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the command. |\n|  `arguments`  | [ [ArgumentDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition) | false | The argument definitions for the command. |\n|  `outputType`  |  `String`  | true | The name of the return[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)of command. |\n|  `source`  | [ CommandSourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#commandsourceconfiguration) | true | Source configuration for the command. |\n|  `graphql`  | [ GraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#graphqlconfiguration) | true | GraphQL configuration for the command. |\n\n\n#### CommandSourceConfiguration\u200b\n\nSource is an object that defines the source data connector for the command. It has the following fields:\n\n```\nsource :\n   dataConnectorName :  <String >\n   dataConnectorCommand :  <DataConnectorCommand >\n   typeMapping :  <TypeMapping >\n   argumentMapping :  <ArgumentMapping >\n```\n\nA command can either be backed by a function or a procedure.\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnectorName`  |  `String`  | true | Name of the[ data connector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/)backing this command. |\n|  `dataConnectorCommand`  | [ DataConnectorCommand ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#dataconnectorcommand) | true | What command to invoke in the data connector. This will either refer to a function or a procedure. |\n|  `typeMapping`  | [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping) | false | [ Type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)mappings for the command from OpenDD types used in the command inputs/outputs to the corresponding data connector types. |\n|  `argumentMapping`  | [ ArgumentMapping ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#argumentmapping) | false | Mappings for the argument names of the command defined in OpenDD to their corresponding data connector names. |\n\n\n##### DataConnectorCommand\u200b\n\nDataConnectorCommand is an object that defines the NDC `function` or `procedure` to use for executing this command.\n\n```\ndataConnectorCommand :\n   # Either function OR procedure\n   function :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `function` / `procedure`  |  `String`  | true | Name of the function or procedure. One of these must be chosen. |\n\n\nFunctions or Procedures?\n\nFunctions are used for read operations and procedures are used for write operations.\n\n##### ArgumentMapping\u200b\n\nThe `argumentMapping` is used to define the mapping between the OpenDD `arguments` of the command and the arguments\nof the `function` or `procedure` in the data connector. It has the following fields:\n\n```\nargumentMappings :\n   <OpenDDArgumentName> :  <NDCArgumentName >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDArgumentName`  |  `String`  | true | Name of the argument of the command as defined in OpenDD |\n|  `NDCArgumentName`  |  `String`  | true | The name of the argument in function or procedure to which the `OpenDDArgumentName` maps to |\n\n\n#### GraphQLConfiguration\u200b\n\nGraphQL is an object that defines how the command should be surfaced in the GraphQL API. The command can show up either under the query root field or under the mutation root field. This can be configured as follows:\n\n```\ngraphql :\n   rootFieldName :  <String >\n   rootFieldKind :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `rootFieldName`  |  `String`  | true | The GraphQL root field name to use for the command. |\n|  `rootFieldKind`  |  `String`  | true | The type of GraphQL operation ( `Query` ). |\n\n\n## Examples\u200b\n\nBelow, we're creating a `Command` called `get_article_by_id` which takes an argument `article_id` of type `Int!` (non-nullable `Int` ) and returns an object of type `article` (similar to one defined[ here ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples)).[ The command is backed by a function ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings)called `get_article_by_id` in the `db` data connector.\nThe function returns an object with fields `id` , `title` , and `author_id` . The `id` field is mapped to the `article_id` argument and the `title` and `author_id` fields are mapped to the `title` and `author_id` columns respectively.\n\n```\nkind :  Command\nversion :  v1\ndefinition :\n   name :  get_article_by_id\n   arguments :\n     -   name :  article_id\n       type :  Int !\n   outputType :  article\n   source :\n     dataConnectorName :  db\n     dataConnectorCommand :\n       function :  get_article_by_id\n     typeMapping :\n       article :\n         fieldMapping :\n           article_id :\n             column :  id\n           title :\n             column :  title\n           author_id :\n             column :  author_id\n     argumentMapping :\n       article_id :  id\n   graphql :\n     rootFieldName :  getArticleById\n     rootFieldKind :  Query\n```\n\nThis resulting GraphQL API will be:\n\n```\ntype   Query   {\n   getArticleById ( article_id :   Int ! ) :   Article\n}\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#introduction)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure)\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#examples)\n", "https://hasura.io/docs/3.0/data-domain-modeling/permissions/": "# OpenDD Permissions\n\n## Introduction\u200b\n\nThe OpenDD Spec lets you define permissions, (also known as access control or authorization rules) on[ object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/),[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)in your data domain.\n\nThe following types of permissions can be defined in the[ OpenDD spec ](https://hasura.io/docs/3.0/data-domain-modeling/overview/):\n\n- `TypePermissions` define which fields are allowed to be accessed by a role. Defining permissions on output types is\nuseful, as certain fields may be sensitive and should only be accessible to particular roles.\n- `ModelPermissions` define which objects or rows within a model are allowed to be accessed by a role.\n- `CommandPermissions` defines whether the command is executable by a role.\n\n\n## Type permissions\u200b\n\nA type permission will need the type and the role(s) for which the permission should be defined. For each role, you will\nneed to define the fields accessible for that role.\n\n### Metadata Structure\u200b\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  <TypeName >\n   permissions :  <TypePermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `typeName`  | [ TypeName ](https://hasura.io/docs/3.0/data-domain-modeling/types/) | true | The name of the type for which permissions are to be defined. |\n|  `permissions`  | [ [TypePermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#typepermission) | true | The permissions object for this type, one for each role. |\n\n\n#### TypePermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     output :  <OutputPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `output`  | [ OutputPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#outputpermission) | true | The type output permission for the role. |\n\n\n#### OutputPermission\u200b\n\n```\noutput :\n   allowedFields :\n     -  <field1 >\n     -  <field2 >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `allowedFields`  |  `[String]`  | true | List of fields that are accessible to the role. |\n\n\n### Examples\u200b\n\nTo define permissions on an output type `article` for `admin` and `user` role:\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  article\n   permissions :\n     -   role :  admin\n       output :\n         allowedFields :\n           -  id\n           -  title\n           -  author_id\n     -   role :  user\n       output :\n         allowedFields :\n           -  id\n           -  title\n```\n\nTypes are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this type, then none of its fields would be accessible to that role.\n\n## Model Permissions\u200b\n\nA model permission will need the model name and the role(s) for which the permission should be defined. For each role,\nyou will need to define an optional filter expression. Objects (or rows/documents) that satisfy this filter predicate\nwill be returned for that role.\n\n### Metadata Structure\u200b\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  <ModelName >\n   permissions :  <ModelPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| modelName |  `String`  | true | The name of the model for which permissions are to be defined. |\n| permissions | [ [ModelPermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#modelpermission) | true | The permissions object for this model, one for each role. |\n\n\n#### ModelPermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     select :  <SelectPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `select`  | [ SelectPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#selectpermission) | true | The model select permission for the role. |\n\n\n#### SelectPermission\u200b\n\n```\nselect :\n   filter :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| filter | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate) | false | Optional predicate to satisfy. This predicate can use operators supported by the model\u2019s data connector. If the filter is missing then all rows are accessible. If the filter is present, then only the rows satisfying this filter expression are accessible. |\n\n\n### Examples\u200b\n\nBelow, we're creating a set of `ModelPermissions` on the `Articles` model for the roles `admin` , `user_1` , and `user_2` .\n\nAs the `select` object for `admin` role is empty, it will return all rows.\n\nThe `user_1` role's `select` object has a filter predicate that will return rows where the `author_id` field is equal to\nthe `x-hasura-user-id` session variable.\n\nThe `user_2` role's `select` object has a filter predicate that will return rows where the `title` field is like the\nstring `Functional` .\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  Articles\n   permissions :\n     -   role :  admin\n       select :\n         filter :\n     -   role :  user_1\n       select :\n         filter :\n           fieldComparison :\n             field :  author_id\n             operator :  _eq\n             value :\n               sessionVariable :  x - hasura - user - id\n     -   role :  user_2\n       select :\n         filter :\n           and :\n             -   fieldComparison :\n                 field :  title\n                 operator :  _like\n                 value :\n                   literal :   \"%Functional%\"\n```\n\nModels are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this model, then the model won't be selectable for that role.\n\n## Command permissions\u200b\n\nA command permission will need the command name and the role(s) for which the permission should be defined.\n\n### Metadata structure\u200b\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  <CommandName >\n   permissions :  <CommandPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `commandName`  |  `String`  | true | The name of the command for which permissions are to be defined. |\n|  `permissions`  | [ [CommandPermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#commandpermission) | true | The permissions object for this command, one for each role. |\n\n\n#### CommandPermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     allowExecution :  <Boolean >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `allowExecution`  |  `Boolean`  | true | Is the execution of the command allowed for the role |\n\n\n### Examples\u200b\n\nTo define permissions on a command with name `get_article_by_id` for `admin` and `user` role:\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  get_article_by_id\n   permissions :\n     -   role :  admin\n       allowExecution :   true\n     -   role :  user\n       allowExecution :   false\n```\n\nCommands are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this command, then it won't be executable by that role.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#introduction)\n- [ Type permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions)\n    - [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#metadata-structure)\n        - [ TypePermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#typepermission)\n\n- [ OutputPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#outputpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#examples)\n\n- [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#metadata-structure)\n    - [ TypePermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#typepermission)\n- [ Model Permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions)\n    - [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#metadata-structure-1)\n        - [ ModelPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#modelpermission)\n\n- [ SelectPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#selectpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#examples-1)\n\n- [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#metadata-structure-1)\n    - [ ModelPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#modelpermission)\n- [ Command permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#metadata-structure-2)\n        - [ CommandPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#commandpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#metadata-structure-2)\n    - [ CommandPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#commandpermission)\n", "https://hasura.io/docs/3.0/data-domain-modeling/relationships/": "# OpenDD Relationships\n\n## Introduction\u200b\n\nA relationship allows you to query nested or linked information, for example from `Manufacturers` to `Products` . A\nrelationship defined in the OpenDD spec allows you extend[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)objects with related[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/).\n\nTo create a relationship, you will need to define an object with `kind: Relationship` and `version: v1` . The object `definition` has a `name` , the `source` type, a `target` model and the `mapping` between the two.\n\n### Metadata structure\u200b\n\n```\nkind :  Relationship\nversion :  v1\ndefinition :\n   source :  <String >\n   name :  <String >\n   target :  <TargetConfiguration >\n   mapping :  <RelationshipMapping >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `source`  |  `String`  | true | The source[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)of the relationship. |\n|  `name`  |  `String`  | true | The name of the relationship. |\n|  `target`  | [ TargetConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetconfiguration) | true | The target of the relationship. |\n|  `mapping`  | [ [RelationshipMapping] ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationshipmapping) | true | Defines how the `Source` and `Target` should be connected. This field expects a list of objects. |\n\n\n#### TargetConfiguration\u200b\n\n```\ntarget :\n   model :  <TargetModel >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `model`  | [ TargetModel ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel) | true | The target[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/)for the relationship. |\n\n\n#### TargetModel\u200b\n\n```\nmodel :\n   name :  <String >\n   subgraph :  <String >\n   relationshipType :  <RelationshipType >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | The name of the target model. |\n|  `subgraph`  |  `String`  | false | The subgraph of the target model. Defaults to the subgraph of the relationship metadata object. |\n|  `relationshipType`  | [ RelationshipType ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationshiptype) | true | The type of the relationship: either `Object` or `Array` . |\n\n\n#### RelationshipType\u200b\n\n`relationshipType :  Object  |  Array`\n\n| Value | Description |\n|---|---|\n|  `Object`  | The relationship is a one-to-one relationship. |\n|  `Array`  | The relationship is a one-to-many relationship. |\n\n\n#### RelationshipMapping\u200b\n\nDefines how the source type maps to the target model in this relationship. The mapping can have multiple links.\n\n```\nmapping :\n   -   source :  <RelationshipMappingSource >\n     target :  <RelationshipMappingTarget >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `source`  | [ RelationshipMappingSource ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationshipmappingsource) | true | The source link of this mapping. |\n|  `target`  | [ RelationshipMappingTarget ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationshipmappingtarget) | true | The target link of this mapping. |\n\n\n#### RelationshipMappingSource\u200b\n\n```\nsource :\n   fieldPath :\n     -  <FieldAccess >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldPath`  | [ [FieldAccess] ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#fieldaccess) | true | The field path of the source link. |\n\n\n#### RelationshipMappingTarget\u200b\n\n```\ntarget :\n   modelField :\n     -  <FieldAccess >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `modelField`  | [ [FieldAccess] ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#fieldaccess) | true | The field path of the target model the source link maps to. |\n\n\n#### FieldAccess\u200b\n\nDefines a single element of a field path.\n\n`fieldName :  <FieldName >`\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | The name of the field for this path element. |\n\n\n## Example\u200b\n\n### Basic relationship\u200b\n\nLet's add the following relationships to the above types.\n\n1. `Array` relationship where `author` has many `Articles` :\n\n\n```\nkind :  Relationship\nversion :\ndefinition :\n   source :  author\n   name :  articles\n   target :\n     model :\n       name :  Articles\n       relationshipType :  Array\n   mappings :\n     -   source :\n         fieldPath :\n           -   fieldName :  id\n       target :\n         modelField :\n           -   fieldName :  author_id\n```\n\n1. `Object` relationship where `article` has one `Author` :\n\n\n```\nkind :  Relationship\nversion :  v1\ndefinition :\n   source :  article\n   name :  author\n   target :\n     model :\n       name :  Authors\n       relationshipType :  Object\n   mappings :\n     -   source :\n         fieldPath :\n           -   fieldName :  author_id\n       target :\n         modelField :\n           -   fieldName :  id\n```\n\nThe resulting GraphQL schema will appear as:\n\n```\ntype   Authors   {\n   author_id :   Int !\n   first_name :   String !\n   last_name :   String !\n   articles :   [ Article ! ] !\n}\ntype   Articles   {\n   id :   Int !\n   author_id :   Int !\n   title :   String !\n   author :   Author\n}\n```\n\nLocal and Remote Relationships\n\nSyntactically, there are no differences between local (e.g., a relationship between two columns in the same datasource,\nor an existing foreign-key relationship) or remote (a relationship across two different data sources) relationships.\nHasura DDN will automatically detect the type of relationship and make the optimal query plan accordingly.\n\n### Relationship across subgraphs\u200b\n\nNow, imagine if the `Article` model is defined in a **different subgraph** called `subgraph_articles` and the `Author` type\nand the following array relationship are part of the `default` subgraph.\n\nWe will now need to specify the **target** subgraph in the `target` section of the relationship definition as `subgraph: subgraph_articles` as shown below:\n\n```\nkind :  Relationship\nversion :\ndefinition :\n   source :  author\n   name :  articles\n   target :\n     model :\n       name :  Articles\n       relationshipType :  Array\n       subgraph :  subgraph_articles\n   mappings :\n     -   source :\n         fieldPath :\n           -   fieldName :  id\n       target :\n         modelField :\n           -   fieldName :  author_id\n```\n\nNext, imagine you want to query the author from the `Article` model, which is specified in the `subgraph_articles` subgraph. You will need to specify where the `Authors` can be queried from by specifying the **subgraph** in the `target` section of the relationship.\n\nIn this case, by specifying the subgraph as `subgraph: default` as shown below:\n\n```\nkind :  Relationship\nversion :  v1\ndefinition :\n   source :  article\n   name :  author\n   target :\n     model :\n       name :  Authors\n       relationshipType :  Object\n       subgraph :  default\n   mapping :\n     -   source :\n         fieldPath :\n           -   fieldName :  author_id\n       target :\n         modelField :\n           -   fieldName :  id\n```\n\nCurrent limitations\n\n1. Only types to top-level model types relationships are supported.\n2. Simple top-level type field to top-level model field mapping are supported.\n\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#introduction)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#metadata-structure)\n        - [ TargetConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetconfiguration)\n\n- [ TargetModel ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel)\n\n- [ RelationshipType ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationshiptype)\n\n- [ RelationshipMapping ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationshipmapping)\n\n- [ RelationshipMappingSource ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationshipmappingsource)\n\n- [ RelationshipMappingTarget ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationshipmappingtarget)\n\n- [ FieldAccess ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#fieldaccess)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#metadata-structure)\n    - [ TargetConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetconfiguration)\n- [ Example ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#example)\n    - [ Basic relationship ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#basic-relationship)\n\n- [ Relationship across subgraphs ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#relationship-across-subgraphs)\n", "https://hasura.io/docs/3.0/data-domain-modeling/global-id/": "# OpenDD Global ID\n\n## Introduction\u200b\n\nA Global ID is a unique identifier for an object across the entire application, not just within a specific table or\ntype. Think of it as an ID which you can use to fetch any object directly, regardless of what kind of object it is. This\nis different from typical database IDs, which are often guaranteed unique only within a particular table.\n\nHasura's Global ID implementation can be used to provide options for GraphQL clients to elegantly handle caching and\ndata re-fetching in a predictable and standardized way.\n\nThe Global ID generated by Hasura DDN follows the[ Relay Global ID spec ](https://relay.dev/graphql/objectidentification.htm).\n\nAs the example below shows, the `user` object type has a field `user_id` that uniquely identifies a user. The Global ID\nfor the `user` object type will be generated using the `user_id` field:\n\nFor the following request on a model which has enabled Global ID:\n\n```\n{\n   user_by_id ( user_id :   1 )   {\n     id  //  Global   ID\n     user_id\n     name\n   }\n}\n```\n\nThe response obtained should look like the following:\n\n```\n{\n   \"data\" :   {\n     \"user_by_id\" :   {\n       \"id\" :   \"eyJ2ZXJzaW9uIjoxLCJ0eXBlbmFtZSI6IkFydGljbGUiLCJpZCI6eyJhcnRpY2xlX2lkIjoyfX0=\" ,\n       \"user_id\" :   1 ,\n       \"name\" :   \"Bob\"\n     }\n   }\n}\n```\n\nNow, with the Global ID received above, the `User` object corresponding to `user_id: 1` can be retrieved, as shown\nbelow.\n\n```\n{\n   node ( id :   \"eyJ2ZXJzaW9uIjoxLCJ0eXBlbmFtZSI6IkFydGljbGUiLCJpZCI6eyJhcnRpY2xlX2lkIjoyfX0=\" )   {\n     id\n     __typename\n     ...   on   User   {\n       name\n     }\n   }\n}\n```\n\nThe response to the above request should identify the `User` with `user_id: 1` .\n\n```\n{\n   \"node\" :   {\n     \"id\" :   \"eyJ2ZXJzaW9uIjoxLCJ0eXBlbmFtZSI6IkFydGljbGUiLCJpZCI6eyJhcnRpY2xlX2lkIjoyfX0=\" ,\n     \"__typename\" :   \"User\" ,\n     \"name\" :   \"Bob\"\n   }\n}\n```\n\n## Description\u200b\n\nYou can configure an `ObjectType` to generate a Global ID, by extending its definition to accept the list of the fields\nthat will uniquely identify the object.\n\n### Metadata structure:\u200b\n\n1. `objectType`\n\n\n```\nkind :  ObjectType\nname :  <NAME >\nfields :  <FIELDS >\nglobalIdFields :  <GlobalId >\n```\n\n1. `model`\n\n\n```\nkind :  Model\nname :  <NAME >\ndataType :  <DATATYPE >\nglobalIdSource :  <GlobalIDSource >\n```\n\n### Metadata fields reference:\u200b\n\n1. `GlobalIdFields` - `[String]` - A list of field(s) which can uniquely identify the object.\n2. `GlobalIdSource` - boolean - Boolean value that indicates that this model should be used to retrieve objects using a global ID corresponding to the model's `objectType` .\n\n\n `GlobalIdFields` - `[String]` - A list of field(s) which can uniquely identify the object.\n\n `GlobalIdSource` - boolean - Boolean value that indicates that this model should be used to retrieve objects using a global ID corresponding to the model's `objectType` .\n\n## Example\u200b\n\nLet's consider the following `article` object and let's assume the `article_id` field uniquely identifies an article:\n\n```\nkind :  ObjectType\nname :  article\nfields :\n   -   name :  article_id\n     type :  Int\n   -   name :  title\n     type :  String\n   -   name :  author_id\n     type :  Int\n```\n\nWe need to add the `article_id` field in the `globalID` .\n\n```\nkind :  ObjectType\nname :  article\nfields :\n   -   name :  article_id\n     type :  Int\n   -   name :  title\n     type :  String\n   -   name :  author_id\n     type :  Int\nglobalIdFields :\n   -  article_id\n```\n\nNext, we need to choose the model that implements the `article` object type to be the Global ID source for the object\ntype `article` . This can be done by adding `globalIDSource: true` in the model's definition:\n\n```\nkind :  Model\nname :  Articles\nobjectType :  article\nglobalIdSource :   true\n```\n\nConsideration for id fields and multiple models\n\n`id`\n\nFor an object type to generate a Global ID, it should not have any field named `id` , because it will be generated\nautomatically.\n\nAdditionally, multiple models can implement the same object type, **but only one model out of this selection can be the\nGlobal ID source of the object type.** \n\nWith the above changes, the following GraphQL schema will be generated:\n\n```\ninterface   Node   {\n   id :   ID !\n}\ntype   Articles   implements   Node   {\n   article_id :   Int !\n   title :   String !\n}\n```\n\n### Examples of GraphQL requests executed on the above GraphQL schema\u200b\n\n1. GraphQL Request to fetch `Article` by `id` that fetches the Global ID,\n\n\n```\n{\n   article_by_id ( article_id :   1 )   {\n     id  //  Global   ID\n     article_id\n   }\n}\n```\n\nThe response obtained should look like the following:\n\n```\n{\n   \"data\" :   {\n     \"article_by_id\" :   {\n       \"id\" :   \"eyJ2ZXJzaW9uIjoxLCJ0eXBlbmFtZSI6IkFydGljbGUiLCJpZCI6eyJhcnRpY2xlX2lkIjoyfX0=\" ,\n       \"article_id\" :   1\n     }\n   }\n}\n```\n\n1. GraphQL request to fetch an object using the Global ID.\n\n\n```\n{\n   node ( id :   \"eyJ2ZXJzaW9uIjoxLCJ0eXBlbmFtZSI6IkFydGljbGUiLCJpZCI6eyJhcnRpY2xlX2lkIjoyfX0=\" )   {\n     id\n     __typename\n     ...   on   Article   {\n       title\n     }\n   }\n}\n```\n\nThe response corresponding to the above request should identify the `Article` with `article_id: 1` .\n\n```\n{\n   \"node\" :   {\n     \"id\" :   \"eyJ2ZXJzaW9uIjoxLCJ0eXBlbmFtZSI6IkFydGljbGUiLCJpZCI6eyJhcnRpY2xlX2lkIjoyfX0=\" ,\n     \"__typename\" :   \"Article\" ,\n     \"title\" :   \"Article title 1\"\n   }\n}\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/#introduction)\n- [ Description ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/#description)\n    - [ Metadata structure: ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/#metadata-structure)\n\n- [ Metadata fields reference: ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/#metadata-fields-reference)\n- [ Example ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/#example)\n    - [ Examples of GraphQL requests executed on the above GraphQL schema ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/#examples-of-graphql-requests-executed-on-the-above-graphql-schema)\n", "https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/": "# Common OpenDD Syntax\n\n## ModelPredicate\u200b\n\nA `ModelPredicate` is used to define the boolean expression for filtering the objects within a model, and is typically used when defining permissions.\n\n```\n[ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#fieldcomparison)\n|\n[ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#relationship)\n|\n[ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#andexp)\n|\n[ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#orexp)\n|\n[ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#notexp)\n```\n\n### FieldComparison\u200b\n\nThis predicate filters objects where the particular `field` of the object returns true when the specified comparison operator `operator` is applied with the `value` as input.\n\n```\nfieldComparison :\n   field :  <FieldName >\n   operator :  <Operator >\n   value :  <ValueExpression >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| field |  `String`  | true | Name of the field of the model to compare. |\n| operator |  `String`  | true | Name of the operator. Either the built-in operators `_ eq` or `_ is_ null` , or any of the operators available from the data connector. |\n| value | [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#valueexpression) | false | The value to compare. Can be a literal value or a a value from session variables. This can be omitted in case of `_ is_ null` operator. |\n\n\n### RelationshipPredicate\u200b\n\nThis predicate evaluates to true if any of the corresponding target objects of the relationship of the source model's object type with `name` meet the nested `predicate` .\n\n```\nrelationship :\n   name :  <RelationshipName >\n   predicate :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| name |  `String`  | true | Name of relationship of the model to compare. |\n| predicate | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate) | false | The filter or predicate expression. |\n\n\n### AndExp\u200b\n\nThis predicates evaluates to true if all sub-predicates of `and` evaluate to true.\n\n```\n{\n  \"and\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate)\n]\n}\n```\n\n### OrExp\u200b\n\nThis predicates evaluates to true if any of the sub-predicates of `or` evaluate to true.\n\n```\n{\n  \"or\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate)\n]\n}\n```\n\n### NotExp\u200b\n\nThis predicates evaluates to true if the sub-predicates of `not` evaluates to false.\n\n```\n{\n  \"not\" :\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate)\n}\n```\n\n## ValueExpression\u200b\n\nAn expression which evaluates to a value that can be used in comparison expressions, etc.\nThis expression can either be a literal value or a reference to a session variable.\n\n```\n[ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#literal)\n|\n[ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#sessionvariable)\n```\n\n### Literal\u200b\n\n```\n{\n   \"literal\" :  <any JSON value>\n}\n```\n\n#### Examples\u200b\n\n`literal :  some string`\n\n### SessionVariable\u200b\n\n`sessionVariable :  String`\n\n#### Examples\u200b\n\n`sessionVariable :  x - hasura - user - id`\n\n## TypeMapping\u200b\n\nThe `typemapping` is used by[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)to define the mapping between the fields of the OpenDD types used in the model/command and\nthe fields of the corresponding types in the data connector. It has the following fields:\n\n```\n<OpenDDTypeName> :\n   fieldMapping :  <FieldMapping >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDTypeName`  |  `String`  | true | Name of the OpenDD object type which is being mapped. |\n|  `fieldMapping`  | [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#fieldmapping) | true | The field mapping between the OpenDD object type and the corresponding NDC object type. |\n\n\n## FieldMapping\u200b\n\nThe `fieldMapping` is used by[ typemapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping)to define mapping for the fields of the `OpenDDTypeName` .\n\nIt has the following fields:\n\n```\n<OpenDDFieldName> :\n   column :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDFieldName`  |  `String`  | true | Name of the field in the OpenDD object type. |\n|  `column`  |  `String`  | true | The name of the field in the NDC object type. |\n\n\n## ArgumentDefinition\u200b\n\nArguments is a list of objects that defines the arguments for the[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure)or a[ command ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure). An argument object has the following fields:\n\n```\nname :  <String > ,\ntype :  <TypeReference >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the argument. |\n|  `type`  |  `Type`  | true | [ TypeReference ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references)of the argument as a string. |\n\n\n## Secret references\u200b\n\nInstead of embedding sensitive values in the metadata, certain fields can be set using[ secrets ](https://hasura.io/docs/3.0/ci-cd/secrets/)stored in DDN.\n\nTo embed a value directly without using a secret:\n\n`value: <your value>`\n\nTo use a value via a secret:\n\n`stringValueFromSecret: <secret name>`\n\n### What did you think of this doc?\n\n- [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate)\n    - [ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#fieldcomparison)\n\n- [ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#relationshippredicate)\n\n- [ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#andexp)\n\n- [ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#orexp)\n\n- [ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#notexp)\n- [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#valueexpression)\n    - [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#literal)\n        - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#examples)\n\n- [ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#sessionvariable)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#examples-1)\n\n- [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#literal)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#examples)\n- [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping)\n- [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#fieldmapping)\n- [ ArgumentDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition)\n- [ Secret references ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret)\n", "https://hasura.io/docs/3.0/graphql-api/queries/": "# GraphQL Queries\n\nQueries are used to read data from the database. Hasura provides a powerful GraphQL API to query your data.\n\nYou can use the GraphiQL interface in the Hasura Console to explore your API and help you to write queries.\n\nDepending on the features enabled by a Native Data Connector, you will have access to a range of queries as defined\nhere.\n\n- [ Simple Queries ](https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/)\n- [ Nested Queries ](https://hasura.io/docs/3.0/graphql-api/queries/nested-queries/)\n- [ Sort Query Results ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/)\n- [ Paginate Query Results ](https://hasura.io/docs/3.0/graphql-api/queries/pagination/)\n- [ Multiple Arguments ](https://hasura.io/docs/3.0/graphql-api/queries/multiple-arguments/)\n- [ Multiple Queries ](https://hasura.io/docs/3.0/graphql-api/queries/multiple-queries/)\n- [ Variables, Aliases, Fragments, Directives ](https://hasura.io/docs/3.0/graphql-api/queries/variables-aliases-fragments-directives/)\n- [ Filtering Queries ](https://hasura.io/docs/3.0/graphql-api/queries/filters/index/)\n    - [ Comparing values ](https://hasura.io/docs/3.0/graphql-api/queries/filters/comparison-operators/)\n\n- [ Boolean expressions ](https://hasura.io/docs/3.0/graphql-api/queries/filters/boolean-operators/)\n\n- [ Text ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/)\n\n- [ Nested objects ](https://hasura.io/docs/3.0/graphql-api/queries/filters/nested-objects/)\n\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/graphql-api/multi-region-routing/": "# Multi-Region Routing with the Native Data Connector for PostgreSQL\n\nWith multi-region routing, you can easily ensure that the data is fetched from the data source closest to the user, thus\nminimizing latency for the request.\n\nFor multi-region routing, you only need a supported data source deployed in (or near) more than one of the[ supported regions ](https://hasura.io/docs/3.0/graphql-api/multi-region-routing/#supported-regions).\n\nSame schema for all databases\n\nYou must ensure that the schema for the different databases are exactly same. If there is any ambiguity between the\nschemas, then the metadata build would fail.\n\n## Configuration\u200b\n\nFor multi-region routing, you will add configuration for each of the data sources' metadata objects\n\nAn example configuration for the PostgreSQL `HasuraHubDataConnector` is provided below:\n\n```\nkind :  HasuraHubDataConnector\nversion :  v1\ndefinition :\n   name :  db\n   connectorId :  hasura/postgres\n   connectorConfiguration :\n     -   region :  gcp - europe - west1\n       mode :  ReadOnly\n       configuration :\n         version :   1\n         metadata :   &db-metadata\n           tables :\n             Album :\n               schemaName :  public\n               tableName :  Album\n               columns :\n                 AlbumId :\n                   name :  AlbumId\n                   type :  integer\n         aggregateFunctions :\n           integer :   { }\n           text :   { }\n         connectionUri :\n           uri :\n             stringValueFromSecret :  PG_EUROPE_URL\n     -   region :  gcp - us - east4\n       mode :  ReadWrite\n       configuration :\n         version :   1\n         metadata :   *db-metadata\n         aggregateFunctions :\n           integer :   { }\n           text :   { }\n         connectionUri :\n           uri :\n             stringValueFromSecret :  PG_US_URL\n```\n\nFor the above configuration, Hasura DDN will route all the write queries (mutations) to the database in the `gcp-us-east4` region and the read queries (query and subscriptions) to either `gcp-us-east4` or `gcp-europe-west1` based on the geolocation of the client.\n\n## Supported regions\u200b\n\nCurrently, Hasura DDN supports the following regions:\n\n- `gcp-asia-south1`\n- `gcp-asia-southeast1`\n- `gcp-australia-southeast1`\n- `gcp-europe-west1`\n- `gcp-southamerica-east1`\n- `gcp-us-east4`\n- `gcp-us-west2`\n\n\n### What did you think of this doc?\n\n- [ Configuration ](https://hasura.io/docs/3.0/graphql-api/multi-region-routing/#configuration)\n- [ Supported regions ](https://hasura.io/docs/3.0/graphql-api/multi-region-routing/#supported-regions)\n", "https://hasura.io/docs/3.0/graphql-api/queries/filters/index/": "# Filter Query Results / Search Queries\n\n## Introduction\u200b\n\nHasura provides a powerful yet simple syntax to filter query results. This is useful for building search queries or\nfiltering data based on some criteria. You can utilize arguments and operators to filter results based on\nequality, comparison, pattern matching, etc.\n\n## The where argument\u200b\n\nYou can use the `where` argument in your queries to filter results based on some field\u2019s values (even nested objects'\nfields). You can even use multiple filters in the same `where` clause using the `_and` or the `_or` operators.\n\nFor example, to fetch data for an author whose name is \"Sidney\":\n\n```\nquery   {\n   authors ( where :   {   name :   {   _eq :   \"Sidney\"   }   } )   {\n     id\n     name\n   }\n}\n```\n\nYou can also use nested objects' fields to filter rows from a table and also filter the nested objects as well.\n\nFor example, to fetch a list of authors who have articles with a rating greater than 4 along with those articles:\n\n```\nquery   {\n   authors ( where :   {   articles :   {   rating :   {   _gt :   4   }   }   } )   {\n     id\n     name\n     articles ( where :   {   rating :   {   _gt :   4   }   } )   {\n       id\n       title\n       rating\n     }\n   }\n}\n```\n\nHere `_eq` and `_gt` are examples of comparison operators that can be used in the `where` argument to filter on\nequality.\n\n## Supported operators\u200b\n\n| Operator | Use case |\n|---|---|\n| [ Simple Comparison Operators ](https://hasura.io/docs/3.0/graphql-api/queries/filters/comparison-operators/) | Utilize comparison operators to selectively filter results by evaluating a field against a specific value. |\n| [ Boolean Operators ](https://hasura.io/docs/3.0/graphql-api/queries/filters/boolean-operators/) | Employ boolean operators to refine result filters based on logical expressions. |\n| [ Text Search Operators ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/) | Apply text search operators to narrow down results according to the presence of text in a field. |\n| [ Nested Objects ](https://hasura.io/docs/3.0/graphql-api/queries/filters/nested-objects/) | Navigate and filter results using nested object structures for advanced filtering. |\n\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/graphql-api/queries/filters/index/#introduction)\n- [ The where argument ](https://hasura.io/docs/3.0/graphql-api/queries/filters/index/#the-where-argument)\n- [ Supported operators ](https://hasura.io/docs/3.0/graphql-api/queries/filters/index/#supported-operators)\n", "https://hasura.io/docs/3.0/graphql-api/queries/sorting/": "# Sort Query Results\n\n## The order_by argument\u200b\n\nResults from your query can be sorted by using the `order_by` argument. The argument can be used to sort nested objects\ntoo.\n\nThe sort order (ascending vs. descending) is set by specifying the `Asc` or `Desc` enum value for the column name in the `order_by` input object, e.g. `{name: Desc}` .\n\nBy default, for ascending ordering `null` values are returned at the end of the results and for descending ordering `null` values are returned at the start of the results.\n\nThe `order_by` argument takes an array of objects to allow sorting by multiple columns.\n\nYou can also use nested objects' fields to sort the results. Only columns from object relationships ** and ** aggregates\nfrom array relationships** can be used for sorting.\n\nThe following are example queries for different sorting use cases:\n\n## Sorting objects\u200b\n\n **Example:** Fetch a list of authors sorted by their names in ascending order:\n\n## Sorting nested objects\u200b\n\n **Example:** Fetch a list of authors sorted by their names with a list of their articles that is sorted by their rating:\n\n## Sorting based on nested object's fields\u200b\n\nOnly **columns from object relationships** and **aggregates from array relationships** can be used for sorting.\n\n### For object relationships\u200b\n\nFor object relationships only columns can be used for sorting.\n\n **Example:** Fetch a list of articles that are sorted by their author's ids in descending order:\n\n### For array relationships\u200b\n\nFor array relationships only aggregates can be used for sorting.\n\n **Example:** Fetch a list of authors sorted in descending order of their article count:\n\n **Example:** Fetch a list of authors sorted in increasing order of their highest article rating:\n\n### For scalar computed fields\u200b\n\nScalar computed fields can be used for sorting just like columns.\n\n **Example:** Computed field `total_marks` is defined on `student` table which calculates the sum of marks obtained in*each subject. Fetch a list of students sorted by their total marks:\n\n### For table computed fields\u200b\n\nAggregates of table being returned by table computed fields can be used for sorting.\n\n **Example:** Computed field `get_articles` is defined to `author` table returns list of articles. Fetch a list of*authors sorted by their articles count.\n\nNote\n\nOnly computed fields whose associated SQL function with no input arguments other than table row and hasura session\narguments are supported in order by.\n\n## Sorting by multiple fields\u200b\n\n **Example:** Fetch a list of articles that is sorted by their rating (descending) and then on their published date\n(ascending):\n\nNote\n\nKey order in input object for order_by is not preserved. This means you should only have a single key per object, or you\nmay see unexpected behavior.\n\n### What did you think of this doc?\n\n- [ The order_by argument ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#the-order_by-argument)\n- [ Sorting objects ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#sorting-objects)\n- [ Sorting nested objects ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#pg-nested-sort)\n- [ Sorting based on nested object's fields ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#sorting-based-on-nested-objects-fields)\n    - [ For object relationships ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#for-object-relationships)\n\n- [ For array relationships ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#for-array-relationships)\n\n- [ For scalar computed fields ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#for-scalar-computed-fields)\n\n- [ For table computed fields ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#for-table-computed-fields)\n- [ Sorting by multiple fields ](https://hasura.io/docs/3.0/graphql-api/queries/sorting/#sorting-by-multiple-fields)\n", "https://hasura.io/docs/3.0/graphql-api/queries/nested-queries/": "# Nested Object Queries\n\n## Introduction\u200b\n\nYou can use the object (one-to-one) or array (one-to-many) relationships defined in your metadata to make a nested\nqueries, i.e. fetch data for one type along with data from a nested or related type.\n\n## Fetch nested object using an object relationship\u200b\n\nThe following is an example of a nested object query using the **object relationship** between an article and an author.\n\n **Example:** Fetch a list of articles and the name of each article\u2019s author:\n\n## Fetch nested objects using an array relationship\u200b\n\nThe following is an example of a nested object query using the **array relationship** between an author and articles.\n\n **Example:** Fetch a list of authors and a related, nested list of each author\u2019s articles:\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/graphql-api/queries/nested-queries/#introduction)\n- [ Fetch nested object using an object relationship ](https://hasura.io/docs/3.0/graphql-api/queries/nested-queries/#fetch-nested-object-using-an-object-relationship)\n- [ Fetch nested objects using an array relationship ](https://hasura.io/docs/3.0/graphql-api/queries/nested-queries/#fetch-nested-objects-using-an-array-relationship)\n", "https://hasura.io/docs/3.0/ci-cd/config/": "# Configuration\n\n## Introduction\u200b\n\nHasura v3 introduces a new configuration model for projects on the Hasura Data Delivery Network (DDN). This model relies\non three types of files:\n\n| File type | Description |\n|---|---|\n|  `hasura. yaml`  | The main configuration file. |\n|  `build-profile-*. yaml`  | Build profiles for a project. |\n|  `*. hml`  | Hasura metadata files for a project. |\n\n\n### hasura.yaml\u200b\n\nThis is the entry point to a Hasura project.\n\n```\nversion :   1\nproject :  <PROJECT_NAME >\nbuildProfiles :\n   -  build - profile.yaml\ndefaultBuildProfile :  build - profile.yaml\n```\n\nThe `version` section is used to specify the version of the configuration file. The `project` field is used to specify\nthe project name.\n\nThe `hasura.yaml` file also contains a `buildProfiles` section. This section is used to specify the build profile files\nassociated with the project. As you can see from this example, we only have one build profile, `build-profile.yaml` which is also identified as the default to use when creating a new build. **The  default  profile is required for a\nproject.** \n\n`default`\n\n### Build profiles\u200b\n\nBuild profiles tell Hasura DDN how to construct your supergraph. A build profile will contain information about the\nshared resources \u2014 such as your authentication configuration \u2014 and the resources belonging to the individual subgraphs\nthat make up your supergraph.\n\nBy default, the included `build-profile.yaml` file is populated with the following content:\n\n```\nversion :   2\nspec :\n   environment :  default\n   mode :  replace\n   supergraph :\n     resources :\n       -  supergraph/*\n   subgraphs :\n     -   name :  default\n       resources :\n         -   \"subgraphs/default/**/*.hml\"\n```\n\nHere, you can see that the `build-profile.yaml` file contains `version` and `spec` sections. The `version` section is\nused to specify the version of the configuration file.\n\nThe `spec` section contains the following fields:\n\n| Field | Description |\n|---|---|\n|  `environment`  | The environment to use for the build. |\n|  `mode`  | The mode to use for the build. `Replace` by default. |\n|  `supergraph`  | The supergraph resources to use for the build. |\n|  `subgraph`  | List of subgraphs and their resources to use for the build |\n\n\nYou can create additional build profile files for different environments you may need e.g., `staging` , `production` ,\netc. By combining build profiles which specify environments with version control, you can easily set up an effective\nCI/CD pipeline for your project.\n\nEach build profile file must be referenced by the `hasura.yaml` file in order to be used.\n\n### Supergraph\u200b\n\nYour `supergraph` directory will contain two configuration files by default: the `auth-config.hml` and `compatibility-config.hml` files.\n\nThe `auth-config.hml` file defines the authentication configuration for your supergraph i.e., the configuration for how\nthe queries to your Hasura DDN project should be authenticated. The `compatibility-config.hml` file defines the\ncompatibility date of your supergraph metadata. You'd likely not want to change the compatibility config unless you're\nsure about it.\n\n#### AuthConfig\u200b\n\n```\nkind :  AuthConfig\nversion :  v1\ndefinition :\n   allowRoleEmulationBy :  admin\n   mode :\n     webhook :\n       method :  Post\n       url :  https : //auth.pro.hasura.io/webhook/ddn ? role=admin\n```\n\nThe `AuthConfig` object is used to configure authentication for your data supergraph. You can learn more about\nauthentication in the[ Auth section ](https://hasura.io/docs/3.0/auth/overview/).\n\n#### CompatibilityConfig\u200b\n\n```\nkind :  CompatibilityConfig\ndate :   2023-10-19\n```\n\nThe `CompatibilityConfig` object is used to configure the compatibility of your metadata with Hasura.\n\n##### Compatibility Date\u200b\n\nThe `CompatibilityConfig` object contains a `date` field which opts your metadata out of all backwards incompatible\nchanges made after that date. Any backwards incompatible changes made to Hasura DDN after that date won't impact your\nmetadata.\n\nWhen starting a new project, this date should be set to today's date so that the most up-to-date behavior of Hasura is\nused.\n\nOlder projects should also periodically update the compatibility date after going over the behavioral changes that have\nhappened since that older date.\n\n### Subgraphs\u200b\n\nInside the `subgraphs` directory, each subgraph is identified by a directory with the name of the subgraph. Within that,\nwe have included three directories to get you started:\n\n```\n\u2514\u2500\u2500  < SUBGRAPH_NAME >\n\u2502       \u251c\u2500\u2500 commands\n\u2502       \u251c\u2500\u2500 dataconnectors\n\u2502       \u2514\u2500\u2500 models\n```\n\nA project is divided into one or more separate subgraphs which are referenced by a build profile.\n\nThe `default` subgraph is required and cannot be deleted.\n\nSubgraphs can be used to group together objects in your metadata in a way that makes sense for you and your team.\nMultiple `hml` files can belong to a subgraph, and you can have multiple subgraphs in a project. Objects in each hml\nfile must conform to the[ OpenDD Spec ](https://hasura.io/docs/3.0/data-domain-modeling/overview/)and[ subgraph rules ](https://hasura.io/docs/3.0/ci-cd/subgraphs/).\n\nThe CLI populates the `default` subgraph with `command` , `dataconnectors` , and `model` directories, but the organization\nof these is completely customizable by you and your team.\n\nWhat is HML?\n\nThese are both `hml` files, which is a new file format for Hasura metadata. It is a superset of the existing `yaml` format, and is designed to provide a more flexible and extensible way to define metadata. You can leverage the power of\nthe[ Hasura VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)to quickly and\neasily author `hml` files.\n\nYour `hml` files contain metadata objects according to the OpenDD spec. In the example above, we could add a `HasuraHubDataConnector` object to connect to a data source. Then, import our tables as models and create a build on\nHasura DDN.\n\nHowever, in the next section, we'll look at how to use subgraphs to organize metadata and break up our `hml` file into\nsmaller, more governable pieces.\n\n## Basic configuration\u200b\n\nWhen using the[ hasura3 CLI ](https://hasura.io/docs/3.0/cli/overview/)to create a new project, you'll run the following command:\n\n`hasura3 init --dir  .`\n\nThis will generate a new project directory in the current folder with the following structure:\n\n```\n< PROJECT_DIRECTORY >\n\u251c\u2500\u2500 build-profile.yaml\n\u251c\u2500\u2500 hasura.yaml\n\u251c\u2500\u2500 subgraphs\n\u2502   \u2514\u2500\u2500 default\n\u2502       \u251c\u2500\u2500 commands\n\u2502       \u251c\u2500\u2500 dataconnectors\n\u2502       \u2514\u2500\u2500 models\n\u2514\u2500\u2500 supergraph\n    \u251c\u2500\u2500 auth-config.hml\n    \u2514\u2500\u2500 compatibility-config.hml\n```\n\n.gitkeep\n\nYou will find empty .gitkeep files in some directories which are used to preserve empty directories in Git.\n\n## Advanced configuration\u200b\n\nLet's consider a data supergraph wherein you'd like to test your API across multiple[ environments ](https://hasura.io/docs/3.0/ci-cd/environments/). We can use subgraphs to organize our metadata and break up our `hml` file into\nsmaller, more governable pieces. We can also utilize build profiles to create different builds for different\nenvironments.\n\nImagine this file structure:\n\n```\n< PROJECT_NAME >\n\u251c\u2500\u2500 build-profile.yaml\n\u251c\u2500\u2500 build-profile-staging.yaml\n\u251c\u2500\u2500 hasura.yaml\n\u251c\u2500\u2500 subgraphs\n\u2502   \u2514\u2500\u2500 app\n\u2502       \u251c\u2500\u2500 commands\n\u2502       \u251c\u2500\u2500 dataconnectors\n\u2502           \u2514\u2500\u2500 app.hml\n\u2502       \u2514\u2500\u2500 models\n\u2502           \u251c\u2500\u2500 cart_items.hml\n\u2502           \u251c\u2500\u2500 carts.hml\n\u2502           \u251c\u2500\u2500 categories.hml\n\u2502           \u251c\u2500\u2500 coupons.hml\n\u2502           \u251c\u2500\u2500 manufactuers.hml\n\u2502           \u251c\u2500\u2500 notifications.hml\n\u2502           \u251c\u2500\u2500 orders.hml\n\u2502           \u251c\u2500\u2500 products.hml\n\u2502           \u251c\u2500\u2500 reviews.hml\n\u2502           \u2514\u2500\u2500 users.hml\n\u2514\u2500\u2500 supergraph\n    \u251c\u2500\u2500 auth-config.hml\n    \u2514\u2500\u2500 compatibility-config.hml\n```\n\n### Build profiles\u200b\n\nIn this example, we have two build profiles: `build-profile.yaml` and `build-profile-staging.yaml` . The `build-profile.yaml` file contains the following content:\n\n```\nversion :   2\nspec :\n   environment :  default\n   mode :  replace\n   supergraph :\n     resources :\n       -  supergraph/*\n   subgraphs :\n     -   name :  app\n       resources :\n         -   \"subgraphs/**/*.hml\"\n```\n\nWhereas the `build-profile-staging.yaml` file contains the following content:\n\n```\nversion :   2\nspec :\n   environment :  staging\n   mode :  replace\n   supergraph :\n     resources :\n       -  supergraph/*\n   subgraphs :\n     -   name :  app\n       resources :\n         -   \"subgraphs/**/*.hml\"\n```\n\nThe two build profiles, `build-profile.yaml` and `build-profile-staging.yaml` , are designed to cater to different\nenvironments. The `build-profile.yaml` is configured for the default environment and is set to include all subgraphs in\nthe subgraphs directory. This configuration is suitable for a general development team working on various parts of the\nproject.\n\nAs this is the default build profile, it will be used when you run the following command:\n\n`hasura3 build create`\n\nOn the other hand, `build-profile-staging.yaml` is specifically configured for the staging environment and is intended\nfor testing with other staging services.\n\nYou can create a build with this profile by running the following command:\n\n`hasura3 build create --profile build-profile-staging.yaml`\n\n### hasura.yaml\u200b\n\nThe `hasura.yaml` in the root of the project contains the following content:\n\n```\nversion :   1\nproject :  <PROJECT_NAME >\nbuildProfiles :\n   -  ./build - profile.yaml\n   -  ./build - profile - staging.yaml\ndefaultBuildProfile :  build - profile.yaml\n```\n\nThis lets Hasura DDN know that we have two build profiles, and that the `build-profile.yaml` is the default to use when\ncreating a new build.\n\n### Custom Directory Structure\u200b\n\nYou could choose to deviate from the default directory structure that the Hasura project initializes for you into one\nthat suits you and your team's needs.\n\nFor example, you could have a single file with all the metadata objects, including your `HasuraHubDataConnector` objects, models, and commands, as long as you specify that file to be in your subgraph resources in the build profile.\nHowever, this would be difficult to manage and maintain.\n\nYou could also choose to arrange your subgraphs by data type. E.g., `subgraphs/default/users` , `subgraphs/defaultproducts` , etc.\n\nThe contents of the `hml` files can be that of any valid OpenDD metadata object as long as they conform to the rules of[ subgraphs ](https://hasura.io/docs/3.0/ci-cd/subgraphs/).\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/config/#introduction)\n    - [ hasura.yaml ](https://hasura.io/docs/3.0/ci-cd/config/#hasurayaml)\n\n- [ Build profiles ](https://hasura.io/docs/3.0/ci-cd/config/#build-profiles)\n\n- [ Supergraph ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph)\n\n- [ Subgraphs ](https://hasura.io/docs/3.0/ci-cd/config/#subgraphs)\n- [ Basic configuration ](https://hasura.io/docs/3.0/ci-cd/config/#basic-configuration)\n- [ Advanced configuration ](https://hasura.io/docs/3.0/ci-cd/config/#advanced-configuration)\n    - [ Build profiles ](https://hasura.io/docs/3.0/ci-cd/config/#build-profiles-1)\n\n- [ hasura.yaml ](https://hasura.io/docs/3.0/ci-cd/config/#hasurayaml-1)\n\n- [ Custom Directory Structure ](https://hasura.io/docs/3.0/ci-cd/config/#custom-directory-structure)\n", "https://hasura.io/docs/3.0/ci-cd/projects/": "# Projects\n\n## Introduction\u200b\n\nBroadly, a project is the configuration of your data supergraph.\n\nA project specifies build profiles, each of which specify supergraph and subgraph configurations that are used create[ builds ](https://hasura.io/docs/3.0/ci-cd/builds/)which are snapshots of the project config and are used to serve your API.\n\n## Initialize a Project\u200b\n\nWe can create a new project and link it to its twin on Hasura DDN by using the Hasura CLI to create a new project.\n\n### Login to Hasura DDN\u200b\n\nIn order to link local and Hasura DDN projects, you'll need to authenticate your CLI. This can be done two ways:\n\n- Via the browser (recommended)\n- Using a Personal Access Token (PAT)\n\n\n#### Browser\u200b\n\n`hasura3 login`\n\nThis will launch a browser window and prompt you to login to your Hasura DDN account. Once you've logged in, you can\nclose the browser window and return to your terminal.\n\n#### PAT\u200b\n\nAlternatively, you can use a PAT to authenticate with the CLI.\n\nYou can create a PAT by navigating to the[ Access Tokens page ](https://cloud.hasura.io/account-settings/access-tokens)in your account settings. Where you can create a new token and copy the value.\n\nBack in the Hasura CLI, run:\n\n`hasura3 login --pat  < PAT >`\n\nYou should see a confirmation that you're now successfully logged in, and can now create a new project and\nsimultaneously link it to its twin on Hasura DDN.\n\n### Create a new project\u200b\n\n`hasura3 init --dir  .`\n\nYou will be presented with the following options:\n\n```\nCreate a new project\nEmpty project\n```\n\nChoose `Create a new project` .\n\n### Configure a project\u200b\n\nThe previous command will create a project on Hasura DDN and local files in a directory structure which will be used to\nmanage your project.\n\nFor more information on the project configuration files, see the[ configuration section ](https://hasura.io/docs/3.0/ci-cd/config/).\n\nRunning CLI commands without specifying a project name each time\n\nBy logging into Hasura DDN via the CLI and specifying the project name in the hasura.yaml file, the CLI will know which\nproject to use when running commands in the directory.\n\n#### VS Code Extension\u200b\n\nThe[ Hasura VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura&ssr=false#review-details)is there to help you author and edit `hml` files in your subgraphs. It provides syntax highlighting, validation, and\nautocompletion.\n\nTo use the extension, ensure you've[ installed it ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)and then run the `login` command using the command palette. You can access this by pressing `Ctrl+Shift+P` on Windows\nand `Cmd+Shift+P` on Mac.\n\n#### Create builds\u200b\n\nIn order to see configurations in your metadata take effect you need to create a build. Head over to the[ Builds ](https://hasura.io/docs/3.0/ci-cd/builds/)section to learn about how to create and manage builds.\n\nAlternatively, during development, you can use[ watch mode ](https://hasura.io/docs/3.0/cli/commands/watch/)to automatically create builds when\nchanges are detected in your project.\n\n#### Describe a project\u200b\n\nYou can get the relevant information of your project by using the CLI and running:\n\n`hasura3 project describe`\n\nYou will see an output similar to the following:\n\n```\n+-------------+--------------------------------------------------------------+\n| Name        | master-shrimp-9462                                           |\n+-------------+--------------------------------------------------------------+\n| ID          | fa2f39db-247d-4820-83c4-96cec5e6bd38                         |\n+-------------+--------------------------------------------------------------+\n| Console URL | https://console.hasura.io/project/master-shrimp-9462/graphql |\n+-------------+--------------------------------------------------------------+\n| Build Count | 1                                                            |\n+-------------+--------------------------------------------------------------+\n| Domain      | master-shrimp-9462.ddn.hasura.app                            |\n+-------------+--------------------------------------------------------------+\n```\n\n#### List all projects\u200b\n\nYou can list all the projects you have access to by running:\n\n`hasura3 project list`\n\nYou will see an output similar to the following:\n\n```\n+-------------+-----------------------+--------------------------------------+-----------------------------------------------------------------+\n| CREATED AT  |         NAME          |                  ID                  |                           CONSOLE URL                           |\n+-------------+-----------------------+--------------------------------------+-----------------------------------------------------------------+\n| 27 Nov 2023 | master-shrimp-9462    | fa2f39db-247d-4820-83c4-96cec5e6bd38 | https://console.hasura.io/project/master-shrimp-9462/graphql    |\n+-------------+-----------------------+--------------------------------------+-----------------------------------------------------------------+\n```\n\n### Delete a project\u200b\n\nYou can delete a project using the CLI by running:\n\n`hasura3 project delete`\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/projects/#introduction)\n- [ Initialize a Project ](https://hasura.io/docs/3.0/ci-cd/projects/#initialize-a-project)\n    - [ Login to Hasura DDN ](https://hasura.io/docs/3.0/ci-cd/projects/#login-to-hasura-ddn)\n\n- [ Create a new project ](https://hasura.io/docs/3.0/ci-cd/projects/#create-a-new-project)\n\n- [ Configure a project ](https://hasura.io/docs/3.0/ci-cd/projects/#configure-a-project)\n\n- [ Delete a project ](https://hasura.io/docs/3.0/ci-cd/projects/#delete-a-project)\n", "https://hasura.io/docs/3.0/ci-cd/environments/": "# Environments\n\n## Introduction\u200b\n\nEnvironments allow you to organize your[ project ](https://hasura.io/docs/3.0/ci-cd/projects/)metadata by creating different environments for\ndifferent stages of your development lifecycle. You can create environments for `development` , `staging` , and `production` and then use them to create different builds for each environment.\n\nOnce you've created an environment you can then use it to create different builds by configuring a build profile file\nfor it. You'll then be able to access this environment's applied build via a different API endpoint.\n\n## Environment lifecycle\u200b\n\n### Create\u200b\n\nYou can create a new environment on Hasura DDN using the CLI by running:\n\n`hasura3 environment create --name  < ENVIRONMENT_NAME >`\n\nThe CLI will return a response specifying the fully-qualified domain name of the environment, such as:\n\n```\n+------+--------------------------------------------+\n| Name | testing                                    |\n+------+--------------------------------------------+\n| Fqdn | secure-catfish-9299-testing.ddn.hasura.app |\n+------+--------------------------------------------+\n```\n\nIn the Console, you'll now see the environment listed as an option in the project and you can select it to view the\nbuilds for that environment.\n\n### Manage\u200b\n\nOnce you've created an environment, you can then use it to create different builds by configuring a build profile file\nto reference the environment name under the `environments` key:\n\n```\n# build-profile-staging.yaml\nversion :   2\nspec :\n   environment :  staging\n   mode :  replace\n   supergraph :\n     resources :\n       -  supergraph - staging/*\n   subgraphs :\n     -   name :  default\n       resources :\n         -   \"subgraphs/staging/**/*.hml\"\n```\n\nIn the example above, the `staging` environment, which would have been created in the previous step, is used for the\nbuild.\n\nWe can title this file `build-profile-staging.yaml` and then reference it in the `hasura.yaml` file as an item in the\narray of `buildProfiles` :\n\n```\nversion :   1\nproject :  secure - catfish - 9299\nbuildProfiles :\n   -  build - profile.yaml\n   -  build - profile - staging.yaml\ndefaultBuildProfile :  build - profile.yaml\n```\n\n### Delete\u200b\n\nYou can delete an environment using the CLI by running:\n\n`hasura3 environment delete --name  < ENVIRONMENT_NAME >`\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/environments/#introduction)\n- [ Environment lifecycle ](https://hasura.io/docs/3.0/ci-cd/environments/#environment-lifecycle)\n    - [ Create ](https://hasura.io/docs/3.0/ci-cd/environments/#create)\n\n- [ Manage ](https://hasura.io/docs/3.0/ci-cd/environments/#manage)\n\n- [ Delete ](https://hasura.io/docs/3.0/ci-cd/environments/#delete)\n", "https://hasura.io/docs/3.0/ci-cd/subgraphs/": "# Subgraphs\n\n## Introduction\u200b\n\nFor a multi-team organization working on a Hasura project, it can make sense for any one team to not have access to all\nmetadata objects. Subgraphs introduces the notion of a module system for your Hasura metadata.\n\nA project can have a collection of subgraphs and the project becomes the 'union' of metadata objects across all\nsubgraphs of the project. Each subgraph can then be accessed and updated independently.\n\nA build profile file with subgraphs looks something like the following:\n\n```\nversion :   2\nspec :\n   environment :  staging\n   mode :  replace\n   supergraph :\n     resources :\n       -  supergraph/*\n   subgraphs :\n     -   name :  default\n       resources :\n         -  subgraphs/default/ **/*.hml\n     -   name :  billing\n       resources :\n         -  subgraphs/fulfillment/ **/*.hml\n     -   name :  stripe\n       resources :\n         -  subgraphs/stripe/ **/*.hml\n```\n\n## Subgraph Lifecycle\u200b\n\n### Create\u200b\n\nYou can create a subgraph for a project on Hasura DDN using the CLI:\n\n`hasura3 subgraph create -n  < SUBGRAPH_NAME >`\n\nWithin the `subgraphs` directory of your local project, create a directory with the name of the subgraph. For example,\nif you created a subgraph named `billing` , then create a directory named `billing` within the `subgraphs` directory. You\ncan use the `default` subgraph as a template for your subgraph.\n\n### Manage\u200b\n\nYou can easily list all the available subgraphs for a project using the CLI:\n\n`hasura3 subgraph list`\n\nYou can connect new data sources, add new types, etc. to a subgraph. Any files you add to the subgraph directory will be\npicked up by the metadata build and associated with the subgraph.\n\n### Delete\u200b\n\nDelete a subgraph by running:\n\n`hasura3 subgraph delete -n  < SUBGRAPH_NAME >`\n\n## Ownership Rules\u200b\n\nThe metadata objects in subgraphs must follow the ownership rules for metadata objects as outlined below.\n\n### DataConnector/ HasuraHubDataConnector\u200b\n\nThe data source metadata object ( `DataConnector` / `HasuraHubDataConnector` ) doesn't depend on (or reference) any other\nmetadata object. Hence, any subgraph can define a data source.\n\nSubgraph ownership\n\nThe subgraph that defines a data source then owns it. This means that no other subgraph can reference this data source\nin their type representations, model, etc.\n\nViolating this rule will result in the metadata build failing with the error, `unable to build schema: subgraph is not consistent: the following data source is defined more than once: <data source name>` .\n\n### ObjectType\u200b\n\nThe `ObjectType` metadata object also doesn't reference any other metadata object. Thus, any subgraph can define an `ObjectType` .\n\n### DataConnectorScalarRepresentation\u200b\n\nThe `DataConnectorScalarRepresentation` metadata object references the data connector metadata object and the scalar\ntype object. Thus, the data source in a `DataConnectorScalarRepresentation` should be owned by the **same** subgraph.\n\n### ScalarType\u200b\n\nThe `ScalarType` metadata object also doesn't reference any other metadata object. Thus, **any** subgraph can define a `ScalarType` .\n\n### Model\u200b\n\nA `Model` metadata object references a data type. Also, the model's `source` references a data source and some data\ntypes in type mappings. **Thus, the same subgraph should own the types and the data source.** \n\n### Command\u200b\n\nA `Command` metadata object references an output data type. Thus, the subgraph defining the `Command` metadata object\nshould also define the output data type.\n\n### Relationship\u200b\n\nThe `Relationship` metadata object references a source type and a target model. The source type used in the `Relationship` should be owned by the subgraph defining the `Relationship` .\n\nTarget model ownership\n\nThe target model can be from any subgraph. This allows us to define relationships across subgraphs. To use a model from\nanother subgraph as the target, you will need to reference the subgraph in the target model definition. Please refer to\nthe[ TargetModel ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel)for syntax.\n\n### TypePermissions\u200b\n\nThe `TypePermissions` metadata object references a type (for which the permission is being defined). Thus, the subgraph\ndefining the `TypePermissions` should own the type referenced.\n\n### ModelPermissions\u200b\n\nSimilar to `TypePermissions` , the subgraph should also own the model referenced in the `ModelPermissions` metadata\nobject.\n\n### CommandPermissions\u200b\n\nThe `CommandPermissions` metadata object references a command, which should be defined in the same subgraph.\n\n### AuthConfig\u200b\n\nThis is defined in the supergraph.\n\nOnly one auth config allowed per project\n\nThere can be only one `AuthConfig` in the project's metadata. If there is more than one `AuthConfig` , then the metadata\nbuild will fail with the error `Found duplicate authentication config` .\n\n## Other Rules\u200b\n\nApart from ownership rules, metadata with subgraphs should also follow the following rules:\n\n### Duplicate Subgraphs\u200b\n\nMetadata should not define two subgraphs with same name.\n\n### Duplicate Metadata Objects\u200b\n\nMetadata should also not define the same subgraph object twice (either in the same subgraph or in different subgraphs).\nIf you violate this rule, then the metadata build will fail with the error `subgraph constraints violated - found multiple subgraphs with the same name` .\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#introduction)\n- [ Subgraph Lifecycle ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#subgraph-lifecycle)\n    - [ Create ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#create)\n\n- [ Manage ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#manage)\n\n- [ Delete ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#delete)\n- [ Ownership Rules ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#ownership-rules)\n    - [ DataConnector/ HasuraHubDataConnector ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#dataconnector-hasurahubdataconnector)\n\n- [ ObjectType ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#objecttype)\n\n- [ DataConnectorScalarRepresentation ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#dataconnectorscalarrepresentation)\n\n- [ ScalarType ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#scalartype)\n\n- [ Model ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#model)\n\n- [ Command ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#command)\n\n- [ Relationship ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#relationship)\n\n- [ TypePermissions ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#typepermissions)\n\n- [ ModelPermissions ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#modelpermissions)\n\n- [ CommandPermissions ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#commandpermissions)\n\n- [ AuthConfig ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#authconfig)\n- [ Other Rules ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#other-rules)\n    - [ Duplicate Subgraphs ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#duplicate-subgraphs)\n\n- [ Duplicate Metadata Objects ](https://hasura.io/docs/3.0/ci-cd/subgraphs/#duplicate-metadata-objects)\n", "https://hasura.io/docs/3.0/ci-cd/builds/": "# Builds\n\n## Introduction\u200b\n\nA build is a fully-functional, immutable supergraph which is built based on your project configuration.\n\nBuilds are created for a specific[ environment ](https://hasura.io/docs/3.0/ci-cd/environments/)and can be used to incrementally test your\nproject's API.\n\nWhile there can be many builds for an environment, only one can be **applied** at a time to an environment. The applied\nbuild is the one that is currently serving your API from your project's endpoint.\n\n## Build lifecycle\u200b\n\n### Create\u200b\n\nTo create a build, you'll first need a[ project ](https://hasura.io/docs/3.0/ci-cd/projects/). After which, you can create a build using the\nfollowing command:\n\n`hasura3 build create`\n\nThe CLI will return information about your build:\n\n```\n+---------------+---------------------------------------------------------------+\n| Build ID      | baa7f15d-5364-4cfd-b94c-8d2a8a51e6e2                          |\n+---------------+---------------------------------------------------------------+\n| Build Version | b6370d7d56                                                    |\n+---------------+---------------------------------------------------------------+\n| Build URL     | https://secure-catfish-9299-b6370d7d56.ddn.hasura.app/graphql |\n+---------------+---------------------------------------------------------------+\n| Project Id    | fc2d7717-e1f8-4213-9132-6a70f78b6026                          |\n+---------------+---------------------------------------------------------------+\n| Console Url   | https://console.hasura.io/project/secure-catfish-9299/graphql |\n+---------------+---------------------------------------------------------------+\n| FQDN          | secure-catfish-9299-b6370d7d56.ddn.hasura.app                 |\n+---------------+---------------------------------------------------------------+\n| Environment   | default                                                       |\n+---------------+---------------------------------------------------------------+\n| Description   |                                                               |\n+---------------+---------------------------------------------------------------+\n```\n\nBy default, the build will be created using the build profile you've identified as the default for your project in your `hasura.yaml` file. You can override this by specifying a different profile using the `--profile` flag:\n\n`hasura3 build create --profile  < BUILD_PROFILE_FILE >`\n\nAt this point, you can interact with and test your API using the GraphQL API Endpoint and Console URL returned by the\nCLI.\n\n### Apply\u200b\n\nWhen you are happy with your build, you can apply it to a project's environment using the following command:\n\n`hasura3 build apply --version  < BUILD_VERSION >`\n\nThe CLI will return the API endpoint for your supergraph:\n\n```\n+---------+----------------------------------------------------+\n| API URL | https://secure-catfish-9299.ddn.hasura.app/graphql |\n+---------+----------------------------------------------------+\n```\n\n### Delete\u200b\n\nBuilds can be individually deleted using the following command:\n\n`hasura3 build delete --version  < BUILD_VERSION >`\n\nAll builds for a project are deleted when a[ project is deleted ](https://hasura.io/docs/3.0/ci-cd/projects/#delete).\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/builds/#introduction)\n- [ Build lifecycle ](https://hasura.io/docs/3.0/ci-cd/builds/#build-lifecycle)\n    - [ Create ](https://hasura.io/docs/3.0/ci-cd/builds/#create)\n\n- [ Apply ](https://hasura.io/docs/3.0/ci-cd/builds/#apply)\n\n- [ Delete ](https://hasura.io/docs/3.0/ci-cd/builds/#delete)\n", "https://hasura.io/docs/3.0/ci-cd/secrets/": "# Secrets\n\n## Introduction\u200b\n\nSecrets are a means of storing sensitive information as key-value pairs that you don't want exposed in your `metadata.hml` file. This could be anything from a database password to an API key.\n\nSecrets are stored in Hasura DDN and can be accessed by a single[ project ](https://hasura.io/docs/3.0/ci-cd/projects/).\n\n## Secrets lifecycle\u200b\n\n### Set\u200b\n\nTo create \u2014 or **set** \u2014 a secret, you'll first need a[ project ](https://hasura.io/docs/3.0/ci-cd/projects/)on Hasura DDN. Then, create\nthe secret using the CLI:\n\n`hasura3 secret  set  --project  < PROJECT_NAME >  --environment  < ENVIRONMENT_NAME >  --subgraph  < SUBGRAPH_NAME >   --key  < KEY >  --value  < VALUE >  --description  \"<DESCRIPTION>\"`\n\n### Use\u200b\n\nYou can then use the key in your `hml` file:\n\n```\nconnectionUri :\n   uri :\n     stringValueFromSecret :  <KEY >\n```\n\n### Delete\u200b\n\nYou can delete a secret using the following command:\n\n`hasura3 secret delete --project  < PROJECT_NAME >  --environment  < ENVIRONMENT_NAME >  --subgraph  < SUBGRAPH_NAME >   --key  < KEY >`\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/secrets/#introduction)\n- [ Secrets lifecycle ](https://hasura.io/docs/3.0/ci-cd/secrets/#secrets-lifecycle)\n    - [ Set ](https://hasura.io/docs/3.0/ci-cd/secrets/#set)\n\n- [ Use ](https://hasura.io/docs/3.0/ci-cd/secrets/#use)\n\n- [ Delete ](https://hasura.io/docs/3.0/ci-cd/secrets/#delete)\n", "https://hasura.io/docs/3.0/ci-cd/tunnels/": "# Secure Connect Tunnels\n\n## Introduction\u200b\n\nSecure Connect Tunnels allow you to securely connect a local database to your Hasura-hosted DDN project. This allows you\nto interact with a local database via your Hasura project and use the Hasura Console and other Hasura services.\n\nTypically, tunnels are used for local development to iterate quickly on your project. We recommend using a service such\nas Docker to manage your local database and other local resources.\n\nAdditionally, you can use tunnels to test local data connectors, such as the[ TypeScript connector ](https://github.com/hasura/ndc-typescript-deno), before[ deploying ](https://hasura.io/docs/3.0/connectors/deployment/)them to Hasura DDN.\n\nUsing Docker\n\nIf you're not familiar with running a database via Docker, we recommend checking out the[ PostgreSQL docker getting started ](https://hub.docker.com/_/postgres)as an example.\n\n## Tunnel lifecycle\u200b\n\n### Create\u200b\n\nThe Hasura CLI creates and manages tunnels. The CLI utilizes a[ daemon ](https://en.wikipedia.org/wiki/Daemon_computing)that runs in the background and manages the tunnel. To create a tunnel, first start the daemon using the `daemon` command:\n\n`hasura3 daemon start`\n\nThe daemon will block the window / tab while it runs. Once the daemon is running, you can create a tunnel using the `tunnel create` command in a new window / tab:\n\n```\n# e.g., hasura3 tunnel create localhost:5432\nhasura3 tunnel create  < SOCKET >\n```\n\nWhat's a socket?\n\nThis argument is the socket address that the daemon will use to communicate with the tunnel.\n\nIt must include the IP address or hostname of the machine running the daemon, and a port number. For example, `localhost:5432` or `localhost:3306` .\n\nThis socket becomes the identifier for the tunnel. You can use the `tunnel list` command to see a list of all tunnels\nthat are currently running.\n\n### Use\u200b\n\nAfter creating a tunnel, the CLI will return a URL that you can use to connect to your database. **You should use this\nURL to form a connection string for your database, like this example using PostgreSQL:** \n\n`postgresql://<USERNAME>:<PASSWORD>@<URL_RETURNED_BY_THE_CLI>/<DATABASE_NAME>`\n\nThis connection string can now be used in your metadata to scaffold our your API and service requests in the Hasura\nConsole or from your projects endpoints.\n\nTesting a data connector?\n\nSimply pass the connection string using your local host and the port that the connector is running on. For example:\n\n`http://localhost:8100`\n\n#### Pause\u200b\n\nTo pause a tunnel, use the `tunnel pause` command:\n\n`hasura3 tunnel pause  < SOCKET >`\n\n#### Activate\u200b\n\nTo activate a tunnel, use the `tunnel activate` command:\n\n`hasura3 tunnel activate  < SOCKET >`\n\n### Delete\u200b\n\nTo delete a tunnel, use the `tunnel delete` command:\n\n`hasura3 tunnel delete  < SOCKET >`\n\nTo stop the daemon at any point, simply kill the process in your terminal using `Ctrl + C` .\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/tunnels/#introduction)\n- [ Tunnel lifecycle ](https://hasura.io/docs/3.0/ci-cd/tunnels/#tunnel-lifecycle)\n    - [ Create ](https://hasura.io/docs/3.0/ci-cd/tunnels/#create)\n\n- [ Use ](https://hasura.io/docs/3.0/ci-cd/tunnels/#use)\n\n- [ Delete ](https://hasura.io/docs/3.0/ci-cd/tunnels/#delete)\n", "https://hasura.io/docs/3.0/ci-cd/collaborators/": "# Collaborators\n\n## Introduction\u200b\n\nAny Hasura DDN user can create a project and share it with other users. This allows you to collaborate with other users\nby giving them access to your project's metadata and builds. A collaborator can also access the project in the Console\nto view metrics, test the API, and more.\n\n## Collaborator lifecycle\u200b\n\n### Create\u200b\n\nA collaborator can be invited from the Console. In `Settings` > `Governance` > `Collaborators` , choose `+ Invite a collaborator` :\n\nImage: [ Invite a collaborator ](https://hasura.io/docs/3.0/assets/images/0.0.1_console_invite-collaborator-26f80ebf23b981ceaf230fc3d5f40c90.png)\n\nThen, enter their email address and choose which role to assign them:\n\nImage: [ Invite a collaborator ](https://hasura.io/docs/3.0/assets/images/0.0.1_console_assign-collaborator-role-e95171f315e0df528439be940275982e.png)\n\n### Manage\u200b\n\nCurrently, collaborators can only be added or deleted from a project. If you wish to change the access level for a user,\nsimply delete them and re-add them with the new role.\n\n| Role | Description |\n|---|---|\n| Admin | Admins have full access to the project meaning that they can create and edit metadata; create and apply builds. |\n| Read Metadata & Explore GraphQL | Collaborators with this role can view the project's metadata and explore the GraphQL API, but they cannot make changes to the project. |\n\n\nProject owners\n\nPlease note, only project owners can delete a project. Ownership transfer is planned for a future release.\n\n### Delete\u200b\n\nYou can remove a collaborator from the Console by selecting `Remove` next to a user's name:\n\nImage: [ Invite a collaborator ](https://hasura.io/docs/3.0/assets/images/0.0.1_console_remove-collaborator-c7344e7784531f02ccd17b5fb46878f6.png)\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/collaborators/#introduction)\n- [ Collaborator lifecycle ](https://hasura.io/docs/3.0/ci-cd/collaborators/#collaborator-lifecycle)\n    - [ Create ](https://hasura.io/docs/3.0/ci-cd/collaborators/#create)\n\n- [ Manage ](https://hasura.io/docs/3.0/ci-cd/collaborators/#manage)\n\n- [ Delete ](https://hasura.io/docs/3.0/ci-cd/collaborators/#delete)\n", "https://hasura.io/docs/3.0/cli/installation/": "# Installation\n\nYou can download the CLI binaries below and start using it immediately. Please follow the instructions for your system.\n\n## Install instructions for Linux/Macs\u200b\n\n- M1 / M2 Macs\n- Intel Macs\n- Linux\n\n\n1. Download the latest `hasura3_aarch64-apple-darwin` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-darwin-arm64 -o hasura3`\n\nDownloading from the browser\n\nIf you are downloading from the browser, you'll likely encounter a notification that macOS cannot verify if this app is\nfree of malware. You can bypass this by right-clicking on the downloaded file and selecting \"Open\". This will open a\ndialog box asking if you want to open the file. Click \"Open\" to continue. A terminal window will open, which you can\nclose, and proceed with the installation instructions below.\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\n1. Download the latest `hasura3_x86_64-apple-darwin` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-darwin-amd64 -o hasura3`\n\nDownloading from the browser\n\nIf you are downloading from the browser, you'll likely encounter a notification that macOS cannot verify if this app is\nfree of malware. You can bypass this by right-clicking on the downloaded file and selecting \"Open\". This will open a\ndialog box asking if you want to open the file. Click \"Open\" to continue. A terminal window will open, which you can\nclose, and proceed with the installation instructions below.\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\n1. Download the latest `hasura3_x86_64-unknown-linux-musl` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-linux-amd64 -o hasura3`\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\nPermissions error\n\nIf you get a message about permissions, run the above commands with the `sudo` keyword and enter your password.\n\n## Install instructions for Windows\u200b\n\n1. Download the latest `hasura3_x86_64-pc-windows-gnu.exe` binary and run it.\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-windows-amd64.exe -o hasura3.exe`\n\nUnrecognized application warning\n\nIn Windows, if you get an \"Unrecognized application\" warning, click \"Run anyway\".\n\n## Verify Installation\u200b\n\nRunning `hasura3` should print the following message:\n\n```\n HH\\                                                         333333\\\n HH |                                                       33 ___33\\\n HHHHHHH\\   AAAAAA\\   SSSSSSS\\ UU\\   UU\\  RRRRRR\\  AAAAAA\\  \\_/   33 |\n HH  __HH\\  \\____AA\\ SS  _____|UU |  UU |RR  __RR\\ \\____AA\\   33333 /\n HH |  HH | AAAAAAA |\\SSSSSS\\  UU |  UU |RR |  \\__|AAAAAAA |  \\___33\\\n HH |  HH |AA  __AA | \\____SS\\ UU |  UU |RR |     AA  __AA |33\\   33 |\n HH |  HH |\\AAAAAAA |SSSSSSS  |\\UUUUUU  |RR |     \\AAAAAAA |\\333333  |\n \\__|  \\__| \\_______|\\_______/  \\______/ \\__|      \\_______| \\______/\nDDN commands:\n  project       Manage Hasura DDN Projects\n  secret        Commands related to Hasura Cloud Secret Ops\n  login         Login to Hasura Cloud\n  logout        Logout from Hasura Cloud\n  build         Manage Hasura DDN Project Builds [alias: builds]\n  environment   Environments in Hasura Projects [aliases: env, environments]\n  subgraph      Manage Hasura project subgraphs\n  daemon        Manage Hasura Secure Connect Tunnel Daemon\n  tunnel        Hasura Secure Connect service\n  init          Init Hasura DDN project\n  metadata      Manage Hasura DDN Projects' Metadata\n  watch         Watch a local Hasura project\nOther commands:\n  version      Print the CLI version\n  update-cli   Update the CLI to latest or a specific version\n  plugins      Manage plugins for the CLI\nUse \"hasura3 [command] --help\" for more information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Install instructions for Linux/Macs ](https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-linuxmacs)\n- [ Install instructions for Windows ](https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-windows)\n- [ Verify Installation ](https://hasura.io/docs/3.0/cli/installation/#verify-installation)\n", "https://hasura.io/docs/3.0/cli/commands/": "# Hasura3 CLI: hasura3\n\n## Synopsis\u200b\n\n`   .`\n\n```\n$ hasura3  --help\n       \n HH \\                                                           333333 \\\n HH  |                                                         33  ___33 \\\n HHHHHHH \\    AAAAAA \\    SSSSSSS \\  UU \\    UU \\   RRRRRR \\   AAAAAA \\    \\ _/    33   |\n HH  __HH \\    \\ ____AA \\  SS  _____ | UU  |   UU  | RR  __RR \\   \\ ____AA \\     33333  /\n HH  |   HH  |  AAAAAAA  | \\ SSSSSS \\   UU  |   UU  | RR  |    \\ __ | AAAAAAA  |    \\ ___33 \\\n HH  |   HH  | AA  __AA  |   \\ ____SS \\  UU  |   UU  | RR  |      AA  __AA  | 33 \\     33   |\n HH  |   HH  | \\ AAAAAAA  | SSSSSSS   | \\ UUUUUU   | RR  |       \\ AAAAAAA  | \\ 333333    |\n  \\ __ |    \\ __ |   \\ _______ | \\ _______/   \\ ______/  \\ __ |        \\ _______ |   \\ ______/\nUsage:\n  hasura3  [ flags ]\n  hasura3  [ command ]\nAvailable Commands:\n  build       Manage Hasura DDN Project Builds  [ alias: builds ]\n  completion  Generate the autocompletion script  for  the specified shell\n  daemon      Manage Hasura Secure Connect Tunnel Daemon\n  environment Environments  in  Hasura Projects  [ aliases: env, environments ]\n   help         Help about any  command\n  init        Init Hasura DDN project\n  login       Login to Hasura Cloud\n   logout       Logout from Hasura Cloud\n  metadata    Manage Hasura DDN Projects' Metadata\n  plugins     Manage plugins  for  the CLI\n  project     Manage Hasura DDN Projects\n  secret      Commands related to Hasura Cloud Secret Ops\n  subgraph    Manage Hasura project subgraphs\n  tunnel      Hasura Secure Connect  service\n  update-cli  Update the CLI to latest or a specific version\n  version     Print the CLI version\n   watch        Watch a  local  Hasura project\nFlags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n  -h, --help                help   for  hasura3\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\nUse  \"hasura3 [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/#synopsis)\n", "https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-linuxmacs": "# Installation\n\nYou can download the CLI binaries below and start using it immediately. Please follow the instructions for your system.\n\n## Install instructions for Linux/Macs\u200b\n\n- M1 / M2 Macs\n- Intel Macs\n- Linux\n\n\n1. Download the latest `hasura3_aarch64-apple-darwin` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-darwin-arm64 -o hasura3`\n\nDownloading from the browser\n\nIf you are downloading from the browser, you'll likely encounter a notification that macOS cannot verify if this app is\nfree of malware. You can bypass this by right-clicking on the downloaded file and selecting \"Open\". This will open a\ndialog box asking if you want to open the file. Click \"Open\" to continue. A terminal window will open, which you can\nclose, and proceed with the installation instructions below.\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\n1. Download the latest `hasura3_x86_64-apple-darwin` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-darwin-amd64 -o hasura3`\n\nDownloading from the browser\n\nIf you are downloading from the browser, you'll likely encounter a notification that macOS cannot verify if this app is\nfree of malware. You can bypass this by right-clicking on the downloaded file and selecting \"Open\". This will open a\ndialog box asking if you want to open the file. Click \"Open\" to continue. A terminal window will open, which you can\nclose, and proceed with the installation instructions below.\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\n1. Download the latest `hasura3_x86_64-unknown-linux-musl` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-linux-amd64 -o hasura3`\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\nPermissions error\n\nIf you get a message about permissions, run the above commands with the `sudo` keyword and enter your password.\n\n## Install instructions for Windows\u200b\n\n1. Download the latest `hasura3_x86_64-pc-windows-gnu.exe` binary and run it.\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-windows-amd64.exe -o hasura3.exe`\n\nUnrecognized application warning\n\nIn Windows, if you get an \"Unrecognized application\" warning, click \"Run anyway\".\n\n## Verify Installation\u200b\n\nRunning `hasura3` should print the following message:\n\n```\n HH\\                                                         333333\\\n HH |                                                       33 ___33\\\n HHHHHHH\\   AAAAAA\\   SSSSSSS\\ UU\\   UU\\  RRRRRR\\  AAAAAA\\  \\_/   33 |\n HH  __HH\\  \\____AA\\ SS  _____|UU |  UU |RR  __RR\\ \\____AA\\   33333 /\n HH |  HH | AAAAAAA |\\SSSSSS\\  UU |  UU |RR |  \\__|AAAAAAA |  \\___33\\\n HH |  HH |AA  __AA | \\____SS\\ UU |  UU |RR |     AA  __AA |33\\   33 |\n HH |  HH |\\AAAAAAA |SSSSSSS  |\\UUUUUU  |RR |     \\AAAAAAA |\\333333  |\n \\__|  \\__| \\_______|\\_______/  \\______/ \\__|      \\_______| \\______/\nDDN commands:\n  project       Manage Hasura DDN Projects\n  secret        Commands related to Hasura Cloud Secret Ops\n  login         Login to Hasura Cloud\n  logout        Logout from Hasura Cloud\n  build         Manage Hasura DDN Project Builds [alias: builds]\n  environment   Environments in Hasura Projects [aliases: env, environments]\n  subgraph      Manage Hasura project subgraphs\n  daemon        Manage Hasura Secure Connect Tunnel Daemon\n  tunnel        Hasura Secure Connect service\n  init          Init Hasura DDN project\n  metadata      Manage Hasura DDN Projects' Metadata\n  watch         Watch a local Hasura project\nOther commands:\n  version      Print the CLI version\n  update-cli   Update the CLI to latest or a specific version\n  plugins      Manage plugins for the CLI\nUse \"hasura3 [command] --help\" for more information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Install instructions for Linux/Macs ](https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-linuxmacs/#install-instructions-for-linuxmacs)\n- [ Install instructions for Windows ](https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-linuxmacs/#install-instructions-for-windows)\n- [ Verify Installation ](https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-linuxmacs/#verify-installation)\n", "https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-windows": "# Installation\n\nYou can download the CLI binaries below and start using it immediately. Please follow the instructions for your system.\n\n## Install instructions for Linux/Macs\u200b\n\n- M1 / M2 Macs\n- Intel Macs\n- Linux\n\n\n1. Download the latest `hasura3_aarch64-apple-darwin` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-darwin-arm64 -o hasura3`\n\nDownloading from the browser\n\nIf you are downloading from the browser, you'll likely encounter a notification that macOS cannot verify if this app is\nfree of malware. You can bypass this by right-clicking on the downloaded file and selecting \"Open\". This will open a\ndialog box asking if you want to open the file. Click \"Open\" to continue. A terminal window will open, which you can\nclose, and proceed with the installation instructions below.\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\n1. Download the latest `hasura3_x86_64-apple-darwin` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-darwin-amd64 -o hasura3`\n\nDownloading from the browser\n\nIf you are downloading from the browser, you'll likely encounter a notification that macOS cannot verify if this app is\nfree of malware. You can bypass this by right-clicking on the downloaded file and selecting \"Open\". This will open a\ndialog box asking if you want to open the file. Click \"Open\" to continue. A terminal window will open, which you can\nclose, and proceed with the installation instructions below.\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\n1. Download the latest `hasura3_x86_64-unknown-linux-musl` binary:\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-linux-amd64 -o hasura3`\n\n1. Run `chmod +x hasura3` (This makes the binary executable on your system)\n2. Move the binary to `/usr/local/bin/` (run `mv hasura3 /usr/local/bin/` ). Please ensure that `/usr/local/bin/` is in\nyour PATH with `echo $PATH` .\n\n\nPermissions error\n\nIf you get a message about permissions, run the above commands with the `sudo` keyword and enter your password.\n\n## Install instructions for Windows\u200b\n\n1. Download the latest `hasura3_x86_64-pc-windows-gnu.exe` binary and run it.\n\n\n`curl  -L https://graphql-engine-cdn.hasura.io/ddn/cli/latest/cli-hasura3-windows-amd64.exe -o hasura3.exe`\n\nUnrecognized application warning\n\nIn Windows, if you get an \"Unrecognized application\" warning, click \"Run anyway\".\n\n## Verify Installation\u200b\n\nRunning `hasura3` should print the following message:\n\n```\n HH\\                                                         333333\\\n HH |                                                       33 ___33\\\n HHHHHHH\\   AAAAAA\\   SSSSSSS\\ UU\\   UU\\  RRRRRR\\  AAAAAA\\  \\_/   33 |\n HH  __HH\\  \\____AA\\ SS  _____|UU |  UU |RR  __RR\\ \\____AA\\   33333 /\n HH |  HH | AAAAAAA |\\SSSSSS\\  UU |  UU |RR |  \\__|AAAAAAA |  \\___33\\\n HH |  HH |AA  __AA | \\____SS\\ UU |  UU |RR |     AA  __AA |33\\   33 |\n HH |  HH |\\AAAAAAA |SSSSSSS  |\\UUUUUU  |RR |     \\AAAAAAA |\\333333  |\n \\__|  \\__| \\_______|\\_______/  \\______/ \\__|      \\_______| \\______/\nDDN commands:\n  project       Manage Hasura DDN Projects\n  secret        Commands related to Hasura Cloud Secret Ops\n  login         Login to Hasura Cloud\n  logout        Logout from Hasura Cloud\n  build         Manage Hasura DDN Project Builds [alias: builds]\n  environment   Environments in Hasura Projects [aliases: env, environments]\n  subgraph      Manage Hasura project subgraphs\n  daemon        Manage Hasura Secure Connect Tunnel Daemon\n  tunnel        Hasura Secure Connect service\n  init          Init Hasura DDN project\n  metadata      Manage Hasura DDN Projects' Metadata\n  watch         Watch a local Hasura project\nOther commands:\n  version      Print the CLI version\n  update-cli   Update the CLI to latest or a specific version\n  plugins      Manage plugins for the CLI\nUse \"hasura3 [command] --help\" for more information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Install instructions for Linux/Macs ](https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-windows/#install-instructions-for-linuxmacs)\n- [ Install instructions for Windows ](https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-windows/#install-instructions-for-windows)\n- [ Verify Installation ](https://hasura.io/docs/3.0/cli/installation/#install-instructions-for-windows/#verify-installation)\n", "https://hasura.io/docs/3.0/observability/traces/": "# Traces\n\n## Introduction\u200b\n\n[ Distributed traces ](https://opentelemetry.io/docs/concepts/signals/traces/)track and map journeys of user requests\nacross various services or components.\n\nTraces are typically used to diagnose or debug which part of your application could potentially be responsible for a\nfailure or error state and to monitor the performance of end-user interactions with your application.\n\nTraces are generated by instrumenting application code. Hasura DDN instruments all API queries with the OpenTelemetry\nformat and supports tracing out of the box. **This means that you don't have to set up your own OpenTelemetry\ncollector.** Simply head to the `Operations` dashboard for a project's Console, and you'll see traces for all your API\nrequests.\n\n## Spans\u200b\n\nEvery request to your GraphQL API will have a unique `trace-id` associated with it and may have the following spans:\n\n- `/graphql` \n    - `handle_authentication` \n        - `execute_authentication`\n\n- `handle_request` \n    - `execute_query` \n        - `execute` \n            - `execute_ndc_query` \n                - `Execute Query`\n\n- `execute_ndc_mutation`\n\n- `execute_ndc_query` \n    - `Execute Query`\n\n- `execute` \n    - `execute_ndc_query` \n        - `Execute Query`\n\n- `execute_query` \n    - `execute` \n        - `execute_ndc_query` \n            - `Execute Query`\n\n- `handle_authentication` \n    - `execute_authentication`\n\n- `handle_request` \n    - `execute_query` \n        - `execute` \n            - `execute_ndc_query` \n                - `Execute Query`\n\n\n| Span name | Description |\n|---|---|\n|  `/graphql`  | The root span for every request to your GraphQL API. |\n|  `handle_ authentication`  | The span responsible for handling authentication before the request is executed by the engine. |\n|  `execute_ authentication`  | The span responsible for executing authentication, either using JWTs or via a Webhook. |\n|  `handle_ request`  | The span responsible for handling a GraphQL request after it is successfully authenticated by the engine. |\n|  `execute_ query`  | The top-level span for executing a GraphQL query. |\n|  `execute`  | The span responsible for executing each query in your GraphQL request. This span has an attribute `usage_ counts` which describes all the models that were used as a part of this operation. |\n|  `execute_ ndc_ query`  | The span responsible for executing a single ndc query. This span has an attribute `field` which describes the schema type that was executed. |\n|  `Execute Query`  | The span responsible for executing the generated query on the data source. |\n|  `execute_ ndc_ mutation`  | The span responsible for executing a single ndc mutation. This span has an attribute `field` which describes the field that was executed. |\n\n\nWhat are spans?\n\nSpans represent the basic unit of work in a distributed system. They describe the operation that an individual component\nof the system is doing, such as the time taken to execute a function or a request.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/observability/traces/#introduction)\n- [ Spans ](https://hasura.io/docs/3.0/observability/traces/#spans)\n", "https://hasura.io/docs/3.0/cli/commands/watch/": "# Hasura3 CLI: hasura3 watch\n\n## Synopsis\u200b\n\nWatch a local Hasura project.\n\n```\n$ hasura3  watch  --help\nWatch a  local  Hasura project\nUsage:\n  hasura3  watch   [ flags ]\nExamples:\n  # Watch and re-create a build on any file changes \n   hasura3  watch  --dir  < path-to-hasura.yaml-file >   \n  # To override the default build profile, provide the --profile flag with a build-profile\n   hasura3  watch  --profile build-profile-staging.yaml --dir  < path-to-hasura.yaml-file >\nFlags:\n  -h, --help              help   for   watch\n      --profile string   Build profile to use, uses the default build profile  if  not provided\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/watch/#synopsis)\n", "https://hasura.io/docs/3.0/basics/core-concepts/#supergraph": "# Core Concepts\n\nThe sprawl of microservices and APIs which any given product needs to connect to in order to function has led to a new\nset of challenges for developers and architects.\n\nIn the modern era of building applications, the data layer is becoming increasingly complex; it's no longer just a\ndatabase, but a collection of databases, services, and APIs.\n\nHasura DDN introduces the concept of a **data supergraph** to help you manage this complexity.\n\n## The state of the data layer\u200b\n\nImagine the following sets of teams within a hypothetical company:\n\n- **Product Management Team** : Responsible for the relational database storing product information. This team focuses on\ncataloging products, managing inventory, and ensuring product details are accurate and up-to-date by use of a **relational PostgreSQL database** .\n- **User Experience Team** : Manages a **MongoDB document database** and related APIs for storing user information. Their\nfocus is on maintaining user profiles, preferences, and ensuring privacy and security of user data.\n- **Search Optimization Team** : Handles the **integration of an Algolia search service** for products and partner\nstores. They work on optimizing search algorithms, ensuring relevant search results, and improving the overall search\nexperience for users.\n- **Finance and Transactions Team** : Oversees the **Stripe payment service and underlying relational database** for\nprocessing payments. This includes managing transaction security, payment gateway integrations, and ensuring smooth\nfinancial transactions.\n- **Logistics and Shipping Team** : Responsible for the **ShipStation shipping service, fulfilling orders, and the\nunderlying relational database that supports this process** . Their primary focus is on logistics, order tracking, and\nensuring timely delivery of products.\n- **Data Science and Recommendations Team** : Manages the **Weaviate vector database** for storing user recommendations.\nThey work on personalization algorithms, user behavior analysis, and providing tailored product recommendations to\nenhance user experience.\n\n\n **Product Management Team** : Responsible for the relational database storing product information. This team focuses on\ncataloging products, managing inventory, and ensuring product details are accurate and up-to-date by use of a **relational PostgreSQL database** .\n\n **User Experience Team** : Manages a **MongoDB document database** and related APIs for storing user information. Their\nfocus is on maintaining user profiles, preferences, and ensuring privacy and security of user data.\n\n **Search Optimization Team** : Handles the **integration of an Algolia search service** for products and partner\nstores. They work on optimizing search algorithms, ensuring relevant search results, and improving the overall search\nexperience for users.\n\n **Finance and Transactions Team** : Oversees the **Stripe payment service and underlying relational database** for\nprocessing payments. This includes managing transaction security, payment gateway integrations, and ensuring smooth\nfinancial transactions.\n\n **Logistics and Shipping Team** : Responsible for the **ShipStation shipping service, fulfilling orders, and the\nunderlying relational database that supports this process** . Their primary focus is on logistics, order tracking, and\nensuring timely delivery of products.\n\n **Data Science and Recommendations Team** : Manages the **Weaviate vector database** for storing user recommendations.\nThey work on personalization algorithms, user behavior analysis, and providing tailored product recommendations to\nenhance user experience.\n\nThe diversity of teams within this hypothetical company, each with their unique focus and specialized data services,\nepitomizes the common challenge in modern data management and API development. These teams all operate with distinct\nAPIs, schemas, and methodologies. This fragmentation not only complicates the process of developing applications but\nalso necessitates the involvement of skilled data architects and engineers to efficiently integrate and maintain these\nvaried data sources.\n\n## Subgraphs\u200b\n\nIn our e-commerce application example, each service above represents what we term a **subgraph** .\n\nA subgraph is much more than just a single data source; it is all the metadata needed to act as a self-contained entity\nthat can be independently authored, owned, maintained, and deployed by an individual team, to then be an **interconnected part of a unified API** .\n\nFor API authors, this means the ability to build out an API \u2014 composed of different sources \u2014 in a simple, declarative\nway. You can utilize unique access-control rules, authentication mechanisms, and custom business logic within your\nsubgraphs to create a secure and robust API.\n\nEach subgraph in our example is a modular component of the data supergraph. These components securely work together to\novercome the traditional barriers posed by isolated data sources, facilitating a more fluid and interconnected data\nlayer. This integrated approach simplifies application development across diverse data systems, enabling faster\niteration and more efficient maintenance by engineering teams.\n\n### How do I build a subgraph?\u200b\n\nSubgraphs are composed of related data sources \u2014 be that as traditional databases, or as custom business logic \u2014 and are\nconnected to your data layer using **data connectors** . Hasura DDN utilizes a number of data\nconnectors that work with popular databases, services, and APIs out-of-the-box; you can also build your own. **These\nsubgraphs can even include your own custom business logic as TypeScript functions that return or mutate data directly\nvia your GraphQL API.** This saves you the time and effort of building and maintaining your own APIs to manage data\nsources and existing microservices.\n\nAfter connecting your data source, you can then author your metadata using the[ Hasura CLI ](https://hasura.io/docs/3.0/cli/overview/)and our[ LSP-enabled VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura). This metadata is\nthen deployed to your Hasura DDN instance, where it is used to build your subgraph and eventually serve your GraphQL\nAPI.\n\n## Supergraph\u200b\n\nA **data supergraph** is the framework that brings together all of your subgraphs into one secure API. This\norchestration allows for the creation of applications that span multiple data sources, services, third-party APIs,\nbusiness logic and \u2014 most importantly \u2014 teams, seamlessly bridging their complexities into a single layer.\n\nFor those responsible for maintaining the data layer, this means you now have a single, holistic API to manage, rather\nthan multiple disparate data sources and connections. This enables you to create CI/CD pipelines, monitor performance\nusing industry-standard observability tools, and manage access control in a more streamlined and efficient manner.\n\nFor your consumers, this means they have a single endpoint to access all the data they need, thereby reducing the\ncomplexity of their applications. This also allows them to focus on building the best possible user experience, rather\nthan wrangling the underlying data layer.\n\n### How do I build a supergraph?\u200b\n\nThis happens automatically.\n\nAs you add subgraphs to your Hasura project, Hasura DDN automatically builds a supergraph of all your data sources. You\nhave the freedom and flexibility to define relationships \u2014 including fine-grained access control \u2014 across this\nsupergraph, connecting data sources together and making them available in ways that make sense for your application.\n\n## Next steps\u200b\n\nCheck out our[ getting started guide ](https://hasura.io/docs/3.0/getting-started/local-dev/)to learn how to build your first data supergraph.\n\n### What did you think of this doc?\n\n- [ The state of the data layer ](https://hasura.io/docs/3.0/basics/core-concepts/#supergraph/#the-state-of-the-data-layer)\n- [ Subgraphs ](https://hasura.io/docs/3.0/basics/core-concepts/#supergraph/#subgraphs)\n    - [ How do I build a subgraph? ](https://hasura.io/docs/3.0/basics/core-concepts/#supergraph/#how-do-i-build-a-subgraph)\n- [ Supergraph ](https://hasura.io/docs/3.0/basics/core-concepts/#supergraph/#supergraph)\n    - [ How do I build a supergraph? ](https://hasura.io/docs/3.0/basics/core-concepts/#supergraph/#how-do-i-build-a-supergraph)\n- [ Next steps ](https://hasura.io/docs/3.0/basics/core-concepts/#supergraph/#next-steps)\n", "https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate": "# Common OpenDD Syntax\n\n## ModelPredicate\u200b\n\nA `ModelPredicate` is used to define the boolean expression for filtering the objects within a model, and is typically used when defining permissions.\n\n```\n[ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#fieldcomparison)\n|\n[ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#relationship)\n|\n[ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#andexp)\n|\n[ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#orexp)\n|\n[ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#notexp)\n```\n\n### FieldComparison\u200b\n\nThis predicate filters objects where the particular `field` of the object returns true when the specified comparison operator `operator` is applied with the `value` as input.\n\n```\nfieldComparison :\n   field :  <FieldName >\n   operator :  <Operator >\n   value :  <ValueExpression >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| field |  `String`  | true | Name of the field of the model to compare. |\n| operator |  `String`  | true | Name of the operator. Either the built-in operators `_ eq` or `_ is_ null` , or any of the operators available from the data connector. |\n| value | [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#valueexpression) | false | The value to compare. Can be a literal value or a a value from session variables. This can be omitted in case of `_ is_ null` operator. |\n\n\n### RelationshipPredicate\u200b\n\nThis predicate evaluates to true if any of the corresponding target objects of the relationship of the source model's object type with `name` meet the nested `predicate` .\n\n```\nrelationship :\n   name :  <RelationshipName >\n   predicate :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| name |  `String`  | true | Name of relationship of the model to compare. |\n| predicate | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#modelpredicate) | false | The filter or predicate expression. |\n\n\n### AndExp\u200b\n\nThis predicates evaluates to true if all sub-predicates of `and` evaluate to true.\n\n```\n{\n  \"and\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#modelpredicate)\n]\n}\n```\n\n### OrExp\u200b\n\nThis predicates evaluates to true if any of the sub-predicates of `or` evaluate to true.\n\n```\n{\n  \"or\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#modelpredicate)\n]\n}\n```\n\n### NotExp\u200b\n\nThis predicates evaluates to true if the sub-predicates of `not` evaluates to false.\n\n```\n{\n  \"not\" :\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#modelpredicate)\n}\n```\n\n## ValueExpression\u200b\n\nAn expression which evaluates to a value that can be used in comparison expressions, etc.\nThis expression can either be a literal value or a reference to a session variable.\n\n```\n[ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#literal)\n|\n[ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#sessionvariable)\n```\n\n### Literal\u200b\n\n```\n{\n   \"literal\" :  <any JSON value>\n}\n```\n\n#### Examples\u200b\n\n`literal :  some string`\n\n### SessionVariable\u200b\n\n`sessionVariable :  String`\n\n#### Examples\u200b\n\n`sessionVariable :  x - hasura - user - id`\n\n## TypeMapping\u200b\n\nThe `typemapping` is used by[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)to define the mapping between the fields of the OpenDD types used in the model/command and\nthe fields of the corresponding types in the data connector. It has the following fields:\n\n```\n<OpenDDTypeName> :\n   fieldMapping :  <FieldMapping >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDTypeName`  |  `String`  | true | Name of the OpenDD object type which is being mapped. |\n|  `fieldMapping`  | [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#fieldmapping) | true | The field mapping between the OpenDD object type and the corresponding NDC object type. |\n\n\n## FieldMapping\u200b\n\nThe `fieldMapping` is used by[ typemapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#typemapping)to define mapping for the fields of the `OpenDDTypeName` .\n\nIt has the following fields:\n\n```\n<OpenDDFieldName> :\n   column :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDFieldName`  |  `String`  | true | Name of the field in the OpenDD object type. |\n|  `column`  |  `String`  | true | The name of the field in the NDC object type. |\n\n\n## ArgumentDefinition\u200b\n\nArguments is a list of objects that defines the arguments for the[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure)or a[ command ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure). An argument object has the following fields:\n\n```\nname :  <String > ,\ntype :  <TypeReference >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the argument. |\n|  `type`  |  `Type`  | true | [ TypeReference ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references)of the argument as a string. |\n\n\n## Secret references\u200b\n\nInstead of embedding sensitive values in the metadata, certain fields can be set using[ secrets ](https://hasura.io/docs/3.0/ci-cd/secrets/)stored in DDN.\n\nTo embed a value directly without using a secret:\n\n`value: <your value>`\n\nTo use a value via a secret:\n\n`stringValueFromSecret: <secret name>`\n\n### What did you think of this doc?\n\n- [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#modelpredicate)\n    - [ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#fieldcomparison)\n\n- [ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#relationshippredicate)\n\n- [ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#andexp)\n\n- [ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#orexp)\n\n- [ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#notexp)\n- [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#valueexpression)\n    - [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#literal)\n        - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#examples)\n\n- [ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#sessionvariable)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#examples-1)\n\n- [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#literal)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#examples)\n- [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#typemapping)\n- [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#fieldmapping)\n- [ ArgumentDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#argumentdefinition)\n- [ Secret references ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate/#secret)\n", "https://hasura.io/docs/3.0/connectors/deployment/#http-connectors": "# Deploy a Data Connector\n\n## Integrated connectors\u200b\n\n[ Integrated connectors ](https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors)do not need to be deployed, and are\navailable for immediate use in any project. You can see a full list of integrated connectors on the[ Connector Hub ](https://hasura.io/connectors).\n\n## HTTP connectors\u200b\n\n### Deploy an HTTP connector via a cloud provider\u200b\n\n[ HTTP connectors ](https://hasura.io/docs/3.0/connectors/introduction/#http-connectors)can easily be deployed to a variety of cloud providers.\nSimply follow the deployment instructions of your chosen provider.\n\n### Deploy an HTTP connector via Hasura using the CLI\u200b\n\nYou can also deploy them to Hasura using our `connector` CLI plugin. You can see a full list of HTTP connectors on the[ Connector Hub ](https://hasura.io/connectors).\n\nOpen source repositories that are set up according to the connector convention can be used via the `connector` CLI\nplugin.\n\nCurious about an example?\n\nSee the[ SendGrid connector's repository ](https://github.com/hasura/ndc-sendgrid/tree/main#sendgrid-connector)to see\nhow the connector is set up.\n\nOnce you have the Hasura v3 CLI you can install the plugin as follows:\n\n`hasura3 plugin  install  connector`\n\nLimit access to your connector\n\nYou can set the `SERVICE_TOKEN_SECRET` environment variable to only allow requests from authorized clients. Set the\ntoken while deploying the connector and then create a secret on Hasura Cloud with the same value:\n\n`hasura3 secret  set  -k SERVICE_TOKEN_SECRET -v  < secret-value >`\n\nDeploy the connector to Hasura Cloud:\n\n```\nhasura3 connector create my-connector:v1 \\\n  --github-repo-url https://github.com/hasura/cool-connector/tree/v0.7 \\\n  --config-file conf.json \\\n  --env SERVICE_TOKEN_SECRET='MY-SECRET-TOKEN-XXX123'\n```\n\n### Add connecotr to Metadata\u200b\n\nGet the URL for the deployed connector and add a `kind: DataConnector` object to your metadata:\n\n```\nkind :  DataConnector\nversion :  v2\ndefinition :\n   name :  my_connector\n   url :\n     singleUrl :\n       value :  https : //my - connector - 9XXX7 - hyc5v23h6a - ue.a.run.app\n   headers :\n     Authorization :\n       stringValueFromSecret :  SERVICE_TOKEN_SECRET\n```\n\nBuild the new metadata:\n\n`hasura3 build create -d  \"add new connector\"`\n\n### What did you think of this doc?\n\n- [ Integrated connectors ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors/#integrated-connectors)\n- [ HTTP connectors ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors/#http-connectors)\n    - [ Deploy an HTTP connector via a cloud provider ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors/#deploy-an-http-connector-via-a-cloud-provider)\n\n- [ Deploy an HTTP connector via Hasura using the CLI ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors/#deploy-an-http-connector-via-hasura-using-the-cli)\n\n- [ Add connecotr to Metadata ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors/#add-connecotr-to-metadata)\n", "https://hasura.io/docs/3.0/connectors/deployment/plugin/": "# Working with connectors via the CLI connector plugin\n\nThis Hasura CLI plugin enables deployment and management of custom Hasura Data Connector agents to Hasura Cloud.\n\n## Install the Hasura CLI Data Connector plugin\u200b\n\nTo start deploying Data Connectors using the Data Connector plugin, the following pre-requisites need to be in place:\n\n1. Install Hasura CLI\n2. Update plugin index\n3. Install cloud plugin\n4. Authenticate the CLI with Hasura Cloud\n5. Install connector plugin\n6. Verify installation with the --help flag\n\n\nhasura3 plugins list\n\nhasura3 plugins install cloud\n\nhasura3 login --pat your-personal-access-token\n\nhasura3 plugins install connector\n\nhasura3 connector --help\n\nPersonal Access Token (PAT)\n\nYou can generate a personal access token[ here ](https://cloud.hasura.io/account-settings/access-tokens).\n\n## Uninstall the Hasura CLI Data Connector plugin\u200b\n\nTo uninstall the Hasura CLI Data Connector plugin, use the `uninstall` command:\n\n`hasura3 plugins uninstall connector`\n\n## Usage\u200b\n\nOnce you have the connector plugin installed you should be able to use the plugin to create and delete hosted\nconnectors.\n\nUsage help:\n\n```\n> hasura3 connector --help\nThis Hasura CLI plugin enables deployment and management of custom Hasura data connector agent to Hasura cloud.\nFurther Reading:\n  - https://hasura.io/docs/latest/databases/data-connectors/\n  - https://github.com/hasura/graphql-engine/tree/master/dc-agents/reference\n  - https://github.com/hasura/graphql-engine/blob/master/dc-agents/DOCUMENTATION.md\nUsage:\n  connector [command]\nAvailable Commands:\n  completion             Generate the autocompletion script for the specified shell\n  create                 Create a new Hasura Cloud connector using CLI\n  delete                 Delete a Hasura Cloud connector.\n  generate-configuration Generate Hasura Connector configuration for the connector given in the flag --github-repo-url\n  help                   Help about any command\n  list                   List all Hasura Cloud data connectors owned by the user.\n  logs                   Tails logs of a deployed custom Hasura data connector.\n  status                 Prints the current status of the custom Hasura data connector deployment.\n  version                get version information of connector CLI\nFlags:\n  -h, --help   help for connector\n```\n\nCreate a connector:\n\n```\nhasura3 connector create my-connector:v1 \\\n  --github-repo-url https://github.com/hasura/cool-connector/tree/v0.7 \\\n  --config-file conf.json\n```\n\nDelete a connector:\n\n`hasura3 connector delete my-connector:v1`\n\n## Advanced Options\u200b\n\n### --env\u200b\n\n`--env`\n\nTo set environment variables when creating a connector you can use the `--env` flag:\n\n```\nhasura3 connector create my-connector:v1 \\\n  --github-repo-url https://github.com/hasura/cool-connector/tree/v0.7 \\\n  --config-file conf.json \\\n  --env LOG_LEVEL=DEBUG\n```\n\n### --volume\u200b\n\n`--volume`\n\nTo mount a volume for access by the connector you can use the[ docker --volume syntax ](https://docs.docker.com/storage/volumes/#choose-the--v-or---mount-flag).\n\nThis will provide the specified file or directory to the build process:\n\n```\nhasura3 connector create my-connector:v1 \\\n  --github-repo-url https://github.com/hasura/cool-connector/tree/v0.7 \\\n  --config-file conf.json \\\n  --volume ./my_data:/data\n```\n\nWARNING: Connector authors must have a `COPY` command in their `Dockerfile` corresponding to the expected volume mount\nlocation.\n\n### SERVICE_TOKEN_SECRET Environment Variable\u200b\n\n`SERVICE_TOKEN_SECRET`\n\nIf you wish your connector to only be accessed by Hasura you should set the `SERVICE_TOKEN_SECRET` environment variable\nto a secure token and then configure your project metadata with the same token (ideally via the secrets function).\n\nFor example:\n\n```\n# Generate a secret token\n> openssl rand  -base64 40\nfErSXC6HDplAZtqxbHJVUmGqGG8AmtJleBquxeNhDsS0CCeXwTYJbg==\n# Deploy Connector using token\n> hasura3 connector create my-connector:v1 \\\n  --github-repo-url https://github.com/hasura/cool-connector/tree/v0.7 \\\n  --config-file conf.json \\\n  --env SERVICE_TOKEN_SECRET=fErSXC6HDplAZtqxbHJVUmGqGG8AmtJleBquxeNhDsS0CCeXwTYJbg==\n> hasura3 connector list\nmy-cool-connector:v1 https://connector-9XXX7-hyc5v23h6a-ue.a.run.app active\n# Include in project metadata\n> code metadata.hml\n> head metadata.hml\nkind: DataSource\nname: sendgrid\ndataConnectorUrl:\n  url: 'https://connector-9XXX7-hyc5v23h6a-ue.a.run.app'\nauth:\n  type: Bearer\n  token: \"fErSXC6HDplAZtqxbHJVUmGqGG8AmtJleBquxeNhDsS0CCeXwTYJbg==\"\n```\n\nSee the[ CLI secret documentation ](https://hasura.io/docs/3.0/cli/commands/secret/)for information on how to securely configure secrets\nsuch as this token in your projects.\n\n### What did you think of this doc?\n\n- [ Install the Hasura CLI Data Connector plugin ](https://hasura.io/docs/3.0/connectors/deployment/plugin/#install-the-hasura-cli-data-connector-plugin)\n- [ Uninstall the Hasura CLI Data Connector plugin ](https://hasura.io/docs/3.0/connectors/deployment/plugin/#uninstall-the-hasura-cli-data-connector-plugin)\n- [ Usage ](https://hasura.io/docs/3.0/connectors/deployment/plugin/#usage)\n- [ Advanced Options ](https://hasura.io/docs/3.0/connectors/deployment/plugin/#advanced-options)\n    - [ --env ](https://hasura.io/docs/3.0/connectors/deployment/plugin/#--env)\n\n- [ --volume ](https://hasura.io/docs/3.0/connectors/deployment/plugin/#--volume)\n\n- [ SERVICE_TOKEN_SECRET Environment Variable ](https://hasura.io/docs/3.0/connectors/deployment/plugin/#service_token_secret-environment-variable)\n", "https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors": "# Introduction\n\n## What is a data connector?\u200b\n\nA data connector is an HTTP service that exposes a set of APIs that Hasura uses to communicate with the data source. The\ndata connector is responsible for interpreting work to be done on behalf of the Hasura Engine, using the native query\nlanguage of the data source.\n\nData connectors, which are built using the[ NDC Specification ](http://hasura.github.io/ndc-spec/)and closely integrated\nwith the[ OpenDD spec ](https://github.com/hasura/open-data-domain-specification), enable anyone to connect rich,\nhighly-native data sources.\n\nThe NDC Specification defines a set of APIs that a data connector must implement. These APIs, which accept and return\nJSON, are used by Hasura to communicate with the data connector agent. The NDC specification also defines a set of\nmetadata that the data connector agent must provide to Hasura. This metadata is used by Hasura to introspect the data\nconnector, generate the GraphQL schema, and execute operations against the data source.\n\nYou can[ build your own data connector ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/), or use one of the many connectors\navailable on the[ Connector Hub ](https://hasura.io/connectors).\n\n## Types of data connectors\u200b\n\nThere are two main types of connectors available for use in Hasura v3 projects: Integrated and HTTP connectors.\n\n### Integrated connectors\u200b\n\nIntegrated connectors are configured and deployed via your project metadata only and do not require any additional\nprocesses.\n\nAn example of an integrated connector is the[ Postgres Connector ](https://hasura.io/connectors/postgres).\n\n### HTTP connectors\u200b\n\nHTTP connectors are configured and deployed **independently** of your project metadata and only the URL of the deployed\nconnector is required in your metadata.\n\nWhile Hasura does not prescribe any process for deploying an HTTP connector it does provide the `connector` CLI plugin\nfor easily deploying connectors that use our SDKs. You can learn more in our[ connector deployment guide ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors).\n\nAn example of an HTTP connector is the[ SendGrid Connector ](https://hasura.io/connectors/sendgrid).\n\n## What data connectors are available?\u200b\n\nBrowse the[ Connector Hub ](https://hasura.io/connectors)for an up-to-date list of all available connectors.\n\n### What did you think of this doc?\n\n- [ What is a data connector? ](https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors/#what-is-a-data-connector)\n- [ Types of data connectors ](https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors/#types-of-data-connectors)\n    - [ Integrated connectors ](https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors/#integrated-connectors)\n\n- [ HTTP connectors ](https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors/#http-connectors)\n- [ What data connectors are available? ](https://hasura.io/docs/3.0/connectors/introduction/#integrated-connectors/#what-data-connectors-are-available)\n", "https://hasura.io/docs/3.0/connectors/introduction/#http-connectors": "# Introduction\n\n## What is a data connector?\u200b\n\nA data connector is an HTTP service that exposes a set of APIs that Hasura uses to communicate with the data source. The\ndata connector is responsible for interpreting work to be done on behalf of the Hasura Engine, using the native query\nlanguage of the data source.\n\nData connectors, which are built using the[ NDC Specification ](http://hasura.github.io/ndc-spec/)and closely integrated\nwith the[ OpenDD spec ](https://github.com/hasura/open-data-domain-specification), enable anyone to connect rich,\nhighly-native data sources.\n\nThe NDC Specification defines a set of APIs that a data connector must implement. These APIs, which accept and return\nJSON, are used by Hasura to communicate with the data connector agent. The NDC specification also defines a set of\nmetadata that the data connector agent must provide to Hasura. This metadata is used by Hasura to introspect the data\nconnector, generate the GraphQL schema, and execute operations against the data source.\n\nYou can[ build your own data connector ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/), or use one of the many connectors\navailable on the[ Connector Hub ](https://hasura.io/connectors).\n\n## Types of data connectors\u200b\n\nThere are two main types of connectors available for use in Hasura v3 projects: Integrated and HTTP connectors.\n\n### Integrated connectors\u200b\n\nIntegrated connectors are configured and deployed via your project metadata only and do not require any additional\nprocesses.\n\nAn example of an integrated connector is the[ Postgres Connector ](https://hasura.io/connectors/postgres).\n\n### HTTP connectors\u200b\n\nHTTP connectors are configured and deployed **independently** of your project metadata and only the URL of the deployed\nconnector is required in your metadata.\n\nWhile Hasura does not prescribe any process for deploying an HTTP connector it does provide the `connector` CLI plugin\nfor easily deploying connectors that use our SDKs. You can learn more in our[ connector deployment guide ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors).\n\nAn example of an HTTP connector is the[ SendGrid Connector ](https://hasura.io/connectors/sendgrid).\n\n## What data connectors are available?\u200b\n\nBrowse the[ Connector Hub ](https://hasura.io/connectors)for an up-to-date list of all available connectors.\n\n### What did you think of this doc?\n\n- [ What is a data connector? ](https://hasura.io/docs/3.0/connectors/introduction/#http-connectors/#what-is-a-data-connector)\n- [ Types of data connectors ](https://hasura.io/docs/3.0/connectors/introduction/#http-connectors/#types-of-data-connectors)\n    - [ Integrated connectors ](https://hasura.io/docs/3.0/connectors/introduction/#http-connectors/#integrated-connectors)\n\n- [ HTTP connectors ](https://hasura.io/docs/3.0/connectors/introduction/#http-connectors/#http-connectors)\n- [ What data connectors are available? ](https://hasura.io/docs/3.0/connectors/introduction/#http-connectors/#what-data-connectors-are-available)\n", "https://hasura.io/docs/3.0/connectors/introduction/#the-connector-cli-plugin": "# Introduction\n\n## What is a data connector?\u200b\n\nA data connector is an HTTP service that exposes a set of APIs that Hasura uses to communicate with the data source. The\ndata connector is responsible for interpreting work to be done on behalf of the Hasura Engine, using the native query\nlanguage of the data source.\n\nData connectors, which are built using the[ NDC Specification ](http://hasura.github.io/ndc-spec/)and closely integrated\nwith the[ OpenDD spec ](https://github.com/hasura/open-data-domain-specification), enable anyone to connect rich,\nhighly-native data sources.\n\nThe NDC Specification defines a set of APIs that a data connector must implement. These APIs, which accept and return\nJSON, are used by Hasura to communicate with the data connector agent. The NDC specification also defines a set of\nmetadata that the data connector agent must provide to Hasura. This metadata is used by Hasura to introspect the data\nconnector, generate the GraphQL schema, and execute operations against the data source.\n\nYou can[ build your own data connector ](https://hasura.io/docs/3.0/connectors/build-your-own-connector/), or use one of the many connectors\navailable on the[ Connector Hub ](https://hasura.io/connectors).\n\n## Types of data connectors\u200b\n\nThere are two main types of connectors available for use in Hasura v3 projects: Integrated and HTTP connectors.\n\n### Integrated connectors\u200b\n\nIntegrated connectors are configured and deployed via your project metadata only and do not require any additional\nprocesses.\n\nAn example of an integrated connector is the[ Postgres Connector ](https://hasura.io/connectors/postgres).\n\n### HTTP connectors\u200b\n\nHTTP connectors are configured and deployed **independently** of your project metadata and only the URL of the deployed\nconnector is required in your metadata.\n\nWhile Hasura does not prescribe any process for deploying an HTTP connector it does provide the `connector` CLI plugin\nfor easily deploying connectors that use our SDKs. You can learn more in our[ connector deployment guide ](https://hasura.io/docs/3.0/connectors/deployment/#http-connectors).\n\nAn example of an HTTP connector is the[ SendGrid Connector ](https://hasura.io/connectors/sendgrid).\n\n## What data connectors are available?\u200b\n\nBrowse the[ Connector Hub ](https://hasura.io/connectors)for an up-to-date list of all available connectors.\n\n### What did you think of this doc?\n\n- [ What is a data connector? ](https://hasura.io/docs/3.0/connectors/introduction/#the-connector-cli-plugin/#what-is-a-data-connector)\n- [ Types of data connectors ](https://hasura.io/docs/3.0/connectors/introduction/#the-connector-cli-plugin/#types-of-data-connectors)\n    - [ Integrated connectors ](https://hasura.io/docs/3.0/connectors/introduction/#the-connector-cli-plugin/#integrated-connectors)\n\n- [ HTTP connectors ](https://hasura.io/docs/3.0/connectors/introduction/#the-connector-cli-plugin/#http-connectors)\n- [ What data connectors are available? ](https://hasura.io/docs/3.0/connectors/introduction/#the-connector-cli-plugin/#what-data-connectors-are-available)\n", "https://hasura.io/docs/3.0/ci-cd/config/#supergraph": "# Configuration\n\n## Introduction\u200b\n\nHasura v3 introduces a new configuration model for projects on the Hasura Data Delivery Network (DDN). This model relies\non three types of files:\n\n| File type | Description |\n|---|---|\n|  `hasura. yaml`  | The main configuration file. |\n|  `build-profile-*. yaml`  | Build profiles for a project. |\n|  `*. hml`  | Hasura metadata files for a project. |\n\n\n### hasura.yaml\u200b\n\nThis is the entry point to a Hasura project.\n\n```\nversion :   1\nproject :  <PROJECT_NAME >\nbuildProfiles :\n   -  build - profile.yaml\ndefaultBuildProfile :  build - profile.yaml\n```\n\nThe `version` section is used to specify the version of the configuration file. The `project` field is used to specify\nthe project name.\n\nThe `hasura.yaml` file also contains a `buildProfiles` section. This section is used to specify the build profile files\nassociated with the project. As you can see from this example, we only have one build profile, `build-profile.yaml` which is also identified as the default to use when creating a new build. **The  default  profile is required for a\nproject.** \n\n`default`\n\n### Build profiles\u200b\n\nBuild profiles tell Hasura DDN how to construct your supergraph. A build profile will contain information about the\nshared resources \u2014 such as your authentication configuration \u2014 and the resources belonging to the individual subgraphs\nthat make up your supergraph.\n\nBy default, the included `build-profile.yaml` file is populated with the following content:\n\n```\nversion :   2\nspec :\n   environment :  default\n   mode :  replace\n   supergraph :\n     resources :\n       -  supergraph/*\n   subgraphs :\n     -   name :  default\n       resources :\n         -   \"subgraphs/default/**/*.hml\"\n```\n\nHere, you can see that the `build-profile.yaml` file contains `version` and `spec` sections. The `version` section is\nused to specify the version of the configuration file.\n\nThe `spec` section contains the following fields:\n\n| Field | Description |\n|---|---|\n|  `environment`  | The environment to use for the build. |\n|  `mode`  | The mode to use for the build. `Replace` by default. |\n|  `supergraph`  | The supergraph resources to use for the build. |\n|  `subgraph`  | List of subgraphs and their resources to use for the build |\n\n\nYou can create additional build profile files for different environments you may need e.g., `staging` , `production` ,\netc. By combining build profiles which specify environments with version control, you can easily set up an effective\nCI/CD pipeline for your project.\n\nEach build profile file must be referenced by the `hasura.yaml` file in order to be used.\n\n### Supergraph\u200b\n\nYour `supergraph` directory will contain two configuration files by default: the `auth-config.hml` and `compatibility-config.hml` files.\n\nThe `auth-config.hml` file defines the authentication configuration for your supergraph i.e., the configuration for how\nthe queries to your Hasura DDN project should be authenticated. The `compatibility-config.hml` file defines the\ncompatibility date of your supergraph metadata. You'd likely not want to change the compatibility config unless you're\nsure about it.\n\n#### AuthConfig\u200b\n\n```\nkind :  AuthConfig\nversion :  v1\ndefinition :\n   allowRoleEmulationBy :  admin\n   mode :\n     webhook :\n       method :  Post\n       url :  https : //auth.pro.hasura.io/webhook/ddn ? role=admin\n```\n\nThe `AuthConfig` object is used to configure authentication for your data supergraph. You can learn more about\nauthentication in the[ Auth section ](https://hasura.io/docs/3.0/auth/overview/).\n\n#### CompatibilityConfig\u200b\n\n```\nkind :  CompatibilityConfig\ndate :   2023-10-19\n```\n\nThe `CompatibilityConfig` object is used to configure the compatibility of your metadata with Hasura.\n\n##### Compatibility Date\u200b\n\nThe `CompatibilityConfig` object contains a `date` field which opts your metadata out of all backwards incompatible\nchanges made after that date. Any backwards incompatible changes made to Hasura DDN after that date won't impact your\nmetadata.\n\nWhen starting a new project, this date should be set to today's date so that the most up-to-date behavior of Hasura is\nused.\n\nOlder projects should also periodically update the compatibility date after going over the behavioral changes that have\nhappened since that older date.\n\n### Subgraphs\u200b\n\nInside the `subgraphs` directory, each subgraph is identified by a directory with the name of the subgraph. Within that,\nwe have included three directories to get you started:\n\n```\n\u2514\u2500\u2500  < SUBGRAPH_NAME >\n\u2502       \u251c\u2500\u2500 commands\n\u2502       \u251c\u2500\u2500 dataconnectors\n\u2502       \u2514\u2500\u2500 models\n```\n\nA project is divided into one or more separate subgraphs which are referenced by a build profile.\n\nThe `default` subgraph is required and cannot be deleted.\n\nSubgraphs can be used to group together objects in your metadata in a way that makes sense for you and your team.\nMultiple `hml` files can belong to a subgraph, and you can have multiple subgraphs in a project. Objects in each hml\nfile must conform to the[ OpenDD Spec ](https://hasura.io/docs/3.0/data-domain-modeling/overview/)and[ subgraph rules ](https://hasura.io/docs/3.0/ci-cd/subgraphs/).\n\nThe CLI populates the `default` subgraph with `command` , `dataconnectors` , and `model` directories, but the organization\nof these is completely customizable by you and your team.\n\nWhat is HML?\n\nThese are both `hml` files, which is a new file format for Hasura metadata. It is a superset of the existing `yaml` format, and is designed to provide a more flexible and extensible way to define metadata. You can leverage the power of\nthe[ Hasura VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)to quickly and\neasily author `hml` files.\n\nYour `hml` files contain metadata objects according to the OpenDD spec. In the example above, we could add a `HasuraHubDataConnector` object to connect to a data source. Then, import our tables as models and create a build on\nHasura DDN.\n\nHowever, in the next section, we'll look at how to use subgraphs to organize metadata and break up our `hml` file into\nsmaller, more governable pieces.\n\n## Basic configuration\u200b\n\nWhen using the[ hasura3 CLI ](https://hasura.io/docs/3.0/cli/overview/)to create a new project, you'll run the following command:\n\n`hasura3 init --dir  .`\n\nThis will generate a new project directory in the current folder with the following structure:\n\n```\n< PROJECT_DIRECTORY >\n\u251c\u2500\u2500 build-profile.yaml\n\u251c\u2500\u2500 hasura.yaml\n\u251c\u2500\u2500 subgraphs\n\u2502   \u2514\u2500\u2500 default\n\u2502       \u251c\u2500\u2500 commands\n\u2502       \u251c\u2500\u2500 dataconnectors\n\u2502       \u2514\u2500\u2500 models\n\u2514\u2500\u2500 supergraph\n    \u251c\u2500\u2500 auth-config.hml\n    \u2514\u2500\u2500 compatibility-config.hml\n```\n\n.gitkeep\n\nYou will find empty .gitkeep files in some directories which are used to preserve empty directories in Git.\n\n## Advanced configuration\u200b\n\nLet's consider a data supergraph wherein you'd like to test your API across multiple[ environments ](https://hasura.io/docs/3.0/ci-cd/environments/). We can use subgraphs to organize our metadata and break up our `hml` file into\nsmaller, more governable pieces. We can also utilize build profiles to create different builds for different\nenvironments.\n\nImagine this file structure:\n\n```\n< PROJECT_NAME >\n\u251c\u2500\u2500 build-profile.yaml\n\u251c\u2500\u2500 build-profile-staging.yaml\n\u251c\u2500\u2500 hasura.yaml\n\u251c\u2500\u2500 subgraphs\n\u2502   \u2514\u2500\u2500 app\n\u2502       \u251c\u2500\u2500 commands\n\u2502       \u251c\u2500\u2500 dataconnectors\n\u2502           \u2514\u2500\u2500 app.hml\n\u2502       \u2514\u2500\u2500 models\n\u2502           \u251c\u2500\u2500 cart_items.hml\n\u2502           \u251c\u2500\u2500 carts.hml\n\u2502           \u251c\u2500\u2500 categories.hml\n\u2502           \u251c\u2500\u2500 coupons.hml\n\u2502           \u251c\u2500\u2500 manufactuers.hml\n\u2502           \u251c\u2500\u2500 notifications.hml\n\u2502           \u251c\u2500\u2500 orders.hml\n\u2502           \u251c\u2500\u2500 products.hml\n\u2502           \u251c\u2500\u2500 reviews.hml\n\u2502           \u2514\u2500\u2500 users.hml\n\u2514\u2500\u2500 supergraph\n    \u251c\u2500\u2500 auth-config.hml\n    \u2514\u2500\u2500 compatibility-config.hml\n```\n\n### Build profiles\u200b\n\nIn this example, we have two build profiles: `build-profile.yaml` and `build-profile-staging.yaml` . The `build-profile.yaml` file contains the following content:\n\n```\nversion :   2\nspec :\n   environment :  default\n   mode :  replace\n   supergraph :\n     resources :\n       -  supergraph/*\n   subgraphs :\n     -   name :  app\n       resources :\n         -   \"subgraphs/**/*.hml\"\n```\n\nWhereas the `build-profile-staging.yaml` file contains the following content:\n\n```\nversion :   2\nspec :\n   environment :  staging\n   mode :  replace\n   supergraph :\n     resources :\n       -  supergraph/*\n   subgraphs :\n     -   name :  app\n       resources :\n         -   \"subgraphs/**/*.hml\"\n```\n\nThe two build profiles, `build-profile.yaml` and `build-profile-staging.yaml` , are designed to cater to different\nenvironments. The `build-profile.yaml` is configured for the default environment and is set to include all subgraphs in\nthe subgraphs directory. This configuration is suitable for a general development team working on various parts of the\nproject.\n\nAs this is the default build profile, it will be used when you run the following command:\n\n`hasura3 build create`\n\nOn the other hand, `build-profile-staging.yaml` is specifically configured for the staging environment and is intended\nfor testing with other staging services.\n\nYou can create a build with this profile by running the following command:\n\n`hasura3 build create --profile build-profile-staging.yaml`\n\n### hasura.yaml\u200b\n\nThe `hasura.yaml` in the root of the project contains the following content:\n\n```\nversion :   1\nproject :  <PROJECT_NAME >\nbuildProfiles :\n   -  ./build - profile.yaml\n   -  ./build - profile - staging.yaml\ndefaultBuildProfile :  build - profile.yaml\n```\n\nThis lets Hasura DDN know that we have two build profiles, and that the `build-profile.yaml` is the default to use when\ncreating a new build.\n\n### Custom Directory Structure\u200b\n\nYou could choose to deviate from the default directory structure that the Hasura project initializes for you into one\nthat suits you and your team's needs.\n\nFor example, you could have a single file with all the metadata objects, including your `HasuraHubDataConnector` objects, models, and commands, as long as you specify that file to be in your subgraph resources in the build profile.\nHowever, this would be difficult to manage and maintain.\n\nYou could also choose to arrange your subgraphs by data type. E.g., `subgraphs/default/users` , `subgraphs/defaultproducts` , etc.\n\nThe contents of the `hml` files can be that of any valid OpenDD metadata object as long as they conform to the rules of[ subgraphs ](https://hasura.io/docs/3.0/ci-cd/subgraphs/).\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#introduction)\n    - [ hasura.yaml ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#hasurayaml)\n\n- [ Build profiles ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#build-profiles)\n\n- [ Supergraph ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#supergraph)\n\n- [ Subgraphs ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#subgraphs)\n- [ Basic configuration ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#basic-configuration)\n- [ Advanced configuration ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#advanced-configuration)\n    - [ Build profiles ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#build-profiles-1)\n\n- [ hasura.yaml ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#hasurayaml-1)\n\n- [ Custom Directory Structure ](https://hasura.io/docs/3.0/ci-cd/config/#supergraph/#custom-directory-structure)\n", "https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector": "# OpenDD Data Connectors\n\n## Introduction\u200b\n\nA data connector is a way to specify where your data comes from and how it can be used. It can connect to various types\nof data sources, like SQL databases, NoSQL databases, REST APIs, GraphQL APIs, files, and more.\n\nYou can declare a data connector and use it in your[ model's ](https://hasura.io/docs/3.0/data-domain-modeling/models/)configuration\nby[ referencing it with the source ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source)property, which connects that model to\nthe respective data connector.\n\nIn the Open Data Domain Specification (OpenDD spec), you can connect to data sources through a `DataConnector` or a `HasuraHubDataConnector` .\n\n## DataConnector\u200b\n\nTo create a data connector object, you will need to define an object with `kind: DataConnector` and `version: v1` .\nThe object `definition` should include four fields: `name` , `url` , `headers` and `schema` .\n\n```\nkind :  DataConnector\nversion :  v2\ndefinition :\n   name :  <DataConnectorName >\n   url :  <DataConnectorURL >\n   headers :  <DataConnectorHeaders >\n   schema :  <SchemaResponse >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the Data Connector. |\n|  `url`  | [ DataConnectorURL ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#dataconnectorurl) | true | URL to access the data connector. |\n|  `headers`  | [ DataConnectorHeaders ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#dataconnectorheaders) | true | Request headers to pass on to the data connector. |\n|  `schema`  | [ SchemaResponse ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#schemaresponse) | true | The schema response from the data connector. This includes `scalar_ types` , `object_ type` , `collections` , `functions` and `procedures` . |\n\n\n### DataConnectorURL\u200b\n\n `DataConnectorURL` is an object that either defines a single URL for the data connector or separate read/write URLs\nfor the data connector. For example, it can take either of the following\n\n```\nurl :\n   singleUrl :  <URL as Secret >\n```\n\n```\nurl :\n   read :  <URL as Secret >\n   write :  <URL as Secret >\n```\n\nThe[ secret syntax ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret)should be used for URLs.\n\nRead/Write URLs are used to access the appropriate data connector based on the GraphQL operation type. For example, if\nthe operation type is `Query` or `Subscription` , then the `read` URL will be used to access the data connector.\nSimilarly, for a `Mutation` operation, the `write` URL will be used.\n\n### DataConnectorHeaders\u200b\n\n `DataConnectorHeaders` is an object that defines the headers to be forwarded to the data connector when making requests.\nThe keys of this object are header names and the values are the header values in the[ secret syntax ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret).\nE.g., if a bearer authorization token needs to be forwarded, the headers field would be:\n\n```\nheaders :\n   Authorization :\n     value :  Bearer <token >\n```\n\nor if the header is coming from a secret:\n\n```\nheaders:\n  Authorization:\n    stringValueFromSecret: <secret name>\n```\n\n### SchemaResponse\u200b\n\n `SchemaResponse` is an object that defines the types, schema, functions, etc. of the data connector. This is usually\nprovided by the `/schema` endpoint of the data connector. It contains the following fields:\n\n```\nschema :\n   scalar_types :  <ScalarTypes >\n   object_types :  <ObjectTypes >\n   collections :  <Collections >\n   functions :  <Functions >\n   procedures :  <Procedures >\n```\n\nThe structure and detailed documentation of these fields can be found[ here ](https://hasura.github.io/ndc-spec/specification/schema/index.html).\n\n### Example\u200b\n\nIn this example, we'll create a data connector for the Chinook data set. The Chinook data set is a sample database that\nrepresents a digital media store, including tables for artists, albums, tracks, and more. Each object we reference above\nis present in the complete example below:\n\n```\nkind :  DataConnector\nversion :  v2\ndefinition :\n   name :  my_data_connector\n   url :\n     singleUrl :\n       value :  http : //localhost : 8080\n   schema :\n     scalar_types :\n       String :\n         aggregate_functions :   { }\n         comparison_operators :\n           like :\n             argument_type :\n               type :  named\n               name :  String\n         update_operators :   { }\n       Int :\n         aggregate_functions :\n           min :\n             result_type :\n               type :  nullable\n               underlying_type :\n                 type :  named\n                 name :  Int\n           max :\n             result_type :\n               type :  nullable\n               underlying_type :\n                 type :  named\n                 name :  Int\n         comparison_operators :   { }\n         update_operators :   { }\n     object_types :\n       Artist :\n         description :  An artist\n         fields :\n           ArtistId :\n             description :  The artist's primary key\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n           Name :\n             description :  The artist's name\n             arguments :   { }\n             type :\n               type :  named\n               name :  String\n       Album :\n         description :  An album\n         fields :\n           AlbumId :\n             description :  The album's primary key\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n           Title :\n             description :  The album's title\n             arguments :   { }\n             type :\n               type :  named\n               name :  String\n           ArtistId :\n             description :  The album's artist ID\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n       Track :\n         description :  A track\n         fields :\n           TrackId :\n             description :  The track's primary key\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n           Name :\n             description :  The track's name\n             arguments :   { }\n             type :\n               type :  named\n               name :  String\n           AlbumId :\n             description :  The track's album ID\n             arguments :   { }\n             type :\n               type :  named\n               name :  Int\n       artist_below_id :\n         description :  An artist\n         fields :\n           ArtistId :\n             description :  The artist's primary key\n             arguments :\n               id :\n                 description :  The cyling id\n                 type :\n                   type :  named\n                   name :  Int\n             type :\n               type :  named\n               name :  Int\n           Name :\n             description :  The artist's name\n             arguments :   { }\n             type :\n               type :  named\n               name :  String\n     collections :\n       -   name :  Artist\n         description :  A collection of artists\n         arguments :   { }\n         type :  Artist\n         deletable :   false\n         uniqueness_constraints :\n           ArtistById :\n             unique_columns :\n               -  ArtistId\n         foreign_keys :   { }\n       -   name :  Album\n         description :  A collection of albums\n         arguments :   { }\n         type :  Album\n         deletable :   false\n         uniqueness_constraints :\n           AlbumById :\n             unique_columns :\n               -  AlbumId\n         foreign_keys :   { }\n       -   name :  Track\n         description :  A collection of tracks\n         arguments :   { }\n         type :  Track\n         deletable :   false\n         uniqueness_constraints :\n           TrackById :\n             unique_columns :\n               -  TrackId\n         foreign_keys :   { }\n       -   name :  artist_below_id\n         description :  A collection of artists below a certain id\n         arguments :\n           id :\n             description :  The ceiling id\n             type :\n               type :  named\n               name :  Int\n         type :  Artist\n         deletable :   false\n         uniqueness_constraints :   { }\n         foreign_keys :   { }\n     functions :   [ ]\n     procedures :   [ ]\n```\n\n## HasuraHubDataConnector\u200b\n\nInstead of deploying your own data connector, Hasura metadata also allows you to directly configure and use one of the standard data connectors from the[ Connector Hub ](https://hasura.io/connectors/).\n\n### Metadata Object\u200b\n\nTo configure a HasuraHubDataConnector, you will need to add the following metadata object:\n\n```\nkind :  HasuraHubDataConnector\nversion :  v1\ndefinition :\n   name :  <DataConnectorName >\n   connectorId :  <HasuraHubConnectorId >\n   connectorConfiguration :  <ConnectorConfigurations >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the Data Connector. |\n|  `connectorId`  |  `String`  | true | The Connector Hub ID of the connector to configure. Currently, only `hasura/postgres` is supported. |\n|  `connectorConfiguration`  | [[ ConnectorConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#connectorConfiguration)] | true | The configurations to deploy the connector, one for every region that the connector should be deployed in. |\n\n\n#### ConnectorConfiguration\u200b\n\nConnectorConfiguration defines the configuration to deploy a connector in a particular region.\nTypically, you want to deploy the connector in a region that's closest to your database. The NDC schemas for deployments across all regions must be identical.\n\nThe structure of ConnectorConfiguration is as follows:\n\n```\nregion :  <String >\nmode :  <ReadOnly / ReadWrite / WriteOnly >\nconfiguration :  <Connector specific configuration >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `region`  |  `String`  | true | Name of the cloud region. Eg: gcp-asia-south1 |\n|  `mode`  |  `String`  | true | Whether this connector should support reads only, writes only, or both. |\n|  `connectorConfiguration`  |  `Any`  | true | The configuration specific to the connector ID you chose from the Hub. |\n\n\n### Example\u200b\n\nIn this example we are configuring a postgres data connector using a postgres database URL in a single region.\n\n```\nkind :  HasuraHubDataConnector\nversion :  v1\ndefinition :\n   name :  foo\n   connectorId :  hasura/postgres\n   connectorConfiguration :\n     -   region :  gcp - asia - south1\n       mode :  ReadWrite\n       configuration :\n         version :   1\n         connectionUri :\n           uri :\n             value :  postgres : //username : password@database - host/database_name\n         metadata :  < ... >\n```\n\nAfter populating the URL, typically, the rest of configuration will be automatically authored through tooling (eg: Hasura VSCode extension).\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#introduction)\n- [ DataConnector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#dataconnector)\n    - [ DataConnectorURL ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#dataconnectorurl)\n\n- [ DataConnectorHeaders ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#dataconnectorheaders)\n\n- [ SchemaResponse ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#schemaresponse)\n\n- [ Example ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#example)\n- [ HasuraHubDataConnector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#hasura-hub-data-connector)\n    - [ Metadata Object ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#metadata-object)\n        - [ ConnectorConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#connectorConfiguration)\n\n- [ Example ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#example-1)\n\n- [ Metadata Object ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#metadata-object)\n    - [ ConnectorConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/#hasura-hub-data-connector/#connectorConfiguration)\n", "https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types": "# OpenDD Types\n\n## Introduction\u200b\n\nIn the OpenDD spec in Hasura, types serve as the fundamental elements that define the structure of your data.\n\nBeing able to define types in your data domain is beneficial because it provides you with the flexibility to define them\nseparately from the types in your data connector.\n\nThe specification employs a concrete type system that includes both primitive types and user-defined types. All\nsubsequent layers, such as models, commands, and relationships are defined in terms of these types.\n\nThe types can be one of the following:\n\n| OpenDD Type | Description |\n|---|---|\n| Primitive | These are the basic types `ID` , `Int` , `Float` , `Boolean` , or `String`  |\n| Custom | These are user-defined types, such as[ ScalarType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#scalar-types)or[ ObjectType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#object-types) |\n| Type References | When specifying the types of a field or an argument, you can mark them as required `!` or repeated `[]` . |\n\n\nThe spec also allows you to map existing data connector scalars to types in your data domain.\n\nYou can also define custom types by either aliasing existing types (such as primitives or custom), or you can define a\ntype with fields. In turn, the fields themselves can be a primitive or another custom type.\n\nType references are types of fields and arguments that refer to other primitive or custom types and which can be marked\nas nullable, required or repeated (in the case of arrays).\n\n[ Scalar type representation ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#scalar-type-representation)helps in mapping data connector scalars to any of the OpenDD\ntypes.\n\n## Primitive types and type references\u200b\n\nPrimitive types supported by the OpenDD spec are `ID` , `Int` , `Float` , `Boolean` and `String` .\n\nType references in OpenDD follow[ GraphQL type\nsyntax ](https://spec.graphql.org/June2018/#sec-Combining-List-and-Non-Null). Fields and arguments are nullable by\ndefault. To represent non-nullability, specify a `!` after the type name. Similarly, array fields and arguments are\nwrapped in `[]` .\n\n### Examples\u200b\n\nIf the field is nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory\n```\n\nIf the field is non-nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory !\n```\n\nIf the field is a nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ]\n```\n\nIf the field is a nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ]\n```\n\nIf the field is a non-nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ] !\n```\n\nIf the field is a non-nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ] !\n```\n\n## Scalar types\u200b\n\nIn the OpenDD spec, you can create opaque types whose semantics are unknown to OpenDD by defining an object with `kind:\nScalarType` and `version: v1` . These show up as scalars in your GraphQL schema. The object `definition` should include `name` and an optional `graphql` field.\n\n### Metadata structure\u200b\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   graphql :  <ScalarTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `graphql`  | [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#scalartypegraphqlconfig) | false | Configuration for using this scalar type in the GraphQL API. |\n\n\n#### ScalarTypeGraphQLConfig\u200b\n\n `ScalarTypeGraphQLConfig` is an object that defines the configuration for using this scalar type in the GraphQL API.\nAll scalar types are represented as custom[ GraphQL scalars ](https://graphql.org/learn/schema/#scalar-types)in the resulting GraphQL API.\nThis object has a field `typeName` that corresponds to the GraphQL type name to use for this scalar type.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\nBelow, we define an `Email` type that is represented as a primitive `String` type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  Email\n   graphql :\n     typeName :  EmailScalar\n```\n\nBelow, we define an `OpaqueDate` type that is represented as a custom object type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  OpaqueDate\n```\n\n## Object types\u200b\n\nIn the OpenDD spec, completely new types can be created by defining an object with `kind: ObjectType` and `version: v1` .\nYou need to also define a name and the fields for this type.\n\n### Metadata structure\u200b\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   fields :\n     -   name :  field1\n       type :  <TypeReference >\n     -   name :  field2\n       type :  <TypeReference >\n   globalIdFields :\n     -  field1\n   graphql :  <ObjectTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `fields`  | [ [Field] ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#field) | true | List of fields. |\n|  `globalIdFields`  |  `[String]`  | false | Names of the fields that will form the Global ID associated with the object type. |\n|  `graphql`  | [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#objecttypegraphqlconfig) | false | Configuration for using this object type in the GraphQL API. |\n\n\n#### Field\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the field. |\n|  `type`  |  `String`  | true | Type reference of the field. |\n\n\n#### ObjectTypeGraphQLConfig\u200b\n\n `ObjectTypeGraphQLConfig` is config that defines the configuration for using this object type in the GraphQL API.\nWhen used in an output context, a[ GraphQL object type ](https://graphql.org/learn/schema/#object-types-and-fields)is generated for each OpenDD object. `ObjectTypeGraphQLConfig` has a field `typeName` that corresponds to the GraphQL type name to use for this OpenDD object type.\nThe fields of this generated GraphQL object type will have the same names as the OpenDD field names. The generated GraphQL field types\nwill also pick the nullability and repeated characteristics based on the OpenDD type reference for the field.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Below, we define an `author` type that has three fields: `author_id` , `first_name` , and `last_name` . Each field is\nrepresented as a primitive `Int` or `String` type. The `author_id` field is non-nullable whereas `first_name` and `last_name` fields are nullable.\nWhen used in the GraphQL API in an output context, this will result in a GraphQL object type called `Author` .\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n```\n\n1. Extending the `author` type to also have a Global ID field\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n   globalIdFields :\n     -  author_id\n```\n\nNow, the `Author` GraphQL type will have an auto-generated `id` field that is a globally\nunique ID across your data domain, which will be based on the `author_id` field of `artist` .\nThe `node` query root field of the Relay API can then be used to retrieve this global ID,\ngiven there is a model whose `objectType` is `artist` and it is set as the `globalIdSource` .\n\n## Scalar type representation for data connectors\u200b\n\nA scalar type from a data connector can be represented as an OpenDD type by defining an object with `kind: DataConnectorScalarRepresentation` and `version: v1` . To define a scalar type representation, you need to\nhave a data connector name, a data connector scalar type, a type representation and an optional graphql field.\n\nMap scalars for user in your GraphQL API\n\nIt is necessary to map **any** available scalar from a data connector that is used in the GraphQL API.\n\n### Metadata structure\u200b\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  <DataSourceName >\n   dataConnectorScalarType :  <ScalarTypeName >\n   representation :  <TypeName >\n   graphql :  <DataConnectorScalarGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnectorName`  |  `String`  | true | Name of the data connector. |\n|  `dataConnectorScalarType`  |  `String`  | true | Name of the scalar type from the data connector. |\n|  `representation`  |  `String`  | true | Representation of the scalar type in GraphQL schema. |\n|  `graphql`  | [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#dcscalargraphqlconfig) | false | Configuration for using this data connector scalar type in the GraphQL API. |\n\n\n#### DCScalarGraphQLConfig\u200b\n\n `DCScalarGraphQLConfig` is an object that defines the configuration for using this data connector scalar type in the\nGraphQL API. This object has a field `comparisonExpressionTypeName` that corresponds to the GraphQL type name to use for\nthe comparison expression input type that is generated for this data connector scalar type. This comparison expression type\nwill contain the comparison operators for this scalar as defined by the data connector.\n\n```\ngraphql :\n   comparisonExpressionTypeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Mapping a `text` scalar type from the `my_source` connector to a primitive `String` type and giving its GraphQL comparison expression a type name.\n\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  my_source\n   dataConnectorScalarType :  text\n   representation :  String\n   graphql :\n     comparisonExpressionTypeName :  text_comparison_exp\n```\n\n1. Mapping a PostgreSQL scalar `geography` to a custom object type.\n\n\n```\n-   kind :  ObjectType\n   version :  v1\n   definition :\n     name :  Geography\n     fields :\n       -   name :  type\n         type :  String\n       -   name :  coordinates\n         type :   [ Float ]\n-   kind :  DataConnectorScalarRepresentation\n   version :  v1\n   definition :\n     dataConnectorName :  pg_source\n     dataConnectorScalarType :  geography\n     representation :  Geography\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#introduction)\n- [ Primitive types and type references ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#primitive-types-and-type-references)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#examples)\n- [ Scalar types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#scalar-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#metadata-structure)\n        - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#scalartypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#examples-1)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#metadata-structure)\n    - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#scalartypegraphqlconfig)\n- [ Object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#object-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#metadata-structure-1)\n        - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#field)\n\n- [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#objecttypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#object-type-examples)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#metadata-structure-1)\n    - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#field)\n- [ Scalar type representation for data connectors ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#scalar-type-representation)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#metadata-structure-2)\n        - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#dcscalargraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#metadata-structure-2)\n    - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-types/#dcscalargraphqlconfig)\n", "https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types": "# OpenDD Types\n\n## Introduction\u200b\n\nIn the OpenDD spec in Hasura, types serve as the fundamental elements that define the structure of your data.\n\nBeing able to define types in your data domain is beneficial because it provides you with the flexibility to define them\nseparately from the types in your data connector.\n\nThe specification employs a concrete type system that includes both primitive types and user-defined types. All\nsubsequent layers, such as models, commands, and relationships are defined in terms of these types.\n\nThe types can be one of the following:\n\n| OpenDD Type | Description |\n|---|---|\n| Primitive | These are the basic types `ID` , `Int` , `Float` , `Boolean` , or `String`  |\n| Custom | These are user-defined types, such as[ ScalarType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#scalar-types)or[ ObjectType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#object-types) |\n| Type References | When specifying the types of a field or an argument, you can mark them as required `!` or repeated `[]` . |\n\n\nThe spec also allows you to map existing data connector scalars to types in your data domain.\n\nYou can also define custom types by either aliasing existing types (such as primitives or custom), or you can define a\ntype with fields. In turn, the fields themselves can be a primitive or another custom type.\n\nType references are types of fields and arguments that refer to other primitive or custom types and which can be marked\nas nullable, required or repeated (in the case of arrays).\n\n[ Scalar type representation ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#scalar-type-representation)helps in mapping data connector scalars to any of the OpenDD\ntypes.\n\n## Primitive types and type references\u200b\n\nPrimitive types supported by the OpenDD spec are `ID` , `Int` , `Float` , `Boolean` and `String` .\n\nType references in OpenDD follow[ GraphQL type\nsyntax ](https://spec.graphql.org/June2018/#sec-Combining-List-and-Non-Null). Fields and arguments are nullable by\ndefault. To represent non-nullability, specify a `!` after the type name. Similarly, array fields and arguments are\nwrapped in `[]` .\n\n### Examples\u200b\n\nIf the field is nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory\n```\n\nIf the field is non-nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory !\n```\n\nIf the field is a nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ]\n```\n\nIf the field is a nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ]\n```\n\nIf the field is a non-nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ] !\n```\n\nIf the field is a non-nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ] !\n```\n\n## Scalar types\u200b\n\nIn the OpenDD spec, you can create opaque types whose semantics are unknown to OpenDD by defining an object with `kind:\nScalarType` and `version: v1` . These show up as scalars in your GraphQL schema. The object `definition` should include `name` and an optional `graphql` field.\n\n### Metadata structure\u200b\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   graphql :  <ScalarTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `graphql`  | [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#scalartypegraphqlconfig) | false | Configuration for using this scalar type in the GraphQL API. |\n\n\n#### ScalarTypeGraphQLConfig\u200b\n\n `ScalarTypeGraphQLConfig` is an object that defines the configuration for using this scalar type in the GraphQL API.\nAll scalar types are represented as custom[ GraphQL scalars ](https://graphql.org/learn/schema/#scalar-types)in the resulting GraphQL API.\nThis object has a field `typeName` that corresponds to the GraphQL type name to use for this scalar type.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\nBelow, we define an `Email` type that is represented as a primitive `String` type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  Email\n   graphql :\n     typeName :  EmailScalar\n```\n\nBelow, we define an `OpaqueDate` type that is represented as a custom object type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  OpaqueDate\n```\n\n## Object types\u200b\n\nIn the OpenDD spec, completely new types can be created by defining an object with `kind: ObjectType` and `version: v1` .\nYou need to also define a name and the fields for this type.\n\n### Metadata structure\u200b\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   fields :\n     -   name :  field1\n       type :  <TypeReference >\n     -   name :  field2\n       type :  <TypeReference >\n   globalIdFields :\n     -  field1\n   graphql :  <ObjectTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `fields`  | [ [Field] ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#field) | true | List of fields. |\n|  `globalIdFields`  |  `[String]`  | false | Names of the fields that will form the Global ID associated with the object type. |\n|  `graphql`  | [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#objecttypegraphqlconfig) | false | Configuration for using this object type in the GraphQL API. |\n\n\n#### Field\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the field. |\n|  `type`  |  `String`  | true | Type reference of the field. |\n\n\n#### ObjectTypeGraphQLConfig\u200b\n\n `ObjectTypeGraphQLConfig` is config that defines the configuration for using this object type in the GraphQL API.\nWhen used in an output context, a[ GraphQL object type ](https://graphql.org/learn/schema/#object-types-and-fields)is generated for each OpenDD object. `ObjectTypeGraphQLConfig` has a field `typeName` that corresponds to the GraphQL type name to use for this OpenDD object type.\nThe fields of this generated GraphQL object type will have the same names as the OpenDD field names. The generated GraphQL field types\nwill also pick the nullability and repeated characteristics based on the OpenDD type reference for the field.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Below, we define an `author` type that has three fields: `author_id` , `first_name` , and `last_name` . Each field is\nrepresented as a primitive `Int` or `String` type. The `author_id` field is non-nullable whereas `first_name` and `last_name` fields are nullable.\nWhen used in the GraphQL API in an output context, this will result in a GraphQL object type called `Author` .\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n```\n\n1. Extending the `author` type to also have a Global ID field\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n   globalIdFields :\n     -  author_id\n```\n\nNow, the `Author` GraphQL type will have an auto-generated `id` field that is a globally\nunique ID across your data domain, which will be based on the `author_id` field of `artist` .\nThe `node` query root field of the Relay API can then be used to retrieve this global ID,\ngiven there is a model whose `objectType` is `artist` and it is set as the `globalIdSource` .\n\n## Scalar type representation for data connectors\u200b\n\nA scalar type from a data connector can be represented as an OpenDD type by defining an object with `kind: DataConnectorScalarRepresentation` and `version: v1` . To define a scalar type representation, you need to\nhave a data connector name, a data connector scalar type, a type representation and an optional graphql field.\n\nMap scalars for user in your GraphQL API\n\nIt is necessary to map **any** available scalar from a data connector that is used in the GraphQL API.\n\n### Metadata structure\u200b\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  <DataSourceName >\n   dataConnectorScalarType :  <ScalarTypeName >\n   representation :  <TypeName >\n   graphql :  <DataConnectorScalarGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnectorName`  |  `String`  | true | Name of the data connector. |\n|  `dataConnectorScalarType`  |  `String`  | true | Name of the scalar type from the data connector. |\n|  `representation`  |  `String`  | true | Representation of the scalar type in GraphQL schema. |\n|  `graphql`  | [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#dcscalargraphqlconfig) | false | Configuration for using this data connector scalar type in the GraphQL API. |\n\n\n#### DCScalarGraphQLConfig\u200b\n\n `DCScalarGraphQLConfig` is an object that defines the configuration for using this data connector scalar type in the\nGraphQL API. This object has a field `comparisonExpressionTypeName` that corresponds to the GraphQL type name to use for\nthe comparison expression input type that is generated for this data connector scalar type. This comparison expression type\nwill contain the comparison operators for this scalar as defined by the data connector.\n\n```\ngraphql :\n   comparisonExpressionTypeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Mapping a `text` scalar type from the `my_source` connector to a primitive `String` type and giving its GraphQL comparison expression a type name.\n\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  my_source\n   dataConnectorScalarType :  text\n   representation :  String\n   graphql :\n     comparisonExpressionTypeName :  text_comparison_exp\n```\n\n1. Mapping a PostgreSQL scalar `geography` to a custom object type.\n\n\n```\n-   kind :  ObjectType\n   version :  v1\n   definition :\n     name :  Geography\n     fields :\n       -   name :  type\n         type :  String\n       -   name :  coordinates\n         type :   [ Float ]\n-   kind :  DataConnectorScalarRepresentation\n   version :  v1\n   definition :\n     dataConnectorName :  pg_source\n     dataConnectorScalarType :  geography\n     representation :  Geography\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#introduction)\n- [ Primitive types and type references ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#primitive-types-and-type-references)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#examples)\n- [ Scalar types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#scalar-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#metadata-structure)\n        - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#scalartypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#examples-1)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#metadata-structure)\n    - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#scalartypegraphqlconfig)\n- [ Object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#object-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#metadata-structure-1)\n        - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#field)\n\n- [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#objecttypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#object-type-examples)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#metadata-structure-1)\n    - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#field)\n- [ Scalar type representation for data connectors ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#scalar-type-representation)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#metadata-structure-2)\n        - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#dcscalargraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#metadata-structure-2)\n    - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-types/#dcscalargraphqlconfig)\n", "https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation": "# OpenDD Types\n\n## Introduction\u200b\n\nIn the OpenDD spec in Hasura, types serve as the fundamental elements that define the structure of your data.\n\nBeing able to define types in your data domain is beneficial because it provides you with the flexibility to define them\nseparately from the types in your data connector.\n\nThe specification employs a concrete type system that includes both primitive types and user-defined types. All\nsubsequent layers, such as models, commands, and relationships are defined in terms of these types.\n\nThe types can be one of the following:\n\n| OpenDD Type | Description |\n|---|---|\n| Primitive | These are the basic types `ID` , `Int` , `Float` , `Boolean` , or `String`  |\n| Custom | These are user-defined types, such as[ ScalarType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#scalar-types)or[ ObjectType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#object-types) |\n| Type References | When specifying the types of a field or an argument, you can mark them as required `!` or repeated `[]` . |\n\n\nThe spec also allows you to map existing data connector scalars to types in your data domain.\n\nYou can also define custom types by either aliasing existing types (such as primitives or custom), or you can define a\ntype with fields. In turn, the fields themselves can be a primitive or another custom type.\n\nType references are types of fields and arguments that refer to other primitive or custom types and which can be marked\nas nullable, required or repeated (in the case of arrays).\n\n[ Scalar type representation ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#scalar-type-representation)helps in mapping data connector scalars to any of the OpenDD\ntypes.\n\n## Primitive types and type references\u200b\n\nPrimitive types supported by the OpenDD spec are `ID` , `Int` , `Float` , `Boolean` and `String` .\n\nType references in OpenDD follow[ GraphQL type\nsyntax ](https://spec.graphql.org/June2018/#sec-Combining-List-and-Non-Null). Fields and arguments are nullable by\ndefault. To represent non-nullability, specify a `!` after the type name. Similarly, array fields and arguments are\nwrapped in `[]` .\n\n### Examples\u200b\n\nIf the field is nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory\n```\n\nIf the field is non-nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory !\n```\n\nIf the field is a nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ]\n```\n\nIf the field is a nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ]\n```\n\nIf the field is a non-nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ] !\n```\n\nIf the field is a non-nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ] !\n```\n\n## Scalar types\u200b\n\nIn the OpenDD spec, you can create opaque types whose semantics are unknown to OpenDD by defining an object with `kind:\nScalarType` and `version: v1` . These show up as scalars in your GraphQL schema. The object `definition` should include `name` and an optional `graphql` field.\n\n### Metadata structure\u200b\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   graphql :  <ScalarTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `graphql`  | [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#scalartypegraphqlconfig) | false | Configuration for using this scalar type in the GraphQL API. |\n\n\n#### ScalarTypeGraphQLConfig\u200b\n\n `ScalarTypeGraphQLConfig` is an object that defines the configuration for using this scalar type in the GraphQL API.\nAll scalar types are represented as custom[ GraphQL scalars ](https://graphql.org/learn/schema/#scalar-types)in the resulting GraphQL API.\nThis object has a field `typeName` that corresponds to the GraphQL type name to use for this scalar type.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\nBelow, we define an `Email` type that is represented as a primitive `String` type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  Email\n   graphql :\n     typeName :  EmailScalar\n```\n\nBelow, we define an `OpaqueDate` type that is represented as a custom object type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  OpaqueDate\n```\n\n## Object types\u200b\n\nIn the OpenDD spec, completely new types can be created by defining an object with `kind: ObjectType` and `version: v1` .\nYou need to also define a name and the fields for this type.\n\n### Metadata structure\u200b\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   fields :\n     -   name :  field1\n       type :  <TypeReference >\n     -   name :  field2\n       type :  <TypeReference >\n   globalIdFields :\n     -  field1\n   graphql :  <ObjectTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `fields`  | [ [Field] ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#field) | true | List of fields. |\n|  `globalIdFields`  |  `[String]`  | false | Names of the fields that will form the Global ID associated with the object type. |\n|  `graphql`  | [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#objecttypegraphqlconfig) | false | Configuration for using this object type in the GraphQL API. |\n\n\n#### Field\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the field. |\n|  `type`  |  `String`  | true | Type reference of the field. |\n\n\n#### ObjectTypeGraphQLConfig\u200b\n\n `ObjectTypeGraphQLConfig` is config that defines the configuration for using this object type in the GraphQL API.\nWhen used in an output context, a[ GraphQL object type ](https://graphql.org/learn/schema/#object-types-and-fields)is generated for each OpenDD object. `ObjectTypeGraphQLConfig` has a field `typeName` that corresponds to the GraphQL type name to use for this OpenDD object type.\nThe fields of this generated GraphQL object type will have the same names as the OpenDD field names. The generated GraphQL field types\nwill also pick the nullability and repeated characteristics based on the OpenDD type reference for the field.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Below, we define an `author` type that has three fields: `author_id` , `first_name` , and `last_name` . Each field is\nrepresented as a primitive `Int` or `String` type. The `author_id` field is non-nullable whereas `first_name` and `last_name` fields are nullable.\nWhen used in the GraphQL API in an output context, this will result in a GraphQL object type called `Author` .\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n```\n\n1. Extending the `author` type to also have a Global ID field\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n   globalIdFields :\n     -  author_id\n```\n\nNow, the `Author` GraphQL type will have an auto-generated `id` field that is a globally\nunique ID across your data domain, which will be based on the `author_id` field of `artist` .\nThe `node` query root field of the Relay API can then be used to retrieve this global ID,\ngiven there is a model whose `objectType` is `artist` and it is set as the `globalIdSource` .\n\n## Scalar type representation for data connectors\u200b\n\nA scalar type from a data connector can be represented as an OpenDD type by defining an object with `kind: DataConnectorScalarRepresentation` and `version: v1` . To define a scalar type representation, you need to\nhave a data connector name, a data connector scalar type, a type representation and an optional graphql field.\n\nMap scalars for user in your GraphQL API\n\nIt is necessary to map **any** available scalar from a data connector that is used in the GraphQL API.\n\n### Metadata structure\u200b\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  <DataSourceName >\n   dataConnectorScalarType :  <ScalarTypeName >\n   representation :  <TypeName >\n   graphql :  <DataConnectorScalarGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnectorName`  |  `String`  | true | Name of the data connector. |\n|  `dataConnectorScalarType`  |  `String`  | true | Name of the scalar type from the data connector. |\n|  `representation`  |  `String`  | true | Representation of the scalar type in GraphQL schema. |\n|  `graphql`  | [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#dcscalargraphqlconfig) | false | Configuration for using this data connector scalar type in the GraphQL API. |\n\n\n#### DCScalarGraphQLConfig\u200b\n\n `DCScalarGraphQLConfig` is an object that defines the configuration for using this data connector scalar type in the\nGraphQL API. This object has a field `comparisonExpressionTypeName` that corresponds to the GraphQL type name to use for\nthe comparison expression input type that is generated for this data connector scalar type. This comparison expression type\nwill contain the comparison operators for this scalar as defined by the data connector.\n\n```\ngraphql :\n   comparisonExpressionTypeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Mapping a `text` scalar type from the `my_source` connector to a primitive `String` type and giving its GraphQL comparison expression a type name.\n\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  my_source\n   dataConnectorScalarType :  text\n   representation :  String\n   graphql :\n     comparisonExpressionTypeName :  text_comparison_exp\n```\n\n1. Mapping a PostgreSQL scalar `geography` to a custom object type.\n\n\n```\n-   kind :  ObjectType\n   version :  v1\n   definition :\n     name :  Geography\n     fields :\n       -   name :  type\n         type :  String\n       -   name :  coordinates\n         type :   [ Float ]\n-   kind :  DataConnectorScalarRepresentation\n   version :  v1\n   definition :\n     dataConnectorName :  pg_source\n     dataConnectorScalarType :  geography\n     representation :  Geography\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#introduction)\n- [ Primitive types and type references ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#primitive-types-and-type-references)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#examples)\n- [ Scalar types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#scalar-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#metadata-structure)\n        - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#scalartypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#examples-1)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#metadata-structure)\n    - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#scalartypegraphqlconfig)\n- [ Object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#object-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#metadata-structure-1)\n        - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#field)\n\n- [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#objecttypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#object-type-examples)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#metadata-structure-1)\n    - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#field)\n- [ Scalar type representation for data connectors ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#scalar-type-representation)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#metadata-structure-2)\n        - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#dcscalargraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#metadata-structure-2)\n    - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#scalar-type-representation/#dcscalargraphqlconfig)\n", "https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions": "# OpenDD Permissions\n\n## Introduction\u200b\n\nThe OpenDD Spec lets you define permissions, (also known as access control or authorization rules) on[ object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/),[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)in your data domain.\n\nThe following types of permissions can be defined in the[ OpenDD spec ](https://hasura.io/docs/3.0/data-domain-modeling/overview/):\n\n- `TypePermissions` define which fields are allowed to be accessed by a role. Defining permissions on output types is\nuseful, as certain fields may be sensitive and should only be accessible to particular roles.\n- `ModelPermissions` define which objects or rows within a model are allowed to be accessed by a role.\n- `CommandPermissions` defines whether the command is executable by a role.\n\n\n## Type permissions\u200b\n\nA type permission will need the type and the role(s) for which the permission should be defined. For each role, you will\nneed to define the fields accessible for that role.\n\n### Metadata Structure\u200b\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  <TypeName >\n   permissions :  <TypePermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `typeName`  | [ TypeName ](https://hasura.io/docs/3.0/data-domain-modeling/types/) | true | The name of the type for which permissions are to be defined. |\n|  `permissions`  | [ [TypePermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#typepermission) | true | The permissions object for this type, one for each role. |\n\n\n#### TypePermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     output :  <OutputPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `output`  | [ OutputPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#outputpermission) | true | The type output permission for the role. |\n\n\n#### OutputPermission\u200b\n\n```\noutput :\n   allowedFields :\n     -  <field1 >\n     -  <field2 >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `allowedFields`  |  `[String]`  | true | List of fields that are accessible to the role. |\n\n\n### Examples\u200b\n\nTo define permissions on an output type `article` for `admin` and `user` role:\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  article\n   permissions :\n     -   role :  admin\n       output :\n         allowedFields :\n           -  id\n           -  title\n           -  author_id\n     -   role :  user\n       output :\n         allowedFields :\n           -  id\n           -  title\n```\n\nTypes are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this type, then none of its fields would be accessible to that role.\n\n## Model Permissions\u200b\n\nA model permission will need the model name and the role(s) for which the permission should be defined. For each role,\nyou will need to define an optional filter expression. Objects (or rows/documents) that satisfy this filter predicate\nwill be returned for that role.\n\n### Metadata Structure\u200b\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  <ModelName >\n   permissions :  <ModelPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| modelName |  `String`  | true | The name of the model for which permissions are to be defined. |\n| permissions | [ [ModelPermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#modelpermission) | true | The permissions object for this model, one for each role. |\n\n\n#### ModelPermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     select :  <SelectPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `select`  | [ SelectPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#selectpermission) | true | The model select permission for the role. |\n\n\n#### SelectPermission\u200b\n\n```\nselect :\n   filter :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| filter | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate) | false | Optional predicate to satisfy. This predicate can use operators supported by the model\u2019s data connector. If the filter is missing then all rows are accessible. If the filter is present, then only the rows satisfying this filter expression are accessible. |\n\n\n### Examples\u200b\n\nBelow, we're creating a set of `ModelPermissions` on the `Articles` model for the roles `admin` , `user_1` , and `user_2` .\n\nAs the `select` object for `admin` role is empty, it will return all rows.\n\nThe `user_1` role's `select` object has a filter predicate that will return rows where the `author_id` field is equal to\nthe `x-hasura-user-id` session variable.\n\nThe `user_2` role's `select` object has a filter predicate that will return rows where the `title` field is like the\nstring `Functional` .\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  Articles\n   permissions :\n     -   role :  admin\n       select :\n         filter :\n     -   role :  user_1\n       select :\n         filter :\n           fieldComparison :\n             field :  author_id\n             operator :  _eq\n             value :\n               sessionVariable :  x - hasura - user - id\n     -   role :  user_2\n       select :\n         filter :\n           and :\n             -   fieldComparison :\n                 field :  title\n                 operator :  _like\n                 value :\n                   literal :   \"%Functional%\"\n```\n\nModels are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this model, then the model won't be selectable for that role.\n\n## Command permissions\u200b\n\nA command permission will need the command name and the role(s) for which the permission should be defined.\n\n### Metadata structure\u200b\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  <CommandName >\n   permissions :  <CommandPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `commandName`  |  `String`  | true | The name of the command for which permissions are to be defined. |\n|  `permissions`  | [ [CommandPermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#commandpermission) | true | The permissions object for this command, one for each role. |\n\n\n#### CommandPermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     allowExecution :  <Boolean >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `allowExecution`  |  `Boolean`  | true | Is the execution of the command allowed for the role |\n\n\n### Examples\u200b\n\nTo define permissions on a command with name `get_article_by_id` for `admin` and `user` role:\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  get_article_by_id\n   permissions :\n     -   role :  admin\n       allowExecution :   true\n     -   role :  user\n       allowExecution :   false\n```\n\nCommands are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this command, then it won't be executable by that role.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#introduction)\n- [ Type permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#type-permissions)\n    - [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#metadata-structure)\n        - [ TypePermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#typepermission)\n\n- [ OutputPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#outputpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#examples)\n\n- [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#metadata-structure)\n    - [ TypePermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#typepermission)\n- [ Model Permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#model-permissions)\n    - [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#metadata-structure-1)\n        - [ ModelPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#modelpermission)\n\n- [ SelectPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#selectpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#examples-1)\n\n- [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#metadata-structure-1)\n    - [ ModelPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#modelpermission)\n- [ Command permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#command-permissions)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#metadata-structure-2)\n        - [ CommandPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#commandpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#metadata-structure-2)\n    - [ CommandPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#type-permissions/#commandpermission)\n", "https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions": "# OpenDD Permissions\n\n## Introduction\u200b\n\nThe OpenDD Spec lets you define permissions, (also known as access control or authorization rules) on[ object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/),[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)in your data domain.\n\nThe following types of permissions can be defined in the[ OpenDD spec ](https://hasura.io/docs/3.0/data-domain-modeling/overview/):\n\n- `TypePermissions` define which fields are allowed to be accessed by a role. Defining permissions on output types is\nuseful, as certain fields may be sensitive and should only be accessible to particular roles.\n- `ModelPermissions` define which objects or rows within a model are allowed to be accessed by a role.\n- `CommandPermissions` defines whether the command is executable by a role.\n\n\n## Type permissions\u200b\n\nA type permission will need the type and the role(s) for which the permission should be defined. For each role, you will\nneed to define the fields accessible for that role.\n\n### Metadata Structure\u200b\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  <TypeName >\n   permissions :  <TypePermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `typeName`  | [ TypeName ](https://hasura.io/docs/3.0/data-domain-modeling/types/) | true | The name of the type for which permissions are to be defined. |\n|  `permissions`  | [ [TypePermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#typepermission) | true | The permissions object for this type, one for each role. |\n\n\n#### TypePermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     output :  <OutputPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `output`  | [ OutputPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#outputpermission) | true | The type output permission for the role. |\n\n\n#### OutputPermission\u200b\n\n```\noutput :\n   allowedFields :\n     -  <field1 >\n     -  <field2 >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `allowedFields`  |  `[String]`  | true | List of fields that are accessible to the role. |\n\n\n### Examples\u200b\n\nTo define permissions on an output type `article` for `admin` and `user` role:\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  article\n   permissions :\n     -   role :  admin\n       output :\n         allowedFields :\n           -  id\n           -  title\n           -  author_id\n     -   role :  user\n       output :\n         allowedFields :\n           -  id\n           -  title\n```\n\nTypes are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this type, then none of its fields would be accessible to that role.\n\n## Model Permissions\u200b\n\nA model permission will need the model name and the role(s) for which the permission should be defined. For each role,\nyou will need to define an optional filter expression. Objects (or rows/documents) that satisfy this filter predicate\nwill be returned for that role.\n\n### Metadata Structure\u200b\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  <ModelName >\n   permissions :  <ModelPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| modelName |  `String`  | true | The name of the model for which permissions are to be defined. |\n| permissions | [ [ModelPermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#modelpermission) | true | The permissions object for this model, one for each role. |\n\n\n#### ModelPermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     select :  <SelectPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `select`  | [ SelectPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#selectpermission) | true | The model select permission for the role. |\n\n\n#### SelectPermission\u200b\n\n```\nselect :\n   filter :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| filter | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate) | false | Optional predicate to satisfy. This predicate can use operators supported by the model\u2019s data connector. If the filter is missing then all rows are accessible. If the filter is present, then only the rows satisfying this filter expression are accessible. |\n\n\n### Examples\u200b\n\nBelow, we're creating a set of `ModelPermissions` on the `Articles` model for the roles `admin` , `user_1` , and `user_2` .\n\nAs the `select` object for `admin` role is empty, it will return all rows.\n\nThe `user_1` role's `select` object has a filter predicate that will return rows where the `author_id` field is equal to\nthe `x-hasura-user-id` session variable.\n\nThe `user_2` role's `select` object has a filter predicate that will return rows where the `title` field is like the\nstring `Functional` .\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  Articles\n   permissions :\n     -   role :  admin\n       select :\n         filter :\n     -   role :  user_1\n       select :\n         filter :\n           fieldComparison :\n             field :  author_id\n             operator :  _eq\n             value :\n               sessionVariable :  x - hasura - user - id\n     -   role :  user_2\n       select :\n         filter :\n           and :\n             -   fieldComparison :\n                 field :  title\n                 operator :  _like\n                 value :\n                   literal :   \"%Functional%\"\n```\n\nModels are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this model, then the model won't be selectable for that role.\n\n## Command permissions\u200b\n\nA command permission will need the command name and the role(s) for which the permission should be defined.\n\n### Metadata structure\u200b\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  <CommandName >\n   permissions :  <CommandPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `commandName`  |  `String`  | true | The name of the command for which permissions are to be defined. |\n|  `permissions`  | [ [CommandPermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#commandpermission) | true | The permissions object for this command, one for each role. |\n\n\n#### CommandPermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     allowExecution :  <Boolean >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `allowExecution`  |  `Boolean`  | true | Is the execution of the command allowed for the role |\n\n\n### Examples\u200b\n\nTo define permissions on a command with name `get_article_by_id` for `admin` and `user` role:\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  get_article_by_id\n   permissions :\n     -   role :  admin\n       allowExecution :   true\n     -   role :  user\n       allowExecution :   false\n```\n\nCommands are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this command, then it won't be executable by that role.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#introduction)\n- [ Type permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#type-permissions)\n    - [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#metadata-structure)\n        - [ TypePermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#typepermission)\n\n- [ OutputPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#outputpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#examples)\n\n- [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#metadata-structure)\n    - [ TypePermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#typepermission)\n- [ Model Permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#model-permissions)\n    - [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#metadata-structure-1)\n        - [ ModelPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#modelpermission)\n\n- [ SelectPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#selectpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#examples-1)\n\n- [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#metadata-structure-1)\n    - [ ModelPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#modelpermission)\n- [ Command permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#command-permissions)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#metadata-structure-2)\n        - [ CommandPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#commandpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#metadata-structure-2)\n    - [ CommandPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#model-permissions/#commandpermission)\n", "https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions": "# OpenDD Permissions\n\n## Introduction\u200b\n\nThe OpenDD Spec lets you define permissions, (also known as access control or authorization rules) on[ object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/),[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)in your data domain.\n\nThe following types of permissions can be defined in the[ OpenDD spec ](https://hasura.io/docs/3.0/data-domain-modeling/overview/):\n\n- `TypePermissions` define which fields are allowed to be accessed by a role. Defining permissions on output types is\nuseful, as certain fields may be sensitive and should only be accessible to particular roles.\n- `ModelPermissions` define which objects or rows within a model are allowed to be accessed by a role.\n- `CommandPermissions` defines whether the command is executable by a role.\n\n\n## Type permissions\u200b\n\nA type permission will need the type and the role(s) for which the permission should be defined. For each role, you will\nneed to define the fields accessible for that role.\n\n### Metadata Structure\u200b\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  <TypeName >\n   permissions :  <TypePermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `typeName`  | [ TypeName ](https://hasura.io/docs/3.0/data-domain-modeling/types/) | true | The name of the type for which permissions are to be defined. |\n|  `permissions`  | [ [TypePermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#typepermission) | true | The permissions object for this type, one for each role. |\n\n\n#### TypePermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     output :  <OutputPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `output`  | [ OutputPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#outputpermission) | true | The type output permission for the role. |\n\n\n#### OutputPermission\u200b\n\n```\noutput :\n   allowedFields :\n     -  <field1 >\n     -  <field2 >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `allowedFields`  |  `[String]`  | true | List of fields that are accessible to the role. |\n\n\n### Examples\u200b\n\nTo define permissions on an output type `article` for `admin` and `user` role:\n\n```\nkind :  TypePermissions\nversion :  v1\ndefinition :\n   typeName :  article\n   permissions :\n     -   role :  admin\n       output :\n         allowedFields :\n           -  id\n           -  title\n           -  author_id\n     -   role :  user\n       output :\n         allowedFields :\n           -  id\n           -  title\n```\n\nTypes are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this type, then none of its fields would be accessible to that role.\n\n## Model Permissions\u200b\n\nA model permission will need the model name and the role(s) for which the permission should be defined. For each role,\nyou will need to define an optional filter expression. Objects (or rows/documents) that satisfy this filter predicate\nwill be returned for that role.\n\n### Metadata Structure\u200b\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  <ModelName >\n   permissions :  <ModelPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| modelName |  `String`  | true | The name of the model for which permissions are to be defined. |\n| permissions | [ [ModelPermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#modelpermission) | true | The permissions object for this model, one for each role. |\n\n\n#### ModelPermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     select :  <SelectPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `select`  | [ SelectPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#selectpermission) | true | The model select permission for the role. |\n\n\n#### SelectPermission\u200b\n\n```\nselect :\n   filter :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| filter | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#modelpredicate) | false | Optional predicate to satisfy. This predicate can use operators supported by the model\u2019s data connector. If the filter is missing then all rows are accessible. If the filter is present, then only the rows satisfying this filter expression are accessible. |\n\n\n### Examples\u200b\n\nBelow, we're creating a set of `ModelPermissions` on the `Articles` model for the roles `admin` , `user_1` , and `user_2` .\n\nAs the `select` object for `admin` role is empty, it will return all rows.\n\nThe `user_1` role's `select` object has a filter predicate that will return rows where the `author_id` field is equal to\nthe `x-hasura-user-id` session variable.\n\nThe `user_2` role's `select` object has a filter predicate that will return rows where the `title` field is like the\nstring `Functional` .\n\n```\nkind :  ModelPermissions\nversion :  v1\ndefinition :\n   modelName :  Articles\n   permissions :\n     -   role :  admin\n       select :\n         filter :\n     -   role :  user_1\n       select :\n         filter :\n           fieldComparison :\n             field :  author_id\n             operator :  _eq\n             value :\n               sessionVariable :  x - hasura - user - id\n     -   role :  user_2\n       select :\n         filter :\n           and :\n             -   fieldComparison :\n                 field :  title\n                 operator :  _like\n                 value :\n                   literal :   \"%Functional%\"\n```\n\nModels are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this model, then the model won't be selectable for that role.\n\n## Command permissions\u200b\n\nA command permission will need the command name and the role(s) for which the permission should be defined.\n\n### Metadata structure\u200b\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  <CommandName >\n   permissions :  <CommandPermission >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `commandName`  |  `String`  | true | The name of the command for which permissions are to be defined. |\n|  `permissions`  | [ [CommandPermission] ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#commandpermission) | true | The permissions object for this command, one for each role. |\n\n\n#### CommandPermission\u200b\n\n```\npermissions :\n   -   role :  <RoleName >\n     allowExecution :  <Boolean >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `role`  |  `String`  | true | The name of the role for which permissions are to be defined. |\n|  `allowExecution`  |  `Boolean`  | true | Is the execution of the command allowed for the role |\n\n\n### Examples\u200b\n\nTo define permissions on a command with name `get_article_by_id` for `admin` and `user` role:\n\n```\nkind :  CommandPermissions\nversion :  v1\ndefinition :\n   commandName :  get_article_by_id\n   permissions :\n     -   role :  admin\n       allowExecution :   true\n     -   role :  user\n       allowExecution :   false\n```\n\nCommands are inaccessible when undefined for a role\n\nIf a role doesn't define any permissions for this command, then it won't be executable by that role.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#introduction)\n- [ Type permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#type-permissions)\n    - [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#metadata-structure)\n        - [ TypePermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#typepermission)\n\n- [ OutputPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#outputpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#examples)\n\n- [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#metadata-structure)\n    - [ TypePermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#typepermission)\n- [ Model Permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#model-permissions)\n    - [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#metadata-structure-1)\n        - [ ModelPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#modelpermission)\n\n- [ SelectPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#selectpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#examples-1)\n\n- [ Metadata Structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#metadata-structure-1)\n    - [ ModelPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#modelpermission)\n- [ Command permissions ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#command-permissions)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#metadata-structure-2)\n        - [ CommandPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#commandpermission)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#metadata-structure-2)\n    - [ CommandPermission ](https://hasura.io/docs/3.0/data-domain-modeling/permissions/#command-permissions/#commandpermission)\n", "https://hasura.io/docs/3.0/data-domain-modeling/models/#source": "# OpenDD Models\n\n## Introduction\u200b\n\nModels are the link between your data connectors and the API Hasura generates. A model may be backed by a database\ntable, an ad-hoc SQL query, a pre-materialized view, a custom REST or GraphQL API server, etc.\n\nOnce a model is declared it will then often be referenced by `Relationship` and/or `Permissions` objects.\n\n## Description\u200b\n\nTo create a model, you need to define an OpenDD object with `kind: Model` and `version: v1` . The object `definition` has the following fields:\n\n### Metadata structure\u200b\n\n```\nkind :  Model\nversion :  v1\ndefinition :\n   name :  <ModelName >\n   objectType :  <TypeName >\n   globalIDSource :  true  |  false\n   source :  <SourceConfiguration >\n   graphql :  <GraphQLConfiguration >\n   arguments :   [ ArgumentDefinition ]\n   filterableFields :   [ FilterableFields ]\n   orderableFields :   [ OrderableFields ]\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the model. |\n|  `objectType`  |  `String`  | true | [ Type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)of the objects in this model. |\n|  `globalIDSource`  |  `Boolean`  | true | If this model should be used as the[ Global ID ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/)source for its `objectType` . |\n|  `source`  | [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source) | false | Source configuration for the model. |\n|  `graphql`  | [ ModelGraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql) | false | GraphQL configuration for the model. |\n|  `arguments`  | [ [ArgumentDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition) | true | The argument definitions for the model. |\n|  `filterableFields`  | [ [FilterableFieldDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#filterablefielddefinition) | true | Filterable fields for the model. |\n|  `orderableFields`  | [ [OrderableFieldDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#orderablefielddefinition) | true | Orderable fields for the model. |\n\n\nFilterable/Orderable Fields support\n\nAt the moment, we don't support field level filterable/orderable customizations. So, you will have to provide an\nexhaustive list of the fields of your model in `filterableFields` and `orderableFields` .\n\n#### SourceConfiguration\u200b\n\nThe source configuration is an object that defines the data source for the model. It has the following fields:\n\n```\nsource :\n   dataConnectorName :  <DataConnectorName >\n   collection :  <CollectionName >\n   typeMapping :  <TypeMapping >\n```\n\n| source Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnector`  |  `String`  | true | Name of the source data connector backing this model. |\n|  `collection`  |  `String`  | true | Name of the collection in the source data connector backing this model. |\n|  `typeMapping`  | [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping) | true | Type mappings from OpenDD object types used within the model to the corresponding data connector types. |\n\n\n#### ModelGraphQLConfiguration\u200b\n\nModelGraphQLConfiguration is an object that defines how the model should be surfaced in the GraphQL API. It has the following fields:\n\n```\ngraphql :\n   selectUniques :  <SelectUniques >\n   selectMany :  <SelectMany >\n   filterExpressionType :  <FilterExpressionType >\n   orderByExpressionType :  <OrderByExpressionType >\n   argumentsInputType :  <ArgumentsInputType >\n```\n\n| graphql Field | Type | Required | Description |\n|---|---|---|---|\n|  `selectUniques`  | [ [SelectUniques] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#selectuniques) | true | Select uniques configuration for the model. |\n|  `selectMany`  | [ SelectMany ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#selectmany) | false | Select many configuration for the model. |\n|  `filterExpressionType`  |  `String`  | false | GraphQL type name to use for the filter input. |\n|  `orderByExpressionType`  |  `String`  | false | GraphQL type name to use for the order by input. |\n|  `argumentsInputType`  |  `String`  | false | GraphQL type name to use for the model arguments input. |\n\n\n##### SelectUniques\u200b\n\nSelect uniques is an array of objects that defines the unique identifiers for the model. For each select unique defined here,\na query root field is added to the GraphQL API. For each field defined in the `uniqueIdentifier` , an input argument is added\nto the query root field which can be supplied to retrieve the unique identified object from the model.\n\n```\nselectUniques :\n   queryRootField :  <QueryRootField >\n   uniqueIdentifier :  <UniqueIdentifier >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `queryRootField`  |  `String`  | true | Name of the query root field to use in the GraphQL API. |\n|  `uniqueIdentifier`  |  `Array`  | true | Set of fields which can uniquely identify a row/object in the model. |\n\n\n##### SelectMany\u200b\n\nSelect many configuration for a model adds a query root field to the GraphQl API that can be used to retrieve multiple objects from the model.\nThis field can accept the following arguments:\n\n- `args` , used for supplying the values for the model's arguments. This argument is generated only if the model has arguments and `argumentsInputType` is set in the ModelGraphQlConfiguration.\n- `where` , used for filtering the objects to retrieve. This argument is generated only if `filterExpressionType` is set in the ModelGraphQlConfiguration. The filter expression contains all the filterable fields and the `_and` / `_or` / `_not` logical operators.\n- `order_by` , used for sorting the retrieved objects. This argument is generated only if `orderByExpressionType` is set in the ModelGraphQlConfiguration. The order by expression contains all the orderable fields.\n- `limit` , used for limiting the number of retrieved objects.\n- `offset` , used for skipping the first `offset` objects when retrieving.\n\n\n```\nselectMany :\n   queryRootField :  <QueryRootField >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `queryRootField`  |  `String`  | true | Name of the query root field to use in the GraphQL API. |\n\n\n#### FilterableFieldDefinition\u200b\n\nThe filterable field definition is an object that lists the allowed operators for a given field.\n\n```\nfilterableFields :\n   -   fieldName :  <String >\n     operators :\n       enableAll :   true\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | Name of the field. |\n|  `operators`  |  `Object`  | true | Allowed operators (at the moment, we only support `enableAll: true` ) |\n\n\n#### OrderableFieldDefinition\u200b\n\nOrderable field definition is an object that lists down the allowed order by directions for a given field.\n\n```\norderableFields :\n   -   fieldName :  <String >\n     orderByDirections :\n       enableAll :   true\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | Name of the field. |\n|  `orderByDirections`  |  `Object`  | true | Allowed order by directions (at the moment, we only support `enableAll: true` ) |\n\n\n## Examples\u200b\n\nIn this example, we're creating a model called `Authors` backed by a database table called `authors` in the `db` data\nsource:\n\n```\nkind :  Model\nversion :  v1\ndefinition :\n   name :  Authors\n   objectType :  author\n   globalIdSource :   true\n   source :\n     dataConnectorName :  db\n     collection :  authors\n     typeMapping :\n       author :\n         fieldMapping :\n           author_id :\n             column :  id\n           first_name :\n             column :  first_name\n           last_name :\n             column :  last_name\n   graphql :\n     selectUniques :\n       -   queryRootField :  AuthorByID\n         uniqueIdentifier :\n           -  author_id\n     selectMany :\n       queryRootField :  AuthorMany\n     filterExpressionType :  Author_Where_Exp\n     orderByExpressionType :  Author_Order_By\n   arguments :   [ ]\n   filterableFields :\n     -   fieldName :  author_id\n       operators :\n         enableAll :   true\n     -   fieldName :  first_name\n       operators :\n         enableAll :   true\n     -   fieldName :  last_name\n       operators :\n         enableAll :   true\n   orderableFields :\n     -   fieldName :  author_id\n       orderByDirections :\n         enableAll :   true\n     -   fieldName :  first_name\n       orderByDirections :\n         enableAll :   true\n     -   fieldName :  last_name\n       orderByDirections :\n         enableAll :   true\n```\n\nAssuming the ObjectType was defined like[ this ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples), and the scalar types corresponding to the fields had\nappropriate comparison expressions defined, the resulting GraphQl API will be:\n\n```\ntype   Query   {\n   node ( id :   ID ! ) :   Node\n   AuthorByID ( author_id :   Int ! ) :   Author\n   AuthorMany ( where :   Author_Where_Exp ,   order_by   Author_Order_By ,   limit :   Int ,   offset :   Int ) :   Author\n}\ntype   Author   {\n   id :   ID !\n   author_id :   Int !\n   first_name :   String\n   last_name :   String\n}\ninput   Author_Where_Exp :   {\n   _and :   [ Author_Where_Exp ! ]\n   _or :   [ Author_Where_Exp ! ]\n   _not :   [ Author_Where_Exp ! ]\n   author_id :   int_comparison_exp\n   first_name :   text_comparison_exp\n   last_name :   text_comparison_exp\n}\ninput   Author_Order_By   {\n   author_id :   order_by\n   first_name :   order_by\n   last_name :   order_by\n}\nenum   order_by   {\n   Asc ,\n   Desc\n}\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#introduction)\n- [ Description ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#description)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#metadata-structure)\n        - [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#source)\n\n- [ ModelGraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#graphql)\n\n- [ FilterableFieldDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#filterablefielddefinition)\n\n- [ OrderableFieldDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#orderablefielddefinition)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#metadata-structure)\n    - [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#source)\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source/#examples)\n", "https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret": "# Common OpenDD Syntax\n\n## ModelPredicate\u200b\n\nA `ModelPredicate` is used to define the boolean expression for filtering the objects within a model, and is typically used when defining permissions.\n\n```\n[ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#fieldcomparison)\n|\n[ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#relationship)\n|\n[ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#andexp)\n|\n[ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#orexp)\n|\n[ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#notexp)\n```\n\n### FieldComparison\u200b\n\nThis predicate filters objects where the particular `field` of the object returns true when the specified comparison operator `operator` is applied with the `value` as input.\n\n```\nfieldComparison :\n   field :  <FieldName >\n   operator :  <Operator >\n   value :  <ValueExpression >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| field |  `String`  | true | Name of the field of the model to compare. |\n| operator |  `String`  | true | Name of the operator. Either the built-in operators `_ eq` or `_ is_ null` , or any of the operators available from the data connector. |\n| value | [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#valueexpression) | false | The value to compare. Can be a literal value or a a value from session variables. This can be omitted in case of `_ is_ null` operator. |\n\n\n### RelationshipPredicate\u200b\n\nThis predicate evaluates to true if any of the corresponding target objects of the relationship of the source model's object type with `name` meet the nested `predicate` .\n\n```\nrelationship :\n   name :  <RelationshipName >\n   predicate :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| name |  `String`  | true | Name of relationship of the model to compare. |\n| predicate | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#modelpredicate) | false | The filter or predicate expression. |\n\n\n### AndExp\u200b\n\nThis predicates evaluates to true if all sub-predicates of `and` evaluate to true.\n\n```\n{\n  \"and\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#modelpredicate)\n]\n}\n```\n\n### OrExp\u200b\n\nThis predicates evaluates to true if any of the sub-predicates of `or` evaluate to true.\n\n```\n{\n  \"or\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#modelpredicate)\n]\n}\n```\n\n### NotExp\u200b\n\nThis predicates evaluates to true if the sub-predicates of `not` evaluates to false.\n\n```\n{\n  \"not\" :\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#modelpredicate)\n}\n```\n\n## ValueExpression\u200b\n\nAn expression which evaluates to a value that can be used in comparison expressions, etc.\nThis expression can either be a literal value or a reference to a session variable.\n\n```\n[ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#literal)\n|\n[ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#sessionvariable)\n```\n\n### Literal\u200b\n\n```\n{\n   \"literal\" :  <any JSON value>\n}\n```\n\n#### Examples\u200b\n\n`literal :  some string`\n\n### SessionVariable\u200b\n\n`sessionVariable :  String`\n\n#### Examples\u200b\n\n`sessionVariable :  x - hasura - user - id`\n\n## TypeMapping\u200b\n\nThe `typemapping` is used by[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)to define the mapping between the fields of the OpenDD types used in the model/command and\nthe fields of the corresponding types in the data connector. It has the following fields:\n\n```\n<OpenDDTypeName> :\n   fieldMapping :  <FieldMapping >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDTypeName`  |  `String`  | true | Name of the OpenDD object type which is being mapped. |\n|  `fieldMapping`  | [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#fieldmapping) | true | The field mapping between the OpenDD object type and the corresponding NDC object type. |\n\n\n## FieldMapping\u200b\n\nThe `fieldMapping` is used by[ typemapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#typemapping)to define mapping for the fields of the `OpenDDTypeName` .\n\nIt has the following fields:\n\n```\n<OpenDDFieldName> :\n   column :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDFieldName`  |  `String`  | true | Name of the field in the OpenDD object type. |\n|  `column`  |  `String`  | true | The name of the field in the NDC object type. |\n\n\n## ArgumentDefinition\u200b\n\nArguments is a list of objects that defines the arguments for the[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure)or a[ command ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure). An argument object has the following fields:\n\n```\nname :  <String > ,\ntype :  <TypeReference >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the argument. |\n|  `type`  |  `Type`  | true | [ TypeReference ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references)of the argument as a string. |\n\n\n## Secret references\u200b\n\nInstead of embedding sensitive values in the metadata, certain fields can be set using[ secrets ](https://hasura.io/docs/3.0/ci-cd/secrets/)stored in DDN.\n\nTo embed a value directly without using a secret:\n\n`value: <your value>`\n\nTo use a value via a secret:\n\n`stringValueFromSecret: <secret name>`\n\n### What did you think of this doc?\n\n- [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#modelpredicate)\n    - [ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#fieldcomparison)\n\n- [ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#relationshippredicate)\n\n- [ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#andexp)\n\n- [ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#orexp)\n\n- [ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#notexp)\n- [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#valueexpression)\n    - [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#literal)\n        - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#examples)\n\n- [ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#sessionvariable)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#examples-1)\n\n- [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#literal)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#examples)\n- [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#typemapping)\n- [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#fieldmapping)\n- [ ArgumentDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#argumentdefinition)\n- [ Secret references ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#secret/#secret)\n", "https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql": "# OpenDD Models\n\n## Introduction\u200b\n\nModels are the link between your data connectors and the API Hasura generates. A model may be backed by a database\ntable, an ad-hoc SQL query, a pre-materialized view, a custom REST or GraphQL API server, etc.\n\nOnce a model is declared it will then often be referenced by `Relationship` and/or `Permissions` objects.\n\n## Description\u200b\n\nTo create a model, you need to define an OpenDD object with `kind: Model` and `version: v1` . The object `definition` has the following fields:\n\n### Metadata structure\u200b\n\n```\nkind :  Model\nversion :  v1\ndefinition :\n   name :  <ModelName >\n   objectType :  <TypeName >\n   globalIDSource :  true  |  false\n   source :  <SourceConfiguration >\n   graphql :  <GraphQLConfiguration >\n   arguments :   [ ArgumentDefinition ]\n   filterableFields :   [ FilterableFields ]\n   orderableFields :   [ OrderableFields ]\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the model. |\n|  `objectType`  |  `String`  | true | [ Type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)of the objects in this model. |\n|  `globalIDSource`  |  `Boolean`  | true | If this model should be used as the[ Global ID ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/)source for its `objectType` . |\n|  `source`  | [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source) | false | Source configuration for the model. |\n|  `graphql`  | [ ModelGraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql) | false | GraphQL configuration for the model. |\n|  `arguments`  | [ [ArgumentDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition) | true | The argument definitions for the model. |\n|  `filterableFields`  | [ [FilterableFieldDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#filterablefielddefinition) | true | Filterable fields for the model. |\n|  `orderableFields`  | [ [OrderableFieldDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#orderablefielddefinition) | true | Orderable fields for the model. |\n\n\nFilterable/Orderable Fields support\n\nAt the moment, we don't support field level filterable/orderable customizations. So, you will have to provide an\nexhaustive list of the fields of your model in `filterableFields` and `orderableFields` .\n\n#### SourceConfiguration\u200b\n\nThe source configuration is an object that defines the data source for the model. It has the following fields:\n\n```\nsource :\n   dataConnectorName :  <DataConnectorName >\n   collection :  <CollectionName >\n   typeMapping :  <TypeMapping >\n```\n\n| source Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnector`  |  `String`  | true | Name of the source data connector backing this model. |\n|  `collection`  |  `String`  | true | Name of the collection in the source data connector backing this model. |\n|  `typeMapping`  | [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping) | true | Type mappings from OpenDD object types used within the model to the corresponding data connector types. |\n\n\n#### ModelGraphQLConfiguration\u200b\n\nModelGraphQLConfiguration is an object that defines how the model should be surfaced in the GraphQL API. It has the following fields:\n\n```\ngraphql :\n   selectUniques :  <SelectUniques >\n   selectMany :  <SelectMany >\n   filterExpressionType :  <FilterExpressionType >\n   orderByExpressionType :  <OrderByExpressionType >\n   argumentsInputType :  <ArgumentsInputType >\n```\n\n| graphql Field | Type | Required | Description |\n|---|---|---|---|\n|  `selectUniques`  | [ [SelectUniques] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#selectuniques) | true | Select uniques configuration for the model. |\n|  `selectMany`  | [ SelectMany ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#selectmany) | false | Select many configuration for the model. |\n|  `filterExpressionType`  |  `String`  | false | GraphQL type name to use for the filter input. |\n|  `orderByExpressionType`  |  `String`  | false | GraphQL type name to use for the order by input. |\n|  `argumentsInputType`  |  `String`  | false | GraphQL type name to use for the model arguments input. |\n\n\n##### SelectUniques\u200b\n\nSelect uniques is an array of objects that defines the unique identifiers for the model. For each select unique defined here,\na query root field is added to the GraphQL API. For each field defined in the `uniqueIdentifier` , an input argument is added\nto the query root field which can be supplied to retrieve the unique identified object from the model.\n\n```\nselectUniques :\n   queryRootField :  <QueryRootField >\n   uniqueIdentifier :  <UniqueIdentifier >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `queryRootField`  |  `String`  | true | Name of the query root field to use in the GraphQL API. |\n|  `uniqueIdentifier`  |  `Array`  | true | Set of fields which can uniquely identify a row/object in the model. |\n\n\n##### SelectMany\u200b\n\nSelect many configuration for a model adds a query root field to the GraphQl API that can be used to retrieve multiple objects from the model.\nThis field can accept the following arguments:\n\n- `args` , used for supplying the values for the model's arguments. This argument is generated only if the model has arguments and `argumentsInputType` is set in the ModelGraphQlConfiguration.\n- `where` , used for filtering the objects to retrieve. This argument is generated only if `filterExpressionType` is set in the ModelGraphQlConfiguration. The filter expression contains all the filterable fields and the `_and` / `_or` / `_not` logical operators.\n- `order_by` , used for sorting the retrieved objects. This argument is generated only if `orderByExpressionType` is set in the ModelGraphQlConfiguration. The order by expression contains all the orderable fields.\n- `limit` , used for limiting the number of retrieved objects.\n- `offset` , used for skipping the first `offset` objects when retrieving.\n\n\n```\nselectMany :\n   queryRootField :  <QueryRootField >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `queryRootField`  |  `String`  | true | Name of the query root field to use in the GraphQL API. |\n\n\n#### FilterableFieldDefinition\u200b\n\nThe filterable field definition is an object that lists the allowed operators for a given field.\n\n```\nfilterableFields :\n   -   fieldName :  <String >\n     operators :\n       enableAll :   true\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | Name of the field. |\n|  `operators`  |  `Object`  | true | Allowed operators (at the moment, we only support `enableAll: true` ) |\n\n\n#### OrderableFieldDefinition\u200b\n\nOrderable field definition is an object that lists down the allowed order by directions for a given field.\n\n```\norderableFields :\n   -   fieldName :  <String >\n     orderByDirections :\n       enableAll :   true\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | Name of the field. |\n|  `orderByDirections`  |  `Object`  | true | Allowed order by directions (at the moment, we only support `enableAll: true` ) |\n\n\n## Examples\u200b\n\nIn this example, we're creating a model called `Authors` backed by a database table called `authors` in the `db` data\nsource:\n\n```\nkind :  Model\nversion :  v1\ndefinition :\n   name :  Authors\n   objectType :  author\n   globalIdSource :   true\n   source :\n     dataConnectorName :  db\n     collection :  authors\n     typeMapping :\n       author :\n         fieldMapping :\n           author_id :\n             column :  id\n           first_name :\n             column :  first_name\n           last_name :\n             column :  last_name\n   graphql :\n     selectUniques :\n       -   queryRootField :  AuthorByID\n         uniqueIdentifier :\n           -  author_id\n     selectMany :\n       queryRootField :  AuthorMany\n     filterExpressionType :  Author_Where_Exp\n     orderByExpressionType :  Author_Order_By\n   arguments :   [ ]\n   filterableFields :\n     -   fieldName :  author_id\n       operators :\n         enableAll :   true\n     -   fieldName :  first_name\n       operators :\n         enableAll :   true\n     -   fieldName :  last_name\n       operators :\n         enableAll :   true\n   orderableFields :\n     -   fieldName :  author_id\n       orderByDirections :\n         enableAll :   true\n     -   fieldName :  first_name\n       orderByDirections :\n         enableAll :   true\n     -   fieldName :  last_name\n       orderByDirections :\n         enableAll :   true\n```\n\nAssuming the ObjectType was defined like[ this ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples), and the scalar types corresponding to the fields had\nappropriate comparison expressions defined, the resulting GraphQl API will be:\n\n```\ntype   Query   {\n   node ( id :   ID ! ) :   Node\n   AuthorByID ( author_id :   Int ! ) :   Author\n   AuthorMany ( where :   Author_Where_Exp ,   order_by   Author_Order_By ,   limit :   Int ,   offset :   Int ) :   Author\n}\ntype   Author   {\n   id :   ID !\n   author_id :   Int !\n   first_name :   String\n   last_name :   String\n}\ninput   Author_Where_Exp :   {\n   _and :   [ Author_Where_Exp ! ]\n   _or :   [ Author_Where_Exp ! ]\n   _not :   [ Author_Where_Exp ! ]\n   author_id :   int_comparison_exp\n   first_name :   text_comparison_exp\n   last_name :   text_comparison_exp\n}\ninput   Author_Order_By   {\n   author_id :   order_by\n   first_name :   order_by\n   last_name :   order_by\n}\nenum   order_by   {\n   Asc ,\n   Desc\n}\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#introduction)\n- [ Description ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#description)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#metadata-structure)\n        - [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#source)\n\n- [ ModelGraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#graphql)\n\n- [ FilterableFieldDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#filterablefielddefinition)\n\n- [ OrderableFieldDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#orderablefielddefinition)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#metadata-structure)\n    - [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#source)\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql/#examples)\n", "https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition": "# Common OpenDD Syntax\n\n## ModelPredicate\u200b\n\nA `ModelPredicate` is used to define the boolean expression for filtering the objects within a model, and is typically used when defining permissions.\n\n```\n[ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#fieldcomparison)\n|\n[ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#relationship)\n|\n[ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#andexp)\n|\n[ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#orexp)\n|\n[ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#notexp)\n```\n\n### FieldComparison\u200b\n\nThis predicate filters objects where the particular `field` of the object returns true when the specified comparison operator `operator` is applied with the `value` as input.\n\n```\nfieldComparison :\n   field :  <FieldName >\n   operator :  <Operator >\n   value :  <ValueExpression >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| field |  `String`  | true | Name of the field of the model to compare. |\n| operator |  `String`  | true | Name of the operator. Either the built-in operators `_ eq` or `_ is_ null` , or any of the operators available from the data connector. |\n| value | [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#valueexpression) | false | The value to compare. Can be a literal value or a a value from session variables. This can be omitted in case of `_ is_ null` operator. |\n\n\n### RelationshipPredicate\u200b\n\nThis predicate evaluates to true if any of the corresponding target objects of the relationship of the source model's object type with `name` meet the nested `predicate` .\n\n```\nrelationship :\n   name :  <RelationshipName >\n   predicate :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| name |  `String`  | true | Name of relationship of the model to compare. |\n| predicate | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#modelpredicate) | false | The filter or predicate expression. |\n\n\n### AndExp\u200b\n\nThis predicates evaluates to true if all sub-predicates of `and` evaluate to true.\n\n```\n{\n  \"and\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#modelpredicate)\n]\n}\n```\n\n### OrExp\u200b\n\nThis predicates evaluates to true if any of the sub-predicates of `or` evaluate to true.\n\n```\n{\n  \"or\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#modelpredicate)\n]\n}\n```\n\n### NotExp\u200b\n\nThis predicates evaluates to true if the sub-predicates of `not` evaluates to false.\n\n```\n{\n  \"not\" :\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#modelpredicate)\n}\n```\n\n## ValueExpression\u200b\n\nAn expression which evaluates to a value that can be used in comparison expressions, etc.\nThis expression can either be a literal value or a reference to a session variable.\n\n```\n[ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#literal)\n|\n[ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#sessionvariable)\n```\n\n### Literal\u200b\n\n```\n{\n   \"literal\" :  <any JSON value>\n}\n```\n\n#### Examples\u200b\n\n`literal :  some string`\n\n### SessionVariable\u200b\n\n`sessionVariable :  String`\n\n#### Examples\u200b\n\n`sessionVariable :  x - hasura - user - id`\n\n## TypeMapping\u200b\n\nThe `typemapping` is used by[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)to define the mapping between the fields of the OpenDD types used in the model/command and\nthe fields of the corresponding types in the data connector. It has the following fields:\n\n```\n<OpenDDTypeName> :\n   fieldMapping :  <FieldMapping >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDTypeName`  |  `String`  | true | Name of the OpenDD object type which is being mapped. |\n|  `fieldMapping`  | [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#fieldmapping) | true | The field mapping between the OpenDD object type and the corresponding NDC object type. |\n\n\n## FieldMapping\u200b\n\nThe `fieldMapping` is used by[ typemapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#typemapping)to define mapping for the fields of the `OpenDDTypeName` .\n\nIt has the following fields:\n\n```\n<OpenDDFieldName> :\n   column :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDFieldName`  |  `String`  | true | Name of the field in the OpenDD object type. |\n|  `column`  |  `String`  | true | The name of the field in the NDC object type. |\n\n\n## ArgumentDefinition\u200b\n\nArguments is a list of objects that defines the arguments for the[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure)or a[ command ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure). An argument object has the following fields:\n\n```\nname :  <String > ,\ntype :  <TypeReference >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the argument. |\n|  `type`  |  `Type`  | true | [ TypeReference ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references)of the argument as a string. |\n\n\n## Secret references\u200b\n\nInstead of embedding sensitive values in the metadata, certain fields can be set using[ secrets ](https://hasura.io/docs/3.0/ci-cd/secrets/)stored in DDN.\n\nTo embed a value directly without using a secret:\n\n`value: <your value>`\n\nTo use a value via a secret:\n\n`stringValueFromSecret: <secret name>`\n\n### What did you think of this doc?\n\n- [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#modelpredicate)\n    - [ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#fieldcomparison)\n\n- [ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#relationshippredicate)\n\n- [ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#andexp)\n\n- [ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#orexp)\n\n- [ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#notexp)\n- [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#valueexpression)\n    - [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#literal)\n        - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#examples)\n\n- [ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#sessionvariable)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#examples-1)\n\n- [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#literal)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#examples)\n- [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#typemapping)\n- [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#fieldmapping)\n- [ ArgumentDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#argumentdefinition)\n- [ Secret references ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition/#secret)\n", "https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping": "# Common OpenDD Syntax\n\n## ModelPredicate\u200b\n\nA `ModelPredicate` is used to define the boolean expression for filtering the objects within a model, and is typically used when defining permissions.\n\n```\n[ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#fieldcomparison)\n|\n[ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#relationship)\n|\n[ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#andexp)\n|\n[ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#orexp)\n|\n[ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#notexp)\n```\n\n### FieldComparison\u200b\n\nThis predicate filters objects where the particular `field` of the object returns true when the specified comparison operator `operator` is applied with the `value` as input.\n\n```\nfieldComparison :\n   field :  <FieldName >\n   operator :  <Operator >\n   value :  <ValueExpression >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| field |  `String`  | true | Name of the field of the model to compare. |\n| operator |  `String`  | true | Name of the operator. Either the built-in operators `_ eq` or `_ is_ null` , or any of the operators available from the data connector. |\n| value | [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#valueexpression) | false | The value to compare. Can be a literal value or a a value from session variables. This can be omitted in case of `_ is_ null` operator. |\n\n\n### RelationshipPredicate\u200b\n\nThis predicate evaluates to true if any of the corresponding target objects of the relationship of the source model's object type with `name` meet the nested `predicate` .\n\n```\nrelationship :\n   name :  <RelationshipName >\n   predicate :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| name |  `String`  | true | Name of relationship of the model to compare. |\n| predicate | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#modelpredicate) | false | The filter or predicate expression. |\n\n\n### AndExp\u200b\n\nThis predicates evaluates to true if all sub-predicates of `and` evaluate to true.\n\n```\n{\n  \"and\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#modelpredicate)\n]\n}\n```\n\n### OrExp\u200b\n\nThis predicates evaluates to true if any of the sub-predicates of `or` evaluate to true.\n\n```\n{\n  \"or\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#modelpredicate)\n]\n}\n```\n\n### NotExp\u200b\n\nThis predicates evaluates to true if the sub-predicates of `not` evaluates to false.\n\n```\n{\n  \"not\" :\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#modelpredicate)\n}\n```\n\n## ValueExpression\u200b\n\nAn expression which evaluates to a value that can be used in comparison expressions, etc.\nThis expression can either be a literal value or a reference to a session variable.\n\n```\n[ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#literal)\n|\n[ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#sessionvariable)\n```\n\n### Literal\u200b\n\n```\n{\n   \"literal\" :  <any JSON value>\n}\n```\n\n#### Examples\u200b\n\n`literal :  some string`\n\n### SessionVariable\u200b\n\n`sessionVariable :  String`\n\n#### Examples\u200b\n\n`sessionVariable :  x - hasura - user - id`\n\n## TypeMapping\u200b\n\nThe `typemapping` is used by[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)to define the mapping between the fields of the OpenDD types used in the model/command and\nthe fields of the corresponding types in the data connector. It has the following fields:\n\n```\n<OpenDDTypeName> :\n   fieldMapping :  <FieldMapping >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDTypeName`  |  `String`  | true | Name of the OpenDD object type which is being mapped. |\n|  `fieldMapping`  | [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#fieldmapping) | true | The field mapping between the OpenDD object type and the corresponding NDC object type. |\n\n\n## FieldMapping\u200b\n\nThe `fieldMapping` is used by[ typemapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#typemapping)to define mapping for the fields of the `OpenDDTypeName` .\n\nIt has the following fields:\n\n```\n<OpenDDFieldName> :\n   column :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDFieldName`  |  `String`  | true | Name of the field in the OpenDD object type. |\n|  `column`  |  `String`  | true | The name of the field in the NDC object type. |\n\n\n## ArgumentDefinition\u200b\n\nArguments is a list of objects that defines the arguments for the[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure)or a[ command ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure). An argument object has the following fields:\n\n```\nname :  <String > ,\ntype :  <TypeReference >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the argument. |\n|  `type`  |  `Type`  | true | [ TypeReference ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references)of the argument as a string. |\n\n\n## Secret references\u200b\n\nInstead of embedding sensitive values in the metadata, certain fields can be set using[ secrets ](https://hasura.io/docs/3.0/ci-cd/secrets/)stored in DDN.\n\nTo embed a value directly without using a secret:\n\n`value: <your value>`\n\nTo use a value via a secret:\n\n`stringValueFromSecret: <secret name>`\n\n### What did you think of this doc?\n\n- [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#modelpredicate)\n    - [ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#fieldcomparison)\n\n- [ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#relationshippredicate)\n\n- [ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#andexp)\n\n- [ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#orexp)\n\n- [ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#notexp)\n- [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#valueexpression)\n    - [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#literal)\n        - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#examples)\n\n- [ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#sessionvariable)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#examples-1)\n\n- [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#literal)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#examples)\n- [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#typemapping)\n- [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#fieldmapping)\n- [ ArgumentDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#argumentdefinition)\n- [ Secret references ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping/#secret)\n", "https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples": "# OpenDD Types\n\n## Introduction\u200b\n\nIn the OpenDD spec in Hasura, types serve as the fundamental elements that define the structure of your data.\n\nBeing able to define types in your data domain is beneficial because it provides you with the flexibility to define them\nseparately from the types in your data connector.\n\nThe specification employs a concrete type system that includes both primitive types and user-defined types. All\nsubsequent layers, such as models, commands, and relationships are defined in terms of these types.\n\nThe types can be one of the following:\n\n| OpenDD Type | Description |\n|---|---|\n| Primitive | These are the basic types `ID` , `Int` , `Float` , `Boolean` , or `String`  |\n| Custom | These are user-defined types, such as[ ScalarType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#scalar-types)or[ ObjectType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#object-types) |\n| Type References | When specifying the types of a field or an argument, you can mark them as required `!` or repeated `[]` . |\n\n\nThe spec also allows you to map existing data connector scalars to types in your data domain.\n\nYou can also define custom types by either aliasing existing types (such as primitives or custom), or you can define a\ntype with fields. In turn, the fields themselves can be a primitive or another custom type.\n\nType references are types of fields and arguments that refer to other primitive or custom types and which can be marked\nas nullable, required or repeated (in the case of arrays).\n\n[ Scalar type representation ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#scalar-type-representation)helps in mapping data connector scalars to any of the OpenDD\ntypes.\n\n## Primitive types and type references\u200b\n\nPrimitive types supported by the OpenDD spec are `ID` , `Int` , `Float` , `Boolean` and `String` .\n\nType references in OpenDD follow[ GraphQL type\nsyntax ](https://spec.graphql.org/June2018/#sec-Combining-List-and-Non-Null). Fields and arguments are nullable by\ndefault. To represent non-nullability, specify a `!` after the type name. Similarly, array fields and arguments are\nwrapped in `[]` .\n\n### Examples\u200b\n\nIf the field is nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory\n```\n\nIf the field is non-nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory !\n```\n\nIf the field is a nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ]\n```\n\nIf the field is a nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ]\n```\n\nIf the field is a non-nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ] !\n```\n\nIf the field is a non-nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ] !\n```\n\n## Scalar types\u200b\n\nIn the OpenDD spec, you can create opaque types whose semantics are unknown to OpenDD by defining an object with `kind:\nScalarType` and `version: v1` . These show up as scalars in your GraphQL schema. The object `definition` should include `name` and an optional `graphql` field.\n\n### Metadata structure\u200b\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   graphql :  <ScalarTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `graphql`  | [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#scalartypegraphqlconfig) | false | Configuration for using this scalar type in the GraphQL API. |\n\n\n#### ScalarTypeGraphQLConfig\u200b\n\n `ScalarTypeGraphQLConfig` is an object that defines the configuration for using this scalar type in the GraphQL API.\nAll scalar types are represented as custom[ GraphQL scalars ](https://graphql.org/learn/schema/#scalar-types)in the resulting GraphQL API.\nThis object has a field `typeName` that corresponds to the GraphQL type name to use for this scalar type.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\nBelow, we define an `Email` type that is represented as a primitive `String` type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  Email\n   graphql :\n     typeName :  EmailScalar\n```\n\nBelow, we define an `OpaqueDate` type that is represented as a custom object type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  OpaqueDate\n```\n\n## Object types\u200b\n\nIn the OpenDD spec, completely new types can be created by defining an object with `kind: ObjectType` and `version: v1` .\nYou need to also define a name and the fields for this type.\n\n### Metadata structure\u200b\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   fields :\n     -   name :  field1\n       type :  <TypeReference >\n     -   name :  field2\n       type :  <TypeReference >\n   globalIdFields :\n     -  field1\n   graphql :  <ObjectTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `fields`  | [ [Field] ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#field) | true | List of fields. |\n|  `globalIdFields`  |  `[String]`  | false | Names of the fields that will form the Global ID associated with the object type. |\n|  `graphql`  | [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#objecttypegraphqlconfig) | false | Configuration for using this object type in the GraphQL API. |\n\n\n#### Field\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the field. |\n|  `type`  |  `String`  | true | Type reference of the field. |\n\n\n#### ObjectTypeGraphQLConfig\u200b\n\n `ObjectTypeGraphQLConfig` is config that defines the configuration for using this object type in the GraphQL API.\nWhen used in an output context, a[ GraphQL object type ](https://graphql.org/learn/schema/#object-types-and-fields)is generated for each OpenDD object. `ObjectTypeGraphQLConfig` has a field `typeName` that corresponds to the GraphQL type name to use for this OpenDD object type.\nThe fields of this generated GraphQL object type will have the same names as the OpenDD field names. The generated GraphQL field types\nwill also pick the nullability and repeated characteristics based on the OpenDD type reference for the field.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Below, we define an `author` type that has three fields: `author_id` , `first_name` , and `last_name` . Each field is\nrepresented as a primitive `Int` or `String` type. The `author_id` field is non-nullable whereas `first_name` and `last_name` fields are nullable.\nWhen used in the GraphQL API in an output context, this will result in a GraphQL object type called `Author` .\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n```\n\n1. Extending the `author` type to also have a Global ID field\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n   globalIdFields :\n     -  author_id\n```\n\nNow, the `Author` GraphQL type will have an auto-generated `id` field that is a globally\nunique ID across your data domain, which will be based on the `author_id` field of `artist` .\nThe `node` query root field of the Relay API can then be used to retrieve this global ID,\ngiven there is a model whose `objectType` is `artist` and it is set as the `globalIdSource` .\n\n## Scalar type representation for data connectors\u200b\n\nA scalar type from a data connector can be represented as an OpenDD type by defining an object with `kind: DataConnectorScalarRepresentation` and `version: v1` . To define a scalar type representation, you need to\nhave a data connector name, a data connector scalar type, a type representation and an optional graphql field.\n\nMap scalars for user in your GraphQL API\n\nIt is necessary to map **any** available scalar from a data connector that is used in the GraphQL API.\n\n### Metadata structure\u200b\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  <DataSourceName >\n   dataConnectorScalarType :  <ScalarTypeName >\n   representation :  <TypeName >\n   graphql :  <DataConnectorScalarGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnectorName`  |  `String`  | true | Name of the data connector. |\n|  `dataConnectorScalarType`  |  `String`  | true | Name of the scalar type from the data connector. |\n|  `representation`  |  `String`  | true | Representation of the scalar type in GraphQL schema. |\n|  `graphql`  | [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#dcscalargraphqlconfig) | false | Configuration for using this data connector scalar type in the GraphQL API. |\n\n\n#### DCScalarGraphQLConfig\u200b\n\n `DCScalarGraphQLConfig` is an object that defines the configuration for using this data connector scalar type in the\nGraphQL API. This object has a field `comparisonExpressionTypeName` that corresponds to the GraphQL type name to use for\nthe comparison expression input type that is generated for this data connector scalar type. This comparison expression type\nwill contain the comparison operators for this scalar as defined by the data connector.\n\n```\ngraphql :\n   comparisonExpressionTypeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Mapping a `text` scalar type from the `my_source` connector to a primitive `String` type and giving its GraphQL comparison expression a type name.\n\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  my_source\n   dataConnectorScalarType :  text\n   representation :  String\n   graphql :\n     comparisonExpressionTypeName :  text_comparison_exp\n```\n\n1. Mapping a PostgreSQL scalar `geography` to a custom object type.\n\n\n```\n-   kind :  ObjectType\n   version :  v1\n   definition :\n     name :  Geography\n     fields :\n       -   name :  type\n         type :  String\n       -   name :  coordinates\n         type :   [ Float ]\n-   kind :  DataConnectorScalarRepresentation\n   version :  v1\n   definition :\n     dataConnectorName :  pg_source\n     dataConnectorScalarType :  geography\n     representation :  Geography\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#introduction)\n- [ Primitive types and type references ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#primitive-types-and-type-references)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#examples)\n- [ Scalar types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#scalar-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#metadata-structure)\n        - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#scalartypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#examples-1)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#metadata-structure)\n    - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#scalartypegraphqlconfig)\n- [ Object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#object-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#metadata-structure-1)\n        - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#field)\n\n- [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#objecttypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#object-type-examples)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#metadata-structure-1)\n    - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#field)\n- [ Scalar type representation for data connectors ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#scalar-type-representation)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#metadata-structure-2)\n        - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#dcscalargraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#metadata-structure-2)\n    - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples/#dcscalargraphqlconfig)\n", "https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings": "# Common OpenDD Syntax\n\n## ModelPredicate\u200b\n\nA `ModelPredicate` is used to define the boolean expression for filtering the objects within a model, and is typically used when defining permissions.\n\n```\n[ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#fieldcomparison)\n|\n[ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#relationship)\n|\n[ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#andexp)\n|\n[ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#orexp)\n|\n[ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#notexp)\n```\n\n### FieldComparison\u200b\n\nThis predicate filters objects where the particular `field` of the object returns true when the specified comparison operator `operator` is applied with the `value` as input.\n\n```\nfieldComparison :\n   field :  <FieldName >\n   operator :  <Operator >\n   value :  <ValueExpression >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| field |  `String`  | true | Name of the field of the model to compare. |\n| operator |  `String`  | true | Name of the operator. Either the built-in operators `_ eq` or `_ is_ null` , or any of the operators available from the data connector. |\n| value | [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#valueexpression) | false | The value to compare. Can be a literal value or a a value from session variables. This can be omitted in case of `_ is_ null` operator. |\n\n\n### RelationshipPredicate\u200b\n\nThis predicate evaluates to true if any of the corresponding target objects of the relationship of the source model's object type with `name` meet the nested `predicate` .\n\n```\nrelationship :\n   name :  <RelationshipName >\n   predicate :  <ModelPredicate >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n| name |  `String`  | true | Name of relationship of the model to compare. |\n| predicate | [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#modelpredicate) | false | The filter or predicate expression. |\n\n\n### AndExp\u200b\n\nThis predicates evaluates to true if all sub-predicates of `and` evaluate to true.\n\n```\n{\n  \"and\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#modelpredicate)\n]\n}\n```\n\n### OrExp\u200b\n\nThis predicates evaluates to true if any of the sub-predicates of `or` evaluate to true.\n\n```\n{\n  \"or\" : [\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#modelpredicate)\n]\n}\n```\n\n### NotExp\u200b\n\nThis predicates evaluates to true if the sub-predicates of `not` evaluates to false.\n\n```\n{\n  \"not\" :\n[ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#modelpredicate)\n}\n```\n\n## ValueExpression\u200b\n\nAn expression which evaluates to a value that can be used in comparison expressions, etc.\nThis expression can either be a literal value or a reference to a session variable.\n\n```\n[ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#literal)\n|\n[ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#sessionvariable)\n```\n\n### Literal\u200b\n\n```\n{\n   \"literal\" :  <any JSON value>\n}\n```\n\n#### Examples\u200b\n\n`literal :  some string`\n\n### SessionVariable\u200b\n\n`sessionVariable :  String`\n\n#### Examples\u200b\n\n`sessionVariable :  x - hasura - user - id`\n\n## TypeMapping\u200b\n\nThe `typemapping` is used by[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/)and[ commands ](https://hasura.io/docs/3.0/data-domain-modeling/commands/)to define the mapping between the fields of the OpenDD types used in the model/command and\nthe fields of the corresponding types in the data connector. It has the following fields:\n\n```\n<OpenDDTypeName> :\n   fieldMapping :  <FieldMapping >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDTypeName`  |  `String`  | true | Name of the OpenDD object type which is being mapped. |\n|  `fieldMapping`  | [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#fieldmapping) | true | The field mapping between the OpenDD object type and the corresponding NDC object type. |\n\n\n## FieldMapping\u200b\n\nThe `fieldMapping` is used by[ typemapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#typemapping)to define mapping for the fields of the `OpenDDTypeName` .\n\nIt has the following fields:\n\n```\n<OpenDDFieldName> :\n   column :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDFieldName`  |  `String`  | true | Name of the field in the OpenDD object type. |\n|  `column`  |  `String`  | true | The name of the field in the NDC object type. |\n\n\n## ArgumentDefinition\u200b\n\nArguments is a list of objects that defines the arguments for the[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure)or a[ command ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure). An argument object has the following fields:\n\n```\nname :  <String > ,\ntype :  <TypeReference >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the argument. |\n|  `type`  |  `Type`  | true | [ TypeReference ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references)of the argument as a string. |\n\n\n## Secret references\u200b\n\nInstead of embedding sensitive values in the metadata, certain fields can be set using[ secrets ](https://hasura.io/docs/3.0/ci-cd/secrets/)stored in DDN.\n\nTo embed a value directly without using a secret:\n\n`value: <your value>`\n\nTo use a value via a secret:\n\n`stringValueFromSecret: <secret name>`\n\n### What did you think of this doc?\n\n- [ ModelPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#modelpredicate)\n    - [ FieldComparison ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#fieldcomparison)\n\n- [ RelationshipPredicate ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#relationshippredicate)\n\n- [ AndExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#andexp)\n\n- [ OrExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#orexp)\n\n- [ NotExp ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#notexp)\n- [ ValueExpression ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#valueexpression)\n    - [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#literal)\n        - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#examples)\n\n- [ SessionVariable ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#sessionvariable)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#examples-1)\n\n- [ Literal ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#literal)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#examples)\n- [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#typemapping)\n- [ FieldMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#fieldmapping)\n- [ ArgumentDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#argumentdefinition)\n- [ Secret references ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings/#secret)\n", "https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure": "# OpenDD Models\n\n## Introduction\u200b\n\nModels are the link between your data connectors and the API Hasura generates. A model may be backed by a database\ntable, an ad-hoc SQL query, a pre-materialized view, a custom REST or GraphQL API server, etc.\n\nOnce a model is declared it will then often be referenced by `Relationship` and/or `Permissions` objects.\n\n## Description\u200b\n\nTo create a model, you need to define an OpenDD object with `kind: Model` and `version: v1` . The object `definition` has the following fields:\n\n### Metadata structure\u200b\n\n```\nkind :  Model\nversion :  v1\ndefinition :\n   name :  <ModelName >\n   objectType :  <TypeName >\n   globalIDSource :  true  |  false\n   source :  <SourceConfiguration >\n   graphql :  <GraphQLConfiguration >\n   arguments :   [ ArgumentDefinition ]\n   filterableFields :   [ FilterableFields ]\n   orderableFields :   [ OrderableFields ]\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the model. |\n|  `objectType`  |  `String`  | true | [ Type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)of the objects in this model. |\n|  `globalIDSource`  |  `Boolean`  | true | If this model should be used as the[ Global ID ](https://hasura.io/docs/3.0/data-domain-modeling/global-id/)source for its `objectType` . |\n|  `source`  | [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#source) | false | Source configuration for the model. |\n|  `graphql`  | [ ModelGraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#graphql) | false | GraphQL configuration for the model. |\n|  `arguments`  | [ [ArgumentDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition) | true | The argument definitions for the model. |\n|  `filterableFields`  | [ [FilterableFieldDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#filterablefielddefinition) | true | Filterable fields for the model. |\n|  `orderableFields`  | [ [OrderableFieldDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#orderablefielddefinition) | true | Orderable fields for the model. |\n\n\nFilterable/Orderable Fields support\n\nAt the moment, we don't support field level filterable/orderable customizations. So, you will have to provide an\nexhaustive list of the fields of your model in `filterableFields` and `orderableFields` .\n\n#### SourceConfiguration\u200b\n\nThe source configuration is an object that defines the data source for the model. It has the following fields:\n\n```\nsource :\n   dataConnectorName :  <DataConnectorName >\n   collection :  <CollectionName >\n   typeMapping :  <TypeMapping >\n```\n\n| source Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnector`  |  `String`  | true | Name of the source data connector backing this model. |\n|  `collection`  |  `String`  | true | Name of the collection in the source data connector backing this model. |\n|  `typeMapping`  | [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping) | true | Type mappings from OpenDD object types used within the model to the corresponding data connector types. |\n\n\n#### ModelGraphQLConfiguration\u200b\n\nModelGraphQLConfiguration is an object that defines how the model should be surfaced in the GraphQL API. It has the following fields:\n\n```\ngraphql :\n   selectUniques :  <SelectUniques >\n   selectMany :  <SelectMany >\n   filterExpressionType :  <FilterExpressionType >\n   orderByExpressionType :  <OrderByExpressionType >\n   argumentsInputType :  <ArgumentsInputType >\n```\n\n| graphql Field | Type | Required | Description |\n|---|---|---|---|\n|  `selectUniques`  | [ [SelectUniques] ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#selectuniques) | true | Select uniques configuration for the model. |\n|  `selectMany`  | [ SelectMany ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#selectmany) | false | Select many configuration for the model. |\n|  `filterExpressionType`  |  `String`  | false | GraphQL type name to use for the filter input. |\n|  `orderByExpressionType`  |  `String`  | false | GraphQL type name to use for the order by input. |\n|  `argumentsInputType`  |  `String`  | false | GraphQL type name to use for the model arguments input. |\n\n\n##### SelectUniques\u200b\n\nSelect uniques is an array of objects that defines the unique identifiers for the model. For each select unique defined here,\na query root field is added to the GraphQL API. For each field defined in the `uniqueIdentifier` , an input argument is added\nto the query root field which can be supplied to retrieve the unique identified object from the model.\n\n```\nselectUniques :\n   queryRootField :  <QueryRootField >\n   uniqueIdentifier :  <UniqueIdentifier >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `queryRootField`  |  `String`  | true | Name of the query root field to use in the GraphQL API. |\n|  `uniqueIdentifier`  |  `Array`  | true | Set of fields which can uniquely identify a row/object in the model. |\n\n\n##### SelectMany\u200b\n\nSelect many configuration for a model adds a query root field to the GraphQl API that can be used to retrieve multiple objects from the model.\nThis field can accept the following arguments:\n\n- `args` , used for supplying the values for the model's arguments. This argument is generated only if the model has arguments and `argumentsInputType` is set in the ModelGraphQlConfiguration.\n- `where` , used for filtering the objects to retrieve. This argument is generated only if `filterExpressionType` is set in the ModelGraphQlConfiguration. The filter expression contains all the filterable fields and the `_and` / `_or` / `_not` logical operators.\n- `order_by` , used for sorting the retrieved objects. This argument is generated only if `orderByExpressionType` is set in the ModelGraphQlConfiguration. The order by expression contains all the orderable fields.\n- `limit` , used for limiting the number of retrieved objects.\n- `offset` , used for skipping the first `offset` objects when retrieving.\n\n\n```\nselectMany :\n   queryRootField :  <QueryRootField >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `queryRootField`  |  `String`  | true | Name of the query root field to use in the GraphQL API. |\n\n\n#### FilterableFieldDefinition\u200b\n\nThe filterable field definition is an object that lists the allowed operators for a given field.\n\n```\nfilterableFields :\n   -   fieldName :  <String >\n     operators :\n       enableAll :   true\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | Name of the field. |\n|  `operators`  |  `Object`  | true | Allowed operators (at the moment, we only support `enableAll: true` ) |\n\n\n#### OrderableFieldDefinition\u200b\n\nOrderable field definition is an object that lists down the allowed order by directions for a given field.\n\n```\norderableFields :\n   -   fieldName :  <String >\n     orderByDirections :\n       enableAll :   true\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | Name of the field. |\n|  `orderByDirections`  |  `Object`  | true | Allowed order by directions (at the moment, we only support `enableAll: true` ) |\n\n\n## Examples\u200b\n\nIn this example, we're creating a model called `Authors` backed by a database table called `authors` in the `db` data\nsource:\n\n```\nkind :  Model\nversion :  v1\ndefinition :\n   name :  Authors\n   objectType :  author\n   globalIdSource :   true\n   source :\n     dataConnectorName :  db\n     collection :  authors\n     typeMapping :\n       author :\n         fieldMapping :\n           author_id :\n             column :  id\n           first_name :\n             column :  first_name\n           last_name :\n             column :  last_name\n   graphql :\n     selectUniques :\n       -   queryRootField :  AuthorByID\n         uniqueIdentifier :\n           -  author_id\n     selectMany :\n       queryRootField :  AuthorMany\n     filterExpressionType :  Author_Where_Exp\n     orderByExpressionType :  Author_Order_By\n   arguments :   [ ]\n   filterableFields :\n     -   fieldName :  author_id\n       operators :\n         enableAll :   true\n     -   fieldName :  first_name\n       operators :\n         enableAll :   true\n     -   fieldName :  last_name\n       operators :\n         enableAll :   true\n   orderableFields :\n     -   fieldName :  author_id\n       orderByDirections :\n         enableAll :   true\n     -   fieldName :  first_name\n       orderByDirections :\n         enableAll :   true\n     -   fieldName :  last_name\n       orderByDirections :\n         enableAll :   true\n```\n\nAssuming the ObjectType was defined like[ this ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples), and the scalar types corresponding to the fields had\nappropriate comparison expressions defined, the resulting GraphQl API will be:\n\n```\ntype   Query   {\n   node ( id :   ID ! ) :   Node\n   AuthorByID ( author_id :   Int ! ) :   Author\n   AuthorMany ( where :   Author_Where_Exp ,   order_by   Author_Order_By ,   limit :   Int ,   offset :   Int ) :   Author\n}\ntype   Author   {\n   id :   ID !\n   author_id :   Int !\n   first_name :   String\n   last_name :   String\n}\ninput   Author_Where_Exp :   {\n   _and :   [ Author_Where_Exp ! ]\n   _or :   [ Author_Where_Exp ! ]\n   _not :   [ Author_Where_Exp ! ]\n   author_id :   int_comparison_exp\n   first_name :   text_comparison_exp\n   last_name :   text_comparison_exp\n}\ninput   Author_Order_By   {\n   author_id :   order_by\n   first_name :   order_by\n   last_name :   order_by\n}\nenum   order_by   {\n   Asc ,\n   Desc\n}\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#introduction)\n- [ Description ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#description)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#metadata-structure)\n        - [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#source)\n\n- [ ModelGraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#graphql)\n\n- [ FilterableFieldDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#filterablefielddefinition)\n\n- [ OrderableFieldDefinition ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#orderablefielddefinition)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#metadata-structure)\n    - [ SourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#source)\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/models/#metadata-structure/#examples)\n", "https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure": "# OpenDD Commands\n\n## Introduction\u200b\n\nCommands are backed by **functions** or **procedures** declared in a `DataConnector` allowing you to execute business logic\ndirectly from your GraphQL API. You can use them to validate, process, or enrich some data, call another API, or log a\nuser in. As an example, with commands you can connect to a REST endpoint which can be your own custom server, a public\nAPI, or a serverless function.\n\nTo create a command, you need to define an OpenDD object with `kind: Command` and `version: v1` . The object `definition` has the following fields:\n\n### Metadata structure\u200b\n\n```\nkind :  Command\nversion :  v1\ndefinition :\n   name :  <String >\n   arguments :  <ArgumentDefinition >\n   outputType :  <String >\n   source :  <CommandSourceConfiguration >\n   graphql :  <GraphQLConfiguration >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the command. |\n|  `arguments`  | [ [ArgumentDefinition] ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#argumentdefinition) | false | The argument definitions for the command. |\n|  `outputType`  |  `String`  | true | The name of the return[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)of command. |\n|  `source`  | [ CommandSourceConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure/#commandsourceconfiguration) | true | Source configuration for the command. |\n|  `graphql`  | [ GraphQLConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure/#graphqlconfiguration) | true | GraphQL configuration for the command. |\n\n\n#### CommandSourceConfiguration\u200b\n\nSource is an object that defines the source data connector for the command. It has the following fields:\n\n```\nsource :\n   dataConnectorName :  <String >\n   dataConnectorCommand :  <DataConnectorCommand >\n   typeMapping :  <TypeMapping >\n   argumentMapping :  <ArgumentMapping >\n```\n\nA command can either be backed by a function or a procedure.\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnectorName`  |  `String`  | true | Name of the[ data connector ](https://hasura.io/docs/3.0/data-domain-modeling/data-connectors/)backing this command. |\n|  `dataConnectorCommand`  | [ DataConnectorCommand ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure/#dataconnectorcommand) | true | What command to invoke in the data connector. This will either refer to a function or a procedure. |\n|  `typeMapping`  | [ TypeMapping ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemapping) | false | [ Type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)mappings for the command from OpenDD types used in the command inputs/outputs to the corresponding data connector types. |\n|  `argumentMapping`  | [ ArgumentMapping ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure/#argumentmapping) | false | Mappings for the argument names of the command defined in OpenDD to their corresponding data connector names. |\n\n\n##### DataConnectorCommand\u200b\n\nDataConnectorCommand is an object that defines the NDC `function` or `procedure` to use for executing this command.\n\n```\ndataConnectorCommand :\n   # Either function OR procedure\n   function :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `function` / `procedure`  |  `String`  | true | Name of the function or procedure. One of these must be chosen. |\n\n\nFunctions or Procedures?\n\nFunctions are used for read operations and procedures are used for write operations.\n\n##### ArgumentMapping\u200b\n\nThe `argumentMapping` is used to define the mapping between the OpenDD `arguments` of the command and the arguments\nof the `function` or `procedure` in the data connector. It has the following fields:\n\n```\nargumentMappings :\n   <OpenDDArgumentName> :  <NDCArgumentName >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `OpenDDArgumentName`  |  `String`  | true | Name of the argument of the command as defined in OpenDD |\n|  `NDCArgumentName`  |  `String`  | true | The name of the argument in function or procedure to which the `OpenDDArgumentName` maps to |\n\n\n#### GraphQLConfiguration\u200b\n\nGraphQL is an object that defines how the command should be surfaced in the GraphQL API. The command can show up either under the query root field or under the mutation root field. This can be configured as follows:\n\n```\ngraphql :\n   rootFieldName :  <String >\n   rootFieldKind :  <String >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `rootFieldName`  |  `String`  | true | The GraphQL root field name to use for the command. |\n|  `rootFieldKind`  |  `String`  | true | The type of GraphQL operation ( `Query` ). |\n\n\n## Examples\u200b\n\nBelow, we're creating a `Command` called `get_article_by_id` which takes an argument `article_id` of type `Int!` (non-nullable `Int` ) and returns an object of type `article` (similar to one defined[ here ](https://hasura.io/docs/3.0/data-domain-modeling/types/#object-type-examples)).[ The command is backed by a function ](https://hasura.io/docs/3.0/data-domain-modeling/common-syntax/#typemappings)called `get_article_by_id` in the `db` data connector.\nThe function returns an object with fields `id` , `title` , and `author_id` . The `id` field is mapped to the `article_id` argument and the `title` and `author_id` fields are mapped to the `title` and `author_id` columns respectively.\n\n```\nkind :  Command\nversion :  v1\ndefinition :\n   name :  get_article_by_id\n   arguments :\n     -   name :  article_id\n       type :  Int !\n   outputType :  article\n   source :\n     dataConnectorName :  db\n     dataConnectorCommand :\n       function :  get_article_by_id\n     typeMapping :\n       article :\n         fieldMapping :\n           article_id :\n             column :  id\n           title :\n             column :  title\n           author_id :\n             column :  author_id\n     argumentMapping :\n       article_id :  id\n   graphql :\n     rootFieldName :  getArticleById\n     rootFieldKind :  Query\n```\n\nThis resulting GraphQL API will be:\n\n```\ntype   Query   {\n   getArticleById ( article_id :   Int ! ) :   Article\n}\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure/#introduction)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure/#metadata-structure)\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/commands/#metadata-structure/#examples)\n", "https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references": "# OpenDD Types\n\n## Introduction\u200b\n\nIn the OpenDD spec in Hasura, types serve as the fundamental elements that define the structure of your data.\n\nBeing able to define types in your data domain is beneficial because it provides you with the flexibility to define them\nseparately from the types in your data connector.\n\nThe specification employs a concrete type system that includes both primitive types and user-defined types. All\nsubsequent layers, such as models, commands, and relationships are defined in terms of these types.\n\nThe types can be one of the following:\n\n| OpenDD Type | Description |\n|---|---|\n| Primitive | These are the basic types `ID` , `Int` , `Float` , `Boolean` , or `String`  |\n| Custom | These are user-defined types, such as[ ScalarType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#scalar-types)or[ ObjectType ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#object-types) |\n| Type References | When specifying the types of a field or an argument, you can mark them as required `!` or repeated `[]` . |\n\n\nThe spec also allows you to map existing data connector scalars to types in your data domain.\n\nYou can also define custom types by either aliasing existing types (such as primitives or custom), or you can define a\ntype with fields. In turn, the fields themselves can be a primitive or another custom type.\n\nType references are types of fields and arguments that refer to other primitive or custom types and which can be marked\nas nullable, required or repeated (in the case of arrays).\n\n[ Scalar type representation ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#scalar-type-representation)helps in mapping data connector scalars to any of the OpenDD\ntypes.\n\n## Primitive types and type references\u200b\n\nPrimitive types supported by the OpenDD spec are `ID` , `Int` , `Float` , `Boolean` and `String` .\n\nType references in OpenDD follow[ GraphQL type\nsyntax ](https://spec.graphql.org/June2018/#sec-Combining-List-and-Non-Null). Fields and arguments are nullable by\ndefault. To represent non-nullability, specify a `!` after the type name. Similarly, array fields and arguments are\nwrapped in `[]` .\n\n### Examples\u200b\n\nIf the field is nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory\n```\n\nIf the field is non-nullable, it should be defined as\n\n```\nname :  category\ntype :\n  ProductCategory !\n```\n\nIf the field is a nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ]\n```\n\nIf the field is a nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ]\n```\n\nIf the field is a non-nullable array of nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ] !\n```\n\nIf the field is a non-nullable array of non-nullable type, it should be defined as\n\n```\nname :  tags\ntype :\n   [ String ! ] !\n```\n\n## Scalar types\u200b\n\nIn the OpenDD spec, you can create opaque types whose semantics are unknown to OpenDD by defining an object with `kind:\nScalarType` and `version: v1` . These show up as scalars in your GraphQL schema. The object `definition` should include `name` and an optional `graphql` field.\n\n### Metadata structure\u200b\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   graphql :  <ScalarTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `graphql`  | [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#scalartypegraphqlconfig) | false | Configuration for using this scalar type in the GraphQL API. |\n\n\n#### ScalarTypeGraphQLConfig\u200b\n\n `ScalarTypeGraphQLConfig` is an object that defines the configuration for using this scalar type in the GraphQL API.\nAll scalar types are represented as custom[ GraphQL scalars ](https://graphql.org/learn/schema/#scalar-types)in the resulting GraphQL API.\nThis object has a field `typeName` that corresponds to the GraphQL type name to use for this scalar type.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\nBelow, we define an `Email` type that is represented as a primitive `String` type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  Email\n   graphql :\n     typeName :  EmailScalar\n```\n\nBelow, we define an `OpaqueDate` type that is represented as a custom object type:\n\n```\nkind :  ScalarType\nversion :  v1\ndefinition :\n   name :  OpaqueDate\n```\n\n## Object types\u200b\n\nIn the OpenDD spec, completely new types can be created by defining an object with `kind: ObjectType` and `version: v1` .\nYou need to also define a name and the fields for this type.\n\n### Metadata structure\u200b\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  <TypeName >\n   fields :\n     -   name :  field1\n       type :  <TypeReference >\n     -   name :  field2\n       type :  <TypeReference >\n   globalIdFields :\n     -  field1\n   graphql :  <ObjectTypeGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the type. |\n|  `fields`  | [ [Field] ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#field) | true | List of fields. |\n|  `globalIdFields`  |  `[String]`  | false | Names of the fields that will form the Global ID associated with the object type. |\n|  `graphql`  | [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#objecttypegraphqlconfig) | false | Configuration for using this object type in the GraphQL API. |\n\n\n#### Field\u200b\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | Name of the field. |\n|  `type`  |  `String`  | true | Type reference of the field. |\n\n\n#### ObjectTypeGraphQLConfig\u200b\n\n `ObjectTypeGraphQLConfig` is config that defines the configuration for using this object type in the GraphQL API.\nWhen used in an output context, a[ GraphQL object type ](https://graphql.org/learn/schema/#object-types-and-fields)is generated for each OpenDD object. `ObjectTypeGraphQLConfig` has a field `typeName` that corresponds to the GraphQL type name to use for this OpenDD object type.\nThe fields of this generated GraphQL object type will have the same names as the OpenDD field names. The generated GraphQL field types\nwill also pick the nullability and repeated characteristics based on the OpenDD type reference for the field.\n\n```\ngraphql :\n   typeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Below, we define an `author` type that has three fields: `author_id` , `first_name` , and `last_name` . Each field is\nrepresented as a primitive `Int` or `String` type. The `author_id` field is non-nullable whereas `first_name` and `last_name` fields are nullable.\nWhen used in the GraphQL API in an output context, this will result in a GraphQL object type called `Author` .\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n```\n\n1. Extending the `author` type to also have a Global ID field\n\n\n```\nkind :  ObjectType\nversion :  v1\ndefinition :\n   name :  author\n   fields :\n     -   name :  author_id\n       type :  Int !\n     -   name :  first_name\n       type :  String\n     -   name :  last_name\n       type :  String\n   graphql :\n     typeName :  Author\n   globalIdFields :\n     -  author_id\n```\n\nNow, the `Author` GraphQL type will have an auto-generated `id` field that is a globally\nunique ID across your data domain, which will be based on the `author_id` field of `artist` .\nThe `node` query root field of the Relay API can then be used to retrieve this global ID,\ngiven there is a model whose `objectType` is `artist` and it is set as the `globalIdSource` .\n\n## Scalar type representation for data connectors\u200b\n\nA scalar type from a data connector can be represented as an OpenDD type by defining an object with `kind: DataConnectorScalarRepresentation` and `version: v1` . To define a scalar type representation, you need to\nhave a data connector name, a data connector scalar type, a type representation and an optional graphql field.\n\nMap scalars for user in your GraphQL API\n\nIt is necessary to map **any** available scalar from a data connector that is used in the GraphQL API.\n\n### Metadata structure\u200b\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  <DataSourceName >\n   dataConnectorScalarType :  <ScalarTypeName >\n   representation :  <TypeName >\n   graphql :  <DataConnectorScalarGraphQLConfig >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `dataConnectorName`  |  `String`  | true | Name of the data connector. |\n|  `dataConnectorScalarType`  |  `String`  | true | Name of the scalar type from the data connector. |\n|  `representation`  |  `String`  | true | Representation of the scalar type in GraphQL schema. |\n|  `graphql`  | [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#dcscalargraphqlconfig) | false | Configuration for using this data connector scalar type in the GraphQL API. |\n\n\n#### DCScalarGraphQLConfig\u200b\n\n `DCScalarGraphQLConfig` is an object that defines the configuration for using this data connector scalar type in the\nGraphQL API. This object has a field `comparisonExpressionTypeName` that corresponds to the GraphQL type name to use for\nthe comparison expression input type that is generated for this data connector scalar type. This comparison expression type\nwill contain the comparison operators for this scalar as defined by the data connector.\n\n```\ngraphql :\n   comparisonExpressionTypeName :  <GraphQLTypeName >\n```\n\n### Examples\u200b\n\n1. Mapping a `text` scalar type from the `my_source` connector to a primitive `String` type and giving its GraphQL comparison expression a type name.\n\n\n```\nkind :  DataConnectorScalarRepresentation\nversion :  v1\ndefinition :\n   dataConnectorName :  my_source\n   dataConnectorScalarType :  text\n   representation :  String\n   graphql :\n     comparisonExpressionTypeName :  text_comparison_exp\n```\n\n1. Mapping a PostgreSQL scalar `geography` to a custom object type.\n\n\n```\n-   kind :  ObjectType\n   version :  v1\n   definition :\n     name :  Geography\n     fields :\n       -   name :  type\n         type :  String\n       -   name :  coordinates\n         type :   [ Float ]\n-   kind :  DataConnectorScalarRepresentation\n   version :  v1\n   definition :\n     dataConnectorName :  pg_source\n     dataConnectorScalarType :  geography\n     representation :  Geography\n```\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#introduction)\n- [ Primitive types and type references ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#primitive-types-and-type-references)\n    - [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#examples)\n- [ Scalar types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#scalar-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#metadata-structure)\n        - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#scalartypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#examples-1)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#metadata-structure)\n    - [ ScalarTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#scalartypegraphqlconfig)\n- [ Object types ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#object-types)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#metadata-structure-1)\n        - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#field)\n\n- [ ObjectTypeGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#objecttypegraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#object-type-examples)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#metadata-structure-1)\n    - [ Field ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#field)\n- [ Scalar type representation for data connectors ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#scalar-type-representation)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#metadata-structure-2)\n        - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#dcscalargraphqlconfig)\n\n- [ Examples ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#examples-2)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#metadata-structure-2)\n    - [ DCScalarGraphQLConfig ](https://hasura.io/docs/3.0/data-domain-modeling/types/#primitive-types-and-type-references/#dcscalargraphqlconfig)\n", "https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/": "# Simple Object Queries\n\n## Introduction\u200b\n\nYou can fetch a single node or multiple nodes of the same type using a simple object query.\n\n## Fetch a list of objects\u200b\n\n **Example:** Fetch a list of authors:\n\n## Fetch an object using its primary key\u200b\n\n **Example:** Fetch an author using their primary key:\n\n## Fetch list of objects with pagination\u200b\n\n **Example:** Fetch 2 articles after removing the 1st article from the result set.\n\nWarning\n\nWithout an `order_by` in `limit` queries, the results may be unpredictable.\n\n## Fetch list of objects with filtering\u200b\n\n **Example:** Fetch a list of articles whose title contains the word \"The\":\n\n## Fetch list of objects with sorting\u200b\n\n **Example:** Fetch a list of articles with `article_id` in descending order:\n\n## Fetch objects using model arguments\u200b\n\n **Example:** Fetch the articles for the given `author_id` :\n\nOnly available for Native Queries\n\nThis feature is only available for Native Queries.\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/#introduction)\n- [ Fetch a list of objects ](https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/#fetch-a-list-of-objects)\n- [ Fetch an object using its primary key ](https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/#fetch-an-object-using-its-primary-key)\n- [ Fetch list of objects with pagination ](https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/#fetch-list-of-objects-with-pagination)\n- [ Fetch list of objects with filtering ](https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/#fetch-list-of-objects-with-filtering)\n- [ Fetch list of objects with sorting ](https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/#fetch-list-of-objects-with-sorting)\n- [ Fetch objects using model arguments ](https://hasura.io/docs/3.0/graphql-api/queries/simple-queries/#fetch-objects-using-model-arguments)\n", "https://hasura.io/docs/3.0/graphql-api/queries/pagination/": "# Paginate Query Results\n\n## The limit & offset arguments\u200b\n\nThe operators `limit` and `offset` are used for pagination.\n\n `limit` specifies the number of rows to retain from the result set and `offset` determines which slice to retain from\nthe results.\n\nThe following are examples of different pagination scenarios:\n\n## Limit results\u200b\n\n **Example:** Fetch the first 5 authors from the list of all authors:\n\n## Limit results from an offset\u200b\n\n **Example:** Fetch 5 authors from the list of all authors, starting with the 6th one:\n\n## Limit results in a nested object\u200b\n\n **Example:** Fetch a list of authors and a list of their first 2 articles:\n\n## Keyset cursor based pagination\u200b\n\nCursors are used to traverse across rows of a dataset. They work by returning a pointer to a specific row which can then\nbe used to fetch the next batch of data.\n\nKeyset cursors are a column (or a set of columns) of the data that are used as the cursor. The column(s) used as the\ncursor must be unique and sequential. This ensures that data is read after a specific row rather than relying on the\nposition of the row in the dataset as done by `offset` , and that duplicate records are not fetched again.\n\n **For example** , consider the following query to fetch a list of authors with a `where` clause used in place of `offset` :\n\nHere we are fetching authors where the value of `id` is greater than 5. This will always skip the previously fetched\nresults which would have been ids 1 to 5, ensuring no duplicate results. Column `id` is acting as the cursor here,\nunique and sequential.\n\nThe choice of cursor columns depends on the order of the expected results i.e. if the query has an `order_by` clause,\nthe column(s) used in the `order_by` need to be used as the cursor.\n\nColumns such as `id` (auto-incrementing integer/big integer) or `created_at` (timestamp) are commonly used as cursors\nwhen an order is not explicit, as they should be unique and sequential.\n\nWhere vs Offset\n\nKeyset cursor based pagination using `where` is more performant than using `offset` because we can leverage database\nindexes on the columns that are being used as cursors.\n\nNo order_by clause\n\nBecause we ran the above example without an `order_by` clause, it is accidental that we received those results.\nRunning a query without an `order_by` clause will return results in an arbitrary order.\n\n### What did you think of this doc?\n\n- [ The limit & offset arguments ](https://hasura.io/docs/3.0/graphql-api/queries/pagination/#the-limit--offset-arguments)\n- [ Limit results ](https://hasura.io/docs/3.0/graphql-api/queries/pagination/#limit-results)\n- [ Limit results from an offset ](https://hasura.io/docs/3.0/graphql-api/queries/pagination/#limit-results-from-an-offset)\n- [ Limit results in a nested object ](https://hasura.io/docs/3.0/graphql-api/queries/pagination/#pg-nested-paginate)\n- [ Keyset cursor based pagination ](https://hasura.io/docs/3.0/graphql-api/queries/pagination/#keyset-cursor-based-pagination)\n", "https://hasura.io/docs/3.0/graphql-api/queries/multiple-arguments/": "# Use Multiple Query Arguments\n\nMultiple arguments can be used together in the same query.\n\nFor example, you can use the `where` argument to filter the results and then use the `order_by` argument to sort them.\n\n **For example** , fetch a list of authors and only 2 of their published articles that are sorted by their date of*publication:\n\n### What did you think of this doc?", "https://hasura.io/docs/3.0/graphql-api/queries/multiple-queries/": "# Multiple Queries in a Request\n\n## Execution\u200b\n\nYou can fetch objects of different unrelated types in the same query.\n\n## Run multiple top level queries in the same request\u200b\n\n **For example** , fetch a list of `authors` and a list of `articles` :\n\n## Fetch limited results along with data aggregated over all results (e.g. total count) in the same query\u200b\n\nSometimes, some aggregated information on all the data is required along with a subset of data.\n\nE.g. the total count of results can be returned along with a page of results. The count can then be used to calculate\nthe number of pages based on the limit that is set.\n\n **Example:** Fetch a list of articles where a certain condition is true and get their count. Then limit the number of\narticles to return.\n\n### What did you think of this doc?\n\n- [ Execution ](https://hasura.io/docs/3.0/graphql-api/queries/multiple-queries/#execution)\n- [ Run multiple top level queries in the same request ](https://hasura.io/docs/3.0/graphql-api/queries/multiple-queries/#run-multiple-top-level-queries-in-the-same-request)\n- [ Fetch limited results along with data aggregated over all results (e.g. total count) in the same query ](https://hasura.io/docs/3.0/graphql-api/queries/multiple-queries/#fetch-limited-results-along-with-data-aggregated-over-all-results-eg-total-count-in-the-same-query)\n", "https://hasura.io/docs/3.0/graphql-api/queries/variables-aliases-fragments-directives/": "# Use Variables / Aliases / Fragments / Directives in Queries\n\n## Using variables\u200b\n\nIn order to make a query re-usable, it can be made dynamic by using variables.\n\n **Example:** Fetch an author by their `author_id` :\n\n## Using aliases\u200b\n\nAliases can be used to return objects with a different name than their field name. This is especially useful while\nfetching the same type of objects with different arguments in the same query.\n\n **Example:** First, fetch all articles. Second, fetch the two top-rated articles. Third, fetch the worst-rated article:\n\n## Using fragments\u200b\n\nSometimes, queries can get long and confusing. A fragment is a set of fields with any chosen name. This fragment can\nthen be used to represent the defined set.\n\n **Example:** Creating a fragment for a set of `article` fields ( `id` and `title` ) and using it in a query:\n\n## Using directives\u200b\n\nDirectives make it possible to include or skip a field based on a boolean expression passed as a query variable.\n\n### @include(if: Boolean)\u200b\n\nWith `@include(if: Boolean)` , it is possible to include a field in the query result based on a Boolean expression.\n\n **Example:** The query result includes the field `publisher` , as `$with_publisher` is set to `true` :\n\n **Example:** The query result doesn't include the field `publisher` , as `$with_publisher` is set to `false` :\n\n### @skip(if: Boolean)\u200b\n\nWith `@skip(if: Boolean)` , it is possible to exclude (skip) a field in the query result based on a Boolean expression.\n\n **Example:** The query result doesn't include the field `publisher` , as `$with_publisher` is set to `true` :\n\n **Example:** The query result includes the field `publisher` , as `$with_publisher` is set to `false` :\n\n### What did you think of this doc?\n\n- [ Using variables ](https://hasura.io/docs/3.0/graphql-api/queries/variables-aliases-fragments-directives/#using-variables)\n- [ Using aliases ](https://hasura.io/docs/3.0/graphql-api/queries/variables-aliases-fragments-directives/#using-aliases)\n- [ Using fragments ](https://hasura.io/docs/3.0/graphql-api/queries/variables-aliases-fragments-directives/#using-fragments)\n- [ Using directives ](https://hasura.io/docs/3.0/graphql-api/queries/variables-aliases-fragments-directives/#using-directives)\n    - [ @include(if: Boolean) ](https://hasura.io/docs/3.0/graphql-api/queries/variables-aliases-fragments-directives/#includeif-boolean)\n\n- [ @skip(if: Boolean) ](https://hasura.io/docs/3.0/graphql-api/queries/variables-aliases-fragments-directives/#skipif-boolean)\n", "https://hasura.io/docs/3.0/graphql-api/queries/filters/comparison-operators/": "# Filter by Comparing Values\n\n## Introduction\u200b\n\nComparison operators are used to compare values of the same type. For example, to compare two numbers, two strings, two\ndates, etc.\n\n## Equality operators (_eq, _neq)\u200b\n\nThe `_eq` (equal to) or the `_neq` (not equal to) operators are compatible with any type other than `json` or `jsonB` (like `Integer` , `Float` , `Double` , `Text` , `Boolean` , `Date` / `Time` / `Timestamp` , etc.).\n\nThe following are examples of using the equality operators on different types.\n\n **Example: Integer (works with Double, Float, Numeric, etc.)** \n\nFetch data about an author whose `id`  *(an integer field)* is equal to 3:\n\n **Example: String or Text** \n\nFetch a list of authors with `name`  *(a text field)* as \"Sidney\":\n\n **Example: Boolean** \n\nFetch a list of articles that have not been published ( `is_published` is a boolean field):\n\n **Example: Date (works with Time, Timezone, etc.)** \n\nFetch a list of articles that were published on a certain date ( `published_on` is a Date field):\n\n **Example: Integer (works with Integer, Float, Double, etc.)** \n\nFetch a list of users whose age is *not* 30 ( `age` is an Integer field):\n\nCaveat for \"null\" values\n\nBy design, the `_eq` or `_neq` operators will not return rows with `null` values.\n\nTo also return rows with `null` values, the `_is_null` operator needs to be used along with these joined by the `_or` operator.\n\nFor example, to fetch a list of articles where the `is_published` column is either `false` or `null` :\n\n## Greater than or less than operators (_gt, _lt, _gte, _lte)\u200b\n\nThe `_gt` (greater than), `_lt` (less than), `_gte` (greater than or equal to), `_lte` (less than or equal to) operators\nare compatible with any type other than `json` or `jsonB` (like `Integer` , `Float` , `Double` , `Text` , `Boolean` , `Date` / `Time` / `Timestamp` , etc.).\n\nThe following are examples of using these operators on different types:\n\n **Example: Integer (works with Double, Float, Numeric, etc.)** \n\nThis query retrieves all users whose age is less than 30. The `_lt` operator is a comparison operator that means \"less\nthan\". It is used to filter records based on a specified value.\n\n **Example: String or Text** \n\nFetch a list of authors whose names begin with M or any letter that follows M *(essentially, a filter based on a\ndictionary sort)* :\n\n **Example: Integer (works with Double, Float, etc.)** \n\nFetch a list of all products with a price less than or equal to 10.\n\n **Example: Integer (works with Double, Float, etc.)** \n\nFetch a list of articles rated 4 or more ( `rating` is an integer field):\n\n **Example: Date (works with Time, Timezone, etc.)** \n\nFetch a list of articles that were published on or after date \"01/01/2018\":\n\n## List based search operators (_in)\u200b\n\nThe `_in` (in a list) operator is used to compare field values to a list of values. They are compatible with any\ntype other than `json` or `jsonB` (like `Integer` , `Float` , `Double` , `Text` , `Boolean` , `Date` / `Time` / `Timestamp` , etc.).\n\nThe following are examples of using these operators on different types:\n\n **Example: Integer (works with Double, Float, etc.)** \n\nFetch a list of articles rated 1, 3 or 5:\n\n## Filter or check for null values (_is_null)\u200b\n\nChecking for null values can be achieved using the `_is_null` operator.\n\n **Example: Filter null values in a field** \n\nFetch a list of articles that have a value in the `published_on` field:\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/graphql-api/queries/filters/comparison-operators/#introduction)\n- [ Equality operators (_eq, _neq) ](https://hasura.io/docs/3.0/graphql-api/queries/filters/comparison-operators/#equality-operators-_eq-_neq)\n- [ Greater than or less than operators (_gt, _lt, _gte, _lte) ](https://hasura.io/docs/3.0/graphql-api/queries/filters/comparison-operators/#greater-than-or-less-than-operators-_gt-_lt-_gte-_lte)\n- [ List based search operators (_in) ](https://hasura.io/docs/3.0/graphql-api/queries/filters/comparison-operators/#list-based-search-operators-_in)\n- [ Filter or check for null values (_is_null) ](https://hasura.io/docs/3.0/graphql-api/queries/filters/comparison-operators/#filter-or-check-for-null-values-_is_null)\n", "https://hasura.io/docs/3.0/graphql-api/queries/filters/boolean-operators/": "# Filter by Boolean Expressions\n\n## Filter based on failure of some criteria (_not)\u200b\n\nThe `_not` operator can be used to fetch results for which some condition does not hold true. i.e. to invert the filter\nset for a condition.\n\n **Example:  _ not** \n\nFetch all authors who don't have any published articles:\n\n## Using multiple filters in the same query (_and, _or)\u200b\n\nYou can group multiple parameters in the same `where` argument using the `_and` or the `_or` operators to filter results\nbased on more than one criterion.\n\nNote\n\nYou can use the `_or` and `_and` operators along with the `_not` operator to create arbitrarily complex boolean\nexpressions involving multiple filtering criteria.\n\n **Example:  _ and** \n\nFetch a list of articles published in a specific time-frame (for example: in year 2017):\n\nNote\n\nCertain `_and` expressions can be expressed in a simpler format using some syntactic sugar.\n\n **Example:  _ or** \n\nFetch a list of articles rated more than 4 or published after \"01/01/2018\":\n\n### What did you think of this doc?\n\n- [ Filter based on failure of some criteria (_not) ](https://hasura.io/docs/3.0/graphql-api/queries/filters/boolean-operators/#filter-based-on-failure-of-some-criteria-_not)\n- [ Using multiple filters in the same query (_and, _or) ](https://hasura.io/docs/3.0/graphql-api/queries/filters/boolean-operators/#using-multiple-filters-in-the-same-query-_and-_or)\n", "https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/": "# Filter by Text\n\n## Introduction\u200b\n\nThe `_like` , `_nlike` , `_ilike` , `_nilike` , `_similar` , `_nsimilar` , `_regex` , `_nregex` , `_iregex` , `_niregex` operators are used for pattern matching on string/text fields.\n\n## _like\u200b\n\nFetch a list of articles whose titles contain the word \u201camet\u201d:\n\n## _ilike\u200b\n\nThis query will return all users whose name contains the string \"john\", regardless of case.\n\n## _nilike\u200b\n\nThis query would return all users whose name does not contain the string \"John\".\n\nNote\n\n `_like` is case-sensitive. Use `_ilike` for case-insensitive search.\n\n## _similar\u200b\n\nFetch a list of authors whose names begin with A or C:\n\n## _nsimilar\u200b\n\nFetch a list of authors whose names do not begin with A or C:\n\nNote\n\n `_similar` and `_nsimilar` are case-sensitive.\n\n## _regex\u200b\n\nFetch a list of articles whose titles match the regex `[ae]met` :\n\n## _iregex\u200b\n\nThis query will return all users whose name matches the regular expression `/^joh?n$/i` , which matches \"John\" and \"Jon\".\n\n## _nregex\u200b\n\nThe_nregex operator in this GraphQL query is a negated regular expression filter that matches all users whose names do\nnot start with the letter \"J\".\n\nNote\n\n `_regex` is case-sensitive. Use `_iregex` for case-insensitive search.\n\nNote\n\n `regex` operators are supported in `v2.0.0` and above\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#introduction)\n- [ _like ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#_like)\n- [ _ilike ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#_ilike)\n- [ _nilike ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#_nilike)\n- [ _similar ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#_similar)\n- [ _nsimilar ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#_nsimilar)\n- [ _regex ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#_regex)\n- [ _iregex ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#_iregex)\n- [ _nregex ](https://hasura.io/docs/3.0/graphql-api/queries/filters/text-search-operators/#_nregex)\n", "https://hasura.io/docs/3.0/graphql-api/queries/filters/nested-objects/": "# Filter Based on Fields of Nested Objects\n\n## Introduction\u200b\n\nYou can use the fields of nested objects as well to filter your query results.\n\nFor example:\n\n```\nquery   {\n   articles ( where :   {   author :   {   name :   {   _eq :   \"Sidney\"   }   }   } )   {\n     id\n     title\n   }\n}\n```\n\nThe behavior of the comparison operators depends on whether the nested objects are a single object related via an object\nrelationship or an array of objects related via an array relationship.\n\n- In case of an **object relationship** , a row will be returned if the single nested object satisfies the defined\ncondition.\n- In case of an **array relationship** , a row will be returned if **any of the nested objects** satisfy the defined\ncondition.\n\n\nLimitations\n\n **This is only supported for local relationships** , such as relationships between two local database tables. **This is\nnot supported for remote relationships** , such as remote database relationships or Remote Schema relationships.\n\nLet's look at a few use cases based on the above:\n\n## Fetch if the single nested object defined via an object relationship satisfies a condition\u200b\n\n **Example:** \n\nFetch all articles whose author's name starts with \"A\":\n\n## Fetch if nested object(s) exist/do not exist\u200b\n\nYou can filter results based on if they have nested objects by checking if any nested objects exist. This can be\nachieved by using the expression `{}` which evaluates to `true` if any object exists.\n\n **Example where nested object(s) exist:** \n\nFetch all authors which have at least one article written by them:\n\n **Example where nested object(s) do not exist:** \n\nFetch all authors which have not written any articles:\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/graphql-api/queries/filters/nested-objects/#introduction)\n- [ Fetch if the single nested object defined via an object relationship satisfies a condition ](https://hasura.io/docs/3.0/graphql-api/queries/filters/nested-objects/#fetch-if-the-single-nested-object-defined-via-an-object-relationship-satisfies-a-condition)\n- [ Fetch if nested object(s) exist/do not exist ](https://hasura.io/docs/3.0/graphql-api/queries/filters/nested-objects/#fetch-if-nested-objects-existdo-not-exist)\n", "https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel": "# OpenDD Relationships\n\n## Introduction\u200b\n\nA relationship allows you to query nested or linked information, for example from `Manufacturers` to `Products` . A\nrelationship defined in the OpenDD spec allows you extend[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)objects with related[ models ](https://hasura.io/docs/3.0/data-domain-modeling/models/).\n\nTo create a relationship, you will need to define an object with `kind: Relationship` and `version: v1` . The object `definition` has a `name` , the `source` type, a `target` model and the `mapping` between the two.\n\n### Metadata structure\u200b\n\n```\nkind :  Relationship\nversion :  v1\ndefinition :\n   source :  <String >\n   name :  <String >\n   target :  <TargetConfiguration >\n   mapping :  <RelationshipMapping >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `source`  |  `String`  | true | The source[ type ](https://hasura.io/docs/3.0/data-domain-modeling/types/)of the relationship. |\n|  `name`  |  `String`  | true | The name of the relationship. |\n|  `target`  | [ TargetConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#targetconfiguration) | true | The target of the relationship. |\n|  `mapping`  | [ [RelationshipMapping] ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationshipmapping) | true | Defines how the `Source` and `Target` should be connected. This field expects a list of objects. |\n\n\n#### TargetConfiguration\u200b\n\n```\ntarget :\n   model :  <TargetModel >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `model`  | [ TargetModel ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#targetmodel) | true | The target[ model ](https://hasura.io/docs/3.0/data-domain-modeling/models/)for the relationship. |\n\n\n#### TargetModel\u200b\n\n```\nmodel :\n   name :  <String >\n   subgraph :  <String >\n   relationshipType :  <RelationshipType >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `name`  |  `String`  | true | The name of the target model. |\n|  `subgraph`  |  `String`  | false | The subgraph of the target model. Defaults to the subgraph of the relationship metadata object. |\n|  `relationshipType`  | [ RelationshipType ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationshiptype) | true | The type of the relationship: either `Object` or `Array` . |\n\n\n#### RelationshipType\u200b\n\n`relationshipType :  Object  |  Array`\n\n| Value | Description |\n|---|---|\n|  `Object`  | The relationship is a one-to-one relationship. |\n|  `Array`  | The relationship is a one-to-many relationship. |\n\n\n#### RelationshipMapping\u200b\n\nDefines how the source type maps to the target model in this relationship. The mapping can have multiple links.\n\n```\nmapping :\n   -   source :  <RelationshipMappingSource >\n     target :  <RelationshipMappingTarget >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `source`  | [ RelationshipMappingSource ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationshipmappingsource) | true | The source link of this mapping. |\n|  `target`  | [ RelationshipMappingTarget ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationshipmappingtarget) | true | The target link of this mapping. |\n\n\n#### RelationshipMappingSource\u200b\n\n```\nsource :\n   fieldPath :\n     -  <FieldAccess >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldPath`  | [ [FieldAccess] ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#fieldaccess) | true | The field path of the source link. |\n\n\n#### RelationshipMappingTarget\u200b\n\n```\ntarget :\n   modelField :\n     -  <FieldAccess >\n```\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `modelField`  | [ [FieldAccess] ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#fieldaccess) | true | The field path of the target model the source link maps to. |\n\n\n#### FieldAccess\u200b\n\nDefines a single element of a field path.\n\n`fieldName :  <FieldName >`\n\n| Field | Type | Required | Description |\n|---|---|---|---|\n|  `fieldName`  |  `String`  | true | The name of the field for this path element. |\n\n\n## Example\u200b\n\n### Basic relationship\u200b\n\nLet's add the following relationships to the above types.\n\n1. `Array` relationship where `author` has many `Articles` :\n\n\n```\nkind :  Relationship\nversion :\ndefinition :\n   source :  author\n   name :  articles\n   target :\n     model :\n       name :  Articles\n       relationshipType :  Array\n   mappings :\n     -   source :\n         fieldPath :\n           -   fieldName :  id\n       target :\n         modelField :\n           -   fieldName :  author_id\n```\n\n1. `Object` relationship where `article` has one `Author` :\n\n\n```\nkind :  Relationship\nversion :  v1\ndefinition :\n   source :  article\n   name :  author\n   target :\n     model :\n       name :  Authors\n       relationshipType :  Object\n   mappings :\n     -   source :\n         fieldPath :\n           -   fieldName :  author_id\n       target :\n         modelField :\n           -   fieldName :  id\n```\n\nThe resulting GraphQL schema will appear as:\n\n```\ntype   Authors   {\n   author_id :   Int !\n   first_name :   String !\n   last_name :   String !\n   articles :   [ Article ! ] !\n}\ntype   Articles   {\n   id :   Int !\n   author_id :   Int !\n   title :   String !\n   author :   Author\n}\n```\n\nLocal and Remote Relationships\n\nSyntactically, there are no differences between local (e.g., a relationship between two columns in the same datasource,\nor an existing foreign-key relationship) or remote (a relationship across two different data sources) relationships.\nHasura DDN will automatically detect the type of relationship and make the optimal query plan accordingly.\n\n### Relationship across subgraphs\u200b\n\nNow, imagine if the `Article` model is defined in a **different subgraph** called `subgraph_articles` and the `Author` type\nand the following array relationship are part of the `default` subgraph.\n\nWe will now need to specify the **target** subgraph in the `target` section of the relationship definition as `subgraph: subgraph_articles` as shown below:\n\n```\nkind :  Relationship\nversion :\ndefinition :\n   source :  author\n   name :  articles\n   target :\n     model :\n       name :  Articles\n       relationshipType :  Array\n       subgraph :  subgraph_articles\n   mappings :\n     -   source :\n         fieldPath :\n           -   fieldName :  id\n       target :\n         modelField :\n           -   fieldName :  author_id\n```\n\nNext, imagine you want to query the author from the `Article` model, which is specified in the `subgraph_articles` subgraph. You will need to specify where the `Authors` can be queried from by specifying the **subgraph** in the `target` section of the relationship.\n\nIn this case, by specifying the subgraph as `subgraph: default` as shown below:\n\n```\nkind :  Relationship\nversion :  v1\ndefinition :\n   source :  article\n   name :  author\n   target :\n     model :\n       name :  Authors\n       relationshipType :  Object\n       subgraph :  default\n   mapping :\n     -   source :\n         fieldPath :\n           -   fieldName :  author_id\n       target :\n         modelField :\n           -   fieldName :  id\n```\n\nCurrent limitations\n\n1. Only types to top-level model types relationships are supported.\n2. Simple top-level type field to top-level model field mapping are supported.\n\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#introduction)\n    - [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#metadata-structure)\n        - [ TargetConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#targetconfiguration)\n\n- [ TargetModel ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#targetmodel)\n\n- [ RelationshipType ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationshiptype)\n\n- [ RelationshipMapping ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationshipmapping)\n\n- [ RelationshipMappingSource ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationshipmappingsource)\n\n- [ RelationshipMappingTarget ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationshipmappingtarget)\n\n- [ FieldAccess ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#fieldaccess)\n\n- [ Metadata structure ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#metadata-structure)\n    - [ TargetConfiguration ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#targetconfiguration)\n- [ Example ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#example)\n    - [ Basic relationship ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#basic-relationship)\n\n- [ Relationship across subgraphs ](https://hasura.io/docs/3.0/data-domain-modeling/relationships/#targetmodel/#relationship-across-subgraphs)\n", "https://hasura.io/docs/3.0/ci-cd/projects/#delete": "# Projects\n\n## Introduction\u200b\n\nBroadly, a project is the configuration of your data supergraph.\n\nA project specifies build profiles, each of which specify supergraph and subgraph configurations that are used create[ builds ](https://hasura.io/docs/3.0/ci-cd/builds/)which are snapshots of the project config and are used to serve your API.\n\n## Initialize a Project\u200b\n\nWe can create a new project and link it to its twin on Hasura DDN by using the Hasura CLI to create a new project.\n\n### Login to Hasura DDN\u200b\n\nIn order to link local and Hasura DDN projects, you'll need to authenticate your CLI. This can be done two ways:\n\n- Via the browser (recommended)\n- Using a Personal Access Token (PAT)\n\n\n#### Browser\u200b\n\n`hasura3 login`\n\nThis will launch a browser window and prompt you to login to your Hasura DDN account. Once you've logged in, you can\nclose the browser window and return to your terminal.\n\n#### PAT\u200b\n\nAlternatively, you can use a PAT to authenticate with the CLI.\n\nYou can create a PAT by navigating to the[ Access Tokens page ](https://cloud.hasura.io/account-settings/access-tokens)in your account settings. Where you can create a new token and copy the value.\n\nBack in the Hasura CLI, run:\n\n`hasura3 login --pat  < PAT >`\n\nYou should see a confirmation that you're now successfully logged in, and can now create a new project and\nsimultaneously link it to its twin on Hasura DDN.\n\n### Create a new project\u200b\n\n`hasura3 init --dir  .`\n\nYou will be presented with the following options:\n\n```\nCreate a new project\nEmpty project\n```\n\nChoose `Create a new project` .\n\n### Configure a project\u200b\n\nThe previous command will create a project on Hasura DDN and local files in a directory structure which will be used to\nmanage your project.\n\nFor more information on the project configuration files, see the[ configuration section ](https://hasura.io/docs/3.0/ci-cd/config/).\n\nRunning CLI commands without specifying a project name each time\n\nBy logging into Hasura DDN via the CLI and specifying the project name in the hasura.yaml file, the CLI will know which\nproject to use when running commands in the directory.\n\n#### VS Code Extension\u200b\n\nThe[ Hasura VS Code extension ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura&ssr=false#review-details)is there to help you author and edit `hml` files in your subgraphs. It provides syntax highlighting, validation, and\nautocompletion.\n\nTo use the extension, ensure you've[ installed it ](https://marketplace.visualstudio.com/items?itemName=HasuraHQ.hasura)and then run the `login` command using the command palette. You can access this by pressing `Ctrl+Shift+P` on Windows\nand `Cmd+Shift+P` on Mac.\n\n#### Create builds\u200b\n\nIn order to see configurations in your metadata take effect you need to create a build. Head over to the[ Builds ](https://hasura.io/docs/3.0/ci-cd/builds/)section to learn about how to create and manage builds.\n\nAlternatively, during development, you can use[ watch mode ](https://hasura.io/docs/3.0/cli/commands/watch/)to automatically create builds when\nchanges are detected in your project.\n\n#### Describe a project\u200b\n\nYou can get the relevant information of your project by using the CLI and running:\n\n`hasura3 project describe`\n\nYou will see an output similar to the following:\n\n```\n+-------------+--------------------------------------------------------------+\n| Name        | master-shrimp-9462                                           |\n+-------------+--------------------------------------------------------------+\n| ID          | fa2f39db-247d-4820-83c4-96cec5e6bd38                         |\n+-------------+--------------------------------------------------------------+\n| Console URL | https://console.hasura.io/project/master-shrimp-9462/graphql |\n+-------------+--------------------------------------------------------------+\n| Build Count | 1                                                            |\n+-------------+--------------------------------------------------------------+\n| Domain      | master-shrimp-9462.ddn.hasura.app                            |\n+-------------+--------------------------------------------------------------+\n```\n\n#### List all projects\u200b\n\nYou can list all the projects you have access to by running:\n\n`hasura3 project list`\n\nYou will see an output similar to the following:\n\n```\n+-------------+-----------------------+--------------------------------------+-----------------------------------------------------------------+\n| CREATED AT  |         NAME          |                  ID                  |                           CONSOLE URL                           |\n+-------------+-----------------------+--------------------------------------+-----------------------------------------------------------------+\n| 27 Nov 2023 | master-shrimp-9462    | fa2f39db-247d-4820-83c4-96cec5e6bd38 | https://console.hasura.io/project/master-shrimp-9462/graphql    |\n+-------------+-----------------------+--------------------------------------+-----------------------------------------------------------------+\n```\n\n### Delete a project\u200b\n\nYou can delete a project using the CLI by running:\n\n`hasura3 project delete`\n\n### What did you think of this doc?\n\n- [ Introduction ](https://hasura.io/docs/3.0/ci-cd/projects/#delete/#introduction)\n- [ Initialize a Project ](https://hasura.io/docs/3.0/ci-cd/projects/#delete/#initialize-a-project)\n    - [ Login to Hasura DDN ](https://hasura.io/docs/3.0/ci-cd/projects/#delete/#login-to-hasura-ddn)\n\n- [ Create a new project ](https://hasura.io/docs/3.0/ci-cd/projects/#delete/#create-a-new-project)\n\n- [ Configure a project ](https://hasura.io/docs/3.0/ci-cd/projects/#delete/#configure-a-project)\n\n- [ Delete a project ](https://hasura.io/docs/3.0/ci-cd/projects/#delete/#delete-a-project)\n", "https://hasura.io/docs/3.0/cli/commands/build/": "# Hasura3 CLI: hasura3 build\n\n## Synopsis\u200b\n\nManage Hasura DDN Project Builds[alias: builds].\n\n```\n$ hasura3 build --help\nManage Hasura DDN Project Builds  [ alias: builds ]\nUsage:\n  hasura3 build  [ command ]\nAliases:\n  build, builds\nAvailable Commands:\n  apply       Apply a Build to a Hasura DDN Project\n  create      Create a build  in  a Hasura Cloud Project\n  delete      Delete a Build from a Hasura Cloud Project  [ aliases: rm, remove ]\n  describe    Describe a Build  [ aliases: info, details ]\n  list        List the builds of a Hasura Project  [ alias: ls ]\nFlags:\n  -h, --help    help   for  build\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\nUse  \"hasura3 build [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/build/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/build-apply/": "# Hasura3 CLI: hasura3 build apply\n\n## Synopsis\u200b\n\nApply a Build to a Hasura DDN Project.\n\n```\n$ hasura3 build apply --help\nApply a Build to a Hasura DDN Project\nUsage:\n  hasura3 build apply  [ flags ]\nExamples:\n  # Apply a build to your project\n   hasura3 build apply --project  < project-name >  --version  < build-version >\nFlags:\n  -h, --help              help   for  apply\n      --version string   Version of the build to apply  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/build-apply/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/build-create/": "# Hasura3 CLI: hasura3 build create\n\n## Synopsis\u200b\n\nCreate a build in a Hasura Cloud Project.\n\n```\n$ hasura3 build create --help\nCreate a build  in  a Hasura Cloud Project\nUsage:\n  hasura3 build create  [ flags ]\nExamples:\n  # Create a build with the default build profile (hasura.yaml present in current working directory)\n   hasura3 build create \n  # Create a build with an alternate build profile (hasura.yaml is not present in current working directory)\n   hasura3 build create --profile build-profile-staging.yaml --dir  < path-to-hasura.yaml-file >  --description  \"overridden build profile\"\n  # Create a Patch build by overriding the value present in the selected build profile (build-profile-preprod has build mode as patch)\n   hasura build create --profile build-profile-preprod.yaml --patch-on-build latest \n  # Create a build with metadata.json file (Mode: Replace)\n   hasura3 build create --mode replace --project  < project-name >  --metadata-from-file  < path-to-metadata.json-file >  --environment default --description  \"profiless build\"\nFlags:\n  -d, --description string           ( Optional )  description about the build\n      --dry-run                     Prints the metadata used to create the build. No build artifact is generated\n      --environment string          Environment to create the build in. To be used when building with metadata JSON only. When provided, --mode, --project and --metadata-from-file must also be provided\n  -h, --help                         help   for  create\n      --metadata-from-file string   Path to the metadata JSON file. To be used when building with metadata JSON only. When provided, --mode, --project and --environment must also be provided\n      --mode string                 Can be patch or replace. To be used when building with metadata JSON only. When provided, --metadata-from-file, --project and --environment must also be provided\n      --patch-on-build string       Override the patch on build value provided  in  the build profile, only valid  if  the mode is patch. Takes a build version, applied or latest as allowed values\n      --profile string              Build profile to use, uses the default build profile  if  not provided\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/build-create/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/build-delete/": "# Hasura3 CLI: hasura3 build delete\n\n## Synopsis\u200b\n\nDelete a Build from a Hasura Cloud Project[aliases: rm, remove].\n\n```\n$ hasura3 build delete --help\nDelete a Build from a Hasura Cloud Project  [ aliases: rm, remove ]\nUsage:\n  hasura3 build delete  [ flags ]\nAliases:\n  delete, remove,  rm\nExamples:\n  # Delete a build from your project\n   hasura3 build delete --project  < project-name >  --version  < build-version >\nFlags:\n  -h, --help              help   for  delete\n      --version string   Version of the build to delete  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/build-delete/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/build-describe/": "# Hasura3 CLI: hasura3 build describe\n\n## Synopsis\u200b\n\nDescribe a Build[aliases: info, details].\n\n```\n$ hasura3 build describe --help\nDescribe a Build  [ aliases: info, details ]\nUsage:\n  hasura3 build describe  [ flags ]\nAliases:\n  describe, info, details\nExamples:\n  # View details of a build in your project\n   hasura3 build describe --project  < project-name >  --version  < build-version >\nFlags:\n  -h, --help              help   for  describe\n      --version string   Version of the build to describe  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/build-describe/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/build-list/": "# Hasura3 CLI: hasura3 build list\n\n## Synopsis\u200b\n\nList the builds of a Hasura Project[alias: ls].\n\n```\n$ hasura3 build list --help\nList the builds of a Hasura Project  [ alias: ls ]\nUsage:\n  hasura3 build list  [ flags ]\nAliases:\n  list,  ls\nExamples:\n  # List all builds (across all environments) in your project\n   hasura3 build list --project  < project-name >\n \n  # List all builds in the default environment of your project\n   hasura3 build list --project  < project-name >  --environment default\nFlags:\n      --environment string    ( optionally )  list builds by an environment\n  -h, --help                  help   for  list\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/build-list/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/completion/": "# Hasura3 CLI: hasura3 completion\n\n## Synopsis\u200b\n\nGenerate the autocompletion script for hasura3 for the specified shell..\n\n```\n$ hasura3 completion --help\nGenerate the autocompletion script  for  hasura3  for  the specified shell.\nSee each sub-command's  help   for  details on how to use the generated script.\nUsage:\n  hasura3 completion  [ command ]\nAvailable Commands:\n   bash         Generate the autocompletion script  for   bash\n  fish        Generate the autocompletion script  for  fish\n  powershell  Generate the autocompletion script  for  powershell\n   zsh          Generate the autocompletion script  for   zsh\nFlags:\n  -h, --help    help   for  completion\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\nUse  \"hasura3 completion [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/completion/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/completion-bash/": "# Hasura3 CLI: hasura3 completion bash\n\n## Synopsis\u200b\n\nGenerate the autocompletion script for the bash shell..\n\n```\n$ hasura3 completion  bash  --help\nGenerate the autocompletion script  for  the  bash  shell.\nThis script depends on the  'bash-completion'  package.\nIf it is not installed already, you can  install  it via your OS's package manager.\nTo load completions  in  your current shell session:\n     source   < ( hasura3 completion  bash )\nTo load completions  for  every new session, execute once:\n#### Linux:\n    hasura3 completion  bash   >  /etc/bash_completion.d/hasura3\n#### macOS:\n    hasura3 completion  bash   >   $( brew --prefix ) /etc/bash_completion.d/hasura3\nYou will need to start a new shell  for  this setup to take effect.\nUsage:\n  hasura3 completion  bash\nFlags:\n  -h, --help               help   for   bash\n      --no-descriptions   disable completion descriptions\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/completion-bash/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/completion-fish/": "# Hasura3 CLI: hasura3 completion fish\n\n## Synopsis\u200b\n\nGenerate the autocompletion script for the fish shell..\n\n```\n$ hasura3 completion fish --help\nGenerate the autocompletion script  for  the fish shell.\nTo load completions  in  your current shell session:\n    hasura3 completion fish  |   source\nTo load completions  for  every new session, execute once:\n    hasura3 completion fish  >  ~/.config/fish/completions/hasura3.fish\nYou will need to start a new shell  for  this setup to take effect.\nUsage:\n  hasura3 completion fish  [ flags ]\nFlags:\n  -h, --help               help   for  fish\n      --no-descriptions   disable completion descriptions\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/completion-fish/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/completion-powershell/": "# Hasura3 CLI: hasura3 completion powershell\n\n## Synopsis\u200b\n\nGenerate the autocompletion script for powershell..\n\n```\n$ hasura3 completion powershell --help\nGenerate the autocompletion script  for  powershell.\nTo load completions  in  your current shell session:\n    hasura3 completion powershell  |  Out-String  |  Invoke-Expression\nTo load completions  for  every new session,  add  the output of the above  command\nto your powershell profile.\nUsage:\n  hasura3 completion powershell  [ flags ]\nFlags:\n  -h, --help               help   for  powershell\n      --no-descriptions   disable completion descriptions\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/completion-powershell/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/completion-zsh/": "# Hasura3 CLI: hasura3 completion zsh\n\n## Synopsis\u200b\n\nGenerate the autocompletion script for the zsh shell..\n\n```\n$ hasura3 completion  zsh  --help\nGenerate the autocompletion script  for  the  zsh  shell.\nIf shell completion is not already enabled  in  your environment you will need\nto  enable  it.  You can execute the following once:\n     echo   \"autoload -U compinit; compinit\"   >>  ~/.zshrc\nTo load completions  in  your current shell session:\n     source   < ( hasura3 completion  zsh )\nTo load completions  for  every new session, execute once:\n#### Linux:\n    hasura3 completion  zsh   >   \" ${fpath [ 1 ] } /_hasura3\"\n#### macOS:\n    hasura3 completion  zsh   >   $( brew --prefix ) /share/zsh/site-functions/_hasura3\nYou will need to start a new shell  for  this setup to take effect.\nUsage:\n  hasura3 completion  zsh   [ flags ]\nFlags:\n  -h, --help               help   for   zsh\n      --no-descriptions   disable completion descriptions\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/completion-zsh/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/daemon/": "# Hasura3 CLI: hasura3 daemon\n\n## Synopsis\u200b\n\nManage Hasura Secure Connect Tunnel Daemon.\n\n```\n$ hasura3 daemon --help\nManage Hasura Secure Connect Tunnel Daemon\nUsage:\n  hasura3 daemon  [ command ]\nAvailable Commands:\n  start       Start Hasura Secure Connect Daemon\nFlags:\n  -h, --help    help   for  daemon\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\nUse  \"hasura3 daemon [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/daemon/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/daemon-start/": "# Hasura3 CLI: hasura3 daemon start\n\n## Synopsis\u200b\n\nStart Hasura Secure Connect Daemon.\n\n```\n$ hasura3 daemon start --help\nStart Hasura Secure Connect Daemon\nUsage:\n  hasura3 daemon start  [ flags ]\nExamples:\n  # Start the tunnel daemon on port 4321\n   hasura3 daemon start --port  4321\nFlags:\n  -h, --help        help   for  start\n      --port int   The TCP Port on  which  the Secure Connect Tunnel Daemon will run\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/daemon-start/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/environment/": "# Hasura3 CLI: hasura3 environment\n\n## Synopsis\u200b\n\nEnvironments in Hasura Projects[aliases: env, environments].\n\n```\n$ hasura3 environment --help\nEnvironments  in  Hasura Projects  [ aliases: env, environments ]\nUsage:\n  hasura3 environment  [ command ]\nAliases:\n  environment, env, environments\nAvailable Commands:\n  create      Create an environment  in  a Hasura Project\n  delete      Delete an environment from a Hasura Cloud Project  [ aliases: rm, remove ]\n  describe    View environment details  [ aliases: details, info ]\n  list        List all environment of a Hasura Project  [ alias: ls ]\nFlags:\n  -h, --help              help   for  environment\n  -p, --project string   Hasura DDN Project Name\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\nUse  \"hasura3 environment [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/environment/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/environment-create/": "# Hasura3 CLI: hasura3 environment create\n\n## Synopsis\u200b\n\nCreate an environment in a Hasura Project.\n\n```\n$ hasura3 environment create --help\nCreate an environment  in  a Hasura Project\nUsage:\n  hasura3 environment create  [ flags ]\nExamples:\n  # Create an environment \"staging\" in a project\n   hasura3 environment create --name staging --project  < project-name >\nFlags:\n  -d, --description string   Environment description\n  -h, --help                  help   for  create\n  -n, --name string          Environment name  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/environment-create/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/environment-delete/": "# Hasura3 CLI: hasura3 environment delete\n\n## Synopsis\u200b\n\nDelete an environment from a Hasura Cloud Project[aliases: rm, remove].\n\n```\n$ hasura3 environment delete --help\nDelete an environment from a Hasura Cloud Project  [ aliases: rm, remove ]\nUsage:\n  hasura3 environment delete  [ flags ]\nAliases:\n  delete, rm, remove\nExamples:\n  # Delete the environment \"staging\"\n   hasura3 environment delete --project  < project-name >  --name staging\nFlags:\n  -h, --help           help   for  delete\n  -n, --name string   Name of the environment  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/environment-delete/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/environment-describe/": "# Hasura3 CLI: hasura3 environment describe\n\n## Synopsis\u200b\n\nView environment details[aliases: details, info].\n\n```\n$ hasura3 environment describe --help\nView environment details  [ aliases: details, info ]\nUsage:\n  hasura3 environment describe  [ flags ]\nAliases:\n  describe, details, info\nExamples:\n  # View details of a \"staging\" environment\n   hasura3 environment describe --project  < project-name >  --name staging\nFlags:\n  -h, --help           help   for  describe\n  -n, --name string   Environment name  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/environment-describe/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/environment-list/": "# Hasura3 CLI: hasura3 environment list\n\n## Synopsis\u200b\n\nList all environment of a Hasura Project[alias: ls].\n\n```\n$ hasura3 environment list --help\nList all environment of a Hasura Project  [ alias: ls ]\nUsage:\n  hasura3 environment list  [ flags ]\nAliases:\n  list,  ls\nExamples:\n  # List all your environments in a project\n   hasura3 environment list --project  < project-name >\nFlags:\n  -h, --help    help   for  list\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/environment-list/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/help/": "# Hasura3 CLI: hasura3 help\n\n## Synopsis\u200b\n\nHelp provides help for any command in the CLI.\n\n```\n$ hasura3  help  --help\nHelp provides  help   for  any  command   in  the CLI\nUsage:\n  hasura3  help   [ flags ]\nFlags:\n  -h, --help    help   for   help\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/help/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/init/": "# Hasura3 CLI: hasura3 init\n\n## Synopsis\u200b\n\nInit Hasura DDN project.\n\n```\n$ hasura3 init --help\nInit Hasura DDN project\nUsage:\n  hasura3 init  [ flags ]\nExamples:\n  # Init Hasura from a list of options to a directory\n   hasura3 init --dir ~/Desktop/hasura/\nFlags:\n  -d, --dir string   Directory where the v3 project should be created or cloned  ( required )\n  -h, --help          help   for  init\nGlobal Flags:\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/init/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/login/": "# Hasura3 CLI: hasura3 login\n\n## Synopsis\u200b\n\nLogin to Hasura Cloud.\n\n```\n$ hasura3 login --help\nLogin to Hasura Cloud\nUsage:\n  hasura3 login  [ flags ]\nExamples:\n  # Login with browser\n hasura3 login\n  # Login with Personal Access token\n hasura3 login --pat  < your-personal-access-token >\nFlags:\n  -h, --help          help   for  login\n      --pat string   Personal Access token  [ env: HASURA_DDN_PAT ]\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/login/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/logout/": "# Hasura3 CLI: hasura3 logout\n\n## Synopsis\u200b\n\nLogout from Hasura Cloud.\n\n```\n$ hasura3  logout  --help\nLogout from Hasura Cloud\nUsage:\n  hasura3  logout   [ flags ]\nFlags:\n  -h, --help    help   for   logout\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/logout/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/metadata/": "# Hasura3 CLI: hasura3 metadata\n\n## Synopsis\u200b\n\nManage Hasura DDN Projects' Metadata.\n\n```\n$ hasura3 metadata --help\nManage Hasura DDN Projects' Metadata\nUsage:\n  hasura3 metadata  [ command ]\nAvailable Commands:\n  add-hub-connector Adds the data connector and creates the required metadata files.\nFlags:\n  -h, --help    help   for  metadata\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\nUse  \"hasura3 metadata [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/metadata/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/metadata-add-hub-connector/": "# Hasura3 CLI: hasura3 metadata add-hub-connector\n\n## Synopsis\u200b\n\nAdds the data connector and creates the required metadata files..\n\n```\n$ hasura3 metadata add-hub-connector --help\nAdds the data connector and creates the required metadata files.\nUsage:\n  hasura3 metadata add-hub-connector  [ source-name ]   [ flags ]\nAliases:\n  add-hub-connector, ahc\nExamples:\n# Add a Postgres Datasource\nhasura3 metadata add-hub-connector  < source_name >  --id hasura/postgres --url = < pg_uri >  --subgraph  < subgraph_name >  --dir  < path to hasura.yaml >\n# Add a TypeScript Connector\nhasura3 metadata add-hub-connector bizlogic --id hasura/ts-deno --url = http://localhost:8100 --subgraph default --dir  < path to hasura.yaml >\nFlags:\n  -d, --dir string        Directory where the v3 project exists\n  -h, --help               help   for  add-hub-connector\n      --id string         Hasura Connector Hub ID of the data connector to use\n      --profile string    Build profile to use, uses the default build profile  if  not provided\n      --subgraph string   Name of the subgraph on  which  the connector needs to be added  ( default  \"default\" )\n      --url string        Endpoint on  which  the data connector can be reached\nGlobal Flags:\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/metadata-add-hub-connector/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/plugins/": "# Hasura3 CLI: hasura3 plugins\n\n## Synopsis\u200b\n\nThe functionality of the CLI can be extended by using plugins. For a list of all available plugins, run `hasura3 plugins list` , or visit this repository:[ https://github.com/hasura/cli-plugins-index ](https://github.com/hasura/cli-plugins-index)..\n\n```\n$ hasura3 plugins --help\nThe functionality of the CLI can be extended by using plugins. For a list of all available plugins, run ` ` hasura3 plugins list ` `, or visit this repository: https://github.com/hasura/cli-plugins-index.\nIf you're interested  in  contributing, please  open  a PR against this repo to  add  new plugin.\nUsage:\n  hasura3 plugins  [ command ]\nAliases:\n  plugins, plugin\nAvailable Commands:\n   install      Install a plugin from the index\n  list        List all available plugins from index, versions and installation status\n  uninstall   Uninstall a plugin\n  upgrade     Upgrade a plugin to a newer version\nFlags:\n  -h, --help    help   for  plugins\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\nUse  \"hasura3 plugins [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/plugins/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/plugins-install/": "# Hasura3 CLI: hasura3 plugins install\n\n## Synopsis\u200b\n\nTo install plugins that extend the functionality of the Hasura CLI, you can use the install command. This command will install the plugin from the index and add it to your configuration file..\n\n```\n$ hasura3 plugins  install  --help\nTo  install  plugins that extend the functionality of the Hasura CLI, you can use the  install  command. This  command  will  install  the plugin from the index and  add  it to your configuration file.\nUsage:\n  hasura3 plugins  install   [ plugin-name ]   [ flags ]\nAliases:\n  install,  add\nExamples:\n   # Install a plugin:\n  hasura3 plugins  install   [ plugin-name ]\nFlags:\n  -h, --help              help   for   install\n      --version string   version to be installed\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/plugins-install/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/plugins-list/": "# Hasura3 CLI: hasura3 plugins list\n\n## Synopsis\u200b\n\nTo see a list of all the available plugins which extend the functionality of the CLI, their versions and installation status, run the list command..\n\n```\n$ hasura3 plugins list --help\nTo see a list of all the available plugins  which  extend the functionality of the CLI, their versions and installation status, run the list command.\nUsage:\n  hasura3 plugins list  [ flags ]\nAliases:\n  list,  ls\nExamples:\n   # List all plugins\n  hasura3 plugins list\n   # The command also updates the plugin index that is cached locally\n   # To avoid updating the index, use the following flag:\n  hasura3 plugins list --dont-update-index\nFlags:\n      --dont-update-index   don't update the plugin index  local  cache, only show the list\n  -h, --help                 help   for  list\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/plugins-list/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/plugins-uninstall/": "# Hasura3 CLI: hasura3 plugins uninstall\n\n## Synopsis\u200b\n\nTo uninstall a plugin, run the uninstall command with the name of the plugin as an argument. If unsure of the plugin's name, you can run the `Hasura plugins list` command to see a list of all the available plugins..\n\n```\n$ hasura3 plugins uninstall --help\nTo uninstall a plugin, run the uninstall  command  with the name of the plugin as an argument. If unsure of the plugin's name, you can run the  ` Hasura plugins list `   command  to see a list of all the available plugins.\nUsage:\n  hasura3 plugins uninstall  [ plugin-name ]   [ flags ]\nAliases:\n  uninstall, remove\nExamples:\n   # Uninstall a plugin\n  hasura3 plugins uninstall  [ plugin-name ]\nFlags:\n  -h, --help    help   for  uninstall\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/plugins-uninstall/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/plugins-upgrade/": "# Hasura3 CLI: hasura3 plugins upgrade\n\n## Synopsis\u200b\n\nTo upgrade a plugin, run the upgrade command with the name of the plugin as an argument. If unsure of the plugin's name, you can run the `hasura3 plugins list` command to see a list of all the available plugins..\n\n```\n$ hasura3 plugins upgrade --help\nTo upgrade a plugin, run the upgrade  command  with the name of the plugin as an argument. If unsure of the plugin's name, you can run the  ` hasura3 plugins list `   command  to see a list of all the available plugins.\nUsage:\n  hasura3 plugins upgrade  [ flags ]\nAliases:\n  upgrade, update\nExamples:\n   # Upgrade a plugin to a newer version\n  hasura3 plugins upgrade  [ plugin-name ]\nFlags:\n  -h, --help              help   for  upgrade\n      --version string   version to be upgraded\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/plugins-upgrade/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/project/": "# Hasura3 CLI: hasura3 project\n\n## Synopsis\u200b\n\nManage Hasura DDN Projects.\n\n```\n$ hasura3 project --help\nManage Hasura DDN Projects\nUsage:\n  hasura3 project  [ command ]\nAliases:\n  project, projects\nAvailable Commands:\n  create      Create a new project  in  Hasura Cloud\n  delete      Delete a project from Hasura Cloud  [ aliases: remove, rm ]\n  describe    View project details  [ aliases: details, info ]\n  list        View a list of your projects on Hasura Cloud  [ alias: ls ]\nFlags:\n  -h, --help    help   for  project\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\nUse  \"hasura3 project [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/project/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/project-create/": "# Hasura3 CLI: hasura3 project create\n\n## Synopsis\u200b\n\nCreate a new project in Hasura Cloud.\n\n```\n$ hasura3 project create --help\nCreate a new project  in  Hasura Cloud\nUsage:\n  hasura3 project create  [ flags ]\nExamples:\n  # Create a project\n   hasura3 project create\nFlags:\n  -h, --help    help   for  create\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/project-create/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/project-delete/": "# Hasura3 CLI: hasura3 project delete\n\n## Synopsis\u200b\n\nDelete a project from Hasura Cloud[aliases: remove, rm].\n\n```\n$ hasura3 project delete --help\nDelete a project from Hasura Cloud  [ aliases: remove, rm ]\nUsage:\n  hasura3 project delete  [ flags ]\nAliases:\n  delete, remove,  rm\nExamples:\n  # Delete a project\n   hasura3 project delete --project  < project-name >\nFlags:\n  -h, --help    help   for  delete\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/project-delete/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/project-describe/": "# Hasura3 CLI: hasura3 project describe\n\n## Synopsis\u200b\n\nView project details[aliases: details, info].\n\n```\n$ hasura3 project describe --help\nView project details  [ aliases: details, info ]\nUsage:\n  hasura3 project describe  [ flags ]\nAliases:\n  describe, details, info\nExamples:\n  # View details of a project\n   hasura3 project describe --project  < project-name >\nFlags:\n  -h, --help    help   for  describe\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/project-describe/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/project-list/": "# Hasura3 CLI: hasura3 project list\n\n## Synopsis\u200b\n\nView a list of your projects on Hasura Cloud[alias: ls].\n\n```\n$ hasura3 project list --help\nView a list of your projects on Hasura Cloud  [ alias: ls ]\nUsage:\n  hasura3 project list  [ flags ]\nAliases:\n  list,  ls\nExamples:\n  # List all your projects\n   hasura3 project list\nFlags:\n  -h, --help    help   for  list\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/project-list/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/secret/": "# Hasura3 CLI: hasura3 secret\n\n## Synopsis\u200b\n\nCommands related to Hasura Cloud Secret Ops.\n\n```\n$ hasura3 secret --help\nCommands related to Hasura Cloud Secret Ops\nUsage:\n  hasura3 secret  [ command ]\nAliases:\n  secret, secrets\nAvailable Commands:\n  delete      Delete/Remove a secret  [ aliases: rm, remove ]\n  get         Get the value of a secret key\n  list        List all secrets  [ aliases: ls ]\n   set          Create/Update a secret\nFlags:\n  -h, --help              help   for  secret\n  -p, --project string   Hasura DDN Project Name\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\nUse  \"hasura3 secret [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/secret/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/secret-delete/": "# Hasura3 CLI: hasura3 secret delete\n\n## Synopsis\u200b\n\nDelete/Remove a secret[aliases: rm, remove].\n\n```\n$ hasura3 secret delete --help\nDelete/Remove a secret  [ aliases: rm, remove ]\nUsage:\n  hasura3 secret delete  [ flags ]\nAliases:\n  delete, rm, remove\nExamples:\n  # Remove the Secret MY_KEY\n   hasura3 secret delete --project  < project-name >  --environment default --subgraph default --key MY_KEY\nFlags:\n  -e, --environment string   Environment where the secret can be referenced  ( required )\n  -h, --help                  help   for  delete\n  -k, --key string           SetSecret key  ( required )\n  -n, --subgraph string      Subgraph where the secret can be referenced  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/secret-delete/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/secret-get/": "# Hasura3 CLI: hasura3 secret get\n\n## Synopsis\u200b\n\nGet the value of a secret key.\n\n```\n$ hasura3 secret get --help\nGet the value of a secret key\nUsage:\n  hasura3 secret get  [ flags ]\nExamples:\n  # Get the value of secret MY_KEY\n   hasura3 secret get --project  < project-name >  --key MY_KEY\n  # Get the value of secret MY_KEY in default environment (across all subgraphs) of a project\n   hasura3 secret get --project  < project-name >  --key MY_KEY --environment default\n  # Get the value of secret MY_KEY in default subgraph (across all environments) of a project\n   hasura3 secret get --project  < project-name >  --subgraph default -key MY_KEY\n  # Get the value of secret MY_KEY in default environment in default subgraph\n   hasura3 secret get --project  < project-name >  --subgraph default --environment default -key MY_KEY\nFlags:\n  -e, --environment string   Environment of secret\n  -h, --help                  help   for  get\n  -k, --key string           SetSecret key  ( required )\n  -n, --subgraph string      Subgraph of secret\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/secret-get/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/secret-list/": "# Hasura3 CLI: hasura3 secret list\n\n## Synopsis\u200b\n\nList all secrets[aliases: ls].\n\n```\n$ hasura3 secret list --help\nList all secrets  [ aliases: ls ]\nUsage:\n  hasura3 secret list  [ flags ]\nAliases:\n  list,  ls\nExamples:\n  # List all secrets in a project\n   hasura3 secret list --project  < project-name >  \n  # List all secrets in default environment (across all subgraph) of a project\n   hasura3 secret list --project  < project-name >  --environment default\n  # List all secrets in default subgraph (across all environments) of a project\n   hasura3 secret list --project  < project-name >  --subgraph default\n  # List all secrets in default environment in default subgraph\n   hasura3 secret list --project  < project-name >  --subgraph default --environment default\nFlags:\n  -e, --environment string   Environment of secret\n  -h, --help                  help   for  list\n  -n, --subgraph string      Subgraph of secret\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/secret-list/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/secret-set/": "# Hasura3 CLI: hasura3 secret set\n\n## Synopsis\u200b\n\nCreate/Update a secret.\n\n```\n$ hasura3 secret  set  --help\nCreate/Update a secret\nUsage:\n  hasura3 secret  set   [ flags ]\nExamples:\n  # Create a Secret MY_KEY=myValue\n   hasura3 secret  set  --project  < project-name >  --environment default --subgraph default --key MY_KEY --value myValue --description  \"test secret\"\nFlags:\n  -d, --description string   Description  for  the secret\n  -e, --environment string   Environment where the secret can be referenced  ( required )\n  -h, --help                  help   for   set\n  -k, --key string           SetSecret key  ( required )\n  -n, --subgraph string      Supergraph or Subgraph where the secret can be referenced\n  -v, --value string         Value of the secret  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/secret-set/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/subgraph/": "# Hasura3 CLI: hasura3 subgraph\n\n## Synopsis\u200b\n\nManage Hasura project subgraphs.\n\n```\n$ hasura3 subgraph --help\nManage Hasura project subgraphs\nUsage:\n  hasura3 subgraph  [ command ]\nAvailable Commands:\n  create      Create a subgraph\n  delete      Remove a subgraph from Hasura Cloud Project  [ aliases: remove, rm ]\n  describe    View subgraph details  [ aliases: details, info ]\n  list        List all subgraphs  in  a Hasura project  [ alias: ls ]\nFlags:\n  -h, --help              help   for  subgraph\n  -p, --project string   Hasura DDN Project Name\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\nUse  \"hasura3 subgraph [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/subgraph/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/subgraph-create/": "# Hasura3 CLI: hasura3 subgraph create\n\n## Synopsis\u200b\n\nCreate a subgraph.\n\n```\n$ hasura3 subgraph create --help\nCreate a subgraph\nUsage:\n  hasura3 subgraph create  [ flags ]\nExamples:\n  # Create a subgraph \"accounting\" in a project\n   hasura3 subgraph create --name accounting --project  < project-name >\nFlags:\n  -h, --help           help   for  create\n  -n, --name string   Subgraph name  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/subgraph-create/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/subgraph-delete/": "# Hasura3 CLI: hasura3 subgraph delete\n\n## Synopsis\u200b\n\nRemove a subgraph from Hasura Cloud Project[aliases: remove, rm].\n\n```\n$ hasura3 subgraph delete --help\nRemove a subgraph from Hasura Cloud Project  [ aliases: remove, rm ]\nUsage:\n  hasura3 subgraph delete  [ flags ]\nAliases:\n  delete, rm, remove\nExamples:\n  # Delete the subgraph \"accounting\"\n   hasura3 subgraph delete --project  < project-name >  --name accounting\nFlags:\n  -h, --help           help   for  delete\n  -n, --name string   Subgraph to be deleted  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/subgraph-delete/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/subgraph-describe/": "# Hasura3 CLI: hasura3 subgraph describe\n\n## Synopsis\u200b\n\nView subgraph details[aliases: details, info].\n\n```\n$ hasura3 subgraph describe --help\nView subgraph details  [ aliases: details, info ]\nUsage:\n  hasura3 subgraph describe  [ flags ]\nAliases:\n  describe, details, info\nExamples:\n  # View details of a \"accounting\" subgraph\n   hasura3 subgraph describe --project  < project-name >  --name accounting\nFlags:\n  -h, --help           help   for  describe\n  -n, --name string   Subgraph name  ( required )\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/subgraph-describe/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/subgraph-list/": "# Hasura3 CLI: hasura3 subgraph list\n\n## Synopsis\u200b\n\nList all subgraphs in a Hasura project[alias: ls].\n\n```\n$ hasura3 subgraph list --help\nList all subgraphs  in  a Hasura project  [ alias: ls ]\nUsage:\n  hasura3 subgraph list  [ flags ]\nAliases:\n  list,  ls\nExamples:\n  # List all your subgraphs in a project\n   hasura3 subgraph list --project  < project-name >\nFlags:\n  -h, --help    help   for  list\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/subgraph-list/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/tunnel/": "# Hasura3 CLI: hasura3 tunnel\n\n## Synopsis\u200b\n\nHasura Secure Connect service.\n\n```\n$ hasura3 tunnel --help\nHasura Secure Connect  service\nUsage:\n  hasura3 tunnel  [ command ]\nAliases:\n  tunnel, tunnels\nAvailable Commands:\n  activate    Restart a paused tunnel\n  create      Create a new tunnel\n  delete      Delete/remove a tunnel  [ aliases: rm, remove ]\n  list        List Tunnels  [ aliases: ls ]\n  pause       Pause an active tunnel\nFlags:\n  -h, --help    help   for  tunnel\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\nUse  \"hasura3 tunnel [command] --help\"   for   more  information about a command.\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/tunnel/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/tunnel-activate/": "# Hasura3 CLI: hasura3 tunnel activate\n\n## Synopsis\u200b\n\nRestart a paused tunnel.\n\n```\n$ hasura3 tunnel activate --help\nRestart a paused tunnel\nUsage:\n  hasura3 tunnel activate  [ socket ]   [ flags ]\nExamples:\n  # Restart a paused tunnel that is using the daemon running on localhost:1432\n   hasura3 tunnel activate localhost:1432\nFlags:\n  -h, --help    help   for  activate\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/tunnel-activate/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/tunnel-create/": "# Hasura3 CLI: hasura3 tunnel create\n\n## Synopsis\u200b\n\nCreate a new tunnel.\n\n```\n$ hasura3 tunnel create --help\nCreate a new tunnel\nUsage:\n  hasura3 tunnel create  [ socket ]   [ flags ]\nExamples:\n  # Create a tunnel that is using the daemon running on localhost:1432\n   hasura3 tunnel create localhost:1432\nFlags:\n  -h, --help    help   for  create\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/tunnel-create/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/tunnel-delete/": "# Hasura3 CLI: hasura3 tunnel delete\n\n## Synopsis\u200b\n\nDelete/remove a tunnel[aliases: rm, remove].\n\n```\n$ hasura3 tunnel delete --help\nDelete/remove a tunnel  [ aliases: rm, remove ]\nUsage:\n  hasura3 tunnel delete  [ socket ]   [ flags ]\nAliases:\n  delete, rm, remove\nExamples:\n  # Delete the tunnel that is using the daemon running on localhost:1432\n   hasura3 tunnel delete localhost:1432\nFlags:\n  -h, --help    help   for  delete\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/tunnel-delete/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/tunnel-list/": "# Hasura3 CLI: hasura3 tunnel list\n\n## Synopsis\u200b\n\nList Tunnels[aliases: ls].\n\n```\n$ hasura3 tunnel list --help\nList Tunnels  [ aliases: ls ]\nUsage:\n  hasura3 tunnel list  [ flags ]\nAliases:\n  list,  ls\nExamples:\n  # List the created tunnels\n   hasura3 tunnel list\nFlags:\n  -h, --help    help   for  list\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/tunnel-list/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/tunnel-pause/": "# Hasura3 CLI: hasura3 tunnel pause\n\n## Synopsis\u200b\n\nPause an active tunnel.\n\n```\n$ hasura3 tunnel pause --help\nPause an active tunnel\nUsage:\n  hasura3 tunnel pause  [ socket ]   [ flags ]\nExamples:\n  # Pause the tunnel that is using the daemon running on localhost:1432\n   hasura3 tunnel pause localhost:1432\nFlags:\n  -h, --help    help   for  pause\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/tunnel-pause/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/update-cli/": "# Hasura3 CLI: hasura3 update-cli\n\n## Synopsis\u200b\n\nYou can use this command to update the CLI to the latest version or a specific version. Each time you run a CLI command, if a new version is available, you will be prompted to update the CLI..\n\n```\n$ hasura3 update-cli --help\nYou can use this  command  to update the CLI to the latest version or a specific version. Each  time  you run a CLI command,  if  a new version is available, you will be prompted to update the CLI.\nUsage:\n  hasura3 update-cli  [ flags ]\nExamples:\n   # Update CLI to latest version:\n  hasura3 update-cli\n   # To disable auto-update check on the CLI, set\n   # \"show_update_notification\": false\n   # in ~/.hasura3/config.yaml\n   # Update CLI to a specific version (say 2023.11.20):\n  hasura3 update-cli --version  2023.11 .20\nFlags:\n  -h, --help              help   for  update-cli\n      --version string   a specific version to  install\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/update-cli/#synopsis)\n", "https://hasura.io/docs/3.0/cli/commands/version/": "# Hasura3 CLI: hasura3 version\n\n## Synopsis\u200b\n\nIf unsure which version of the CLI you are using, you can use this command to print the version of the CLI. This command can also be used to check if a new version of the CLI is available..\n\n```\n$ hasura3 version --help\nIf unsure  which  version of the CLI you are using, you can use this  command  to print the version of the CLI. This  command  can also be used to check  if  a new version of the CLI is available.\nUsage:\n  hasura3 version  [ flags ]\nFlags:\n  -h, --help    help   for  version\nGlobal Flags:\n      --dir string         Hasura project directory  in   which  hasura.yaml is present  ( default  \".\" )\n      --log-level string   Log level. accepts DEBUG, WARN, INFO, ERROR, FATAL  ( default  \"INFO\" )\n      --no-prompt           set  this flag to no prompt  for  anything, the  command  fails  if  any input is missing\n  -o, --out string          format   in   which  the output should be printed, accepts table, json and yaml  ( default  \"table\" )\n  -p, --project string     Hasura DDN Project Name\n```\n\n### What did you think of this doc?\n\n- [ Synopsis ](https://hasura.io/docs/3.0/cli/commands/version/#synopsis)\n"}